From e35ad06af622e59485f43465a4c99436962cf989 Mon Sep 17 00:00:00 2001
From: YH Lin <yueherngl@google.com>
Date: Thu, 9 May 2019 11:20:14 -0700
Subject: [PATCH 3/7] Squash Kukui ISP ToT #139 against MTK ToT #151.

Change-Id: I53a528641be3f4dd1eb8770322331dc2b4960d34
---
 .../bindings/media/mediatek,cam_smem.txt      |   32 +
 .../bindings/media/mediatek,camisp.txt        |   59 +
 .../bindings/media/mediatek-dip.txt           |   32 +
 .../devicetree/bindings/media/mediatek-fd.txt |   30 +
 .../bindings/media/mediatek-isp.txt           |   73 +
 .../bindings/media/mediatek-seninf.txt        |   54 +
 .../memory-controllers/mediatek,emi.txt       |   19 +
 .../bindings/remoteproc/mtk,scp.txt           |   36 +
 .../mediatek,reserve-memory-cam_smem.txt      |   44 +
 README                                        |    5 +-
 .../boot/dts/mediatek/mt8183-kukui-rev2.dts   |  444 ++
 .../arm64/boot/dts/mediatek/mt8183-kukui.dtsi |  119 +-
 arch/arm64/boot/dts/mediatek/mt8183.dtsi      |  352 +-
 arch/arm64/mm/dma-mapping.c                   |    5 +-
 .../arm64/chromiumos-arm64.flavour.config     |   69 +-
 .../arm64/chromiumos-mediatek.flavour.config  |   66 +-
 .../arm64/chromiumos-qualcomm.flavour.config  |    5 +
 .../chromiumos-rockchip64.flavour.config      |    5 +
 chromeos/config/arm64/common.config           |    2 +-
 chromeos/config/armel/common.config           |    8 +-
 chromeos/config/base.config                   |    5 -
 chromeos/config/x86_64/common.config          |    5 +
 drivers/clk/mediatek/clkchk-mt8183.c          |  409 +
 drivers/clk/mediatek/clkchk.c                 |  188 +
 drivers/clk/mediatek/clkchk.h                 |   18 +
 drivers/clk/mediatek/clkdbg-mt8183.c          |  857 +++
 drivers/clk/mediatek/clkdbg.c                 | 2242 ++++++
 drivers/clk/mediatek/clkdbg.h                 |   83 +
 drivers/gpu/drm/mediatek/mtk_mipi_tx.h        |   52 +
 drivers/gpu/drm/mediatek/mtk_mt8173_mipi_tx.c |  283 +
 drivers/gpu/drm/mediatek/mtk_mt8183_mipi_tx.c |  154 +
 drivers/mailbox/mtk-cmdq-debug.c              |  582 ++
 drivers/mailbox/mtk-cmdq-debug.h              |   21 +
 .../media/common/videobuf2/videobuf2-core.c   |    8 +
 .../common/videobuf2/videobuf2-dma-contig.c   |   58 +-
 .../media/common/videobuf2/videobuf2-v4l2.c   |    1 +
 drivers/media/i2c/Kconfig                     |   26 +
 drivers/media/i2c/ov2685.c                    |  145 +-
 drivers/media/i2c/ov5695.c                    |   39 +-
 drivers/media/media-device.c                  |   11 +-
 drivers/media/platform/Kconfig                |   20 +
 drivers/media/platform/Makefile               |    3 +
 drivers/media/platform/mtk-isp/Kconfig        |  109 +
 drivers/media/platform/mtk-isp/Makefile       |   16 +
 .../media/platform/mtk-isp/common/Makefile    |   32 +
 .../platform/mtk-isp/common/mtk_isp-ctrl.c    |  318 +
 .../platform/mtk-isp/common/mtk_isp-ctrl.h    |   42 +
 .../platform/mtk-isp/common/mtk_isp-ctx.h     |  341 +
 .../mtk-isp/common/mtk_isp-dev-ctx-core.c     | 1045 +++
 .../platform/mtk-isp/common/mtk_isp-dev.c     |  372 +
 .../platform/mtk-isp/common/mtk_isp-dev.h     |  194 +
 .../mtk-isp/common/mtk_isp-smem-drv.c         |  805 ++
 .../platform/mtk-isp/common/mtk_isp-smem.h    |   24 +
 .../platform/mtk-isp/common/mtk_isp-v4l2.c    | 1632 ++++
 .../platform/mtk-isp/common/mtk_isp-v4l2.h    |   49 +
 drivers/media/platform/mtk-isp/fd/Makefile    |   38 +
 .../media/platform/mtk-isp/fd/mtk_fd-core.h   |  157 +
 .../media/platform/mtk-isp/fd/mtk_fd-ctx.h    |  299 +
 .../platform/mtk-isp/fd/mtk_fd-dev-ctx-core.c |  912 +++
 .../media/platform/mtk-isp/fd/mtk_fd-dev.c    |  355 +
 .../media/platform/mtk-isp/fd/mtk_fd-dev.h    |  198 +
 .../platform/mtk-isp/fd/mtk_fd-smem-drv.c     |  452 ++
 .../media/platform/mtk-isp/fd/mtk_fd-smem.h   |   25 +
 .../platform/mtk-isp/fd/mtk_fd-v4l2-util.c    | 1046 +++
 .../media/platform/mtk-isp/fd/mtk_fd-v4l2.c   |  114 +
 .../media/platform/mtk-isp/fd/mtk_fd-v4l2.h   |   36 +
 drivers/media/platform/mtk-isp/fd/mtk_fd.c    |  754 ++
 drivers/media/platform/mtk-isp/fd/mtk_fd.h    |  127 +
 .../media/platform/mtk-isp/isp_50/Makefile    |   26 +
 .../platform/mtk-isp/isp_50/cam/Makefile      |   19 +
 .../mtk-isp/isp_50/cam/mtk_cam-ctrl.c         |  133 +
 .../mtk-isp/isp_50/cam/mtk_cam-ctrl.h         |   32 +
 .../platform/mtk-isp/isp_50/cam/mtk_cam-ctx.h |  116 +
 .../mtk-isp/isp_50/cam/mtk_cam-dev-ctx-core.c |  302 +
 .../platform/mtk-isp/isp_50/cam/mtk_cam-dev.c |  525 ++
 .../platform/mtk-isp/isp_50/cam/mtk_cam-dev.h |  166 +
 .../mtk-isp/isp_50/cam/mtk_cam-regs.h         |  147 +
 .../platform/mtk-isp/isp_50/cam/mtk_cam-scp.c |  488 ++
 .../platform/mtk-isp/isp_50/cam/mtk_cam-scp.h |  215 +
 .../mtk-isp/isp_50/cam/mtk_cam-smem-drv.c     |  398 +
 .../mtk-isp/isp_50/cam/mtk_cam-smem.h         |   25 +
 .../mtk-isp/isp_50/cam/mtk_cam-v4l2-util.c    | 1184 +++
 .../mtk-isp/isp_50/cam/mtk_cam-v4l2-util.h    |   43 +
 .../platform/mtk-isp/isp_50/cam/mtk_cam.c     | 1098 +++
 .../platform/mtk-isp/isp_50/cam/mtk_cam.h     |  288 +
 .../platform/mtk-isp/isp_50/camSV/Makefile    |   15 +
 .../mtk-isp/isp_50/camSV/camerasv_isp.c       | 6613 +++++++++++++++++
 .../mtk-isp/isp_50/camSV/inc/cam_regs.h       |  149 +
 .../mtk-isp/isp_50/camSV/inc/camerasv_isp.h   | 1256 ++++
 .../platform/mtk-isp/isp_50/dip/Makefile      |   35 +
 .../mtk-isp/isp_50/dip/mtk_dip-core.h         |  190 +
 .../mtk-isp/isp_50/dip/mtk_dip-ctrl.c         |  172 +
 .../mtk-isp/isp_50/dip/mtk_dip-ctrl.h         |   42 +
 .../platform/mtk-isp/isp_50/dip/mtk_dip-ctx.h |  319 +
 .../mtk-isp/isp_50/dip/mtk_dip-dev-ctx-core.c | 1643 ++++
 .../platform/mtk-isp/isp_50/dip/mtk_dip-dev.c |  374 +
 .../platform/mtk-isp/isp_50/dip/mtk_dip-dev.h |  191 +
 .../mtk-isp/isp_50/dip/mtk_dip-smem-drv.c     |  454 ++
 .../mtk-isp/isp_50/dip/mtk_dip-smem.h         |   24 +
 .../mtk-isp/isp_50/dip/mtk_dip-v4l2-util.c    | 1002 +++
 .../mtk-isp/isp_50/dip/mtk_dip-v4l2-util.h    |   38 +
 .../mtk-isp/isp_50/dip/mtk_dip-v4l2.c         |  360 +
 .../mtk-isp/isp_50/dip/mtk_dip-v4l2.h         |   64 +
 .../platform/mtk-isp/isp_50/dip/mtk_dip.c     | 1420 ++++
 .../platform/mtk-isp/isp_50/dip/mtk_dip.h     |   93 +
 .../platform/mtk-isp/isp_50/seninf/Makefile   |    4 +
 .../mtk-isp/isp_50/seninf/mtk_seninf.c        | 1339 ++++
 .../mtk-isp/isp_50/seninf/seninf_drv_def.h    |  201 +
 .../mtk-isp/isp_50/seninf/seninf_reg.h        |  992 +++
 drivers/media/platform/mtk-mdp3/Makefile      |   15 +
 drivers/media/platform/mtk-mdp3/isp_reg.h     |   38 +
 .../media/platform/mtk-mdp3/mdp-platform.h    |   67 +
 .../media/platform/mtk-mdp3/mdp_reg_ccorr.h   |   76 +
 .../media/platform/mtk-mdp3/mdp_reg_rdma.h    |  207 +
 drivers/media/platform/mtk-mdp3/mdp_reg_rsz.h |  110 +
 .../media/platform/mtk-mdp3/mdp_reg_wdma.h    |  126 +
 .../media/platform/mtk-mdp3/mdp_reg_wrot.h    |  116 +
 .../media/platform/mtk-mdp3/mmsys_config.h    |  189 +
 drivers/media/platform/mtk-mdp3/mmsys_mutex.h |   36 +
 .../media/platform/mtk-mdp3/mmsys_reg_base.h  |   39 +
 drivers/media/platform/mtk-mdp3/mtk-img-ipi.h |  282 +
 .../media/platform/mtk-mdp3/mtk-mdp3-cmdq.c   |  458 ++
 .../media/platform/mtk-mdp3/mtk-mdp3-cmdq.h   |   57 +
 .../media/platform/mtk-mdp3/mtk-mdp3-comp.c   | 1325 ++++
 .../media/platform/mtk-mdp3/mtk-mdp3-comp.h   |  177 +
 .../media/platform/mtk-mdp3/mtk-mdp3-core.c   |  283 +
 .../media/platform/mtk-mdp3/mtk-mdp3-core.h   |   88 +
 .../media/platform/mtk-mdp3/mtk-mdp3-debug.c  | 1102 +++
 .../media/platform/mtk-mdp3/mtk-mdp3-debug.h  |   40 +
 .../media/platform/mtk-mdp3/mtk-mdp3-m2m.c    |  787 ++
 .../media/platform/mtk-mdp3/mtk-mdp3-m2m.h    |   52 +
 .../media/platform/mtk-mdp3/mtk-mdp3-regs.c   |  778 ++
 .../media/platform/mtk-mdp3/mtk-mdp3-regs.h   |  388 +
 drivers/media/platform/mtk-mdp3/mtk-mdp3-ut.c |  663 ++
 .../media/platform/mtk-mdp3/mtk-mdp3-vpu.c    |  277 +
 .../media/platform/mtk-mdp3/mtk-mdp3-vpu.h    |   89 +
 drivers/media/platform/mtk-vpu/mtk_vpu.c      |   20 +-
 drivers/media/platform/mtk-vpu/mtk_vpu.h      |   10 +
 drivers/media/v4l2-core/v4l2-compat-ioctl32.c |    2 +
 drivers/media/v4l2-core/v4l2-dev.c            |   12 +-
 drivers/media/v4l2-core/v4l2-ioctl.c          |   23 +
 drivers/memory/mtk-emi.c                      |  405 +
 drivers/mmc/host/mtk-sdio-proc.c              |  342 +
 drivers/mmc/host/mtk-sdio-proc.h              |   48 +
 drivers/remoteproc/mtk_common.h               |   77 +
 drivers/remoteproc/mtk_scp.c                  |  699 ++
 drivers/remoteproc/mtk_scp_ipi.c              |  163 +
 drivers/rpmsg/mtk_rpmsg.c                     |  396 +
 include/dt-bindings/gce/mt8183-gce.h          |  177 +
 .../reset-controller/mt8183-resets.h          |   89 +
 include/linux/platform_data/mtk_scp.h         |  166 +
 include/linux/rpmsg/mtk_rpmsg.h               |   30 +
 include/media/v4l2-ioctl.h                    |    8 +
 include/soc/mediatek/emi.h                    |  116 +
 include/uapi/linux/v4l2-controls.h            |    4 +
 include/uapi/linux/videodev2.h                |   24 +-
 156 files changed, 48962 insertions(+), 70 deletions(-)
 create mode 100644 Documentation/devicetree/bindings/media/mediatek,cam_smem.txt
 create mode 100644 Documentation/devicetree/bindings/media/mediatek,camisp.txt
 create mode 100644 Documentation/devicetree/bindings/media/mediatek-dip.txt
 create mode 100755 Documentation/devicetree/bindings/media/mediatek-fd.txt
 create mode 100644 Documentation/devicetree/bindings/media/mediatek-isp.txt
 create mode 100644 Documentation/devicetree/bindings/media/mediatek-seninf.txt
 create mode 100644 Documentation/devicetree/bindings/memory-controllers/mediatek,emi.txt
 create mode 100644 Documentation/devicetree/bindings/remoteproc/mtk,scp.txt
 create mode 100644 Documentation/devicetree/bindings/reserved-memory/mediatek,reserve-memory-cam_smem.txt
 create mode 100644 arch/arm64/boot/dts/mediatek/mt8183-kukui-rev2.dts
 create mode 100644 drivers/clk/mediatek/clkchk-mt8183.c
 create mode 100644 drivers/clk/mediatek/clkchk.c
 create mode 100644 drivers/clk/mediatek/clkchk.h
 create mode 100644 drivers/clk/mediatek/clkdbg-mt8183.c
 create mode 100644 drivers/clk/mediatek/clkdbg.c
 create mode 100644 drivers/clk/mediatek/clkdbg.h
 create mode 100644 drivers/gpu/drm/mediatek/mtk_mipi_tx.h
 create mode 100644 drivers/gpu/drm/mediatek/mtk_mt8173_mipi_tx.c
 create mode 100644 drivers/gpu/drm/mediatek/mtk_mt8183_mipi_tx.c
 create mode 100644 drivers/mailbox/mtk-cmdq-debug.c
 create mode 100644 drivers/mailbox/mtk-cmdq-debug.h
 create mode 100644 drivers/media/platform/mtk-isp/Kconfig
 create mode 100644 drivers/media/platform/mtk-isp/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/common/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.c
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.h
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-ctx.h
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-dev-ctx-core.c
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-dev.c
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-dev.h
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-smem-drv.c
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-smem.h
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.c
 create mode 100644 drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.h
 create mode 100644 drivers/media/platform/mtk-isp/fd/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-core.h
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-ctx.h
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-dev-ctx-core.c
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-dev.c
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-dev.h
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-smem-drv.c
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-smem.h
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2-util.c
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.c
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.h
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd.c
 create mode 100644 drivers/media/platform/mtk-isp/fd/mtk_fd.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctx.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev-ctx-core.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-regs.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem-drv.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/camSV/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/camSV/camerasv_isp.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/camSV/inc/cam_regs.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/camSV/inc/camerasv_isp.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-core.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctx.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev-ctx-core.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem-drv.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.h
 create mode 100755 drivers/media/platform/mtk-isp/isp_50/seninf/Makefile
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/seninf/mtk_seninf.c
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/seninf/seninf_drv_def.h
 create mode 100644 drivers/media/platform/mtk-isp/isp_50/seninf/seninf_reg.h
 create mode 100644 drivers/media/platform/mtk-mdp3/Makefile
 create mode 100644 drivers/media/platform/mtk-mdp3/isp_reg.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mdp-platform.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mdp_reg_ccorr.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mdp_reg_rdma.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mdp_reg_rsz.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mdp_reg_wdma.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mdp_reg_wrot.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mmsys_config.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mmsys_mutex.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mmsys_reg_base.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-img-ipi.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-core.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-core.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.h
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-ut.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.c
 create mode 100644 drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.h
 create mode 100644 drivers/memory/mtk-emi.c
 create mode 100644 drivers/mmc/host/mtk-sdio-proc.c
 create mode 100644 drivers/mmc/host/mtk-sdio-proc.h
 create mode 100644 drivers/remoteproc/mtk_common.h
 create mode 100644 drivers/remoteproc/mtk_scp.c
 create mode 100644 drivers/remoteproc/mtk_scp_ipi.c
 create mode 100644 drivers/rpmsg/mtk_rpmsg.c
 create mode 100644 include/dt-bindings/gce/mt8183-gce.h
 create mode 100644 include/dt-bindings/reset-controller/mt8183-resets.h
 create mode 100644 include/linux/platform_data/mtk_scp.h
 create mode 100644 include/linux/rpmsg/mtk_rpmsg.h
 create mode 100644 include/soc/mediatek/emi.h

diff --git a/Documentation/devicetree/bindings/media/mediatek,cam_smem.txt b/Documentation/devicetree/bindings/media/mediatek,cam_smem.txt
new file mode 100644
index 000000000000..d34006a3c69d
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/mediatek,cam_smem.txt
@@ -0,0 +1,32 @@
+Mediatek Camera ISP Pass 1 Shared Memory Device
+
+Mediatek Camera ISP Pass 1 Shared Memory Device is used to manage shared
+memory among CPU, Camera ISP Pass 1 hardware and coprocessor. The Camera
+ISP Pass 1 is a hardware unit for processing image signal from the image
+sensor. Camera ISP Pass 1 is responsible for RAW processing and 3A statistics.
+
+It is associated with a reserved memory region
+(Please see Documentation/devicetree/bindings/reserved-memory/mediatek,
+reserve-memory-cam_smem.txt) and and provides the context to
+allocate memory with dma addresses.
+
+Required properties:
+- compatible: must be "mediatek,mt8183-cam_smem" for MT8183.
+
+- iommus: shall point to the respective IOMMU block with master port
+  as argument, see Documentation/devicetree/bindings/iommu/mediatek,iommu.txt
+  for details.
+
+- mediatek,larb: must contain the local arbiters in the current SoCs, see
+  Documentation/devicetree/bindings/memory-controllers/mediatek,smi-larb.txt
+  for details.
+
+Example:
+	cam_smem: cam_smem {
+		compatible = "mediatek,mt8183-cam_smem";
+		mediatek,larb = <&larb3>,
+				<&larb6>;
+		iommus = <&iommu M4U_PORT_CAM_LSCI0>,
+			 <&iommu M4U_PORT_CAM_LSCI1>,
+			 <&iommu M4U_PORT_CAM_BPCI>;
+	};
diff --git a/Documentation/devicetree/bindings/media/mediatek,camisp.txt b/Documentation/devicetree/bindings/media/mediatek,camisp.txt
new file mode 100644
index 000000000000..dbc7d08a94b8
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/mediatek,camisp.txt
@@ -0,0 +1,59 @@
+* Mediatek Image Signal Processor Pass 1 (ISP P1)
+
+The Pass 1 unit of Mediatek's camera ISP system grabs the sensor data out
+from the sensor interface, applies ISP effects and writes the image data
+to DRAM. Furthermore, Pass 1 unit has the ability to output two different
+resolutions frames at the same time to increase the performance of the
+camera application.
+
+Required properties:
+- compatible: Must be "mediatek,mt8183-camisp" for MT8183.
+- reg: Must contain an entry for each entry in reg-names.
+- interrupts: interrupt number to the cpu.
+- iommus: shall point to the respective IOMMU block with master port
+  as argument, see Documentation/devicetree/bindings/iommu/mediatek,iommu.txt
+  for details.
+- power-domains : a phandle to the power domain of this local arbiter.
+- mediatek,smi : a phandle to the smi_common node.
+- clocks: device clocks, see
+  Documentation/devicetree/bindings/clock/clock-bindings.txt for details.
+- clock-names: must be "CAMSYS_CAM_CGPDN" and "CAMSYS_CAMTG_CGPDN".
+- mediatek,larb: must contain the local arbiters in the current SOCs, see
+  Documentation/devicetree/bindings/memory-controllers/mediatek,smi-larb.txt
+  for details.
+- mediatek,scp : the node of system control processor (SCP).
+- smem_device : the shared memory device managing the shared memory between
+  Pass 1 unit and the video processor unit.
+
+Example:
+	camisp: camisp@1a000000 {
+		compatible = "mediatek,mt8183-camisp", "syscon";
+		reg = <0 0x1a000000 0 0x1000>,
+		      <0 0x1a003000 0 0x1000>,
+		      <0 0x1a004000 0 0x2000>,
+		      <0 0x1a006000 0 0x2000>;
+		reg-names = "camisp",
+		            "cam1",
+		            "cam2",
+		            "cam3";
+		interrupts = <GIC_SPI 253 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_SPI 254 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_SPI 255 IRQ_TYPE_LEVEL_LOW>;
+		interrupt-names = "cam1",
+				  "cam2",
+				  "cam3";
+		iommus = <&iommu M4U_PORT_CAM_LSCI0>,
+			 <&iommu M4U_PORT_CAM_LSCI1>,
+			 <&iommu M4U_PORT_CAM_BPCI>;
+		#clock-cells = <1>;
+		power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
+		/* Camera CCF */
+		clocks = <&camsys CLK_CAM_CAM>,
+			 <&camsys CLK_CAM_CAMTG>;
+		clock-names = "CAMSYS_CAM_CGPDN",
+			      "CAMSYS_CAMTG_CGPDN";
+		mediatek,larb = <&larb3>,
+				<&larb6>;
+		mediatek,scp = <&scp>;
+		smem_device = <&cam_smem>;
+	};
diff --git a/Documentation/devicetree/bindings/media/mediatek-dip.txt b/Documentation/devicetree/bindings/media/mediatek-dip.txt
new file mode 100644
index 000000000000..e1b62d69935c
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/mediatek-dip.txt
@@ -0,0 +1,32 @@
+* Mediatek Digital Image Processor (P2)
+
+Digital Image Processor is a typical memory-to-memory HW device.
+It would read raw format data from memory and then adjust the
+image content by user input tuning parameters. It also
+performs demosaic, noise reduction on the input image buffer.
+Finally, DIP would write the enhanced results to memory.
+
+Required properties:
+  - compatible: "mediatek,mt8183-dip"
+  - reg: Must contain an entry for each entry in reg-names.
+  - reg-names: Must include the following entries:
+  - interrupts: interrupt number to the cpu.
+  - clocks : clock name from clock manager
+  - clock-names: must be main. It is the main clock of DIP
+
+Example:
+	dip: dip@15022000 {
+		compatible = "mediatek,mt8183-dip";
+		mediatek,larb = <&larb5>;
+		mediatek,mdp3 = <&mdp_rdma0>;
+		mediatek,vpu = <&vpu>;
+		iommus = <&iommu M4U_PORT_CAM_IMGI>;
+		reg = <0 0x15022000 0 0x6000>;
+		interrupts = <GIC_SPI 268 IRQ_TYPE_LEVEL_LOW>;
+		clocks =
+				<&imgsys CLK_IMG_LARB5>,
+				<&imgsys CLK_IMG_DIP>;
+		clock-names =
+				"DIP_CG_IMG_LARB5",
+				"DIP_CG_IMG_DIP";
+	};
diff --git a/Documentation/devicetree/bindings/media/mediatek-fd.txt b/Documentation/devicetree/bindings/media/mediatek-fd.txt
new file mode 100755
index 000000000000..8d1829ca3227
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/mediatek-fd.txt
@@ -0,0 +1,30 @@
+* Mediatek Face Detection Unit (FD)
+
+Face detection unit is a typical memory-to-memory HW device.
+It would read yuv format image from memory, and detect the appeared faces
+inside the image by the meta input configurotation from user.
+FD would write result of the detected face into memory.
+
+Required properties:
+  - compatible: "mediatek,fd"
+  - reg: Must contain an entry for each entry in reg-names.
+  - reg-names: Must include the following entries:
+  - interrupts: interrupt number to the cpu.
+  - clocks : clock name from clock manager
+  - clock-names: must be main. It is the main clock of FD
+
+Example:
+	fd:fd@1502b000 {
+		compatible = "mediatek,fd";
+		/* mediatek,larbid = <3>;*/
+		mediatek,larb = <&larb5>;
+		mediatek,vpu = <&vpu>;
+		iommus = <&iommu M4U_PORT_CAM_FDVT_RP>,
+			<&iommu M4U_PORT_CAM_FDVT_WR>,
+			<&iommu M4U_PORT_CAM_FDVT_RB>;
+		reg = <0 0x1502b000 0 0x1000>;
+		interrupts = <GIC_SPI 269 IRQ_TYPE_LEVEL_LOW>;
+		clocks = <&imgsys CLK_IMG_FDVT>;
+		clock-names = "FD_CLK_IMG_FDVT";
+		smem_device = <&fd_smem>;
+	};
diff --git a/Documentation/devicetree/bindings/media/mediatek-isp.txt b/Documentation/devicetree/bindings/media/mediatek-isp.txt
new file mode 100644
index 000000000000..91cd5e7ee8ad
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/mediatek-isp.txt
@@ -0,0 +1,73 @@
+* Mediatek Simultaneously Virtual-channel at Cam-sys(CamSV)
+
+CamSV is one of camera HW device, get image data from sensor
+and then output the RAW data directly without ISP processing.
+It can configure format, crops, RAW format and sub-sample to
+come out RAW data.
+
+Required properties:
+  - compatible: "mediatek,mt8183-camsv" for camera main part
+                "mediatek,camsv1" for camSV module index 1
+                "mediatek,camsv2" for camSV module index 2
+                "mediatek,camsv3" for camSV module index 3
+                "mediatek,camsv4" for camSV module index 4
+                "mediatek,camsv5" for camSV module index 5
+                "mediatek,camsv6" for camSV module index 6
+  - reg: Must contain an entry for each entry in reg-names.
+  - interrupts: interrupt number to the cpu.
+  - power-domains : a phandle to the power domain of this local arbiter.
+  - mediatek,smi : a phandle to the smi_common node.
+  - clocks : clock name from clock manager
+  - clock-names: must be main. It is the main clock of CamSV
+  - mediatek,larb: must contain the local arbiters in the current Socs, see
+  Documentation/devicetree/bindings/memory-controllers/mediatek,smi-larb.txt
+  for details.
+
+Example:
+	camsv: camsv@1a000000 {
+		compatible = "mediatek,mt8183-camsv", "syscon";
+		reg = <0 0x1a000000 0 0x1000>;
+		#clock-cells = <1>;
+		power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
+		mediatek,smi = <&smi_common>;
+		clocks = <&camsys CLK_CAM_CAM>,
+				<&camsys CLK_CAM_CAMTG>,
+				<&camsys CLK_CAM_CAMSV0>,
+				<&camsys CLK_CAM_CAMSV1>,
+				<&camsys CLK_CAM_CAMSV2>;
+		clock-names = "CAMSYS_CAM_CGPDN",
+				"CAMSYS_CAMTG_CGPDN",
+				"CAMSYS_CAMSV0_CGPDN",
+				"CAMSYS_CAMSV1_CGPDN",
+				"CAMSYS_CAMSV2_CGPDN";
+		mediatek,larb = <&larb3>,
+				<&larb6>;
+	};
+	camsv1@1a050000 {
+		compatible = "mediatek,camsv1";
+		reg = <0 0x1a050000 0 0x1000>;
+		interrupts = <GIC_SPI 258 IRQ_TYPE_LEVEL_LOW>;
+	};
+	camsv2@1a051000 {
+		compatible = "mediatek,camsv2";
+		reg = <0 0x1a051000 0 0x1000>;
+		interrupts = <GIC_SPI 259 IRQ_TYPE_LEVEL_LOW>;
+	};
+	camsv3@1a052000 {
+		compatible = "mediatek,camsv3";
+		reg = <0 0x1a052000 0 0x1000>;
+		interrupts = <GIC_SPI 260 IRQ_TYPE_LEVEL_LOW>;
+	};
+	camsv4@1a053000 {
+		compatible = "mediatek,camsv4";
+		reg = <0 0x1a053000 0 0x1000>;
+		interrupts = <GIC_SPI 261 IRQ_TYPE_LEVEL_LOW>;
+	};
+	camsv5@1a054000 {
+		compatible = "mediatek,camsv5";
+		reg = <0 0x1a054000 0 0x1000>;
+	};
+	camsv6@1a055000 {
+		compatible = "mediatek,camsv6";
+		reg = <0 0x1a055000 0 0x1000>;
+	};
diff --git a/Documentation/devicetree/bindings/media/mediatek-seninf.txt b/Documentation/devicetree/bindings/media/mediatek-seninf.txt
new file mode 100644
index 000000000000..e8dd4cb47dd7
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/mediatek-seninf.txt
@@ -0,0 +1,54 @@
+* Mediatek seninf MIPI-CSI2 host driver
+
+Seninf MIPI-CSI2 host driver is a HW camera interface controller. It support a widely adopted,
+simple, high-speed protocol primarily intended for point-to-point image and video
+transmission between cameras and host devices.
+
+Required properties:
+  - compatible: "mediatek,mt8183-seninf"
+  - reg: Must contain an entry for each entry in reg-names.
+  - reg-names: Must include the following entries:
+    "base_reg": seninf registers base
+    "rx_reg": Rx analog registers base
+  - interrupts: interrupt number to the cpu.
+  - clocks : clock name from clock manager
+  - clock-names: must be CLK_CAM_SENINF and CLK_TOP_MUX_SENINF.
+    It is the clocks of seninf
+  - port : port for camera sensor
+  - port reg : must be '0' for camera_0, '1' for camera_1
+  - endpoint : config mipi-csi2 port setting for each camera
+  - data-lanes : the number of the data lane
+
+Example:
+    seninf: seninf@1a040000 {
+       compatible = "mediatek,mt8183_seninf";
+		reg = <0 0x1a040000 0 0x8000>,
+		      <0 0x10400000 0 0x6000>;
+		reg-names = "base_reg", "ana_reg";
+		interrupts = <GIC_SPI 251 IRQ_TYPE_LEVEL_LOW>;
+		power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
+	    clocks =
+			<&camsys CLK_CAM_SENINF>,
+			<&topckgen CLK_TOP_MUX_SENINF>;
+		clock-names =
+			"CLK_CAM_SENINF",
+			"CLK_TOP_MUX_SENINF";
+		ports {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			port@0 {
+				reg = <0>;
+				mipi_in_cam0: endpoint@0 {
+					reg = <0>;
+					data-lanes = <2 4>;
+				};
+			};
+			port@1 {
+				reg = <1>;
+				mipi_in_cam1: endpoint@0 {
+					reg = <1>;
+					data-lanes = <2 4>;
+				};
+			};
+		};
+	}
\ No newline at end of file
diff --git a/Documentation/devicetree/bindings/memory-controllers/mediatek,emi.txt b/Documentation/devicetree/bindings/memory-controllers/mediatek,emi.txt
new file mode 100644
index 000000000000..a19e3b39ba66
--- /dev/null
+++ b/Documentation/devicetree/bindings/memory-controllers/mediatek,emi.txt
@@ -0,0 +1,19 @@
+EMI (External Memory Interface)
+
+Required properties:
+- compatible : must be one of :
+	"mediatek,mt8183-emi"
+- reg : the register and size of the EMI block.
+- interrupts : includes MPU, CGM, ELM.
+
+Example:
+	emi@10219000 {
+	compatible = "mediatek,mt8183-emi";
+	reg = <0 0x10219000 0 0x1000>, /* CEN EMI */
+		  <0 0x10226000 0 0x1000>, /* EMI MPU */
+		  <0 0x1022d000 0 0x1000>, /* CHA EMI */
+		  <0 0x10235000 0 0x1000>; /* CHB EMI */
+	interrupts = <GIC_SPI 147 IRQ_TYPE_LEVEL_LOW>, /* MPU */
+			 <GIC_SPI 148 IRQ_TYPE_LEVEL_HIGH>, /* CGM */
+			 <GIC_SPI 155 IRQ_TYPE_LEVEL_HIGH>; /* ELM */
+};
diff --git a/Documentation/devicetree/bindings/remoteproc/mtk,scp.txt b/Documentation/devicetree/bindings/remoteproc/mtk,scp.txt
new file mode 100644
index 000000000000..3ba668bab14b
--- /dev/null
+++ b/Documentation/devicetree/bindings/remoteproc/mtk,scp.txt
@@ -0,0 +1,36 @@
+Mediatek SCP Bindings
+----------------------------------------
+
+This binding provides support for ARM Cortex M4 Co-processor found on some
+Mediatek SoCs.
+
+Required properties:
+- compatible		Should be "mediatek,mt8183-scp"
+- reg			Should contain the address ranges for the two memory
+			regions, SRAM and CFG.
+- reg-names		Contains the corresponding names for the two memory
+			regions. These should be named "sram" & "cfg".
+- clocks		Clock for co-processor (See: ../clock/clock-bindings.txt)
+- clock-names		Contains the corresponding name for the clock. This
+			should be named "main".
+
+Subnodes
+--------
+
+Subnodes of the SCP represent rpmsg devices. The names of the devices are not
+important. The properties of these nodes are defined by the individual bindings
+for the rpmsg devices - but must contain the following property:
+
+- mtk,rpmsg-name	Contains the name for the rpmsg device. Used to match
+			the subnode to rpmsg device announced by SCP.
+
+Example:
+
+	scp: scp@10500000 {
+		compatible = "mediatek,mt8183-scp";
+		reg = <0 0x10500000 0 0x80000>,
+		      <0 0x105c0000 0 0x5000>;
+		reg-names = "sram", "cfg";
+		clocks = <&infracfg CLK_INFRA_SCPSYS>;
+		clock-names = "main";
+	};
diff --git a/Documentation/devicetree/bindings/reserved-memory/mediatek,reserve-memory-cam_smem.txt b/Documentation/devicetree/bindings/reserved-memory/mediatek,reserve-memory-cam_smem.txt
new file mode 100644
index 000000000000..05c1bf185925
--- /dev/null
+++ b/Documentation/devicetree/bindings/reserved-memory/mediatek,reserve-memory-cam_smem.txt
@@ -0,0 +1,44 @@
+Mediatek ISP Pass 1 Shared Memory binding
+
+This binding describes the shared memory, which serves the purpose of
+describing the shared memory region used to exchange data between Pass 1
+unit of Image Signal Processor (ISP) and the co-processor in Mediatek
+SoCs.
+
+The co-processor doesn't have the iommu so we need to use the physical
+address to access the shared buffer in the firmware.
+
+The Pass 1 unit of ISP can access memory through the iommu so it
+uses the dma address to access the memory region.
+(See iommu/mediatek,iommu.txt for the detailed description of Mediatek IOMMU)
+
+
+Required properties:
+
+- compatible: must be "mediatek,reserve-memory-cam_smem"
+
+- reg: required for static allocation (see reserved-memory.txt for
+  the detailed usage)
+
+- alloc-range: required for dynamic allocation. The range must
+  between 0x00000400 and 0x100000000 due to the co-processer's
+  addressing limitation
+
+- size: required for dynamic allocation. The unit is bytes.
+
+
+Example:
+
+The following example shows the ISP Pass1 shared memory setup for MT8183.
+
+	reserved-memory {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+		reserve-memory-cam_smem {
+			compatible = "mediatek,reserve-memory-cam_smem";
+			size = <0 0x1400000>;
+			alignment = <0 0x1000>;
+			alloc-ranges = <0 0x40000000 0 0x50000000>;
+		};
+	};
diff --git a/README b/README
index 768caa3970ef..977bc3b04f5a 100644
--- a/README
+++ b/README
@@ -1,4 +1,5 @@
-MTK TOT
+ISP TOT
+
 Linux kernel
 ============
 
@@ -18,3 +19,5 @@ See Documentation/00-INDEX for a list of what is contained in each file.
 Please read the Documentation/process/changes.rst file, as it contains the
 requirements for building and running the kernel, and information about
 the problems which may result by upgrading your kernel.
+
+
diff --git a/arch/arm64/boot/dts/mediatek/mt8183-kukui-rev2.dts b/arch/arm64/boot/dts/mediatek/mt8183-kukui-rev2.dts
new file mode 100644
index 000000000000..e0304b04ea37
--- /dev/null
+++ b/arch/arm64/boot/dts/mediatek/mt8183-kukui-rev2.dts
@@ -0,0 +1,444 @@
+// SPDX-License-Identifier: (GPL-2.0 OR MIT)
+/*
+ * Copyright (c) 2018 Google LLC
+ */
+
+/dts-v1/;
+#include <dt-bindings/gpio/gpio.h>
+#include "mt8183-kukui.dtsi"
+
+/ {
+	model = "MediaTek kukui rev2 board";
+	compatible = "google,kukui-rev2", "google,kukui", "mediatek,mt8183";
+};
+
+&pio {
+	/* 192 lines */
+	gpio-line-names =
+		"SPI_AP_EC_CS_L",
+		"SPI_AP_EC_MOSI",
+		"SPI_AP_EC_CLK",
+		"I2S3_DO",
+		"USB_PD_INT_ODL",
+		"",
+		"",
+		"",
+		"",
+		"IT6505_HPD_L",
+		"I2S3_TDM_D3",
+		"SOC_I2C6_1V8_SCL",
+		"SOC_I2C6_1V8_SDA",
+		"DPI_D0",
+		"DPI_D1",
+		"DPI_D2",
+		"DPI_D3",
+		"DPI_D4",
+		"DPI_D5",
+		"DPI_D6",
+		"DPI_D7",
+		"DPI_D8",
+		"DPI_D9",
+		"DPI_D10",
+		"DPI_D11",
+		"DPI_HSYNC",
+		"DPI_VSYNC",
+		"DPI_DE",
+		"DPI_CK",
+		"AP_MSDC1_CLK",
+		"AP_MSDC1_DAT3",
+		"AP_MSDC1_CMD",
+		"AP_MSDC1_DAT0",
+		"AP_MSDC1_DAT2",
+		"AP_MSDC1_DAT1",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"OTG_EN",
+		"DRVBUS",
+		"DISP_PWM",
+		"DSI_TE",
+		"LCM_RST_1V8",
+		"AP_CTS_WIFI_RTS",
+		"AP_RTS_WIFI_CTS",
+		"SOC_I2C5_1V8_SCL",
+		"SOC_I2C5_1V8_SDA",
+		"SOC_I2C3_1V8_SCL",
+		"SOC_I2C3_1V8_SDA",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"SOC_I2C1_1V8_SDA",
+		"SOC_I2C0_1V8_SDA",
+		"SOC_I2C0_1V8_SCL",
+		"SOC_I2C1_1V8_SCL",
+		"AP_SPI_H1_MISO",
+		"AP_SPI_H1_CS_L",
+		"AP_SPI_H1_MOSI",
+		"AP_SPI_H1_CLK",
+		"I2S5_BCK",
+		"I2S5_LRCK",
+		"I2S5_DO",
+		"BOOTBLOCK_EN_L",
+		"MT8183_KPCOL0",
+		"SPI_AP_EC_MISO",
+		"UART_DBG_TX_AP_RX",
+		"UART_AP_TX_DBG_RX",
+		"I2S2_MCK",
+		"I2S2_BCK",
+		"CLK_5M_WCAM",
+		"CLK_2M_UCAM",
+		"I2S2_LRCK",
+		"I2S2_DI",
+		"SOC_I2C2_1V8_SCL",
+		"SOC_I2C2_1V8_SDA",
+		"SOC_I2C4_1V8_SCL",
+		"SOC_I2C4_1V8_SDA",
+		"",
+		"SCL8",
+		"SDA8",
+		"FCAM_PWDN_L",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"I2S_PMIC",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		/*
+		 * AP_FLASH_WP_L is crossystem ABI. Rev1 schematics
+		 * call it BIOS_FLASH_WP_R_L.
+		 */
+		"AP_FLASH_WP_L",
+		"EC_AP_INT_ODL",
+		"IT6505_INT_ODL",
+		"H1_INT_OD_L",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"AP_SPI_FLASH_MISO",
+		"AP_SPI_FLASH_CS_L",
+		"AP_SPI_FLASH_MOSI",
+		"AP_SPI_FLASH_CLK",
+		"DA7219_IRQ",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"",
+		"";
+};
+
+&scp_pins {
+	/* EINT pins are used for other purpose on rev2. */
+	/delete-node/ pins_eint;
+};
+
+/* rev2 has a pen controller with eject detection GPIO. */
+/ {
+	gpio-keys {
+		compatible = "gpio-keys";
+		pinctrl-names = "default";
+		pinctrl-0 = <&pen_eject>;
+
+		pen-insert {
+			label = "Pen Insert";
+			/* Insert = low, eject = high */
+			gpios = <&pio 6 GPIO_ACTIVE_LOW>;
+			linux,code = <SW_PEN_INSERTED>;
+			linux,input-type = <EV_SW>;
+			wakeup-source;
+		};
+	};
+};
+
+&i2c0 {
+	digitizer: digitizer@9 {
+		compatible = "wacom,w9013", "hid-over-i2c";
+		reg = <0x9>;
+		pinctrl-names = "default";
+		pinctrl-0 = <&pen_default>;
+
+		interrupt-parent = <&pio>;
+		interrupts = <5 IRQ_TYPE_LEVEL_LOW>;
+
+		hid-descr-addr = <0x1>;
+	};
+};
+
+&i2c2 {
+	sensor_main: sensor_main {
+		status = "okay";
+		reset-gpios = <&pio 111 1>;
+	};
+};
+
+&i2c4 {
+	sensor_sub: sensor_sub {
+		status = "okay";
+		reset-gpios = <&pio 107 1>;
+	};
+};
+
+&pio {
+	pen_default: pendefault {
+		pen_int_odl {
+			pinmux = <PINMUX_GPIO5__FUNC_GPIO5>;
+			input-enable;
+			bias-pull-up;
+		};
+
+		pen_reset_odl {
+			pinmux = <PINMUX_GPIO53__FUNC_GPIO53>;
+
+			/*
+			 * The pen driver doesn't currently support  driving
+			 * this reset line.  By specifying output-high here
+			 * we're relying on the fact that this pin has a default
+			 * pulldown at boot (which makes sure the pen was in
+			 * reset if it was powered) and then we set it high here
+			 * to take it out of reset.  Better would be if the pen
+			 * driver could control this and we could remove
+			 * "output-high" here.
+			 */
+			output-high;
+		};
+	};
+
+	pen_eject: peneject {
+		pen_eject {
+			pinmux = <PINMUX_GPIO6__FUNC_GPIO6>;
+			input-enable;
+			/* External pull-up. */
+			bias-disable;
+		};
+	};
+};
+
+/* rev2 panel is behind a SSD 2858 bridge. */
+/ {
+        ppvarn_lcd: ppvarn-lcd {
+                compatible = "regulator-fixed";
+                regulator-name = "ppvarn_lcd";
+                pinctrl-names = "default";
+                pinctrl-0 = <&ppvarn_lcd_en>;
+
+                enable-active-high;
+
+                gpio = <&pio 66 GPIO_ACTIVE_HIGH>;
+        };
+
+        ppvarp_lcd: ppvarp-lcd {
+                compatible = "regulator-fixed";
+                regulator-name = "ppvarp_lcd";
+                pinctrl-names = "default";
+                pinctrl-0 = <&ppvarp_lcd_en>;
+
+                enable-active-high;
+
+                gpio = <&pio 166 GPIO_ACTIVE_HIGH>;
+        };
+
+        pp1800_lcd: pp1800-lcd {
+                compatible = "regulator-fixed";
+                regulator-name = "pp1800_lcd";
+                pinctrl-names = "default";
+                pinctrl-0 = <&pp1800_lcm_en>;
+
+                enable-active-high;
+
+                gpio = <&pio 36 GPIO_ACTIVE_HIGH>;
+        };
+
+        pp3300_lcd: pp3300-lcd {
+                compatible = "regulator-fixed";
+                regulator-name = "pp3300_lcd";
+                pinctrl-names = "default";
+                pinctrl-0 = <&pp3300_lcm_en>;
+
+                enable-active-high;
+
+                gpio = <&pio 35 GPIO_ACTIVE_HIGH>;
+        };
+
+        pp1200_mipibrdg: pp1200-mipibrdg {
+                compatible = "regulator-fixed";
+                regulator-name = "pp1200_mipibrdg";
+                pinctrl-names = "default";
+                pinctrl-0 = <&pp1200_mipibrdg_en>;
+
+                enable-active-high;
+
+                gpio = <&pio 54 GPIO_ACTIVE_HIGH>;
+        };
+
+	vddio_mipibrdg: vddio-mipibrdg {
+                compatible = "regulator-fixed";
+                regulator-name = "vddio_mipibrdg";
+                pinctrl-names = "default";
+                pinctrl-0 = <&vddio_mipibrdg_en>;
+
+                enable-active-high;
+
+                gpio = <&pio 37 GPIO_ACTIVE_HIGH>;
+        };
+
+};
+
+&panel {
+	compatible = "innolux,p097pfg_ssd2858";
+	reg = <0>;
+	enable-gpios = <&pio 45 0 &pio 73 0>;
+	pinctrl-names = "default";
+	pinctrl-0 = <&panel_pins_default>;
+	/delete-property/ power-supply;
+	avdd-supply = <&ppvarp_lcd>;
+	avee-supply = <&ppvarn_lcd>;
+	pp1800-supply = <&pp1800_lcd>;
+	pp3300-supply = <&pp3300_lcd>;
+	pp1200-bridge-supply = <&pp1200_mipibrdg>;
+	vddio-bridge-supply = <&vddio_mipibrdg>;
+	backlight = <&backlight_lcd0>;
+	status = "okay";
+	port {
+		panel_in: endpoint {
+			remote-endpoint = <&dsi_out>;
+		};
+	};
+};
+
+&panel_pins_default {
+	bridge_reset {
+		pinmux = <PINMUX_GPIO73__FUNC_GPIO73>;
+		output-low;
+		bias-pull-up;
+	};
+};
+
+&pio {
+	ppvarp_lcd_en: ppvarp-lcd-en {
+		pins1 {
+			pinmux = <PINMUX_GPIO66__FUNC_GPIO66>;
+			output-low;
+		};
+	};
+
+	ppvarn_lcd_en: ppvarn-lcd-en {
+		pins1 {
+			pinmux = <PINMUX_GPIO166__FUNC_GPIO166>;
+			output-low;
+		};
+	};
+
+	pp1800_lcm_en: pp1800-lcd-en {
+		pins1 {
+			pinmux = <PINMUX_GPIO36__FUNC_GPIO36>;
+			output-low;
+		};
+	};
+
+	pp3300_lcm_en: pp3300-lcd-en {
+		pins1 {
+			pinmux = <PINMUX_GPIO35__FUNC_GPIO35>;
+			output-low;
+		};
+	};
+
+	pp1200_mipibrdg_en: pp1200-mipibrdg-en {
+		pins1 {
+			pinmux = <PINMUX_GPIO54__FUNC_GPIO54>;
+			output-low;
+		};
+	};
+
+	vddio_mipibrdg_en: vddio_mipibrdg_en {
+		pins1 {
+			pinmux = <PINMUX_GPIO37__FUNC_GPIO37>;
+			output-low;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/mediatek/mt8183-kukui.dtsi b/arch/arm64/boot/dts/mediatek/mt8183-kukui.dtsi
index 467bc98f551e..b2fd77e04164 100644
--- a/arch/arm64/boot/dts/mediatek/mt8183-kukui.dtsi
+++ b/arch/arm64/boot/dts/mediatek/mt8183-kukui.dtsi
@@ -213,7 +213,35 @@
 	pinctrl-names = "default";
 	pinctrl-0 = <&i2c2_pins>;
 	status = "okay";
-	clock-frequency = <100000>;
+	clock-frequency = <400000>;
+
+	sensor_main: sensor_main {
+		compatible = "ovti,ov5695";
+		reg = <0x36>;
+
+		clocks = <&topckgen CLK_TOP_MUX_CAMTG>,
+			<&topckgen CLK_TOP_UNIVP_192M_D8>;
+		clock-names = "xvclk", "freq_mux";
+
+		assigned-clocks = <&topckgen CLK_TOP_MUX_CAMTG>,
+		    <&topckgen CLK_TOP_UNIVP_192M_D8>;
+		assigned-clock-parents = <&topckgen CLK_TOP_UNIVP_192M_D8>;
+		assigned-clock-rates = <0>, <24000000>;
+
+		reset-gpios = <&pio 112 1>;
+		pinctrl-names = "default";
+		pinctrl-0 = <&camera_pins_cam0_mclk_on>;
+
+		avdd-supply = <&mt6358_vcama2_reg>;
+		dvdd-supply = <&mt6358_vcamd_reg>;
+		dovdd-supply = <&mt6358_vcamio_reg>;
+
+		port@0 {
+		   ov5695_core: endpoint {
+		       remote-endpoint = <&ov5695_0>;
+		   };
+		};
+	};
 };
 
 &i2c3 {
@@ -227,7 +255,35 @@
 	pinctrl-names = "default";
 	pinctrl-0 = <&i2c4_pins>;
 	status = "okay";
-	clock-frequency = <100000>;
+	clock-frequency = <400000>;
+
+	sensor_sub: sensor_sub {
+		compatible = "ovti,ov2685";
+		reg = <0x3c>;
+
+		clocks = <&topckgen CLK_TOP_MUX_CAMTG2>,
+			<&topckgen CLK_TOP_UNIVP_192M_D8>;
+		clock-names = "xvclk", "freq_mux";
+
+		assigned-clocks = <&topckgen CLK_TOP_MUX_CAMTG2>,
+		    <&topckgen CLK_TOP_UNIVP_192M_D8>;
+		assigned-clock-parents = <&topckgen CLK_TOP_UNIVP_192M_D8>;
+		assigned-clock-rates = <0>, <24000000>;
+
+		reset-gpios = <&pio 110 1>;
+		pinctrl-names = "default";
+		pinctrl-0 = <&camera_pins_cam1_mclk_on>;
+
+		avdd-supply = <&mt6358_vcama1_reg>;
+		dvdd-supply = <&mt6358_vcn18_reg>;
+		dovdd-supply = <&mt6358_vcamio_reg>;
+
+		port@0 {
+		   ov2685_core: endpoint {
+		       remote-endpoint = <&ov2685_0>;
+		   };
+		};
+	};
 };
 
 &i2c5 {
@@ -316,6 +372,53 @@
 	Avdd-supply = <&mt6358_vaud28_reg>;
 };
 
+&camisp {
+	port@0 {
+		ov2685_0: endpoint {
+			remote-endpoint = <&ov2685_core>;
+		};
+	};
+	port@1 {
+		ov5695_0: endpoint {
+			remote-endpoint = <&ov5695_core>;
+		};
+	};
+	port@2 {
+		seninf_0: endpoint {
+			remote-endpoint = <&seninf_core>;
+		};
+	};
+};
+
+&seninf {
+	status = "okay";
+	ports {
+		#address-cells = <1>;
+		#size-cells = <0>;
+		port@0 {
+			reg = <0>;
+			mipi_in_cam0: endpoint@0 {
+				reg = <0>;
+				data-lanes = <1 3>;
+			};
+		};
+
+		port@1 {
+			reg = <1>;
+			mipi_in_cam1: endpoint@0 {
+				reg = <1>;
+				data-lanes = <1 3>;
+			};
+		};
+	};
+
+	port@2 {
+		seninf_core: endpoint {
+			remote-endpoint = <&seninf_0>;
+	   };
+	};
+};
+
 &pio {
 	aud_pins: audiopins {
 		pins_bus {
@@ -437,6 +540,18 @@
 		};
 	};
 
+	camera_pins_cam0_mclk_on: cam0@2 {
+		pins_cmd_dat {
+			pinmux = <PINMUX_GPIO99__FUNC_CMMCLK0>;
+		};
+	};
+
+	camera_pins_cam1_mclk_on: cam1@2 {
+		pins_cmd_dat {
+			pinmux = <PINMUX_GPIO100__FUNC_CMMCLK1>;
+		};
+	};
+
 	mmc0_pins_default: mmc0default {
 		pins_cmd_dat {
 			pinmux = <PINMUX_GPIO123__FUNC_MSDC0_DAT0>,
diff --git a/arch/arm64/boot/dts/mediatek/mt8183.dtsi b/arch/arm64/boot/dts/mediatek/mt8183.dtsi
index eaf3be4b3568..f3ab0cf7afca 100644
--- a/arch/arm64/boot/dts/mediatek/mt8183.dtsi
+++ b/arch/arm64/boot/dts/mediatek/mt8183.dtsi
@@ -442,9 +442,30 @@
 		};
 		scp_mem_reserved: scp_mem_region {
 			compatible = "shared-dma-pool";
-			reg = <0 0x50000000 0 0x2300000>;
+			reg = <0 0x50000000 0 0x2900000>;
 			no-map;
 		};
+		reserve-memory-cam_smem {
+			compatible = "mediatek,reserve-memory-cam_smem";
+			no-map;
+			size = <0 0x01400000>; /*20 MB share mem size */
+			alignment = <0 0x1000>;
+			alloc-ranges = <0 0x40000000 0 0x10000000>;
+		};
+		reserve-memory-dip_smem {
+			compatible = "mediatek,reserve-memory-dip_smem";
+			no-map;
+			size = <0 0x01A00000>;  /*26 MB share mem size */
+			alignment = <0 0x1000>;
+			alloc-ranges = <0 0x40000000 0 0x10000000>;
+		};
+		reserve-memory-fd_smem {
+			compatible = "mediatek,reserve-memory-fd_smem";
+			no-map;
+			size = <0 0x00100000>;  /*1 MB share mem size */
+			alignment = <0 0x1000>;
+			alloc-ranges = <0 0x40000000 0 0x10000000>;
+		};
 	};
 
 	timer {
@@ -648,8 +669,8 @@
 			reg = <0 0x10238000 0 0x4000>;
 			interrupts = <GIC_SPI 162 IRQ_TYPE_LEVEL_LOW>;
 			#mbox-cells = <3>;
-			#gce-event-cells = <1>;
-			#gce-subsys-cells = <2>;
+			#event-cells = <1>;
+			#subsys-cells = <3>;
 			clocks = <&infracfg CLK_INFRA_GCE>;
 			clock-names = "gce";
 		};
@@ -674,7 +695,7 @@
 			clocks = <&infracfg CLK_INFRA_SCPSYS>;
 			clock-names = "main";
 			memory-region = <&scp_mem_reserved>;
-			status = "disabled";
+			status = "okay";
 		};
 
 		auxadc: auxadc@11001000 {
@@ -1439,9 +1460,169 @@
 		mmsys: syscon@14000000 {
 			compatible = "mediatek,mt8183-mmsys", "syscon";
 			reg = <0 0x14000000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0 0x1000>;
 			#clock-cells = <1>;
 		};
 
+		mdp_camin@14000000 {
+			compatible = "mediatek,mt8183-mdp-dl";
+			mediatek,mdp-id = <0>;
+			reg = <0 0x14000000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0 0x1000>;
+			clocks = <&mmsys CLK_MM_MDP_DL_TXCK>,
+				<&mmsys CLK_MM_MDP_DL_RX>;
+		};
+
+		mdp_camin2@14000000 {
+			compatible = "mediatek,mt8183-mdp-dl";
+			mediatek,mdp-id = <1>;
+			reg = <0 0x14000000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0 0x1000>;
+			clocks = <&mmsys CLK_MM_IPU_DL_TXCK>,
+				<&mmsys CLK_MM_IPU_DL_RX>;
+		};
+
+		mdp_rdma0: mdp_rdma0@14001000 {
+			compatible = "mediatek,mt8183-mdp-rdma",
+				     "mediatek,mt8183-mdp3";
+			mediatek,vpu = <&vpu>;
+			mediatek,scp = <&scp>;
+			mediatek,mdp-id = <0>;
+			reg = <0 0x14001000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0x1000 0x1000>;
+			power-domains = <&scpsys MT8183_POWER_DOMAIN_DISP>;
+			clocks = <&mmsys CLK_MM_MDP_RDMA0>,
+				<&mmsys CLK_MM_MDP_RSZ1>;
+			iommus = <&iommu M4U_PORT_MDP_RDMA0>;
+			mediatek,larb = <&larb0>;
+			mediatek,mmsys = <&mmsys>;
+			mediatek,mm-mutex = <&mutex>;
+			mediatek,mailbox-gce = <&gce>;
+			mdp_rsz0 = <&mdp_rsz0>;
+			mdp_rsz1 = <&mdp_rsz1>;
+			mdp_wrot0 = <&mdp_wrot0>;
+			mdp_wdma0 = <&mdp_wdma>;
+			mdp_ccorr0 = <&mdp_ccorr>;
+			mboxes = <&gce 20 0 CMDQ_THR_PRIO_LOWEST>,
+				<&gce 21 0 CMDQ_THR_PRIO_LOWEST>,
+				<&gce 22 0 CMDQ_THR_PRIO_LOWEST>,
+				<&gce 23 0 CMDQ_THR_PRIO_LOWEST>;
+			gce-subsys = <&gce 0x14000000 SUBSYS_1400XXXX>,
+				<&gce 0x14010000 SUBSYS_1401XXXX>,
+				<&gce 0x14020000 SUBSYS_1402XXXX>,
+				<&gce 0x15020000 SUBSYS_1502XXXX>;
+			mediatek,gce-event-names = "rdma0_sof",
+				"rsz0_sof",
+				"rsz1_sof",
+				"tdshp0_sof",
+				"wrot0_sof",
+				"wdma0_sof",
+				"rdma0_done",
+				"wrot0_done",
+				"wdma0_done",
+				"isp_p2_0_done",
+				"isp_p2_1_done",
+				"isp_p2_2_done",
+				"isp_p2_3_done",
+				"isp_p2_4_done",
+				"isp_p2_5_done",
+				"isp_p2_6_done",
+				"isp_p2_7_done",
+				"isp_p2_8_done",
+				"isp_p2_9_done",
+				"isp_p2_10_done",
+				"isp_p2_11_done",
+				"isp_p2_12_done",
+				"isp_p2_13_done",
+				"isp_p2_14_done",
+				"wpe_done",
+				"wpe_b_done";
+			mediatek,gce-events = <&gce CMDQ_EVENT_MDP_RDMA0_SOF>,
+				<&gce CMDQ_EVENT_MDP_RSZ0_SOF>,
+				<&gce CMDQ_EVENT_MDP_RSZ1_SOF>,
+				<&gce CMDQ_EVENT_MDP_TDSHP_SOF>,
+				<&gce CMDQ_EVENT_MDP_WROT0_SOF>,
+				<&gce CMDQ_EVENT_MDP_WDMA0_SOF>,
+				<&gce CMDQ_EVENT_MDP_RDMA0_EOF>,
+				<&gce CMDQ_EVENT_MDP_WROT0_EOF>,
+				<&gce CMDQ_EVENT_MDP_WDMA0_EOF>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_0>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_1>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_2>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_3>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_4>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_5>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_6>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_7>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_8>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_9>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_10>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_11>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_12>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_13>,
+				<&gce CMDQ_EVENT_ISP_FRAME_DONE_P2_14>,
+				<&gce CMDQ_EVENT_WPE_A_DONE>,
+				<&gce CMDQ_EVENT_SPE_B_DONE>;
+		};
+
+		mdp_imgi@15020000 {
+			compatible = "mediatek,mt8183-mdp-imgi";
+			mediatek,mdp-id = <0>;
+			reg = <0 0x15020000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1502XXXX 0 0x1000>;
+		};
+
+		mdp_img2o@15020000 {
+			compatible = "mediatek,mt8183-mdp-exto";
+			mediatek,mdp-id = <1>;
+		};
+
+		mdp_rsz0: mdp_rsz0@14003000 {
+			compatible = "mediatek,mt8183-mdp-rsz";
+			mediatek,mdp-id = <0>;
+			reg = <0 0x14003000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0x3000 0x1000>;
+			clocks = <&mmsys CLK_MM_MDP_RSZ0>;
+		};
+
+		mdp_rsz1: mdp_rsz1@14004000 {
+			compatible = "mediatek,mt8183-mdp-rsz";
+			mediatek,mdp-id = <1>;
+			reg = <0 0x14004000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0x4000 0x1000>;
+			clocks = <&mmsys CLK_MM_MDP_RSZ1>;
+		};
+
+		mdp_wrot0: mdp_wrot0@14005000 {
+			compatible = "mediatek,mt8183-mdp-wrot";
+			mediatek,mdp-id = <0>;
+			reg = <0 0x14005000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0x5000 0x1000>;
+			clocks = <&mmsys CLK_MM_MDP_WROT0>;
+			iommus = <&iommu M4U_PORT_MDP_WROT0>;
+			mediatek,larb = <&larb0>;
+		};
+
+		mdp_path0_sout@14005000 {
+			compatible = "mediatek,mt8183-mdp-path";
+			mediatek,mdp-id = <0>;
+		};
+
+		mdp_wdma: mdp_wdma@14006000 {
+			compatible = "mediatek,mt8183-mdp-wdma";
+			mediatek,mdp-id = <0>;
+			reg = <0 0x14006000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1400XXXX 0x6000 0x1000>;
+			clocks = <&mmsys CLK_MM_MDP_WDMA0>;
+			iommus = <&iommu M4U_PORT_MDP_WDMA0>;
+			mediatek,larb = <&larb0>;
+		};
+
+		mdp_path1_sout@14006000 {
+			compatible = "mediatek,mt8183-mdp-path";
+			mediatek,mdp-id = <1>;
+		};
+
 		display_components: dispsys@14000000 {
 			compatible = "mediatek,mt8183-display";
 			reg = <0 0x14000000 0 0x1000>;
@@ -1559,6 +1740,7 @@
 		mutex: mutex@14016000 {
 			compatible = "mediatek,mt8183-disp-mutex";
 			reg = <0 0x14016000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1401XXXX 0x6000 0x1000>;
 			interrupts = <GIC_SPI 217 IRQ_TYPE_LEVEL_LOW>;
 			power-domains = <&scpsys MT8183_POWER_DOMAIN_DISP>;
 		};
@@ -1584,12 +1766,44 @@
 			power-domains = <&scpsys MT8183_POWER_DOMAIN_DISP>;
 		};
 
+		mdp_ccorr: mdp_ccorr@1401c000 {
+			compatible = "mediatek,mt8183-mdp-ccorr";
+			mediatek,mdp-id = <0>;
+			reg = <0 0x1401c000 0 0x1000>;
+			mediatek,gce-client-reg = <&gce SUBSYS_1401XXXX 0xc000 0x1000>;
+			clocks = <&mmsys CLK_MM_MDP_CCORR>;
+		};
+
 		imgsys: syscon@15020000 {
 			compatible = "mediatek,mt8183-imgsys", "syscon";
 			reg = <0 0x15020000 0 0x1000>;
 			#clock-cells = <1>;
 		};
 
+		dip_smem: dip_smem {
+			compatible = "mediatek,dip_smem";
+			mediatek,larb = <&larb5>;
+			iommus = <&iommu M4U_PORT_CAM_IMGI>;
+		};
+
+		dip: dip@15022000 {
+			compatible = "mediatek,mt8183-dip";
+			mediatek,larb = <&larb5>;
+			mediatek,mdp3 = <&mdp_rdma0>;
+			mediatek,vpu = <&vpu>;
+			mediatek,scp = <&scp>;
+			iommus = <&iommu M4U_PORT_CAM_IMGI>;
+			reg = <0 0x15022000 0 0x6000>;
+			interrupts = <GIC_SPI 268 IRQ_TYPE_LEVEL_LOW>;
+			clocks =
+					<&imgsys CLK_IMG_LARB5>,
+					<&imgsys CLK_IMG_DIP>;
+			clock-names =
+					"DIP_CG_IMG_LARB5",
+					"DIP_CG_IMG_DIP";
+			smem_device = <&dip_smem>;
+		};
+
 		larb5: larb@15021000 {
 			compatible = "mediatek,mt8183-smi-larb";
 			reg = <0 0x15021000 0 0x1000>;
@@ -1600,6 +1814,27 @@
 			power-domains = <&scpsys MT8183_POWER_DOMAIN_ISP>;
 		};
 
+		fd_smem: fd_smem {
+			compatible = "mediatek,fd_smem";
+			mediatek,larb = <&larb5>;
+			iommus = <&iommu M4U_PORT_CAM_IMGI>;
+		};
+
+		fd:fd@1502b000 {
+			compatible = "mediatek,fd";
+			mediatek,larb = <&larb5>;
+			mediatek,vpu = <&vpu>;
+			mediatek,scp = <&scp>;
+			iommus = <&iommu M4U_PORT_CAM_FDVT_RP>,
+				 <&iommu M4U_PORT_CAM_FDVT_WR>,
+				 <&iommu M4U_PORT_CAM_FDVT_RB>;
+			reg = <0 0x1502b000 0 0x1000>;
+			interrupts = <GIC_SPI 269 IRQ_TYPE_LEVEL_LOW>;
+			clocks = <&imgsys CLK_IMG_FDVT>;
+			clock-names = "FD_CLK_IMG_FD";
+			smem_device = <&fd_smem>;
+			};
+
 		larb2: larb@1502f000 {
 			compatible = "mediatek,mt8183-smi-larb";
 			reg = <0 0x1502f000 0 0x1000>;
@@ -1671,6 +1906,67 @@
 			#clock-cells = <1>;
 		};
 
+		cam_smem: cam_smem {
+			compatible = "mediatek,mt8183-cam_smem";
+			mediatek,larb = <&larb3>,
+					<&larb6>;
+			iommus = <&iommu M4U_PORT_CAM_LSCI0>,
+				 <&iommu M4U_PORT_CAM_LSCI1>,
+				 <&iommu M4U_PORT_CAM_BPCI>;
+		};
+
+		camisp: camisp@1a000000 {
+			compatible = "mediatek,mt8183-camisp", "syscon";
+			reg = <0 0x1a000000 0 0x1000>,
+			      <0 0x1a003000 0 0x1000>,
+			      <0 0x1a004000 0 0x2000>,
+			      <0 0x1a006000 0 0x2000>;
+			reg-names = "camisp",
+				    "cam1",
+				    "cam2",
+				    "cam3";
+			interrupts = <GIC_SPI 253 IRQ_TYPE_LEVEL_LOW>,
+				     <GIC_SPI 254 IRQ_TYPE_LEVEL_LOW>,
+				     <GIC_SPI 255 IRQ_TYPE_LEVEL_LOW>;
+			interrupt-names = "cam1",
+					  "cam2",
+					  "cam3";
+			iommus = <&iommu M4U_PORT_CAM_LSCI0>,
+				 <&iommu M4U_PORT_CAM_LSCI1>,
+				 <&iommu M4U_PORT_CAM_BPCI>;
+			#clock-cells = <1>;
+			power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
+			/* Camera CCF */
+			clocks = <&camsys CLK_CAM_CAM>,
+				 <&camsys CLK_CAM_CAMTG>;
+			clock-names = "CAMSYS_CAM_CGPDN",
+				      "CAMSYS_CAMTG_CGPDN";
+			mediatek,larb = <&larb3>,
+					<&larb6>;
+			mediatek,scp = <&scp>;
+			smem_device = <&cam_smem>;
+		};
+
+		camsv: camsv@1a000000 {
+			compatible = "mediatek,mt8183-camsv", "syscon";
+			reg = <0 0x1a000000 0 0x1000>;
+			#clock-cells = <1>;
+			power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
+			mediatek,smi = <&smi_common>;
+			clocks = <&camsys CLK_CAM_CAM>,
+					<&camsys CLK_CAM_CAMTG>,
+					<&camsys CLK_CAM_CAMSV0>,
+					<&camsys CLK_CAM_CAMSV1>,
+					<&camsys CLK_CAM_CAMSV2>;
+			clock-names = "CAMSYS_CAM_CGPDN",
+					"CAMSYS_CAMTG_CGPDN",
+					"CAMSYS_CAMSV0_CGPDN",
+					"CAMSYS_CAMSV1_CGPDN",
+					"CAMSYS_CAMSV2_CGPDN";
+			mediatek,larb = <&larb3>,
+					<&larb6>;
+		};
+
 		larb6: larb@1a001000 {
 			compatible = "mediatek,mt8183-smi-larb";
 			reg = <0 0x1a001000 0 0x1000>;
@@ -1690,5 +1986,53 @@
 			clock-names = "apb", "smi", "gals";
 			power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
 		};
+
+		camsv1@1a050000 {
+			compatible = "mediatek,camsv1";
+			reg = <0 0x1a050000 0 0x1000>;
+			interrupts = <GIC_SPI 258 IRQ_TYPE_LEVEL_LOW>;
+		};
+
+		camsv2@1a051000 {
+			compatible = "mediatek,camsv2";
+			reg = <0 0x1a051000 0 0x1000>;
+			interrupts = <GIC_SPI 259 IRQ_TYPE_LEVEL_LOW>;
+		};
+
+		camsv3@1a052000 {
+			compatible = "mediatek,camsv3";
+			reg = <0 0x1a052000 0 0x1000>;
+			interrupts = <GIC_SPI 260 IRQ_TYPE_LEVEL_LOW>;
+		};
+
+		camsv4@1a053000 {
+			compatible = "mediatek,camsv4";
+			reg = <0 0x1a053000 0 0x1000>;
+			interrupts = <GIC_SPI 261 IRQ_TYPE_LEVEL_LOW>;
+		};
+
+		camsv5@1a054000 {
+			compatible = "mediatek,camsv5";
+			reg = <0 0x1a054000 0 0x1000>;
+		};
+
+		camsv6@1a055000 {
+			compatible = "mediatek,camsv6";
+			reg = <0 0x1a055000 0 0x1000>;
+		};
+
+		seninf: seninf@1a040000 {
+			compatible = "mediatek,mt8183-seninf";
+			reg = <0 0x1a040000 0 0x8000>,
+			      <0 0x11C80000 0 0x6000>;
+			reg-names = "base_reg", "rx_reg";
+			interrupts = <GIC_SPI 251 IRQ_TYPE_LEVEL_LOW>;
+			power-domains = <&scpsys MT8183_POWER_DOMAIN_CAM>;
+			clocks =
+				<&camsys CLK_CAM_SENINF>, <&topckgen CLK_TOP_MUX_SENINF>;
+			clock-names =
+				"CLK_CAM_SENINF", "CLK_TOP_MUX_SENINF";
+			status = "disabled";
+		};
 	};
 };
diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c
index 9998d224c51a..fa0bd42d1a52 100644
--- a/arch/arm64/mm/dma-mapping.c
+++ b/arch/arm64/mm/dma-mapping.c
@@ -37,6 +37,9 @@ static int swiotlb __ro_after_init;
 static pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot,
 				 bool coherent)
 {
+	if (attrs & DMA_ATTR_NON_CONSISTENT)
+		return prot;
+
 	if (!coherent || (attrs & DMA_ATTR_WRITE_COMBINE))
 		return pgprot_writecombine(prot);
 	return prot;
@@ -766,7 +769,7 @@ static void __iommu_sync_sg_for_cpu(struct device *dev,
 		return;
 
 	for_each_sg(sgl, sg, nelems, i)
-		__dma_unmap_area(sg_virt(sg), sg->length, dir);
+			__dma_unmap_area(sg_virt(sg), sg->length, dir);
 }
 
 static void __iommu_sync_sg_for_device(struct device *dev,
diff --git a/chromeos/config/arm64/chromiumos-arm64.flavour.config b/chromeos/config/arm64/chromiumos-arm64.flavour.config
index 86ef390d6160..4a054df0d6cb 100644
--- a/chromeos/config/arm64/chromiumos-arm64.flavour.config
+++ b/chromeos/config/arm64/chromiumos-arm64.flavour.config
@@ -132,6 +132,7 @@ CONFIG_CROS_EC_RPMSG=m
 CONFIG_CRYPTO_DEV_ROCKCHIP=y
 CONFIG_CRYPTO_DEV_VIRTIO=m
 CONFIG_CRYPTO_ENGINE=m
+# CONFIG_CXD2880_SPI_DRV is not set
 # CONFIG_DEBUG_EFI is not set
 CONFIG_DEVPORT=y
 # CONFIG_DGNC is not set
@@ -179,10 +180,25 @@ CONFIG_DRM_PANEL_INNOLUX_P079ZCA=y
 CONFIG_DRM_TI_SN65DSI86=y
 CONFIG_DRM_TTM=y
 CONFIG_DRM_VIRTIO_GPU=y
+# CONFIG_DVB_AS102 is not set
+# CONFIG_DVB_B2C2_FLEXCOP_USB is not set
+CONFIG_DVB_CORE=y
+# CONFIG_DVB_DEMUX_SECTION_LOSS_LOG is not set
+# CONFIG_DVB_DYNAMIC_MINORS is not set
+CONFIG_DVB_MAX_ADAPTERS=16
+# CONFIG_DVB_MMAP is not set
+CONFIG_DVB_NET=y
+# CONFIG_DVB_PLATFORM_DRIVERS is not set
+# CONFIG_DVB_TTUSB_BUDGET is not set
+# CONFIG_DVB_TTUSB_DEC is not set
+# CONFIG_DVB_ULE_DEBUG is not set
+# CONFIG_DVB_USB is not set
+# CONFIG_DVB_USB_V2 is not set
 # CONFIG_DWMAC_IPQ806X is not set
 CONFIG_DWMAC_ROCKCHIP=m
 # CONFIG_DW_DMAC_PCI is not set
 CONFIG_DW_WATCHDOG=y
+CONFIG_DYNAMIC_DEBUG=y
 # CONFIG_E100 is not set
 # CONFIG_E1000 is not set
 # CONFIG_E1000E is not set
@@ -344,8 +360,23 @@ CONFIG_IOMMU_IO_PGTABLE_LPAE=y
 # CONFIG_MDM_LCC_9615 is not set
 # CONFIG_MEDIATEK_MT6577_AUXADC is not set
 CONFIG_MEDIATEK_WATCHDOG=y
-# CONFIG_MEDIA_CONTROLLER is not set
+CONFIG_MEDIA_ANALOG_TV_SUPPORT=y
+CONFIG_MEDIA_ATTACH=y
+CONFIG_MEDIA_CONTROLLER=y
+# CONFIG_MEDIA_CONTROLLER_DVB is not set
+CONFIG_MEDIA_DIGITAL_TV_SUPPORT=y
 # CONFIG_MEDIA_PCI_SUPPORT is not set
+CONFIG_MEDIA_TUNER=y
+CONFIG_MEDIA_TUNER_MC44S803=y
+CONFIG_MEDIA_TUNER_MT20XX=y
+CONFIG_MEDIA_TUNER_SIMPLE=y
+CONFIG_MEDIA_TUNER_TDA18271=y
+CONFIG_MEDIA_TUNER_TDA827X=y
+CONFIG_MEDIA_TUNER_TDA8290=y
+CONFIG_MEDIA_TUNER_TDA9887=y
+CONFIG_MEDIA_TUNER_XC2028=y
+CONFIG_MEDIA_TUNER_XC4000=y
+CONFIG_MEDIA_TUNER_XC5000=y
 # CONFIG_MEGARAID_LEGACY is not set
 # CONFIG_MEGARAID_NEWGEN is not set
 # CONFIG_MEGARAID_SAS is not set
@@ -400,8 +431,9 @@ CONFIG_MTK_EMI_MBW=y
 CONFIG_MTK_INFRACFG=y
 CONFIG_MTK_IOMMU=y
 CONFIG_MTK_PMIC_WRAP=y
-CONFIG_MTK_SCP=m
+CONFIG_MTK_SCP=y
 CONFIG_MTK_SCPSYS=y
+CONFIG_MTK_SENINF=y
 CONFIG_MTK_SMI=y
 CONFIG_MTK_THERMAL=y
 CONFIG_MTK_TIMER=y
@@ -673,7 +705,7 @@ CONFIG_ROCKCHIP_THERMAL=y
 CONFIG_ROCKCHIP_TIMER=y
 CONFIG_RPMSG=y
 CONFIG_RPMSG_CHAR=y
-CONFIG_RPMSG_MTK_SCP=m
+CONFIG_RPMSG_MTK_SCP=y
 CONFIG_RPMSG_QCOM_GLINK_NATIVE=y
 CONFIG_RPMSG_QCOM_GLINK_SMEM=y
 CONFIG_RPMSG_QCOM_SMD=y
@@ -803,6 +835,8 @@ CONFIG_SKY2=m
 # CONFIG_SKY2_DEBUG is not set
 # CONFIG_SLICOSS is not set
 # CONFIG_SMSC9420 is not set
+# CONFIG_SMS_SDIO_DRV is not set
+# CONFIG_SMS_USB_DRV is not set
 # CONFIG_SND_AD1889 is not set
 # CONFIG_SND_ATIIXP is not set
 # CONFIG_SND_ATIIXP_MODEM is not set
@@ -891,6 +925,7 @@ CONFIG_SND_SOC_RT5677_SPI=y
 # CONFIG_SND_VIRTUOSO is not set
 # CONFIG_SND_VX222 is not set
 # CONFIG_SND_YMFPCI is not set
+# CONFIG_SOC_CAMERA is not set
 CONFIG_SPI_BITBANG=y
 CONFIG_SPI_GPIO=y
 CONFIG_SPI_MT65XX=y
@@ -953,19 +988,45 @@ CONFIG_USB_U_SERIAL=y
 CONFIG_USB_XHCI_MTK=y
 CONFIG_USB_XHCI_PCI=y
 # CONFIG_U_SERIAL_CONSOLE is not set
+CONFIG_V4L2_FWNODE=y
 CONFIG_V4L2_MEM2MEM_DEV=y
+CONFIG_V4L_PLATFORM_DRIVERS=y
 CONFIG_VGA_ARB=y
 CONFIG_VGA_ARB_MAX_GPUS=16
 CONFIG_VIDEOBUF2_CORE=y
 CONFIG_VIDEOBUF2_DMA_CONTIG=y
 CONFIG_VIDEOBUF2_MEMOPS=y
 CONFIG_VIDEOBUF2_V4L2=y
-CONFIG_VIDEO_MEDIATEK_MDP=y
+CONFIG_VIDEOBUF2_VMALLOC=y
+# CONFIG_VIDEO_AU0828 is not set
+# CONFIG_VIDEO_CADENCE is not set
+# CONFIG_VIDEO_CAFE_CCIC is not set
+# CONFIG_VIDEO_CX231XX is not set
+# CONFIG_VIDEO_GO7007 is not set
+# CONFIG_VIDEO_HDPVR is not set
+# CONFIG_VIDEO_MEDIATEK_ISP_CAMSV_SUPPORT is not set
+CONFIG_VIDEO_MEDIATEK_ISP_DIP_SUPPORT=y
+CONFIG_VIDEO_MEDIATEK_ISP_FD_SUPPORT=y
+CONFIG_VIDEO_MEDIATEK_ISP_PASS1_SUPPORT=y
+# CONFIG_VIDEO_MEDIATEK_MDP is not set
+CONFIG_VIDEO_MEDIATEK_MDP3=y
 CONFIG_VIDEO_MEDIATEK_VCODEC=y
 CONFIG_VIDEO_MEDIATEK_VPU=y
+# CONFIG_VIDEO_MUX is not set
+CONFIG_VIDEO_OV2685=y
+CONFIG_VIDEO_OV5695=y
 # CONFIG_VIDEO_PCI_SKELETON is not set
+# CONFIG_VIDEO_PVRUSB2 is not set
+# CONFIG_VIDEO_QCOM_CAMSS is not set
 # CONFIG_VIDEO_QCOM_VENUS is not set
 # CONFIG_VIDEO_ROCKCHIP_RGA is not set
+# CONFIG_VIDEO_STK1160_COMMON is not set
+# CONFIG_VIDEO_TM6000 is not set
+# CONFIG_VIDEO_USBVISION is not set
+CONFIG_VIDEO_V4L2_SUBDEV_API=y
+# CONFIG_VIDEO_VICODEC is not set
+# CONFIG_VIDEO_VIMC is not set
+# CONFIG_VIDEO_XILINX is not set
 CONFIG_VIRTIO=y
 # CONFIG_VIRTIO_BALLOON is not set
 CONFIG_VIRTIO_BLK=y
diff --git a/chromeos/config/arm64/chromiumos-mediatek.flavour.config b/chromeos/config/arm64/chromiumos-mediatek.flavour.config
index cf176ec20448..74855922e1c7 100644
--- a/chromeos/config/arm64/chromiumos-mediatek.flavour.config
+++ b/chromeos/config/arm64/chromiumos-mediatek.flavour.config
@@ -61,6 +61,7 @@ CONFIG_COMMON_CLK_XGENE=y
 CONFIG_CROS_EC_RPMSG=m
 CONFIG_CRYPTO_DEV_VIRTIO=m
 CONFIG_CRYPTO_ENGINE=m
+# CONFIG_CXD2880_SPI_DRV is not set
 CONFIG_DRM_ANALOGIX_ANX78XX=y
 CONFIG_DRM_GEM_CMA_HELPER=y
 CONFIG_DRM_MEDIATEK=y
@@ -80,7 +81,20 @@ CONFIG_DRM_PANEL_INNOLUX_P079ZCA=y
 # CONFIG_DRM_PANEL_SHARP_LS043T1LE01 is not set
 # CONFIG_DRM_TI_SN65DSI86 is not set
 # CONFIG_DRM_VIRTIO_GPU is not set
+# CONFIG_DVB_AS102 is not set
+# CONFIG_DVB_B2C2_FLEXCOP_USB is not set
+CONFIG_DVB_CORE=y
+# CONFIG_DVB_DEMUX_SECTION_LOSS_LOG is not set
+# CONFIG_DVB_DYNAMIC_MINORS is not set
+CONFIG_DVB_MAX_ADAPTERS=16
+# CONFIG_DVB_MMAP is not set
+CONFIG_DVB_NET=y
+# CONFIG_DVB_PLATFORM_DRIVERS is not set
+# CONFIG_DVB_ULE_DEBUG is not set
+# CONFIG_DVB_USB is not set
+# CONFIG_DVB_USB_V2 is not set
 # CONFIG_DW_WATCHDOG is not set
+CONFIG_DYNAMIC_DEBUG=y
 # CONFIG_EDAC is not set
 # CONFIG_EFI is not set
 CONFIG_EINT_MTK=y
@@ -113,8 +127,23 @@ CONFIG_MALI_PLATFORM_NAME="mediatek"
 # CONFIG_MALI_PWRSOFT_765 is not set
 # CONFIG_MEDIATEK_MT6577_AUXADC is not set
 CONFIG_MEDIATEK_WATCHDOG=y
+CONFIG_MEDIA_ANALOG_TV_SUPPORT=y
+CONFIG_MEDIA_ATTACH=y
 CONFIG_MEDIA_CONTROLLER=y
+# CONFIG_MEDIA_CONTROLLER_DVB is not set
 CONFIG_MEDIA_CONTROLLER_REQUEST_API=y
+CONFIG_MEDIA_DIGITAL_TV_SUPPORT=y
+CONFIG_MEDIA_TUNER=y
+CONFIG_MEDIA_TUNER_MC44S803=y
+CONFIG_MEDIA_TUNER_MT20XX=y
+CONFIG_MEDIA_TUNER_SIMPLE=y
+CONFIG_MEDIA_TUNER_TDA18271=y
+CONFIG_MEDIA_TUNER_TDA827X=y
+CONFIG_MEDIA_TUNER_TDA8290=y
+CONFIG_MEDIA_TUNER_TDA9887=y
+CONFIG_MEDIA_TUNER_XC2028=y
+CONFIG_MEDIA_TUNER_XC4000=y
+CONFIG_MEDIA_TUNER_XC5000=y
 # CONFIG_MFD_PALMAS is not set
 # CONFIG_MFD_RK808 is not set
 # CONFIG_MMC_DW is not set
@@ -130,8 +159,9 @@ CONFIG_MTK_EMI_MBW=y
 CONFIG_MTK_INFRACFG=y
 CONFIG_MTK_IOMMU=y
 CONFIG_MTK_PMIC_WRAP=y
-CONFIG_MTK_SCP=m
+CONFIG_MTK_SCP=y
 CONFIG_MTK_SCPSYS=y
+CONFIG_MTK_SENINF=y
 CONFIG_MTK_SMI=y
 CONFIG_MTK_THERMAL=y
 CONFIG_MTK_TIMER=y
@@ -164,9 +194,9 @@ CONFIG_REGULATOR_MT6358=y
 # CONFIG_REGULATOR_TPS6586X is not set
 CONFIG_REMOTEPROC=y
 # CONFIG_RMNET is not set
-CONFIG_RPMSG=m
+CONFIG_RPMSG=y
 # CONFIG_RPMSG_CHAR is not set
-CONFIG_RPMSG_MTK_SCP=m
+CONFIG_RPMSG_MTK_SCP=y
 # CONFIG_RTC_DRV_AS3722 is not set
 CONFIG_RTC_DRV_MT6397=y
 # CONFIG_RTC_DRV_MT7622 is not set
@@ -182,6 +212,8 @@ CONFIG_SERIAL_8250_MT6577=y
 # CONFIG_SERIAL_AMBA_PL011 is not set
 CONFIG_SERIAL_DEV_BUS=y
 CONFIG_SERIAL_DEV_CTRL_TTYPORT=y
+# CONFIG_SMS_SDIO_DRV is not set
+# CONFIG_SMS_USB_DRV is not set
 CONFIG_SND_SOC_BT_SCO=y
 CONFIG_SND_SOC_MAX98357A=y
 CONFIG_SND_SOC_MEDIATEK=y
@@ -201,6 +233,7 @@ CONFIG_SND_SOC_RT5514=y
 CONFIG_SND_SOC_RT5645=y
 CONFIG_SND_SOC_RT5677=y
 CONFIG_SND_SOC_RT5677_SPI=y
+# CONFIG_SOC_CAMERA is not set
 CONFIG_SPI_BITBANG=y
 CONFIG_SPI_GPIO=y
 CONFIG_SPI_MT65XX=y
@@ -229,15 +262,38 @@ CONFIG_USB_MTU3_DUAL_ROLE=y
 CONFIG_USB_U_SERIAL=y
 CONFIG_USB_XHCI_MTK=y
 # CONFIG_U_SERIAL_CONSOLE is not set
+CONFIG_V4L2_FWNODE=y
 CONFIG_V4L2_MEM2MEM_DEV=y
+CONFIG_V4L_PLATFORM_DRIVERS=y
 CONFIG_VIDEOBUF2_CORE=y
 CONFIG_VIDEOBUF2_DMA_CONTIG=y
 CONFIG_VIDEOBUF2_MEMOPS=y
 CONFIG_VIDEOBUF2_V4L2=y
-CONFIG_VIDEO_MEDIATEK_MDP=y
+CONFIG_VIDEOBUF2_VMALLOC=y
+# CONFIG_VIDEO_AU0828 is not set
+# CONFIG_VIDEO_CADENCE is not set
+# CONFIG_VIDEO_CX231XX is not set
+# CONFIG_VIDEO_GO7007 is not set
+# CONFIG_VIDEO_HDPVR is not set
+# CONFIG_VIDEO_MEDIATEK_ISP_CAMSV_SUPPORT is not set
+CONFIG_VIDEO_MEDIATEK_ISP_DIP_SUPPORT=y
+CONFIG_VIDEO_MEDIATEK_ISP_FD_SUPPORT=y
+CONFIG_VIDEO_MEDIATEK_ISP_PASS1_SUPPORT=y
+# CONFIG_VIDEO_MEDIATEK_MDP is not set
+CONFIG_VIDEO_MEDIATEK_MDP3=y
 CONFIG_VIDEO_MEDIATEK_VCODEC=y
 CONFIG_VIDEO_MEDIATEK_VPU=y
-# CONFIG_VIDEO_V4L2_SUBDEV_API is not set
+# CONFIG_VIDEO_MUX is not set
+CONFIG_VIDEO_OV2685=y
+CONFIG_VIDEO_OV5695=y
+# CONFIG_VIDEO_PVRUSB2 is not set
+# CONFIG_VIDEO_STK1160_COMMON is not set
+# CONFIG_VIDEO_TM6000 is not set
+# CONFIG_VIDEO_USBVISION is not set
+CONFIG_VIDEO_V4L2_SUBDEV_API=y
+# CONFIG_VIDEO_VICODEC is not set
+# CONFIG_VIDEO_VIMC is not set
+# CONFIG_VIDEO_XILINX is not set
 CONFIG_VIRTIO=y
 # CONFIG_VIRTIO_BALLOON is not set
 # CONFIG_VIRTIO_BLK is not set
diff --git a/chromeos/config/arm64/chromiumos-qualcomm.flavour.config b/chromeos/config/arm64/chromiumos-qualcomm.flavour.config
index df8dee5a9ad2..4eef80d63014 100644
--- a/chromeos/config/arm64/chromiumos-qualcomm.flavour.config
+++ b/chromeos/config/arm64/chromiumos-qualcomm.flavour.config
@@ -77,6 +77,7 @@ CONFIG_DRM_TI_SN65DSI86=y
 # CONFIG_DRM_VIRTIO_GPU is not set
 # CONFIG_DWMAC_IPQ806X is not set
 # CONFIG_DW_WATCHDOG is not set
+# CONFIG_DYNAMIC_DEBUG is not set
 CONFIG_EDAC=y
 # CONFIG_EDAC_DEBUG is not set
 # CONFIG_EDAC_LEGACY_SYSFS is not set
@@ -110,7 +111,9 @@ CONFIG_IOMMU_IO_PGTABLE_LPAE=y
 # CONFIG_MALI_MIDGARD is not set
 # CONFIG_MDM_GCC_9615 is not set
 # CONFIG_MDM_LCC_9615 is not set
+# CONFIG_MEDIA_ANALOG_TV_SUPPORT is not set
 # CONFIG_MEDIA_CONTROLLER is not set
+# CONFIG_MEDIA_DIGITAL_TV_SUPPORT is not set
 # CONFIG_MFD_PALMAS is not set
 # CONFIG_MFD_QCOM_RPM is not set
 # CONFIG_MFD_RK808 is not set
@@ -286,9 +289,11 @@ CONFIG_USB_CONFIGFS=m
 CONFIG_USB_DWC3_QCOM=y
 CONFIG_USB_F_FS=m
 CONFIG_USB_LIBCOMPOSITE=m
+# CONFIG_V4L_PLATFORM_DRIVERS is not set
 CONFIG_VIDEOBUF2_CORE=m
 CONFIG_VIDEOBUF2_MEMOPS=m
 CONFIG_VIDEOBUF2_V4L2=m
+CONFIG_VIDEOBUF2_VMALLOC=m
 # CONFIG_VIDEO_QCOM_VENUS is not set
 CONFIG_VIRTIO=y
 # CONFIG_VIRTIO_BALLOON is not set
diff --git a/chromeos/config/arm64/chromiumos-rockchip64.flavour.config b/chromeos/config/arm64/chromiumos-rockchip64.flavour.config
index 74542fedbd29..43d65f15f7a9 100644
--- a/chromeos/config/arm64/chromiumos-rockchip64.flavour.config
+++ b/chromeos/config/arm64/chromiumos-rockchip64.flavour.config
@@ -90,6 +90,7 @@ CONFIG_DRM_ROCKCHIP=y
 CONFIG_DWMAC_ROCKCHIP=m
 # CONFIG_DW_DMAC_PCI is not set
 CONFIG_DW_WATCHDOG=y
+# CONFIG_DYNAMIC_DEBUG is not set
 # CONFIG_E100 is not set
 # CONFIG_E1000 is not set
 # CONFIG_E1000E is not set
@@ -204,7 +205,9 @@ CONFIG_I2C_RK3X=y
 # CONFIG_LPC_SCH is not set
 # CONFIG_MALI_MIDGARD is not set
 # CONFIG_MDIO_THUNDER is not set
+# CONFIG_MEDIA_ANALOG_TV_SUPPORT is not set
 # CONFIG_MEDIA_CONTROLLER is not set
+# CONFIG_MEDIA_DIGITAL_TV_SUPPORT is not set
 # CONFIG_MEDIA_PCI_SUPPORT is not set
 # CONFIG_MEGARAID_LEGACY is not set
 # CONFIG_MEGARAID_NEWGEN is not set
@@ -561,11 +564,13 @@ CONFIG_USB_OHCI_HCD_PCI=y
 CONFIG_USB_PCI=y
 # CONFIG_USB_UHCI_HCD is not set
 CONFIG_USB_XHCI_PCI=y
+# CONFIG_V4L_PLATFORM_DRIVERS is not set
 CONFIG_VGA_ARB=y
 CONFIG_VGA_ARB_MAX_GPUS=16
 CONFIG_VIDEOBUF2_CORE=m
 CONFIG_VIDEOBUF2_MEMOPS=m
 CONFIG_VIDEOBUF2_V4L2=m
+CONFIG_VIDEOBUF2_VMALLOC=m
 # CONFIG_VIDEO_ROCKCHIP_RGA is not set
 # CONFIG_VIRTIO_MMIO is not set
 # CONFIG_VIRTIO_PCI is not set
diff --git a/chromeos/config/arm64/common.config b/chromeos/config/arm64/common.config
index 7073cb8566dc..e31977035cfe 100644
--- a/chromeos/config/arm64/common.config
+++ b/chromeos/config/arm64/common.config
@@ -161,7 +161,7 @@ CONFIG_CHARGER_CROS_USBPD=y
 CONFIG_CHARGER_GPIO=y
 # CONFIG_CHARGER_MANAGER is not set
 # CONFIG_CHARGER_TPS65090 is not set
-CONFIG_CLANG_VERSION=80000
+CONFIG_CLANG_VERSION=90000
 # CONFIG_CLK_HSDK is not set
 # CONFIG_CLK_QORIQ is not set
 # CONFIG_CLOCK_THERMAL is not set
diff --git a/chromeos/config/armel/common.config b/chromeos/config/armel/common.config
index d7ddad0f26b4..fb97c7f686c2 100644
--- a/chromeos/config/armel/common.config
+++ b/chromeos/config/armel/common.config
@@ -333,6 +333,7 @@ CONFIG_DW_APB_TIMER_OF=y
 # CONFIG_DW_AXI_DMAC is not set
 # CONFIG_DW_DMAC is not set
 CONFIG_DW_WATCHDOG=y
+# CONFIG_DYNAMIC_DEBUG is not set
 CONFIG_DYNAMIC_FTRACE_WITH_REGS=y
 CONFIG_EDAC_ATOMIC_SCRUB=y
 # CONFIG_EEPROM_93CX6 is not set
@@ -487,8 +488,9 @@ CONFIG_LIBFDT=y
 # CONFIG_MDIO_BUS_MUX_GPIO is not set
 # CONFIG_MDIO_BUS_MUX_MMIOREG is not set
 # CONFIG_MDIO_HISI_FEMAC is not set
-CONFIG_MEDIA_CONTROLLER=y
-CONFIG_MEDIA_CONTROLLER_REQUEST_API=y
+# CONFIG_MEDIA_ANALOG_TV_SUPPORT is not set
+# CONFIG_MEDIA_CONTROLLER is not set
+# CONFIG_MEDIA_DIGITAL_TV_SUPPORT is not set
 CONFIG_MEDIA_SUBDRV_AUTOSELECT=y
 # CONFIG_MELLANOX_PLATFORM is not set
 CONFIG_MEMORY=y
@@ -890,6 +892,7 @@ CONFIG_USB_LIBCOMPOSITE=m
 CONFIG_USE_OF=y
 CONFIG_V4L2_MEM2MEM_DEV=m
 CONFIG_V4L_MEM2MEM_DRIVERS=y
+# CONFIG_V4L_PLATFORM_DRIVERS is not set
 CONFIG_VDSO=y
 # CONFIG_VEXPRESS_CONFIG is not set
 # CONFIG_VF610_ADC is not set
@@ -901,6 +904,7 @@ CONFIG_VIDEOBUF2_CORE=m
 CONFIG_VIDEOBUF2_DMA_CONTIG=m
 CONFIG_VIDEOBUF2_MEMOPS=m
 CONFIG_VIDEOBUF2_V4L2=m
+CONFIG_VIDEOBUF2_VMALLOC=m
 CONFIG_VIDEOMODE_HELPERS=y
 # CONFIG_VIDEO_MEM2MEM_DEINTERLACE is not set
 # CONFIG_VIDEO_ROCKCHIP_RGA is not set
diff --git a/chromeos/config/base.config b/chromeos/config/base.config
index f9fcd8e0e4ea..d78bb62f5549 100644
--- a/chromeos/config/base.config
+++ b/chromeos/config/base.config
@@ -669,7 +669,6 @@ CONFIG_DST_CACHE=y
 CONFIG_DUMMY_CONSOLE=y
 # CONFIG_DUMMY_IRQ is not set
 # CONFIG_DWC_XLGMAC is not set
-# CONFIG_DYNAMIC_DEBUG is not set
 CONFIG_DYNAMIC_FTRACE=y
 # CONFIG_ECHO is not set
 CONFIG_ECRYPT_FS=y
@@ -1481,10 +1480,8 @@ CONFIG_MD=y
 CONFIG_MDIO_BUS=y
 CONFIG_MDIO_DEVICE=y
 # CONFIG_MDIO_MSCC_MIIM is not set
-# CONFIG_MEDIA_ANALOG_TV_SUPPORT is not set
 CONFIG_MEDIA_CAMERA_SUPPORT=y
 # CONFIG_MEDIA_CEC_SUPPORT is not set
-# CONFIG_MEDIA_DIGITAL_TV_SUPPORT is not set
 # CONFIG_MEDIA_RADIO_SUPPORT is not set
 # CONFIG_MEDIA_SDR_SUPPORT is not set
 CONFIG_MEDIA_SUPPORT=y
@@ -3218,7 +3215,6 @@ CONFIG_USB_VIDEO_CLASS=m
 CONFIG_USER_NS=y
 CONFIG_UTS_NS=y
 # CONFIG_UWB is not set
-# CONFIG_V4L_PLATFORM_DRIVERS is not set
 CONFIG_V4L_TEST_DRIVERS=y
 # CONFIG_VCNL4000 is not set
 # CONFIG_VEML6070 is not set
@@ -3226,7 +3222,6 @@ CONFIG_VETH=m
 CONFIG_VFAT_FS=m
 # CONFIG_VIA_RHINE is not set
 # CONFIG_VIA_VELOCITY is not set
-CONFIG_VIDEOBUF2_VMALLOC=m
 # CONFIG_VIDEO_ADV_DEBUG is not set
 # CONFIG_VIDEO_CPIA2 is not set
 CONFIG_VIDEO_DEV=y
diff --git a/chromeos/config/x86_64/common.config b/chromeos/config/x86_64/common.config
index 89cc91210bc5..e0df649342f4 100644
--- a/chromeos/config/x86_64/common.config
+++ b/chromeos/config/x86_64/common.config
@@ -350,6 +350,7 @@ CONFIG_DUMMY_CONSOLE_COLUMNS=80
 CONFIG_DUMMY_CONSOLE_ROWS=25
 # CONFIG_DW_DMAC_PCI is not set
 # CONFIG_DW_WATCHDOG is not set
+# CONFIG_DYNAMIC_DEBUG is not set
 CONFIG_DYNAMIC_FTRACE_WITH_REGS=y
 CONFIG_DYNAMIC_MEMORY_LAYOUT=y
 CONFIG_E100=m
@@ -706,6 +707,8 @@ CONFIG_MAILBOX=y
 # CONFIG_MAXSMP is not set
 # CONFIG_MCORE2 is not set
 # CONFIG_MDIO_THUNDER is not set
+# CONFIG_MEDIA_ANALOG_TV_SUPPORT is not set
+# CONFIG_MEDIA_DIGITAL_TV_SUPPORT is not set
 CONFIG_MEDIA_PCI_SUPPORT=y
 # CONFIG_MEGARAID_LEGACY is not set
 # CONFIG_MEGARAID_NEWGEN is not set
@@ -1300,6 +1303,7 @@ CONFIG_USB_XHCI_PCI=y
 CONFIG_USB_XHCI_PLATFORM=m
 CONFIG_USER_STACKTRACE_SUPPORT=y
 # CONFIG_V4L_MEM2MEM_DRIVERS is not set
+# CONFIG_V4L_PLATFORM_DRIVERS is not set
 # CONFIG_VGACON_SOFT_SCROLLBACK is not set
 # CONFIG_VGA_ARB is not set
 CONFIG_VGA_CONSOLE=y
@@ -1310,6 +1314,7 @@ CONFIG_VGA_CONSOLE=y
 CONFIG_VIDEOBUF2_CORE=m
 CONFIG_VIDEOBUF2_MEMOPS=m
 CONFIG_VIDEOBUF2_V4L2=m
+CONFIG_VIDEOBUF2_VMALLOC=m
 # CONFIG_VIDEO_SOLO6X10 is not set
 # CONFIG_VIDEO_TW5864 is not set
 # CONFIG_VIDEO_TW68 is not set
diff --git a/drivers/clk/mediatek/clkchk-mt8183.c b/drivers/clk/mediatek/clkchk-mt8183.c
new file mode 100644
index 000000000000..99813e053fca
--- /dev/null
+++ b/drivers/clk/mediatek/clkchk-mt8183.c
@@ -0,0 +1,409 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+// Author: Weiyi Lu <weiyi.lu@mediatek.com>
+
+#include <linux/module.h>
+#include "clkchk.h"
+
+static const char * const off_pll_names[] = {
+	"armpll_ll",
+	"armpll_l",
+	"ccipll",
+	"mainpll",
+	"univ2pll",
+	"msdcpll",
+	"mmpll",
+	"mfgpll",
+	"tvdpll",
+	"apll1",
+	"apll2",
+	NULL
+};
+
+static const char * const all_clk_names[] = {
+	"armpll_ll",
+	"armpll_l",
+	"ccipll",
+	"mainpll",
+	"univ2pll",
+	"msdcpll",
+	"mmpll",
+	"mfgpll",
+	"tvdpll",
+	"apll1",
+	"apll2",
+	"apmixed_ssusb26m",
+	"apmixed_appll26m",
+	"apmixed_mipic026m",
+	"apmixed_mdpll26m",
+	"apmixed_mmsys26m",
+	"apmixed_ufs26m",
+	"apmixed_mipic126m",
+	"apmixed_mempll26m",
+	"apmixed_lvpll26m",
+	"apmixed_mipid026m",
+	"apmixed_mipid126m",
+	"syspll_ck",
+	"syspll_d2",
+	"syspll_d3",
+	"syspll_d5",
+	"syspll_d7",
+	"syspll_d2_d2",
+	"syspll_d2_d4",
+	"syspll_d2_d8",
+	"syspll_d2_d16",
+	"syspll_d3_d2",
+	"syspll_d3_d4",
+	"syspll_d3_d8",
+	"syspll_d5_d2",
+	"syspll_d5_d4",
+	"syspll_d7_d2",
+	"syspll_d7_d4",
+	"univpll_ck",
+	"univpll_d2",
+	"univpll_d3",
+	"univpll_d5",
+	"univpll_d7",
+	"univpll_d2_d2",
+	"univpll_d2_d4",
+	"univpll_d2_d8",
+	"univpll_d3_d2",
+	"univpll_d3_d4",
+	"univpll_d3_d8",
+	"univpll_d5_d2",
+	"univpll_d5_d4",
+	"univpll_d5_d8",
+	"apll1_ck",
+	"apll1_d2",
+	"apll1_d4",
+	"apll1_d8",
+	"apll2_ck",
+	"apll2_d2",
+	"apll2_d4",
+	"apll2_d8",
+	"tvdpll_ck",
+	"tvdpll_d2",
+	"tvdpll_d4",
+	"tvdpll_d8",
+	"tvdpll_d16",
+	"msdcpll_ck",
+	"msdcpll_d2",
+	"msdcpll_d4",
+	"msdcpll_d8",
+	"msdcpll_d16",
+	"ad_osc_ck",
+	"osc_d2",
+	"osc_d4",
+	"osc_d8",
+	"osc_d16",
+	"csw_f26m_ck_d2",
+	"mfgpll_ck",
+	"univ_192m_ck",
+	"univ_192m_d2",
+	"univ_192m_d4",
+	"univ_192m_d8",
+	"univ_192m_d16",
+	"univ_192m_d32",
+	"mmpll_ck",
+	"mmpll_d4",
+	"mmpll_d4_d2",
+	"mmpll_d4_d4",
+	"mmpll_d5",
+	"mmpll_d5_d2",
+	"mmpll_d5_d4",
+	"mmpll_d6",
+	"mmpll_d7",
+	"f_f26m_ck",
+	"clk13m",
+	"osc",
+	"univpll_192m",
+	"apll_i2s0_sel",
+	"apll_i2s1_sel",
+	"apll_i2s2_sel",
+	"apll_i2s3_sel",
+	"apll_i2s4_sel",
+	"apll_i2s5_sel",
+	"apll12_div0",
+	"apll12_div1",
+	"apll12_div2",
+	"apll12_div3",
+	"apll12_div4",
+	"apll12_divb",
+	"univpll",
+	"armpll_div_pll1",
+	"armpll_div_pll2",
+	"axi_sel",
+	"mm_sel",
+	"cam_sel",
+	"mfg_sel",
+	"camtg_sel",
+	"uart_sel",
+	"spi_sel",
+	"msdc50_hclk_sel",
+	"msdc50_0_sel",
+	"msdc30_1_sel",
+	"msdc30_2_sel",
+	"audio_sel",
+	"aud_intbus_sel",
+	"fpwrap_ulposc_sel",
+	"scp_sel",
+	"atb_sel",
+	"sspm_sel",
+	"dpi0_sel",
+	"scam_sel",
+	"aud_1_sel",
+	"aud_2_sel",
+	"disppwm_sel",
+	"ssusb_top_xhci_sel",
+	"usb_top_sel",
+	"spm_sel",
+	"i2c_sel",
+	"f52m_mfg_sel",
+	"seninf_sel",
+	"dxcc_sel",
+	"camtg2_sel",
+	"aud_eng1_sel",
+	"aud_eng2_sel",
+	"faes_ufsfde_sel",
+	"fufs_sel",
+	"img_sel",
+	"dsp_sel",
+	"dsp1_sel",
+	"dsp2_sel",
+	"ipu_if_sel",
+	"camtg3_sel",
+	"camtg4_sel",
+	"pmicspi_sel",
+	"mcu_mp0_sel",
+	"mcu_mp2_sel",
+	"mcu_bus_sel",
+	"infra_pmic_tmr",
+	"infra_pmic_ap",
+	"infra_pmic_md",
+	"infra_pmic_conn",
+	"infra_scp",
+	"infra_sej",
+	"infra_apxgpt",
+	"infra_icusb",
+	"infra_gce",
+	"infra_therm",
+	"infra_i2c0",
+	"infra_i2c1",
+	"infra_i2c2",
+	"infra_i2c3",
+	"infra_pwm_hclk",
+	"infra_pwm1",
+	"infra_pwm2",
+	"infra_pwm3",
+	"infra_pwm4",
+	"infra_pwm",
+	"infra_uart0",
+	"infra_uart1",
+	"infra_uart2",
+	"infra_uart3",
+	"infra_gce_26m",
+	"infra_cqdma_fpc",
+	"infra_btif",
+	"infra_spi0",
+	"infra_msdc0",
+	"infra_msdc1",
+	"infra_msdc2",
+	"infra_msdc0_sck",
+	"infra_dvfsrc",
+	"infra_gcpu",
+	"infra_trng",
+	"infra_auxadc",
+	"infra_cpum",
+	"infra_ccif1_ap",
+	"infra_ccif1_md",
+	"infra_auxadc_md",
+	"infra_msdc1_sck",
+	"infra_msdc2_sck",
+	"infra_apdma",
+	"infra_xiu",
+	"infra_device_apc",
+	"infra_ccif_ap",
+	"infra_debugsys",
+	"infra_audio",
+	"infra_ccif_md",
+	"infra_dxcc_sec_core",
+	"infra_dxcc_ao",
+	"infra_dramc_f26m",
+	"infra_irtx",
+	"infra_disppwm",
+	"infra_cldma_bclk",
+	"infra_audio_26m_bclk",
+	"infra_spi1",
+	"infra_i2c4",
+	"infra_md_tmp_share",
+	"infra_spi2",
+	"infra_spi3",
+	"infra_unipro_sck",
+	"infra_unipro_tick",
+	"infra_ufs_mp_sap_bck",
+	"infra_md32_bclk",
+	"infra_sspm",
+	"infra_unipro_mbist",
+	"infra_sspm_bus_hclk",
+	"infra_i2c5",
+	"infra_i2c5_arbiter",
+	"infra_i2c5_imm",
+	"infra_i2c1_arbiter",
+	"infra_i2c1_imm",
+	"infra_i2c2_arbiter",
+	"infra_i2c2_imm",
+	"infra_spi4",
+	"infra_spi5",
+	"infra_cqdma",
+	"infra_ufs",
+	"infra_aes_ufsfde",
+	"infra_ufs_tick",
+	"infra_msdc0_self",
+	"infra_msdc1_self",
+	"infra_msdc2_self",
+	"infra_sspm_26m_self",
+	"infra_sspm_32k_self",
+	"infra_ufs_axi",
+	"infra_i2c6",
+	"infra_ap_msdc0",
+	"infra_md_msdc0",
+	"infra_usb",
+	"infra_devmpu_bclk",
+	"infra_ccif2_ap",
+	"infra_ccif2_md",
+	"infra_ccif3_ap",
+	"infra_ccif3_md",
+	"infra_sej_f13m",
+	"infra_aes_bclk",
+	"infra_i2c7",
+	"infra_i2c8",
+	"infra_fbist2fpc",
+	"aud_tml",
+	"aud_dac_predis",
+	"aud_dac",
+	"aud_adc",
+	"aud_apll_tuner",
+	"aud_apll2_tuner",
+	"aud_24m",
+	"aud_22m",
+	"aud_afe",
+	"aud_i2s4",
+	"aud_i2s3",
+	"aud_i2s2",
+	"aud_i2s1",
+	"aud_pdn_adda6_adc",
+	"aud_tdm",
+	"mfg_bg3d",
+	"mm_smi_common",
+	"mm_smi_larb0",
+	"mm_smi_larb1",
+	"mm_gals_comm0",
+	"mm_gals_comm1",
+	"mm_gals_ccu2mm",
+	"mm_gals_ipu12mm",
+	"mm_gals_img2mm",
+	"mm_gals_cam2mm",
+	"mm_gals_ipu2mm",
+	"mm_mdp_dl_txck",
+	"mm_ipu_dl_txck",
+	"mm_mdp_rdma0",
+	"mm_mdp_rdma1",
+	"mm_mdp_rsz0",
+	"mm_mdp_rsz1",
+	"mm_mdp_tdshp",
+	"mm_mdp_wrot0",
+	"mm_fake_eng",
+	"mm_disp_ovl0",
+	"mm_disp_ovl0_2l",
+	"mm_disp_ovl1_2l",
+	"mm_disp_rdma0",
+	"mm_disp_rdma1",
+	"mm_disp_wdma0",
+	"mm_disp_color0",
+	"mm_disp_ccorr0",
+	"mm_disp_aal0",
+	"mm_disp_gamma0",
+	"mm_disp_dither0",
+	"mm_disp_split",
+	"mm_dsi0_mm",
+	"mm_dsi0_if",
+	"mm_dpi_mm",
+	"mm_dpi_if",
+	"mm_fake_eng2",
+	"mm_mdp_dl_rx",
+	"mm_ipu_dl_rx",
+	"mm_26m",
+	"mm_mmsys_r2y",
+	"mm_disp_rsz",
+	"mm_mdp_wdma0",
+	"mm_mdp_aal",
+	"mm_mdp_ccorr",
+	"mm_dbi_mm",
+	"mm_dbi_if",
+	"vdec_vdec",
+	"vdec_larb1",
+	"venc_larb",
+	"venc_venc",
+	"venc_jpgenc",
+	"img_owe",
+	"img_wpe_b",
+	"img_wpe_a",
+	"img_mfb",
+	"img_rsc",
+	"img_dpe",
+	"img_fdvt",
+	"img_dip",
+	"img_larb2",
+	"img_larb5",
+	"cam_larb6",
+	"cam_dfp_vad",
+	"cam_cam",
+	"cam_camtg",
+	"cam_seninf",
+	"cam_camsv0",
+	"cam_camsv1",
+	"cam_camsv2",
+	"cam_ccu",
+	"cam_larb3",
+	"ipu_conn_ipu",
+	"ipu_conn_ahb",
+	"ipu_conn_axi",
+	"ipu_conn_isp",
+	"ipu_conn_cam_adl",
+	"ipu_conn_img_adl",
+	"ipu_conn_dap_rx",
+	"ipu_conn_apb2axi",
+	"ipu_conn_apb2ahb",
+	"ipu_conn_ipu_cab1to2",
+	"ipu_conn_ipu1_cab1to2",
+	"ipu_conn_ipu2_cab1to2",
+	"ipu_conn_cab3to3",
+	"ipu_conn_cab2to1",
+	"ipu_conn_cab3to1_slice",
+	"ipu_adl_cabgen",
+	"ipu_core0_jtag",
+	"ipu_core0_axi",
+	"ipu_core0_ipu",
+	"ipu_core1_jtag",
+	"ipu_core1_axi",
+	"ipu_core1_ipu",
+	/* end */
+	NULL
+};
+
+static const char * const compatible[] = {"mediatek,mt8183", NULL};
+
+static struct clkchk_cfg_t cfg = {
+	.aee_excp_on_fail = false,
+	.warn_on_fail = true,
+	.compatible = compatible,
+	.off_pll_names = off_pll_names,
+	.all_clk_names = all_clk_names,
+};
+
+static int __init clkchk_platform_init(void)
+{
+	return clkchk_init(&cfg);
+}
+subsys_initcall(clkchk_platform_init);
diff --git a/drivers/clk/mediatek/clkchk.c b/drivers/clk/mediatek/clkchk.c
new file mode 100644
index 000000000000..d50110a0d538
--- /dev/null
+++ b/drivers/clk/mediatek/clkchk.c
@@ -0,0 +1,188 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+// Author: Weiyi Lu <weiyi.lu@mediatek.com>
+
+#define pr_fmt(fmt) "[clkchk] " fmt
+
+#include <linux/clk-provider.h>
+#include <linux/syscore_ops.h>
+#include "clkchk.h"
+
+#define AEE_EXCP_CHECK_PLL_FAIL	0
+#define CLKDBG_CCF_API_4_4	1
+#define MAX_PLLS		32
+
+#if AEE_EXCP_CHECK_PLL_FAIL
+#include <mt-plat/aee.h>
+#endif
+
+#if !CLKDBG_CCF_API_4_4
+
+/* backward compatible */
+
+static const char *clk_hw_get_name(const struct clk_hw *hw)
+{
+	return __clk_get_name(hw->clk);
+}
+
+static bool clk_hw_is_prepared(const struct clk_hw *hw)
+{
+	return __clk_is_prepared(hw->clk);
+}
+
+static bool clk_hw_is_enabled(const struct clk_hw *hw)
+{
+	return __clk_is_enabled(hw->clk);
+}
+
+static unsigned long clk_hw_get_rate(const struct clk_hw *hw)
+{
+	return __clk_get_rate(hw->clk);
+}
+
+static struct clk_hw *clk_hw_get_parent(const struct clk_hw *hw)
+{
+	return __clk_get_hw(clk_get_parent(hw->clk));
+}
+
+#endif /* !CLKDBG_CCF_API_4_4 */
+
+static struct clkchk_cfg_t *clkchk_cfg;
+
+static const char *ccf_state(struct clk_hw *hw)
+{
+	if (__clk_get_enable_count(hw->clk))
+		return "enabled";
+
+	if (clk_hw_is_prepared(hw))
+		return "prepared";
+
+	return "disabled";
+}
+
+static void print_enabled_clks(void)
+{
+	const char * const *cn = clkchk_cfg->all_clk_names;
+
+	pr_warn("enabled clks:\n");
+
+	for (; *cn != NULL; cn++) {
+		struct clk *c = __clk_lookup(*cn);
+		struct clk_hw *c_hw = __clk_get_hw(c);
+		struct clk_hw *p_hw;
+
+		if (IS_ERR_OR_NULL(c) || c_hw == NULL)
+			continue;
+
+		p_hw = clk_hw_get_parent(c_hw);
+
+		if (p_hw == NULL)
+			continue;
+
+		if (!clk_hw_is_prepared(c_hw) &&
+			__clk_get_enable_count(c) <= 0U)
+			continue;
+
+		pr_warn("[%-17s: %8s, %3d, %3d, %10ld, %17s]\n",
+			clk_hw_get_name(c_hw),
+			ccf_state(c_hw),
+			clk_hw_is_prepared(c_hw),
+			__clk_get_enable_count(c),
+			clk_hw_get_rate(c_hw),
+			p_hw != NULL ? clk_hw_get_name(p_hw) : "- ");
+	}
+}
+
+static void check_pll_off(void)
+{
+	static struct clk *off_plls[MAX_PLLS];
+
+	struct clk **c;
+	int invalid = 0;
+	char buf[128] = {0};
+	int n = 0;
+
+	if (off_plls[0] == NULL) {
+		const char * const *pn = clkchk_cfg->off_pll_names;
+		struct clk **end = off_plls + MAX_PLLS - 1;
+
+		for (c = off_plls; *pn != NULL && c < end; pn++, c++)
+			*c = __clk_lookup(*pn);
+	}
+
+	for (c = off_plls; *c != NULL; c++) {
+		struct clk_hw *c_hw = __clk_get_hw(*c);
+
+		if (c_hw == NULL)
+			continue;
+
+		if (!clk_hw_is_prepared(c_hw) && !clk_hw_is_enabled(c_hw))
+			continue;
+
+		n += snprintf(buf + n, sizeof(buf) - (size_t)n, "%s ",
+				clk_hw_get_name(c_hw));
+
+		invalid++;
+	}
+
+	if (invalid == 0)
+		return;
+
+	/* invalid. output debug info */
+
+	pr_warn("unexpected unclosed PLL: %s\n", buf);
+	print_enabled_clks();
+
+#if AEE_EXCP_CHECK_PLL_FAIL
+	if (clkchk_cfg->aee_excp_on_fail)
+		aee_kernel_exception("clkchk", "unclosed PLL: %s\n", buf);
+#endif
+
+	if (clkchk_cfg->warn_on_fail)
+		WARN_ON(true);
+}
+
+static int clkchk_syscore_suspend(void)
+{
+	check_pll_off();
+
+	return 0;
+}
+
+static void clkchk_syscore_resume(void)
+{
+}
+
+static struct syscore_ops clkchk_syscore_ops = {
+	.suspend = clkchk_syscore_suspend,
+	.resume = clkchk_syscore_resume,
+};
+
+int clkchk_init(struct clkchk_cfg_t *cfg)
+{
+	const char * const *c;
+	bool match = false;
+
+	if (cfg == NULL || cfg->compatible == NULL
+		|| cfg->all_clk_names == NULL || cfg->off_pll_names == NULL) {
+		pr_warn("Invalid clkchk_cfg.\n");
+		return -EINVAL;
+	}
+
+	clkchk_cfg = cfg;
+
+	for (c = cfg->compatible; *c != NULL; c++) {
+		if (of_machine_is_compatible(*c) != 0) {
+			match = true;
+			break;
+		}
+	}
+
+	if (!match)
+		return -ENODEV;
+
+	register_syscore_ops(&clkchk_syscore_ops);
+
+	return 0;
+}
diff --git a/drivers/clk/mediatek/clkchk.h b/drivers/clk/mediatek/clkchk.h
new file mode 100644
index 000000000000..d99e1acb6477
--- /dev/null
+++ b/drivers/clk/mediatek/clkchk.h
@@ -0,0 +1,18 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Weiyi Lu <weiyi.lu@mediatek.com>
+ */
+
+#include <stdbool.h>
+#include <stddef.h>
+
+struct clkchk_cfg_t {
+	bool aee_excp_on_fail;
+	bool warn_on_fail;
+	const char * const *compatible;
+	const char * const *off_pll_names;
+	const char * const *all_clk_names;
+};
+
+int clkchk_init(struct clkchk_cfg_t *cfg);
diff --git a/drivers/clk/mediatek/clkdbg-mt8183.c b/drivers/clk/mediatek/clkdbg-mt8183.c
new file mode 100644
index 000000000000..89060ec19e88
--- /dev/null
+++ b/drivers/clk/mediatek/clkdbg-mt8183.c
@@ -0,0 +1,857 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+// Author: Weiyi Lu <weiyi.lu@mediatek.com>
+
+#include <linux/clk-provider.h>
+#include <linux/io.h>
+
+#include "clkdbg.h"
+
+#define DUMP_INIT_STATE		0
+
+/*
+ * clkdbg dump_regs
+ */
+
+enum {
+	topckgen,
+	infracfg,
+	scpsys,
+	apmixedsys,
+	audiosys,
+	mfgsys,
+	mmsys,
+	imgsys,
+	camsys,
+	vencsys,
+};
+
+#define REGBASE_V(_phys, _id_name) { .phys = _phys, .name = #_id_name }
+
+/*
+ * checkpatch.pl ERROR:COMPLEX_MACRO
+ *
+ * #define REGBASE(_phys, _id_name) [_id_name] = REGBASE_V(_phys, _id_name)
+ */
+
+static struct regbase rb[] = {
+	[topckgen] = REGBASE_V(0x10000000, topckgen),
+	[infracfg] = REGBASE_V(0x10001000, infracfg),
+	[scpsys]   = REGBASE_V(0x10006000, scpsys),
+	[apmixedsys]  = REGBASE_V(0x1000c000, apmixedsys),
+	[audiosys]    = REGBASE_V(0x11220000, audiosys),
+	[mfgsys]   = REGBASE_V(0x13000000, mfgsys),
+	[mmsys]    = REGBASE_V(0x14000000, mmsys),
+	[imgsys]   = REGBASE_V(0x15020000, imgsys),
+	[camsys]   = REGBASE_V(0x1a000000, camsys),
+	[vencsys]  = REGBASE_V(0x17000000, vencsys),
+};
+
+#define REGNAME(_base, _ofs, _name)	\
+	{ .base = &rb[_base], .ofs = _ofs, .name = #_name }
+
+static struct regname rn[] = {
+	REGNAME(topckgen,  0x040, CLK_CFG_0),
+	REGNAME(topckgen,  0x050, CLK_CFG_1),
+	REGNAME(topckgen,  0x060, CLK_CFG_2),
+	REGNAME(topckgen,  0x070, CLK_CFG_3),
+	REGNAME(topckgen,  0x080, CLK_CFG_4),
+	REGNAME(topckgen,  0x090, CLK_CFG_5),
+	REGNAME(topckgen,  0x0a0, CLK_CFG_6),
+	REGNAME(topckgen,  0x0b0, CLK_CFG_7),
+	REGNAME(topckgen,  0x0c0, CLK_CFG_8),
+	REGNAME(topckgen,  0x0d0, CLK_CFG_9),
+	REGNAME(topckgen,  0x0e0, CLK_CFG_10),
+	REGNAME(audiosys,  0x000, AUDIO_TOP_CON0),
+	REGNAME(audiosys,  0x004, AUDIO_TOP_CON1),
+	REGNAME(camsys,  0x000, CAMSYS_CG),
+	REGNAME(imgsys,  0x000, IMG_CG),
+	REGNAME(infracfg,  0x090, MODULE_SW_CG_0),
+	REGNAME(infracfg,  0x094, MODULE_SW_CG_1),
+	REGNAME(infracfg,  0x0ac, MODULE_SW_CG_2),
+	REGNAME(infracfg,  0x0c8, MODULE_SW_CG_3),
+	REGNAME(mfgsys,  0x000, MFG_CG),
+	REGNAME(mmsys,	0x100, MMSYS_CG_CON0),
+	REGNAME(mmsys,	0x110, MMSYS_CG_CON1),
+	REGNAME(vencsys,  0x000, VENCSYS_CG),
+	REGNAME(apmixedsys,  0x200, ARMPLL_LL_CON0),
+	REGNAME(apmixedsys,  0x204, ARMPLL_LL_CON1),
+	REGNAME(apmixedsys,  0x20C, ARMPLL_LL_PWR_CON0),
+	REGNAME(apmixedsys,  0x210, ARMPLL_L_CON0),
+	REGNAME(apmixedsys,  0x214, ARMPLL_L_CON1),
+	REGNAME(apmixedsys,  0x21C, ARMPLL_L_PWR_CON0),
+	REGNAME(apmixedsys,  0x220, MAINPLL_CON0),
+	REGNAME(apmixedsys,  0x224, MAINPLL_CON1),
+	REGNAME(apmixedsys,  0x22C, MAINPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x230, UNIVPLL_CON0),
+	REGNAME(apmixedsys,  0x234, UNIVPLL_CON1),
+	REGNAME(apmixedsys,  0x23C, UNIVPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x240, MFGPLL_CON0),
+	REGNAME(apmixedsys,  0x244, MFGPLL_CON1),
+	REGNAME(apmixedsys,  0x24C, MFGPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x250, MSDCPLL_CON0),
+	REGNAME(apmixedsys,  0x254, MSDCPLL_CON1),
+	REGNAME(apmixedsys,  0x25C, MSDCPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x260, TVDPLL_CON0),
+	REGNAME(apmixedsys,  0x264, TVDPLL_CON1),
+	REGNAME(apmixedsys,  0x26C, TVDPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x270, MMPLL_CON0),
+	REGNAME(apmixedsys,  0x274, MMPLL_CON1),
+	REGNAME(apmixedsys,  0x27C, MMPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x280, MPLL_CON0),
+	REGNAME(apmixedsys,  0x284, MPLL_CON1),
+	REGNAME(apmixedsys,  0x28C, MPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x290, CCIPLL_CON0),
+	REGNAME(apmixedsys,  0x294, CCIPLL_CON1),
+	REGNAME(apmixedsys,  0x29C, CCIPLL_PWR_CON0),
+	REGNAME(apmixedsys,  0x2A0, APLL1_CON0),
+	REGNAME(apmixedsys,  0x2A4, APLL1_CON1),
+	REGNAME(apmixedsys,  0x2B0, APLL1_PWR_CON0),
+	REGNAME(apmixedsys,  0x2B4, APLL2_CON0),
+	REGNAME(apmixedsys,  0x2B8, APLL2_CON1),
+	REGNAME(apmixedsys,  0x2C4, APLL2_PWR_CON0),
+	REGNAME(scpsys,  0x0180, PWR_STATUS),
+	REGNAME(scpsys,  0x0184, PWR_STATUS_2ND),
+	REGNAME(scpsys,  0x0334, MFG_ASYNC_PWR_CON),
+	REGNAME(scpsys,  0x0338, MFG_PWR_CON),
+	REGNAME(scpsys,  0x033C, MFG_CORE0_PWR_CON),
+	REGNAME(scpsys,  0x0340, MFG_CORE1_PWR_CON),
+	REGNAME(scpsys,  0x0320, MD1_PWR_CON),
+	REGNAME(scpsys,  0x032C, CONN_PWR_CON),
+	REGNAME(scpsys,  0x0314, AUD_PWR_CON),
+	REGNAME(scpsys,  0x030C, DIS_PWR_CON),
+	REGNAME(scpsys,  0x0344, CAM_PWR_CON),
+	REGNAME(scpsys,  0x0308, ISP_PWR_CON),
+	REGNAME(scpsys,  0x0304, VEN_PWR_CON),
+	{}
+};
+
+static const struct regname *get_all_regnames(void)
+{
+	return rn;
+}
+
+static void __init init_regbase(void)
+{
+	size_t i;
+
+	for (i = 0; i < ARRAY_SIZE(rb); i++)
+		rb[i].virt = ioremap(rb[i].phys, PAGE_SIZE);
+}
+
+/*
+ * clkdbg fmeter
+ */
+
+#include <linux/delay.h>
+
+#define clk_readl(addr)		readl(addr)
+#define clk_writel(addr, val)	\
+	do { writel(val, addr); wmb(); } while (0) /* sync write */
+
+#define FMCLK(_t, _i, _n) { .type = _t, .id = _i, .name = _n }
+
+static const struct fmeter_clk fclks[] = {
+	FMCLK(CKGEN,  1, "hd_faxi_ck"),
+	FMCLK(CKGEN,  2, "hf_fmm_ck"),
+	FMCLK(CKGEN,  3, "hf_fimg_ck"),
+	FMCLK(CKGEN,  4, "hf_fcam_ck"),
+	FMCLK(CKGEN,  5, "hf_fdsp_ck"),
+	FMCLK(CKGEN,  6, "hf_fdsp1_ck"),
+	FMCLK(CKGEN,  7, "hf_fdsp2_ck"),
+	FMCLK(CKGEN,  8, "hf_fipu_if_ck"),
+	FMCLK(CKGEN,  9, "hf_fmfg_ck"),
+	FMCLK(CKGEN,  10, "f52m_mfg_ck"),
+	FMCLK(CKGEN,  11, "f_fcamtg_ck"),
+	FMCLK(CKGEN,  12, "f_fcamtg2_ck"),
+	FMCLK(CKGEN,  13, "f_fcamtg3_ck"),
+	FMCLK(CKGEN,  14, "f_fcamtg4_ck"),
+	FMCLK(CKGEN,  15, "f_fuart_ck"),
+	FMCLK(CKGEN,  16, "hf_fspi_ck"),
+	FMCLK(CKGEN,  17, "hf_fmsdc50_0_hclk_ck"),
+	FMCLK(CKGEN,  18, "hf_fmsdc50_0_ck"),
+	FMCLK(CKGEN,  19, "hf_fmsdc30_1_ck"),
+	FMCLK(CKGEN,  20, "hf_fmsdc30_2_ck"),
+	FMCLK(CKGEN,  21, "hf_faudio_ck"),
+	FMCLK(CKGEN,  22, "hf_faud_intbus_ck"),
+	FMCLK(CKGEN,  23, "hf_fpmicspi_ck"),
+	FMCLK(CKGEN,  24, "f_fpwrap_ulposc_ck"),
+	FMCLK(CKGEN,  25, "hf_fatb_ck"),
+	FMCLK(CKGEN,  26, "hf_fsspm_ck"),
+	FMCLK(CKGEN,  27, "hf_fdpi0_ck"),
+	FMCLK(CKGEN,  28, "hf_fscam_ck"),
+	FMCLK(CKGEN,  29, "f_fdisp_pwm_ck"),
+	FMCLK(CKGEN,  30, "f_fusb_top_ck"),
+	FMCLK(CKGEN,  31, "f_fssusb_xhci_ck"),
+	FMCLK(CKGEN,  32, "hg_fspm_ck"),
+	FMCLK(CKGEN,  33, "f_fi2c_ck"),
+	FMCLK(CKGEN,  34, "hf_fscp_ck"),
+	FMCLK(CKGEN,  35, "f_fseninf_ck"),
+	FMCLK(CKGEN,  36, "f_fdxcc_ck"),
+	FMCLK(CKGEN,  37, "hf_faud_engin1_ck"),
+	FMCLK(CKGEN,  38, "hf_faud_engin2_ck"),
+	FMCLK(CKGEN,  39, "hf_faes_ufsfde_ck"),
+	FMCLK(CKGEN,  40, "hf_fufs_ck"),
+	FMCLK(CKGEN,  41, "hf_faud_1_ck"),
+	FMCLK(CKGEN,  42, "hf_faud_2_ck"),
+	FMCLK(CKGEN,  49, "hf_fref_mm_ck"),
+	FMCLK(CKGEN,  50, "hf_fref_cam_ck"),
+	FMCLK(CKGEN,  51, "hf_hddrphycfg_ck"),
+	FMCLK(CKGEN,  52, "f_ufs_mp_sap_cfg_ck"),
+	FMCLK(CKGEN,  53, "f_ufs_tick1us_ck"),
+	FMCLK(CKGEN,  54, "hd_faxi_east_ck"),
+	FMCLK(CKGEN,  55, "hd_faxi_west_ck"),
+	FMCLK(CKGEN,  56, "hd_faxi_north_ck"),
+	FMCLK(CKGEN,  57, "hd_faxi_south_ck"),
+	FMCLK(CKGEN,  58, "hg_fmipicfg_tx_ck"),
+	FMCLK(CKGEN,  59, "fmem_ck_bfe_dcm_ch0"),
+	FMCLK(CKGEN,  60, "fmem_ck_aft_dcm_ch0"),
+	FMCLK(CKGEN,  61, "fmem_ck_bfe_dcm_ch1"),
+	FMCLK(CKGEN,  62, "fmem_ck_aft_dcm_ch1"),
+	FMCLK(CKGEN,  63, "dramc_pll104m_ck"),
+	FMCLK(ABIST,  1, "AD_WBG_DIG_CK_832M"),
+	FMCLK(ABIST,  2, "AD_WBG_DIG_CK_960M"),
+	FMCLK(ABIST,  3, "UFS_MP_CLK2FREQ"),
+	FMCLK(ABIST,  4, "AD_CSI0A_CDPHY_DELAYCAL_CK"),
+	FMCLK(ABIST,  5, "AD_CSI0B_CDPHY_DELAYCAL_CK"),
+	FMCLK(ABIST,  6, "AD_CSI1A_DPHY_DELAYCAL_CK"),
+	FMCLK(ABIST,  7, "AD_CSI1B_DPHY_DELAYCAL_CK"),
+	FMCLK(ABIST,  8, "AD_CSI2A_DPHY_DELAYCAL_CK"),
+	FMCLK(ABIST,  9, "AD_CSI2B_DPHY_DELAYCAL_CK"),
+	FMCLK(ABIST,  10, "AD_MDBPIPLL_CK"),
+	FMCLK(ABIST,  11, "AD_MDBRPPLL_CK"),
+	FMCLK(ABIST,  12, "AD_MDMCUPLL_CK"),
+	FMCLK(ABIST,  13, "AD_MDTXPLL_CK"),
+	FMCLK(ABIST,  14, "AD_MDVDSPPLL_CK"),
+	FMCLK(ABIST,  16, "AD_MDPLL_FS26M_CK"),
+	FMCLK(ABIST,  20, "AD_ARMPLL_L_CK"),
+	FMCLK(ABIST,  22, "AD_ARMPLL_LL_CK"),
+	FMCLK(ABIST,  23, "AD_MAINPLL_1092M_CK"),
+	FMCLK(ABIST,  24, "AD_UNIVPLL_1248M_CK"),
+	FMCLK(ABIST,  25, "AD_MFGPLL_CK"),
+	FMCLK(ABIST,  26, "AD_MSDCPLL_CK"),
+	FMCLK(ABIST,  27, "AD_MMPLL_CK"),
+	FMCLK(ABIST,  28, "AD_APLL1_CK"),
+	FMCLK(ABIST,  29, "AD_APLL2_CK"),
+	FMCLK(ABIST,  30, "AD_APPLLGP_TST_CK"),
+	FMCLK(ABIST,  32, "AD_UNIV_192M_CK"),
+	FMCLK(ABIST,  34, "AD_TVDPLL_CK"),
+	FMCLK(ABIST,  35, "AD_DSI0_MPPLL_TST_CK"),
+	FMCLK(ABIST,  36, "AD_DSI0_LNTC_DSICLK"),
+	FMCLK(ABIST,  37, "AD_OSC_CK_2"),
+	FMCLK(ABIST,  38, "AD_OSC_CK"),
+	FMCLK(ABIST,  39, "rtc32k_ck_i"),
+	FMCLK(ABIST,  40, "mcusys_arm_clk_out_all"),
+	FMCLK(ABIST,  41, "AD_OSC_SYNC_CK"),
+	FMCLK(ABIST,  42, "AD_OSC_SYNC_CK_2"),
+	FMCLK(ABIST,  43, "msdc01_in_ck"),
+	FMCLK(ABIST,  44, "msdc02_in_ck"),
+	FMCLK(ABIST,  45, "msdc11_in_ck"),
+	FMCLK(ABIST,  46, "msdc12_in_ck"),
+	FMCLK(ABIST,  49, "AD_CCIPLL_CK"),
+	FMCLK(ABIST,  50, "AD_MPLL_208M_CK"),
+	FMCLK(ABIST,  51, "AD_WBG_DIG_CK_CK_416M"),
+	FMCLK(ABIST,  52, "AD_WBG_B_DIG_CK_64M"),
+	FMCLK(ABIST,  53, "AD_WBG_W_DIG_CK_160M"),
+	FMCLK(ABIST,  55, "DA_UNIV_48M_DIV_CK"),
+	FMCLK(ABIST,  57, "DA_MPLL_52M_DIV_CK"),
+	FMCLK(ABIST,  60, "ckmon1_ck"),
+	FMCLK(ABIST,  61, "ckmon2_ck"),
+	FMCLK(ABIST,  62, "ckmon3_ck"),
+	FMCLK(ABIST,  63, "ckmon4_ck"),
+	{}
+};
+
+#define CLK_MISC_CFG_0	(rb[topckgen].virt + 0x104)
+#define CLK_DBG_CFG		(rb[topckgen].virt + 0x10C)
+#define CLK26CALI_0		(rb[topckgen].virt + 0x220)
+#define CLK26CALI_1		(rb[topckgen].virt + 0x224)
+
+static unsigned int mt_get_ckgen_freq(unsigned int ID)
+{
+	int output = 0, i = 0;
+	unsigned int temp, clk_dbg_cfg, clk_misc_cfg_0;
+
+	clk_dbg_cfg = clk_readl(CLK_DBG_CFG);
+	clk_writel(CLK_DBG_CFG, (clk_dbg_cfg & 0xFFFFC0FC)|(ID << 8)|(0x1));
+
+	clk_misc_cfg_0 = clk_readl(CLK_MISC_CFG_0);
+	clk_writel(CLK_MISC_CFG_0, (clk_misc_cfg_0 & 0x00FFFFFF));
+
+	clk_writel(CLK26CALI_0, 0x1000);
+	clk_writel(CLK26CALI_0, 0x1010);
+
+	while (clk_readl(CLK26CALI_0) & 0x10) {
+		mdelay(10);
+		i++;
+		if (i > 10)
+			break;
+	}
+
+	temp = clk_readl(CLK26CALI_1) & 0xFFFF;
+
+	output = (temp * 26000) / 1024;
+
+	clk_writel(CLK_DBG_CFG, clk_dbg_cfg);
+	clk_writel(CLK_MISC_CFG_0, clk_misc_cfg_0);
+
+	if (i > 10)
+		return 0;
+	else
+		return output;
+
+}
+
+static unsigned int mt_get_abist_freq(unsigned int ID)
+{
+	int output = 0, i = 0;
+	unsigned int temp, clk_dbg_cfg, clk_misc_cfg_0;
+
+	clk_dbg_cfg = clk_readl(CLK_DBG_CFG);
+	clk_writel(CLK_DBG_CFG, (clk_dbg_cfg & 0xFFC0FFFC)|(ID << 16));
+
+	clk_misc_cfg_0 = clk_readl(CLK_MISC_CFG_0);
+	clk_writel(CLK_MISC_CFG_0, (clk_misc_cfg_0 & 0x00FFFFFF) | (1 << 24));
+
+	clk_writel(CLK26CALI_0, 0x1000);
+	clk_writel(CLK26CALI_0, 0x1010);
+
+	while (clk_readl(CLK26CALI_0) & 0x10) {
+		mdelay(10);
+		i++;
+		if (i > 10)
+			break;
+	}
+
+	temp = clk_readl(CLK26CALI_1) & 0xFFFF;
+
+	output = (temp * 26000) / 1024;
+
+	clk_writel(CLK_DBG_CFG, clk_dbg_cfg);
+	clk_writel(CLK_MISC_CFG_0, clk_misc_cfg_0);
+
+	if (i > 10)
+		return 0;
+	else
+		return (output * 2);
+}
+
+static u32 fmeter_freq_op(const struct fmeter_clk *fclk)
+{
+	if (fclk->type == ABIST)
+		return mt_get_abist_freq(fclk->id);
+	else if (fclk->type == CKGEN)
+		return mt_get_ckgen_freq(fclk->id);
+	return 0;
+}
+
+static const struct fmeter_clk *get_all_fmeter_clks(void)
+{
+	return fclks;
+}
+
+/*
+ * clkdbg dump_state
+ */
+
+static const char * const *get_all_clk_names(void)
+{
+	static const char * const clks[] = {
+		"armpll_ll",
+		"armpll_l",
+		"ccipll",
+		"mainpll",
+		"univ2pll",
+		"msdcpll",
+		"mmpll",
+		"mfgpll",
+		"tvdpll",
+		"apll1",
+		"apll2",
+		"apmixed_ssusb26m",
+		"apmixed_appll26m",
+		"apmixed_mipic026m",
+		"apmixed_mdpll26m",
+		"apmixed_mmsys26m",
+		"apmixed_ufs26m",
+		"apmixed_mipic126m",
+		"apmixed_mempll26m",
+		"apmixed_lvpll26m",
+		"apmixed_mipid026m",
+		"apmixed_mipid126m",
+		"syspll_ck",
+		"syspll_d2",
+		"syspll_d3",
+		"syspll_d5",
+		"syspll_d7",
+		"syspll_d2_d2",
+		"syspll_d2_d4",
+		"syspll_d2_d8",
+		"syspll_d2_d16",
+		"syspll_d3_d2",
+		"syspll_d3_d4",
+		"syspll_d3_d8",
+		"syspll_d5_d2",
+		"syspll_d5_d4",
+		"syspll_d7_d2",
+		"syspll_d7_d4",
+		"univpll_ck",
+		"univpll_d2",
+		"univpll_d3",
+		"univpll_d5",
+		"univpll_d7",
+		"univpll_d2_d2",
+		"univpll_d2_d4",
+		"univpll_d2_d8",
+		"univpll_d3_d2",
+		"univpll_d3_d4",
+		"univpll_d3_d8",
+		"univpll_d5_d2",
+		"univpll_d5_d4",
+		"univpll_d5_d8",
+		"apll1_ck",
+		"apll1_d2",
+		"apll1_d4",
+		"apll1_d8",
+		"apll2_ck",
+		"apll2_d2",
+		"apll2_d4",
+		"apll2_d8",
+		"tvdpll_ck",
+		"tvdpll_d2",
+		"tvdpll_d4",
+		"tvdpll_d8",
+		"tvdpll_d16",
+		"msdcpll_ck",
+		"msdcpll_d2",
+		"msdcpll_d4",
+		"msdcpll_d8",
+		"msdcpll_d16",
+		"ad_osc_ck",
+		"osc_d2",
+		"osc_d4",
+		"osc_d8",
+		"osc_d16",
+		"csw_f26m_ck_d2",
+		"mfgpll_ck",
+		"univ_192m_ck",
+		"univ_192m_d2",
+		"univ_192m_d4",
+		"univ_192m_d8",
+		"univ_192m_d16",
+		"univ_192m_d32",
+		"mmpll_ck",
+		"mmpll_d4",
+		"mmpll_d4_d2",
+		"mmpll_d4_d4",
+		"mmpll_d5",
+		"mmpll_d5_d2",
+		"mmpll_d5_d4",
+		"mmpll_d6",
+		"mmpll_d7",
+		"f_f26m_ck",
+		"clk13m",
+		"osc",
+		"univpll_192m",
+		"apll_i2s0_sel",
+		"apll_i2s1_sel",
+		"apll_i2s2_sel",
+		"apll_i2s3_sel",
+		"apll_i2s4_sel",
+		"apll_i2s5_sel",
+		"apll12_div0",
+		"apll12_div1",
+		"apll12_div2",
+		"apll12_div3",
+		"apll12_div4",
+		"apll12_divb",
+		"univpll",
+		"armpll_div_pll1",
+		"armpll_div_pll2",
+		"axi_sel",
+		"mm_sel",
+		"cam_sel",
+		"mfg_sel",
+		"camtg_sel",
+		"uart_sel",
+		"spi_sel",
+		"msdc50_hclk_sel",
+		"msdc50_0_sel",
+		"msdc30_1_sel",
+		"msdc30_2_sel",
+		"audio_sel",
+		"aud_intbus_sel",
+		"fpwrap_ulposc_sel",
+		"scp_sel",
+		"atb_sel",
+		"sspm_sel",
+		"dpi0_sel",
+		"scam_sel",
+		"aud_1_sel",
+		"aud_2_sel",
+		"disppwm_sel",
+		"ssusb_top_xhci_sel",
+		"usb_top_sel",
+		"spm_sel",
+		"i2c_sel",
+		"f52m_mfg_sel",
+		"seninf_sel",
+		"dxcc_sel",
+		"camtg2_sel",
+		"aud_eng1_sel",
+		"aud_eng2_sel",
+		"faes_ufsfde_sel",
+		"fufs_sel",
+		"img_sel",
+		"dsp_sel",
+		"dsp1_sel",
+		"dsp2_sel",
+		"ipu_if_sel",
+		"camtg3_sel",
+		"camtg4_sel",
+		"pmicspi_sel",
+		"mcu_mp0_sel",
+		"mcu_mp2_sel",
+		"mcu_bus_sel",
+		"infra_pmic_tmr",
+		"infra_pmic_ap",
+		"infra_pmic_md",
+		"infra_pmic_conn",
+		"infra_scp",
+		"infra_sej",
+		"infra_apxgpt",
+		"infra_icusb",
+		"infra_gce",
+		"infra_therm",
+		"infra_i2c0",
+		"infra_i2c1",
+		"infra_i2c2",
+		"infra_i2c3",
+		"infra_pwm_hclk",
+		"infra_pwm1",
+		"infra_pwm2",
+		"infra_pwm3",
+		"infra_pwm4",
+		"infra_pwm",
+		"infra_uart0",
+		"infra_uart1",
+		"infra_uart2",
+		"infra_uart3",
+		"infra_gce_26m",
+		"infra_cqdma_fpc",
+		"infra_btif",
+		"infra_spi0",
+		"infra_msdc0",
+		"infra_msdc1",
+		"infra_msdc2",
+		"infra_msdc0_sck",
+		"infra_dvfsrc",
+		"infra_gcpu",
+		"infra_trng",
+		"infra_auxadc",
+		"infra_cpum",
+		"infra_ccif1_ap",
+		"infra_ccif1_md",
+		"infra_auxadc_md",
+		"infra_msdc1_sck",
+		"infra_msdc2_sck",
+		"infra_apdma",
+		"infra_xiu",
+		"infra_device_apc",
+		"infra_ccif_ap",
+		"infra_debugsys",
+		"infra_audio",
+		"infra_ccif_md",
+		"infra_dxcc_sec_core",
+		"infra_dxcc_ao",
+		"infra_dramc_f26m",
+		"infra_irtx",
+		"infra_disppwm",
+		"infra_cldma_bclk",
+		"infra_audio_26m_bclk",
+		"infra_spi1",
+		"infra_i2c4",
+		"infra_md_tmp_share",
+		"infra_spi2",
+		"infra_spi3",
+		"infra_unipro_sck",
+		"infra_unipro_tick",
+		"infra_ufs_mp_sap_bck",
+		"infra_md32_bclk",
+		"infra_sspm",
+		"infra_unipro_mbist",
+		"infra_sspm_bus_hclk",
+		"infra_i2c5",
+		"infra_i2c5_arbiter",
+		"infra_i2c5_imm",
+		"infra_i2c1_arbiter",
+		"infra_i2c1_imm",
+		"infra_i2c2_arbiter",
+		"infra_i2c2_imm",
+		"infra_spi4",
+		"infra_spi5",
+		"infra_cqdma",
+		"infra_ufs",
+		"infra_aes_ufsfde",
+		"infra_ufs_tick",
+		"infra_msdc0_self",
+		"infra_msdc1_self",
+		"infra_msdc2_self",
+		"infra_sspm_26m_self",
+		"infra_sspm_32k_self",
+		"infra_ufs_axi",
+		"infra_i2c6",
+		"infra_ap_msdc0",
+		"infra_md_msdc0",
+		"infra_usb",
+		"infra_devmpu_bclk",
+		"infra_ccif2_ap",
+		"infra_ccif2_md",
+		"infra_ccif3_ap",
+		"infra_ccif3_md",
+		"infra_sej_f13m",
+		"infra_aes_bclk",
+		"infra_i2c7",
+		"infra_i2c8",
+		"infra_fbist2fpc",
+		"aud_tml",
+		"aud_dac_predis",
+		"aud_dac",
+		"aud_adc",
+		"aud_apll_tuner",
+		"aud_apll2_tuner",
+		"aud_24m",
+		"aud_22m",
+		"aud_afe",
+		"aud_i2s4",
+		"aud_i2s3",
+		"aud_i2s2",
+		"aud_i2s1",
+		"aud_pdn_adda6_adc",
+		"aud_tdm",
+		"mfg_bg3d",
+		"mm_smi_common",
+		"mm_smi_larb0",
+		"mm_smi_larb1",
+		"mm_gals_comm0",
+		"mm_gals_comm1",
+		"mm_gals_ccu2mm",
+		"mm_gals_ipu12mm",
+		"mm_gals_img2mm",
+		"mm_gals_cam2mm",
+		"mm_gals_ipu2mm",
+		"mm_mdp_dl_txck",
+		"mm_ipu_dl_txck",
+		"mm_mdp_rdma0",
+		"mm_mdp_rdma1",
+		"mm_mdp_rsz0",
+		"mm_mdp_rsz1",
+		"mm_mdp_tdshp",
+		"mm_mdp_wrot0",
+		"mm_fake_eng",
+		"mm_disp_ovl0",
+		"mm_disp_ovl0_2l",
+		"mm_disp_ovl1_2l",
+		"mm_disp_rdma0",
+		"mm_disp_rdma1",
+		"mm_disp_wdma0",
+		"mm_disp_color0",
+		"mm_disp_ccorr0",
+		"mm_disp_aal0",
+		"mm_disp_gamma0",
+		"mm_disp_dither0",
+		"mm_disp_split",
+		"mm_dsi0_mm",
+		"mm_dsi0_if",
+		"mm_dpi_mm",
+		"mm_dpi_if",
+		"mm_fake_eng2",
+		"mm_mdp_dl_rx",
+		"mm_ipu_dl_rx",
+		"mm_26m",
+		"mm_mmsys_r2y",
+		"mm_disp_rsz",
+		"mm_mdp_wdma0",
+		"mm_mdp_aal",
+		"mm_mdp_ccorr",
+		"mm_dbi_mm",
+		"mm_dbi_if",
+		"vdec_vdec",
+		"vdec_larb1",
+		"venc_larb",
+		"venc_venc",
+		"venc_jpgenc",
+		"img_owe",
+		"img_wpe_b",
+		"img_wpe_a",
+		"img_mfb",
+		"img_rsc",
+		"img_dpe",
+		"img_fdvt",
+		"img_dip",
+		"img_larb2",
+		"img_larb5",
+		"cam_larb6",
+		"cam_dfp_vad",
+		"cam_cam",
+		"cam_camtg",
+		"cam_seninf",
+		"cam_camsv0",
+		"cam_camsv1",
+		"cam_camsv2",
+		"cam_ccu",
+		"cam_larb3",
+		"ipu_conn_ipu",
+		"ipu_conn_ahb",
+		"ipu_conn_axi",
+		"ipu_conn_isp",
+		"ipu_conn_cam_adl",
+		"ipu_conn_img_adl",
+		"ipu_conn_dap_rx",
+		"ipu_conn_apb2axi",
+		"ipu_conn_apb2ahb",
+		"ipu_conn_ipu_cab1to2",
+		"ipu_conn_ipu1_cab1to2",
+		"ipu_conn_ipu2_cab1to2",
+		"ipu_conn_cab3to3",
+		"ipu_conn_cab2to1",
+		"ipu_conn_cab3to1_slice",
+		"ipu_adl_cabgen",
+		"ipu_core0_jtag",
+		"ipu_core0_axi",
+		"ipu_core0_ipu",
+		"ipu_core1_jtag",
+		"ipu_core1_axi",
+		"ipu_core1_ipu",
+		/* end */
+		NULL
+	};
+
+	return clks;
+}
+
+/*
+ * clkdbg pwr_status
+ */
+
+static const char * const *get_pwr_names(void)
+{
+	static const char * const pwr_names[] = {
+		[0]  = "MD1",
+		[1]  = "CONN",
+		[2]  = "DDRPHY",
+		[3]  = "DISP",
+		[4]  = "MFG",
+		[5]  = "ISP",
+		[6]  = "INFRA",
+		[7]  = "MFG_CORE0",
+		[8]  = "MP0_CPUTOP",
+		[9]  = "MP0_CPU0",
+		[10] = "MP0_CPU1",
+		[11] = "MP0_CPU2",
+		[12] = "MP0_CPU3",
+		[13] = "",
+		[14] = "",
+		[15] = "",
+		[16] = "",
+		[17] = "",
+		[18] = "",
+		[19] = "",
+		[20] = "MFG_CORE1",
+		[21] = "VENC",
+		[22] = "MFG_2D",
+		[23] = "MFG_ASYNC",
+		[24] = "AUDIO",
+		[25] = "CAM",
+		[26] = "VPU_TOP",
+		[27] = "VPU_CORE0",
+		[28] = "VPU_CORE1",
+		[29] = "VPU_CORE2",
+		[30] = "",
+		[31] = "VDEC",
+	};
+
+	return pwr_names;
+}
+
+u32 get_spm_pwr_status(void)
+{
+	static void __iomem *scpsys_base, *pwr_sta, *pwr_sta_2nd;
+
+	if (scpsys_base == NULL || pwr_sta == NULL || pwr_sta_2nd == NULL) {
+		scpsys_base = ioremap(0x10006000, PAGE_SIZE);
+		pwr_sta = scpsys_base + 0x180;
+		pwr_sta_2nd = scpsys_base + 0x184;
+	}
+
+	return clk_readl(pwr_sta) & clk_readl(pwr_sta_2nd);
+}
+
+/*
+ * clkdbg dump_clks
+ */
+
+static void setup_provider_clk(struct provider_clk *pvdck)
+{
+	static const struct {
+		const char *pvdname;
+		u32 pwr_mask;
+	} pvd_pwr_mask[] = {
+	};
+
+	size_t i;
+	const char *pvdname = pvdck->provider_name;
+
+	if (pvdname == NULL)
+		return;
+
+	for (i = 0; i < ARRAY_SIZE(pvd_pwr_mask); i++) {
+		if (strcmp(pvdname, pvd_pwr_mask[i].pvdname) == 0) {
+			pvdck->pwr_mask = pvd_pwr_mask[i].pwr_mask;
+			return;
+		}
+	}
+}
+
+/*
+ * init functions
+ */
+
+static struct clkdbg_ops clkdbg_mt8183_ops = {
+	.get_all_fmeter_clks = get_all_fmeter_clks,
+	.fmeter_freq = fmeter_freq_op,
+	.get_all_regnames = get_all_regnames,
+	.get_all_clk_names = get_all_clk_names,
+	.get_pwr_names = get_pwr_names,
+	.setup_provider_clk = setup_provider_clk,
+	.get_spm_pwr_status = get_spm_pwr_status,
+};
+
+static void __init init_custom_cmds(void)
+{
+	static const struct cmd_fn cmds[] = {
+		{}
+	};
+
+	set_custom_cmds(cmds);
+}
+
+static int __init clkdbg_mt8183_init(void)
+{
+	if (of_machine_is_compatible("mediatek,mt8183") == 0)
+		return -ENODEV;
+
+	init_regbase();
+
+	init_custom_cmds();
+	set_clkdbg_ops(&clkdbg_mt8183_ops);
+
+#if DUMP_INIT_STATE
+	print_regs();
+	print_fmeter_all();
+#endif /* DUMP_INIT_STATE */
+
+	return 0;
+}
+device_initcall(clkdbg_mt8183_init);
diff --git a/drivers/clk/mediatek/clkdbg.c b/drivers/clk/mediatek/clkdbg.c
new file mode 100644
index 000000000000..8c9f67968160
--- /dev/null
+++ b/drivers/clk/mediatek/clkdbg.c
@@ -0,0 +1,2242 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+// Author: Weiyi Lu <weiyi.lu@mediatek.com>
+
+#define pr_fmt(fmt) "[clkdbg] " fmt
+
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_platform.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+
+#include <linux/proc_fs.h>
+#include <linux/fs.h>
+#include <linux/seq_file.h>
+#include <linux/uaccess.h>
+
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/pm_domain.h>
+#include <linux/pm_runtime.h>
+#include <linux/module.h>
+#include <linux/version.h>
+
+#include "clkdbg.h"
+
+#if defined(CONFIG_PM_DEBUG)
+#define CLKDBG_PM_DOMAIN	1
+#else
+#define CLKDBG_PM_DOMAIN	0
+#endif
+#define CLKDBG_PM_DOMAIN_API_4_9	1
+#define CLKDBG_CCF_API_4_4	1
+#define CLKDBG_HACK_CLK		0
+#define CLKDBG_HACK_CLK_CORE	1
+#define CLKDBG_DROP_GENPD_AS_IN_PARAM	1
+
+#if !CLKDBG_CCF_API_4_4
+
+/* backward compatible */
+
+static const char *clk_hw_get_name(const struct clk_hw *hw)
+{
+	return __clk_get_name(hw->clk);
+}
+
+static bool clk_hw_is_prepared(const struct clk_hw *hw)
+{
+	return __clk_is_prepared(hw->clk);
+}
+
+static bool clk_hw_is_enabled(const struct clk_hw *hw)
+{
+	return __clk_is_enabled(hw->clk);
+}
+
+static unsigned long clk_hw_get_rate(const struct clk_hw *hw)
+{
+	return __clk_get_rate(hw->clk);
+}
+
+static unsigned int clk_hw_get_num_parents(const struct clk_hw *hw)
+{
+	return __clk_get_num_parents(hw->clk);
+}
+
+static struct clk_hw *clk_hw_get_parent_by_index(const struct clk_hw *hw,
+					  unsigned int index)
+{
+	return __clk_get_hw(clk_get_parent_by_index(hw->clk, index));
+}
+
+#endif /* !CLKDBG_CCF_API_4_4 */
+
+#if CLKDBG_HACK_CLK
+
+#include <linux/clk-private.h>
+
+static bool clk_hw_is_on(struct clk_hw *hw)
+{
+	const struct clk_ops *ops = hw->clk->ops;
+
+	if (ops->is_enabled)
+		return clk_hw_is_enabled(hw);
+	else if (ops->is_prepared)
+		return clk_hw_is_prepared(hw);
+	return clk_hw_is_enabled(hw) || clk_hw_is_prepared(hw);
+}
+
+#elif CLKDBG_HACK_CLK_CORE
+
+struct clk_core {
+	const char		*name;
+	const struct clk_ops	*ops;
+	struct clk_hw		*hw;
+};
+
+static bool clk_hw_is_on(struct clk_hw *hw)
+{
+	const struct clk_ops *ops = hw->core->ops;
+
+	if (ops->is_enabled)
+		return clk_hw_is_enabled(hw);
+	else if (ops->is_prepared)
+		return clk_hw_is_prepared(hw);
+	return clk_hw_is_enabled(hw) || clk_hw_is_prepared(hw);
+}
+
+#else
+
+static bool clk_hw_is_on(struct clk_hw *hw)
+{
+	return __clk_get_enable_count(hw->clk) || clk_hw_is_prepared(hw);
+}
+
+#endif /* !CLKDBG_HACK_CLK && !CLKDBG_HACK_CLK_CORE */
+
+static const struct clkdbg_ops *clkdbg_ops;
+
+void set_clkdbg_ops(const struct clkdbg_ops *ops)
+{
+	clkdbg_ops = ops;
+}
+
+static const struct fmeter_clk *get_all_fmeter_clks(void)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->get_all_fmeter_clks  == NULL)
+		return NULL;
+
+	return clkdbg_ops->get_all_fmeter_clks();
+}
+
+static void *prepare_fmeter(void)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->prepare_fmeter == NULL)
+		return NULL;
+
+	return clkdbg_ops->prepare_fmeter();
+}
+
+static void unprepare_fmeter(void *data)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->unprepare_fmeter == NULL)
+		return;
+
+	clkdbg_ops->unprepare_fmeter(data);
+}
+
+static u32 fmeter_freq(const struct fmeter_clk *fclk)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->fmeter_freq == NULL)
+		return 0;
+
+	return clkdbg_ops->fmeter_freq(fclk);
+}
+
+static const struct regname *get_all_regnames(void)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->get_all_regnames == NULL)
+		return NULL;
+
+	return clkdbg_ops->get_all_regnames();
+}
+
+static const char * const *get_all_clk_names(void)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->get_all_clk_names == NULL)
+		return NULL;
+
+	return clkdbg_ops->get_all_clk_names();
+}
+
+static const char * const *get_pwr_names(void)
+{
+	static const char * const default_pwr_names[] = {
+		[0]  = "(MD)",
+		[1]  = "(CONN)",
+		[2]  = "(DDRPHY)",
+		[3]  = "(DISP)",
+		[4]  = "(MFG)",
+		[5]  = "(ISP)",
+		[6]  = "(INFRA)",
+		[7]  = "(VDEC)",
+		[8]  = "(CPU, CA7_CPUTOP)",
+		[9]  = "(FC3, CA7_CPU0, CPUTOP)",
+		[10] = "(FC2, CA7_CPU1, CPU3)",
+		[11] = "(FC1, CA7_CPU2, CPU2)",
+		[12] = "(FC0, CA7_CPU3, CPU1)",
+		[13] = "(MCUSYS, CA7_DBG, CPU0)",
+		[14] = "(MCUSYS, VEN, BDP)",
+		[15] = "(CA15_CPUTOP, ETH, MCUSYS)",
+		[16] = "(CA15_CPU0, HIF)",
+		[17] = "(CA15_CPU1, CA15-CX0, INFRA_MISC)",
+		[18] = "(CA15_CPU2, CA15-CX1)",
+		[19] = "(CA15_CPU3, CA15-CPU0)",
+		[20] = "(VEN2, MJC, CA15-CPU1)",
+		[21] = "(VEN, CA15-CPUTOP)",
+		[22] = "(MFG_2D)",
+		[23] = "(MFG_ASYNC, DBG)",
+		[24] = "(AUDIO, MFG_2D)",
+		[25] = "(USB, VCORE_PDN, MFG_ASYNC)",
+		[26] = "(ARMPLL_DIV, CPUTOP_SRM_SLPB)",
+		[27] = "(MD2, CPUTOP_SRM_PDN)",
+		[28] = "(CPU3_SRM_PDN)",
+		[29] = "(CPU2_SRM_PDN)",
+		[30] = "(CPU1_SRM_PDN)",
+		[31] = "(CPU0_SRM_PDN)",
+	};
+
+	if (clkdbg_ops == NULL || clkdbg_ops->get_pwr_names == NULL)
+		return default_pwr_names;
+
+	return clkdbg_ops->get_pwr_names();
+}
+
+static void setup_provider_clk(struct provider_clk *pvdck)
+{
+	if (clkdbg_ops == NULL || clkdbg_ops->setup_provider_clk == NULL)
+		return;
+
+	clkdbg_ops->setup_provider_clk(pvdck);
+}
+
+static bool is_valid_reg(void __iomem *addr)
+{
+#ifdef CONFIG_64BIT
+	return ((u64)addr & 0xf0000000) != 0UL ||
+			(((u64)addr >> 32U) & 0xf0000000) != 0UL;
+#else
+	return ((u32)addr & 0xf0000000) != 0U;
+#endif
+}
+
+enum clkdbg_opt {
+	CLKDBG_EN_SUSPEND_SAVE_1,
+	CLKDBG_EN_SUSPEND_SAVE_2,
+	CLKDBG_EN_SUSPEND_SAVE_3,
+	CLKDBG_EN_LOG_SAVE_POINTS,
+};
+
+static u32 clkdbg_flags;
+
+static void set_clkdbg_flag(enum clkdbg_opt opt)
+{
+	clkdbg_flags |= BIT(opt);
+}
+
+static void clr_clkdbg_flag(enum clkdbg_opt opt)
+{
+	clkdbg_flags &= ~BIT(opt);
+}
+
+static bool has_clkdbg_flag(enum clkdbg_opt opt)
+{
+	return (clkdbg_flags & BIT(opt)) != 0U;
+}
+
+typedef void (*fn_fclk_freq_proc)(const struct fmeter_clk *fclk,
+					u32 freq, void *data);
+
+static void proc_all_fclk_freq(fn_fclk_freq_proc proc, void *data)
+{
+	void *fmeter_data;
+	const struct fmeter_clk *fclk;
+
+	fclk = get_all_fmeter_clks();
+
+	if (fclk == NULL || proc == NULL)
+		return;
+
+	fmeter_data = prepare_fmeter();
+
+	for (; fclk->type != FT_NULL; fclk++) {
+		u32 freq;
+
+		freq = fmeter_freq(fclk);
+		proc(fclk, freq, data);
+	}
+
+	unprepare_fmeter(fmeter_data);
+}
+
+static void print_fclk_freq(const struct fmeter_clk *fclk, u32 freq, void *data)
+{
+	pr_info("%2d: %-29s: %u\n", fclk->id, fclk->name, freq);
+}
+
+void print_fmeter_all(void)
+{
+	proc_all_fclk_freq(print_fclk_freq, NULL);
+}
+
+static void seq_print_fclk_freq(const struct fmeter_clk *fclk,
+				u32 freq, void *data)
+{
+	struct seq_file *s = data;
+
+	seq_printf(s, "%2d: %-29s: %u\n", fclk->id, fclk->name, freq);
+}
+
+static int seq_print_fmeter_all(struct seq_file *s, void *v)
+{
+	proc_all_fclk_freq(seq_print_fclk_freq, s);
+
+	return 0;
+}
+
+typedef void (*fn_regname_proc)(const struct regname *rn, void *data);
+
+static void proc_all_regname(fn_regname_proc proc, void *data)
+{
+	const struct regname *rn = get_all_regnames();
+
+	if (rn == NULL)
+		return;
+
+	for (; rn->base != NULL; rn++)
+		proc(rn, data);
+}
+
+static void print_reg(const struct regname *rn, void *data)
+{
+	if (!is_valid_reg(ADDR(rn)))
+		return;
+
+	pr_info("%-21s: [0x%08x][0x%p] = 0x%08x\n",
+			rn->name, PHYSADDR(rn), ADDR(rn), clk_readl(ADDR(rn)));
+}
+
+void print_regs(void)
+{
+	proc_all_regname(print_reg, NULL);
+}
+
+static void seq_print_reg(const struct regname *rn, void *data)
+{
+	struct seq_file *s = data;
+
+	if (!is_valid_reg(ADDR(rn)))
+		return;
+
+	seq_printf(s, "%-21s: [0x%08x][0x%p] = 0x%08x\n",
+		rn->name, PHYSADDR(rn), ADDR(rn), clk_readl(ADDR(rn)));
+}
+
+static int seq_print_regs(struct seq_file *s, void *v)
+{
+	proc_all_regname(seq_print_reg, s);
+
+	return 0;
+}
+
+static void print_reg2(const struct regname *rn, void *data)
+{
+	if (!is_valid_reg(ADDR(rn)))
+		return;
+
+	pr_info("%-21s: [0x%08x][0x%p] = 0x%08x\n",
+		rn->name, PHYSADDR(rn), ADDR(rn), clk_readl(ADDR(rn)));
+
+	msleep(20);
+}
+
+static int clkdbg_dump_regs2(struct seq_file *s, void *v)
+{
+	proc_all_regname(print_reg2, s);
+
+	return 0;
+}
+
+static u32 read_spm_pwr_status(void)
+{
+	static void __iomem *scpsys_base, *pwr_sta, *pwr_sta_2nd;
+
+	if (clkdbg_ops == NULL || clkdbg_ops->get_spm_pwr_status  == NULL) {
+		if (scpsys_base == NULL ||
+		    pwr_sta == NULL || pwr_sta_2nd == NULL) {
+			scpsys_base = ioremap(0x10006000, PAGE_SIZE);
+			pwr_sta = scpsys_base + 0x60c;
+			pwr_sta_2nd = scpsys_base + 0x610;
+		}
+
+		return clk_readl(pwr_sta) & clk_readl(pwr_sta_2nd);
+	} else
+		return clkdbg_ops->get_spm_pwr_status();
+}
+
+static bool clk_hw_pwr_is_on(struct clk_hw *c_hw,
+			u32 spm_pwr_status, u32 pwr_mask)
+{
+	if ((spm_pwr_status & pwr_mask) != pwr_mask)
+		return false;
+
+	return clk_hw_is_on(c_hw);
+}
+
+static bool pvdck_pwr_is_on(struct provider_clk *pvdck, u32 spm_pwr_status)
+{
+	struct clk *c = pvdck->ck;
+	struct clk_hw *c_hw = __clk_get_hw(c);
+
+	return clk_hw_pwr_is_on(c_hw, spm_pwr_status, pvdck->pwr_mask);
+}
+
+static bool pvdck_is_on(struct provider_clk *pvdck)
+{
+	u32 spm_pwr_status = 0;
+
+	if (pvdck->pwr_mask != 0U)
+		spm_pwr_status = read_spm_pwr_status();
+
+	return pvdck_pwr_is_on(pvdck, spm_pwr_status);
+}
+
+static const char *ccf_state(struct clk_hw *hw)
+{
+	if (__clk_get_enable_count(hw->clk))
+		return "enabled";
+
+	if (clk_hw_is_prepared(hw))
+		return "prepared";
+
+	return "disabled";
+}
+
+static void dump_clk_state(const char *clkname, struct seq_file *s)
+{
+	struct clk *c = __clk_lookup(clkname);
+	struct clk *p = IS_ERR_OR_NULL(c) ? NULL : clk_get_parent(c);
+	struct clk_hw *c_hw = __clk_get_hw(c);
+	struct clk_hw *p_hw = __clk_get_hw(p);
+
+	if (IS_ERR_OR_NULL(c)) {
+		seq_printf(s, "[%17s: NULL]\n", clkname);
+		return;
+	}
+
+	seq_printf(s, "[%-17s: %8s, %3d, %3d, %10ld, %17s]\n",
+		clk_hw_get_name(c_hw),
+		ccf_state(c_hw),
+		clk_hw_is_prepared(c_hw),
+		__clk_get_enable_count(c),
+		clk_hw_get_rate(c_hw),
+		p != NULL ? clk_hw_get_name(p_hw) : "- ");
+}
+
+static int clkdbg_dump_state_all(struct seq_file *s, void *v)
+{
+	const char * const *ckn = get_all_clk_names();
+
+	if (ckn == NULL)
+		return 0;
+
+	for (; *ckn != NULL; ckn++)
+		dump_clk_state(*ckn, s);
+
+	return 0;
+}
+
+static const char *get_provider_name(struct device_node *node, u32 *cells)
+{
+	const char *name;
+	const char *p;
+	u32 cc;
+
+	if (of_property_read_u32(node, "#clock-cells", &cc) != 0)
+		cc = 0;
+
+	if (cells != NULL)
+		*cells = cc;
+
+	if (cc == 0U) {
+		if (of_property_read_string(node,
+				"clock-output-names", &name) < 0)
+			name = node->name;
+
+		return name;
+	}
+
+	if (of_property_read_string(node, "compatible", &name) < 0)
+		name = node->name;
+
+	p = strchr(name, (int)'-');
+
+	if (p != NULL)
+		return p + 1;
+	else
+		return name;
+}
+
+struct provider_clk *get_all_provider_clks(void)
+{
+	static struct provider_clk provider_clks[512];
+	struct device_node *node = NULL;
+	int n = 0;
+
+	if (provider_clks[0].ck != NULL)
+		return provider_clks;
+
+	do {
+		const char *node_name;
+		u32 cells;
+
+		node = of_find_node_with_property(node, "#clock-cells");
+
+		if (node == NULL)
+			break;
+
+		node_name = get_provider_name(node, &cells);
+
+		if (cells == 0U) {
+			struct clk *ck = __clk_lookup(node_name);
+
+			if (IS_ERR_OR_NULL(ck))
+				continue;
+
+			provider_clks[n].ck = ck;
+			setup_provider_clk(&provider_clks[n]);
+			++n;
+		} else {
+			unsigned int i;
+
+			for (i = 0; i < 256; i++) {
+				struct of_phandle_args pa;
+				struct clk *ck;
+
+				pa.np = node;
+				pa.args[0] = i;
+				pa.args_count = 1;
+				ck = of_clk_get_from_provider(&pa);
+
+				if (PTR_ERR(ck) == -EINVAL)
+					break;
+				else if (IS_ERR_OR_NULL(ck))
+					continue;
+
+				provider_clks[n].ck = ck;
+				provider_clks[n].idx = i;
+				provider_clks[n].provider_name = node_name;
+				setup_provider_clk(&provider_clks[n]);
+				++n;
+			}
+		}
+	} while (node != NULL);
+
+	return provider_clks;
+}
+
+static void dump_provider_clk(struct provider_clk *pvdck, struct seq_file *s)
+{
+	struct clk *c = pvdck->ck;
+	struct clk *p = IS_ERR_OR_NULL(c) ? NULL : clk_get_parent(c);
+	struct clk_hw *c_hw = __clk_get_hw(c);
+	struct clk_hw *p_hw = __clk_get_hw(p);
+
+	seq_printf(s, "[%10s: %-17s: %3s, %3d, %3d, %10ld, %17s]\n",
+		pvdck->provider_name != NULL ? pvdck->provider_name : "/ ",
+		clk_hw_get_name(c_hw),
+		pvdck_is_on(pvdck) ? "ON" : "off",
+		clk_hw_is_prepared(c_hw),
+		__clk_get_enable_count(c),
+		clk_hw_get_rate(c_hw),
+		p != NULL ? clk_hw_get_name(p_hw) : "- ");
+}
+
+static int clkdbg_dump_provider_clks(struct seq_file *s, void *v)
+{
+	struct provider_clk *pvdck = get_all_provider_clks();
+
+	for (; pvdck->ck != NULL; pvdck++)
+		dump_provider_clk(pvdck, s);
+
+	return 0;
+}
+
+static void dump_provider_mux(struct provider_clk *pvdck, struct seq_file *s)
+{
+	unsigned int i;
+	struct clk *c = pvdck->ck;
+	struct clk_hw *c_hw = __clk_get_hw(c);
+	unsigned int np = clk_hw_get_num_parents(c_hw);
+
+	if (np <= 1U)
+		return;
+
+	dump_provider_clk(pvdck, s);
+
+	for (i = 0; i < np; i++) {
+		struct clk_hw *p_hw = clk_hw_get_parent_by_index(c_hw, i);
+
+		if (IS_ERR_OR_NULL(p_hw))
+			continue;
+
+		seq_printf(s, "\t\t\t(%2d: %-17s: %8s, %10ld)\n",
+			i,
+			clk_hw_get_name(p_hw),
+			ccf_state(p_hw),
+			clk_hw_get_rate(p_hw));
+	}
+}
+
+static int clkdbg_dump_muxes(struct seq_file *s, void *v)
+{
+	struct provider_clk *pvdck = get_all_provider_clks();
+
+	for (; pvdck->ck != NULL; pvdck++)
+		dump_provider_mux(pvdck, s);
+
+	return 0;
+}
+
+static void show_pwr_status(u32 spm_pwr_status)
+{
+	unsigned int i;
+	const char * const *pwr_name = get_pwr_names();
+
+	pr_info("SPM_PWR_STATUS: 0x%08x\n\n", spm_pwr_status);
+
+	for (i = 0; i < 32; i++) {
+		const char *st = (spm_pwr_status & BIT(i)) != 0U ? "ON" : "off";
+
+		pr_info("[%2d]: %3s: %s\n", i, st, pwr_name[i]);
+		mdelay(20);
+	}
+}
+
+static int dump_pwr_status(u32 spm_pwr_status, struct seq_file *s)
+{
+	unsigned int i;
+	const char * const *pwr_name = get_pwr_names();
+
+	seq_printf(s, "SPM_PWR_STATUS: 0x%08x\n\n", spm_pwr_status);
+
+	for (i = 0; i < 32; i++) {
+		const char *st = (spm_pwr_status & BIT(i)) != 0U ? "ON" : "off";
+
+		seq_printf(s, "[%2d]: %3s: %s\n", i, st, pwr_name[i]);
+	}
+
+	return 0;
+}
+
+static int clkdbg_pwr_status(struct seq_file *s, void *v)
+{
+	return dump_pwr_status(read_spm_pwr_status(), s);
+}
+
+static char last_cmd[128] = "null";
+
+const char *get_last_cmd(void)
+{
+	return last_cmd;
+}
+
+static int clkop_int_ckname(int (*clkop)(struct clk *clk),
+			const char *clkop_name, const char *clk_name,
+			struct clk *ck, struct seq_file *s)
+{
+	struct clk *clk;
+
+	if (!IS_ERR_OR_NULL(ck)) {
+		clk = ck;
+	} else {
+		clk = __clk_lookup(clk_name);
+		if (IS_ERR_OR_NULL(clk)) {
+			seq_printf(s, "clk_lookup(%s): 0x%p\n", clk_name, clk);
+			return PTR_ERR(clk);
+		}
+	}
+
+	return clkop(clk);
+}
+
+static int clkdbg_clkop_int_ckname(int (*clkop)(struct clk *clk),
+			const char *clkop_name, struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *clk_name;
+	int r = 0;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	clk_name = strsep(&c, " ");
+
+	if (clk_name == NULL)
+		return 0;
+
+	if (strcmp(clk_name, "all") == 0) {
+		struct provider_clk *pvdck = get_all_provider_clks();
+
+		for (; pvdck->ck != NULL; pvdck++) {
+			r |= clkop_int_ckname(clkop, clkop_name, NULL,
+						pvdck->ck, s);
+		}
+
+		seq_printf(s, "%s(%s): %d\n", clkop_name, clk_name, r);
+
+		return r;
+	}
+
+	r = clkop_int_ckname(clkop, clkop_name, clk_name, NULL, s);
+	seq_printf(s, "%s(%s): %d\n", clkop_name, clk_name, r);
+
+	return r;
+}
+
+static void clkop_void_ckname(void (*clkop)(struct clk *clk),
+			const char *clkop_name, const char *clk_name,
+			struct clk *ck, struct seq_file *s)
+{
+	struct clk *clk;
+
+	if (!IS_ERR_OR_NULL(ck)) {
+		clk = ck;
+	} else {
+		clk = __clk_lookup(clk_name);
+		if (IS_ERR_OR_NULL(clk)) {
+			seq_printf(s, "clk_lookup(%s): 0x%p\n", clk_name, clk);
+			return;
+		}
+	}
+
+	clkop(clk);
+}
+
+static int clkdbg_clkop_void_ckname(void (*clkop)(struct clk *clk),
+			const char *clkop_name, struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *clk_name;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	clk_name = strsep(&c, " ");
+
+	if (clk_name == NULL)
+		return 0;
+
+	if (strcmp(clk_name, "all") == 0) {
+		struct provider_clk *pvdck = get_all_provider_clks();
+
+		for (; pvdck->ck != NULL; pvdck++) {
+			clkop_void_ckname(clkop, clkop_name, NULL,
+						pvdck->ck, s);
+		}
+
+		seq_printf(s, "%s(%s)\n", clkop_name, clk_name);
+
+		return 0;
+	}
+
+	clkop_void_ckname(clkop, clkop_name, clk_name, NULL, s);
+	seq_printf(s, "%s(%s)\n", clkop_name, clk_name);
+
+	return 0;
+}
+
+static int clkdbg_prepare(struct seq_file *s, void *v)
+{
+	return clkdbg_clkop_int_ckname(clk_prepare,
+					"clk_prepare", s, v);
+}
+
+static int clkdbg_unprepare(struct seq_file *s, void *v)
+{
+	return clkdbg_clkop_void_ckname(clk_unprepare,
+					"clk_unprepare", s, v);
+}
+
+static int clkdbg_enable(struct seq_file *s, void *v)
+{
+	return clkdbg_clkop_int_ckname(clk_enable,
+					"clk_enable", s, v);
+}
+
+static int clkdbg_disable(struct seq_file *s, void *v)
+{
+	return clkdbg_clkop_void_ckname(clk_disable,
+					"clk_disable", s, v);
+}
+
+static int clkdbg_prepare_enable(struct seq_file *s, void *v)
+{
+	return clkdbg_clkop_int_ckname(clk_prepare_enable,
+					"clk_prepare_enable", s, v);
+}
+
+static int clkdbg_disable_unprepare(struct seq_file *s, void *v)
+{
+	return clkdbg_clkop_void_ckname(clk_disable_unprepare,
+					"clk_disable_unprepare", s, v);
+}
+
+void prepare_enable_provider(const char *pvd)
+{
+	bool allpvd = (pvd == NULL || strcmp(pvd, "all") == 0);
+	struct provider_clk *pvdck = get_all_provider_clks();
+
+	for (; pvdck->ck != NULL; pvdck++) {
+		if (allpvd || (pvdck->provider_name != NULL &&
+				strcmp(pvd, pvdck->provider_name) == 0)) {
+			int r = clk_prepare_enable(pvdck->ck);
+
+			if (r != 0)
+				pr_info("clk_prepare_enable(): %d\n", r);
+		}
+	}
+}
+
+void disable_unprepare_provider(const char *pvd)
+{
+	bool allpvd = (pvd == NULL || strcmp(pvd, "all") == 0);
+	struct provider_clk *pvdck = get_all_provider_clks();
+
+	for (; pvdck->ck != NULL; pvdck++) {
+		if (allpvd || (pvdck->provider_name != NULL &&
+				strcmp(pvd, pvdck->provider_name) == 0))
+			clk_disable_unprepare(pvdck->ck);
+	}
+}
+
+static void clkpvdop(void (*pvdop)(const char *), const char *clkpvdop_name,
+			struct seq_file *s)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *pvd_name;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	pvd_name = strsep(&c, " ");
+
+	if (pvd_name == NULL)
+		return;
+
+	pvdop(pvd_name);
+	seq_printf(s, "%s(%s)\n", clkpvdop_name, pvd_name);
+}
+
+static int clkdbg_prepare_enable_provider(struct seq_file *s, void *v)
+{
+	clkpvdop(prepare_enable_provider, "prepare_enable_provider", s);
+	return 0;
+}
+
+static int clkdbg_disable_unprepare_provider(struct seq_file *s, void *v)
+{
+	clkpvdop(disable_unprepare_provider, "disable_unprepare_provider", s);
+	return 0;
+}
+
+static int clkdbg_set_parent(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *clk_name;
+	char *parent_name;
+	struct clk *clk;
+	struct clk *parent;
+	int r;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	clk_name = strsep(&c, " ");
+	parent_name = strsep(&c, " ");
+
+	if (clk_name == NULL || parent_name == NULL)
+		return 0;
+
+	seq_printf(s, "clk_set_parent(%s, %s): ", clk_name, parent_name);
+
+	clk = __clk_lookup(clk_name);
+	if (IS_ERR_OR_NULL(clk)) {
+		seq_printf(s, "__clk_lookup(): 0x%p\n", clk);
+		return PTR_ERR(clk);
+	}
+
+	parent = __clk_lookup(parent_name);
+	if (IS_ERR_OR_NULL(parent)) {
+		seq_printf(s, "__clk_lookup(): 0x%p\n", parent);
+		return PTR_ERR(parent);
+	}
+
+	r = clk_prepare_enable(clk);
+	if (r != 0) {
+		seq_printf(s, "clk_prepare_enable(): %d\n", r);
+		return r;
+	}
+
+	r = clk_set_parent(clk, parent);
+	seq_printf(s, "%d\n", r);
+
+	clk_disable_unprepare(clk);
+
+	return r;
+}
+
+static int clkdbg_set_rate(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *clk_name;
+	char *rate_str;
+	struct clk *clk;
+	unsigned long rate;
+	int r;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	clk_name = strsep(&c, " ");
+	rate_str = strsep(&c, " ");
+
+	if (clk_name == NULL || rate_str == NULL)
+		return 0;
+
+	r = kstrtoul(rate_str, 0, &rate);
+
+	seq_printf(s, "clk_set_rate(%s, %lu): %d: ", clk_name, rate, r);
+
+	clk = __clk_lookup(clk_name);
+	if (IS_ERR_OR_NULL(clk)) {
+		seq_printf(s, "__clk_lookup(): 0x%p\n", clk);
+		return PTR_ERR(clk);
+	}
+
+	r = clk_set_rate(clk, rate);
+	seq_printf(s, "%d\n", r);
+
+	return r;
+}
+
+static void *reg_from_str(const char *str)
+{
+	static phys_addr_t phys;
+	static void __iomem *virt;
+
+	if (sizeof(void *) == sizeof(unsigned long)) {
+		unsigned long v;
+
+		if (kstrtoul(str, 0, &v) == 0U) {
+			if ((0xf0000000 & v) < 0x20000000) {
+				if (virt != NULL && v > phys
+						&& v < phys + PAGE_SIZE)
+					return virt + v - phys;
+
+				if (virt != NULL)
+					iounmap(virt);
+
+				phys = v & ~(PAGE_SIZE - 1U);
+				virt = ioremap(phys, PAGE_SIZE);
+
+				return virt + v - phys;
+			}
+
+			return (void *)((uintptr_t)v);
+		}
+	} else if (sizeof(void *) == sizeof(unsigned long long)) {
+		unsigned long long v;
+
+		if (kstrtoull(str, 0, &v) == 0) {
+			if ((0xfffffffff0000000ULL & v) < 0x20000000) {
+				if (virt && v > phys && v < phys + PAGE_SIZE)
+					return virt + v - phys;
+
+				if (virt != NULL)
+					iounmap(virt);
+
+				phys = v & ~(PAGE_SIZE - 1);
+				virt = ioremap(phys, PAGE_SIZE);
+
+				return virt + v - phys;
+			}
+
+			return (void *)((uintptr_t)v);
+		}
+	} else {
+		pr_warn("unexpected pointer size: sizeof(void *): %zu\n",
+			sizeof(void *));
+	}
+
+	pr_warn("%s(): parsing error: %s\n", __func__, str);
+
+	return NULL;
+}
+
+static int parse_reg_val_from_cmd(void __iomem **preg, unsigned long *pval)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *reg_str;
+	char *val_str;
+	int r = 0;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	reg_str = strsep(&c, " ");
+	val_str = strsep(&c, " ");
+
+	if (preg != NULL && reg_str != NULL) {
+		*preg = reg_from_str(reg_str);
+		if (*preg != NULL)
+			r++;
+	}
+
+	if (pval != NULL && val_str != NULL && kstrtoul(val_str, 0, pval) == 0)
+		r++;
+
+	return r;
+}
+
+static int clkdbg_reg_read(struct seq_file *s, void *v)
+{
+	void __iomem *reg;
+	unsigned long val;
+
+	if (parse_reg_val_from_cmd(&reg, NULL) != 1)
+		return 0;
+
+	seq_printf(s, "readl(0x%p): ", reg);
+
+	val = clk_readl(reg);
+	seq_printf(s, "0x%08x\n", (u32)val);
+
+	return 0;
+}
+
+static int clkdbg_reg_write(struct seq_file *s, void *v)
+{
+	void __iomem *reg;
+	unsigned long val;
+
+	if (parse_reg_val_from_cmd(&reg, &val) != 2)
+		return 0;
+
+	seq_printf(s, "writel(0x%p, 0x%08x): ", reg, (u32)val);
+
+	clk_writel(reg, val);
+	val = clk_readl(reg);
+	seq_printf(s, "0x%08x\n", (u32)val);
+
+	return 0;
+}
+
+static int clkdbg_reg_set(struct seq_file *s, void *v)
+{
+	void __iomem *reg;
+	unsigned long val;
+
+	if (parse_reg_val_from_cmd(&reg, &val) != 2)
+		return 0;
+
+	seq_printf(s, "writel(0x%p, 0x%08x): ", reg, (u32)val);
+
+	clk_setl(reg, val);
+	val = clk_readl(reg);
+	seq_printf(s, "0x%08x\n", (u32)val);
+
+	return 0;
+}
+
+static int clkdbg_reg_clr(struct seq_file *s, void *v)
+{
+	void __iomem *reg;
+	unsigned long val;
+
+	if (parse_reg_val_from_cmd(&reg, &val) != 2)
+		return 0;
+
+	seq_printf(s, "writel(0x%p, 0x%08x): ", reg, (u32)val);
+
+	clk_clrl(reg, val);
+	val = clk_readl(reg);
+	seq_printf(s, "0x%08x\n", (u32)val);
+
+	return 0;
+}
+
+static int parse_val_from_cmd(unsigned long *pval)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *val_str;
+	int r = 0;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	val_str = strsep(&c, " ");
+
+	if (pval != NULL && val_str != NULL && kstrtoul(val_str, 0, pval) == 0)
+		r++;
+
+	return r;
+}
+
+static int clkdbg_show_flags(struct seq_file *s, void *v)
+{
+	static const char * const clkdbg_opt_name[] = {
+		"CLKDBG_EN_SUSPEND_SAVE_1",
+		"CLKDBG_EN_SUSPEND_SAVE_2",
+		"CLKDBG_EN_SUSPEND_SAVE_3",
+		"CLKDBG_EN_LOG_SAVE_POINTS",
+	};
+
+	size_t i;
+
+	seq_printf(s, "clkdbg_flags: 0x%08x\n", clkdbg_flags);
+
+	for (i = 0; i < ARRAY_SIZE(clkdbg_opt_name); i++) {
+		const char *onff =
+			has_clkdbg_flag((enum clkdbg_opt)i) ? "ON" : "off";
+
+		seq_printf(s, "[%2zd]: %3s: %s\n", i, onff, clkdbg_opt_name[i]);
+	}
+
+	return 0;
+}
+
+static int clkdbg_set_flag(struct seq_file *s, void *v)
+{
+	unsigned long val;
+
+	if (parse_val_from_cmd(&val) != 1)
+		return 0;
+
+	set_clkdbg_flag((enum clkdbg_opt)val);
+
+	seq_printf(s, "clkdbg_flags: 0x%08x\n", clkdbg_flags);
+
+	return 0;
+}
+
+static int clkdbg_clr_flag(struct seq_file *s, void *v)
+{
+	unsigned long val;
+
+	if (parse_val_from_cmd(&val) != 1)
+		return 0;
+
+	clr_clkdbg_flag((enum clkdbg_opt)val);
+
+	seq_printf(s, "clkdbg_flags: 0x%08x\n", clkdbg_flags);
+
+	return 0;
+}
+
+#if CLKDBG_PM_DOMAIN
+
+/*
+ * pm_domain support
+ */
+
+static struct generic_pm_domain **get_all_genpd(void)
+{
+	static struct generic_pm_domain *pds[20];
+	static int num_pds;
+	const size_t maxpd = ARRAY_SIZE(pds);
+	struct device_node *node;
+#if CLKDBG_PM_DOMAIN_API_4_9
+	struct platform_device *pdev;
+	int r;
+#endif
+
+	if (num_pds != 0)
+		goto out;
+
+	node = of_find_node_with_property(NULL, "#power-domain-cells");
+
+	if (node == NULL)
+		return NULL;
+
+#if CLKDBG_PM_DOMAIN_API_4_9
+	pdev = platform_device_alloc("traverse", 0);
+#endif
+
+	for (num_pds = 0; num_pds < maxpd; num_pds++) {
+		struct of_phandle_args pa;
+
+		pa.np = node;
+		pa.args[0] = num_pds;
+		pa.args_count = 1;
+
+#if CLKDBG_PM_DOMAIN_API_4_9
+		r = of_genpd_add_device(&pa, &pdev->dev);
+		if (r == -EINVAL)
+			continue;
+		else if (r != 0)
+			pr_warn("%s(): of_genpd_add_device(%d)\n", __func__, r);
+		pds[num_pds] = pd_to_genpd(pdev->dev.pm_domain);
+#if CLKDBG_DROP_GENPD_AS_IN_PARAM
+		r = pm_genpd_remove_device(&pdev->dev);
+#else
+		r = pm_genpd_remove_device(pds[num_pds], &pdev->dev);
+#endif
+		if (r != 0)
+			pr_warn("%s(): pm_genpd_remove_device(%d)\n",
+					__func__, r);
+#else
+		pds[num_pds] = of_genpd_get_from_provider(&pa);
+#endif
+
+		if (IS_ERR(pds[num_pds])) {
+			pds[num_pds] = NULL;
+			break;
+		}
+	}
+
+#if CLKDBG_PM_DOMAIN_API_4_9
+	platform_device_put(pdev);
+#endif
+
+out:
+	return pds;
+}
+
+static struct platform_device *pdev_from_name(const char *name)
+{
+	struct generic_pm_domain **pds = get_all_genpd();
+
+	for (; *pds != NULL; pds++) {
+		struct pm_domain_data *pdd;
+		struct generic_pm_domain *pd = *pds;
+
+		if (IS_ERR_OR_NULL(pd))
+			continue;
+
+		list_for_each_entry(pdd, &pd->dev_list, list_node) {
+			struct device *dev = pdd->dev;
+			struct platform_device *pdev = to_platform_device(dev);
+
+			if (strcmp(name, pdev->name) == 0)
+				return pdev;
+		}
+	}
+
+	return NULL;
+}
+
+static struct generic_pm_domain *genpd_from_name(const char *name)
+{
+	struct generic_pm_domain **pds = get_all_genpd();
+
+	for (; *pds != NULL; pds++) {
+		struct generic_pm_domain *pd = *pds;
+
+		if (IS_ERR_OR_NULL(pd))
+			continue;
+
+		if (strcmp(name, pd->name) == 0)
+			return pd;
+	}
+
+	return NULL;
+}
+
+struct genpd_dev_state {
+	struct device *dev;
+	bool active;
+	atomic_t usage_count;
+	unsigned int disable_depth;
+	enum rpm_status runtime_status;
+};
+
+struct genpd_state {
+	struct generic_pm_domain *pd;
+	enum gpd_status status;
+	struct genpd_dev_state *dev_state;
+	int num_dev_state;
+};
+
+static void save_all_genpd_state(struct genpd_state *genpd_states,
+				struct genpd_dev_state *genpd_dev_states)
+{
+	struct genpd_state *pdst = genpd_states;
+	struct genpd_dev_state *devst = genpd_dev_states;
+	struct generic_pm_domain **pds = get_all_genpd();
+
+	for (; *pds != NULL; pds++) {
+		struct pm_domain_data *pdd;
+		struct generic_pm_domain *pd = *pds;
+
+		if (IS_ERR_OR_NULL(pd))
+			continue;
+
+		pdst->pd = pd;
+		pdst->status = pd->status;
+		pdst->dev_state = devst;
+		pdst->num_dev_state = 0;
+
+		list_for_each_entry(pdd, &pd->dev_list, list_node) {
+			struct device *d = pdd->dev;
+
+			devst->dev = d;
+			devst->active = pm_runtime_active(d);
+			devst->usage_count = d->power.usage_count;
+			devst->disable_depth = d->power.disable_depth;
+			devst->runtime_status = d->power.runtime_status;
+
+			devst++;
+			pdst->num_dev_state++;
+		}
+
+		pdst++;
+	}
+
+	pdst->pd = NULL;
+	devst->dev = NULL;
+}
+
+static void show_genpd_state(struct genpd_state *pdst)
+{
+	static const char * const gpd_status_name[] = {
+		"ACTIVE",
+		"POWER_OFF",
+	};
+
+	static const char * const prm_status_name[] = {
+		"active",
+		"resuming",
+		"suspended",
+		"suspending",
+	};
+
+	pr_info("domain_on [pmd_name  status]\n");
+	pr_info("\tdev_on (dev_name usage_count, disable, status)\n");
+	pr_info("------------------------------------------------------\n");
+
+	for (; pdst->pd != NULL; pdst++) {
+		int i;
+		struct generic_pm_domain *pd = pdst->pd;
+
+		if (IS_ERR_OR_NULL(pd)) {
+			pr_info("pd: 0x%p\n", pd);
+			continue;
+		}
+
+		pr_info("%c [%-9s %11s]\n",
+			(pdst->status == GPD_STATE_ACTIVE) ? '+' : '-',
+			pd->name, gpd_status_name[pdst->status]);
+
+		for (i = 0; i < pdst->num_dev_state; i++) {
+			struct genpd_dev_state *devst = &pdst->dev_state[i];
+			struct device *dev = devst->dev;
+			struct platform_device *pdev = to_platform_device(dev);
+
+			pr_info("\t%c (%-19s %3d, %d, %10s)\n",
+				devst->active ? '+' : '-',
+				pdev->name,
+				atomic_read(&dev->power.usage_count),
+				devst->disable_depth,
+				prm_status_name[devst->runtime_status]);
+			mdelay(20);
+		}
+	}
+}
+
+static void dump_genpd_state(struct genpd_state *pdst, struct seq_file *s)
+{
+	static const char * const gpd_status_name[] = {
+		"ACTIVE",
+		"POWER_OFF",
+	};
+
+	static const char * const prm_status_name[] = {
+		"active",
+		"resuming",
+		"suspended",
+		"suspending",
+	};
+
+	seq_puts(s, "domain_on [pmd_name  status]\n");
+	seq_puts(s, "\tdev_on (dev_name usage_count, disable, status)\n");
+	seq_puts(s, "------------------------------------------------------\n");
+
+	for (; pdst->pd != NULL; pdst++) {
+		int i;
+		struct generic_pm_domain *pd = pdst->pd;
+
+		if (IS_ERR_OR_NULL(pd)) {
+			seq_printf(s, "pd: 0x%p\n", pd);
+			continue;
+		}
+
+		seq_printf(s, "%c [%-9s %11s]\n",
+			(pdst->status == GPD_STATE_ACTIVE) ? '+' : '-',
+			pd->name, gpd_status_name[pdst->status]);
+
+		for (i = 0; i < pdst->num_dev_state; i++) {
+			struct genpd_dev_state *devst = &pdst->dev_state[i];
+			struct device *dev = devst->dev;
+			struct platform_device *pdev = to_platform_device(dev);
+
+			seq_printf(s, "\t%c (%-19s %3d, %d, %10s)\n",
+				devst->active ? '+' : '-',
+				pdev->name,
+				atomic_read(&dev->power.usage_count),
+				devst->disable_depth,
+				prm_status_name[devst->runtime_status]);
+		}
+	}
+}
+
+static void seq_print_all_genpd(struct seq_file *s)
+{
+	static struct genpd_dev_state devst[100];
+	static struct genpd_state pdst[20];
+
+	save_all_genpd_state(pdst, devst);
+	dump_genpd_state(pdst, s);
+}
+
+static int clkdbg_dump_genpd(struct seq_file *s, void *v)
+{
+	seq_print_all_genpd(s);
+
+	return 0;
+}
+
+static int clkdbg_pm_runtime_enable(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *dev_name;
+	struct platform_device *pdev;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	dev_name = strsep(&c, " ");
+
+	if (dev_name == NULL)
+		return 0;
+
+	seq_printf(s, "pm_runtime_enable(%s): ", dev_name);
+
+	pdev = pdev_from_name(dev_name);
+	if (pdev != NULL) {
+		pm_runtime_enable(&pdev->dev);
+		seq_puts(s, "\n");
+	} else {
+		seq_puts(s, "NULL\n");
+	}
+
+	return 0;
+}
+
+static int clkdbg_pm_runtime_disable(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *dev_name;
+	struct platform_device *pdev;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	dev_name = strsep(&c, " ");
+
+	if (dev_name == NULL)
+		return 0;
+
+	seq_printf(s, "pm_runtime_disable(%s): ", dev_name);
+
+	pdev = pdev_from_name(dev_name);
+	if (pdev != NULL) {
+		pm_runtime_disable(&pdev->dev);
+		seq_puts(s, "\n");
+	} else {
+		seq_puts(s, "NULL\n");
+	}
+
+	return 0;
+}
+
+static int clkdbg_pm_runtime_get_sync(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *dev_name;
+	struct platform_device *pdev;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	dev_name = strsep(&c, " ");
+
+	if (dev_name == NULL)
+		return 0;
+
+	seq_printf(s, "pm_runtime_get_sync(%s): ", dev_name);
+
+	pdev = pdev_from_name(dev_name);
+	if (pdev != NULL) {
+		int r = pm_runtime_get_sync(&pdev->dev);
+
+		seq_printf(s, "%d\n", r);
+	} else {
+		seq_puts(s, "NULL\n");
+	}
+
+	return 0;
+}
+
+static int clkdbg_pm_runtime_put_sync(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *dev_name;
+	struct platform_device *pdev;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	dev_name = strsep(&c, " ");
+
+	if (dev_name == NULL)
+		return 0;
+
+	seq_printf(s, "pm_runtime_put_sync(%s): ", dev_name);
+
+	pdev = pdev_from_name(dev_name);
+	if (pdev != NULL) {
+		int r = pm_runtime_put_sync(&pdev->dev);
+
+		seq_printf(s, "%d\n", r);
+	} else {
+		seq_puts(s, "NULL\n");
+	}
+
+	return 0;
+}
+
+static int genpd_op(const char *gpd_op_name, struct seq_file *s)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *pd_name;
+	struct generic_pm_domain *genpd;
+	int gpd_op_id;
+	int (*gpd_op)(struct generic_pm_domain *genpd);
+	int r = 0;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	pd_name = strsep(&c, " ");
+
+	if (pd_name == NULL)
+		return 0;
+
+	if (strcmp(gpd_op_name, "power_on") == 0)
+		gpd_op_id = 1;
+	else
+		gpd_op_id = 0;
+
+	if (strcmp(pd_name, "all") == 0) {
+		struct generic_pm_domain **pds = get_all_genpd();
+
+		for (; *pds != NULL; pds++) {
+			genpd = *pds;
+
+			if (IS_ERR_OR_NULL(genpd))
+				continue;
+
+			gpd_op = (gpd_op_id == 1) ?
+					genpd->power_on : genpd->power_off;
+			r |= gpd_op(genpd);
+		}
+
+		seq_printf(s, "%s(%s): %d\n", gpd_op_name, pd_name, r);
+
+		return 0;
+	}
+
+	genpd = genpd_from_name(pd_name);
+	if (genpd != NULL) {
+		gpd_op = (gpd_op_id == 1) ? genpd->power_on : genpd->power_off;
+		r = gpd_op(genpd);
+
+		seq_printf(s, "%s(%s): %d\n", gpd_op_name, pd_name, r);
+	} else {
+		seq_printf(s, "genpd_from_name(%s): NULL\n", pd_name);
+	}
+
+	return 0;
+}
+
+static int clkdbg_pwr_on(struct seq_file *s, void *v)
+{
+	return genpd_op("power_on", s);
+}
+
+static int clkdbg_pwr_off(struct seq_file *s, void *v)
+{
+	return genpd_op("power_off", s);
+}
+
+/*
+ * clkdbg reg_pdrv/runeg_pdrv support
+ */
+
+static int clkdbg_probe(struct platform_device *pdev)
+{
+	int r;
+
+	pm_runtime_enable(&pdev->dev);
+	r = pm_runtime_get_sync(&pdev->dev);
+	if (r != 0)
+		pr_warn("%s(): pm_runtime_get_sync(%d)\n", __func__, r);
+
+	return r;
+}
+
+static int clkdbg_remove(struct platform_device *pdev)
+{
+	int r;
+
+	r = pm_runtime_put_sync(&pdev->dev);
+	if (r != 0)
+		pr_warn("%s(): pm_runtime_put_sync(%d)\n", __func__, r);
+	pm_runtime_disable(&pdev->dev);
+
+	return r;
+}
+
+struct pdev_drv {
+	struct platform_driver pdrv;
+	struct platform_device *pdev;
+	struct generic_pm_domain *genpd;
+};
+
+#define PDEV_DRV(_name) {				\
+	.pdrv = {					\
+		.probe		= clkdbg_probe,		\
+		.remove		= clkdbg_remove,	\
+		.driver		= {			\
+			.name	= _name,		\
+		},					\
+	},						\
+}
+
+static struct pdev_drv pderv[] = {
+	PDEV_DRV("clkdbg-pd0"),
+	PDEV_DRV("clkdbg-pd1"),
+	PDEV_DRV("clkdbg-pd2"),
+	PDEV_DRV("clkdbg-pd3"),
+	PDEV_DRV("clkdbg-pd4"),
+	PDEV_DRV("clkdbg-pd5"),
+	PDEV_DRV("clkdbg-pd6"),
+	PDEV_DRV("clkdbg-pd7"),
+	PDEV_DRV("clkdbg-pd8"),
+	PDEV_DRV("clkdbg-pd9"),
+	PDEV_DRV("clkdbg-pd10"),
+	PDEV_DRV("clkdbg-pd11"),
+	PDEV_DRV("clkdbg-pd12"),
+	PDEV_DRV("clkdbg-pd13"),
+	PDEV_DRV("clkdbg-pd14"),
+	PDEV_DRV("clkdbg-pd15"),
+};
+
+static void reg_pdev_drv(const char *pdname, struct seq_file *s)
+{
+	size_t i;
+	struct generic_pm_domain **pds = get_all_genpd();
+	bool allpd = (pdname == NULL || strcmp(pdname, "all") == 0);
+	int r;
+
+	for (i = 0; i < ARRAY_SIZE(pderv) && *pds != NULL; i++, pds++) {
+		const char *name = pderv[i].pdrv.driver.name;
+		struct generic_pm_domain *pd = *pds;
+
+		if (IS_ERR_OR_NULL(pd) || pderv[i].genpd != NULL)
+			continue;
+
+		if (!allpd && strcmp(pdname, pd->name) != 0)
+			continue;
+
+		pderv[i].genpd = pd;
+
+		pderv[i].pdev = platform_device_alloc(name, 0);
+		r = platform_device_add(pderv[i].pdev);
+		if (r != 0 && s != NULL)
+			seq_printf(s, "%s(): platform_device_add(%d)\n",
+						__func__, r);
+
+		r = pm_genpd_add_device(pd, &pderv[i].pdev->dev);
+		if (r != 0 && s != NULL)
+			seq_printf(s, "%s(): pm_genpd_add_device(%d)\n",
+						__func__, r);
+		r = platform_driver_register(&pderv[i].pdrv);
+		if (r != 0 && s != NULL)
+			seq_printf(s, "%s(): platform_driver_register(%d)\n",
+						__func__, r);
+
+		if (s != NULL)
+			seq_printf(s, "%s --> %s\n", name, pd->name);
+	}
+}
+
+static void unreg_pdev_drv(const char *pdname, struct seq_file *s)
+{
+	ssize_t i;
+	bool allpd = (pdname == NULL || strcmp(pdname, "all") == 0);
+	int r;
+
+	for (i = ARRAY_SIZE(pderv) - 1L; i >= 0L; i--) {
+		const char *name = pderv[i].pdrv.driver.name;
+		struct generic_pm_domain *pd = pderv[i].genpd;
+
+		if (IS_ERR_OR_NULL(pd))
+			continue;
+
+		if (!allpd && strcmp(pdname, pd->name) != 0)
+			continue;
+
+#if CLKDBG_DROP_GENPD_AS_IN_PARAM
+		r = pm_genpd_remove_device(&pderv[i].pdev->dev);
+#else
+		r = pm_genpd_remove_device(pd, &pderv[i].pdev->dev);
+#endif
+		if (r != 0 && s != NULL)
+			seq_printf(s, "%s(): pm_genpd_remove_device(%d)\n",
+						__func__, r);
+
+		platform_driver_unregister(&pderv[i].pdrv);
+		platform_device_unregister(pderv[i].pdev);
+
+		pderv[i].genpd = NULL;
+
+		if (s != NULL)
+			seq_printf(s, "%s -x- %s\n", name, pd->name);
+	}
+}
+
+static int clkdbg_reg_pdrv(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *pd_name;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	pd_name = strsep(&c, " ");
+
+	if (pd_name == NULL)
+		return 0;
+
+	reg_pdev_drv(pd_name, s);
+
+	return 0;
+}
+
+static int clkdbg_unreg_pdrv(struct seq_file *s, void *v)
+{
+	char cmd[sizeof(last_cmd)];
+	char *c = cmd;
+	char *ign;
+	char *pd_name;
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	ign = strsep(&c, " ");
+	pd_name = strsep(&c, " ");
+
+	if (pd_name == NULL)
+		return 0;
+
+	unreg_pdev_drv(pd_name, s);
+
+	return 0;
+}
+
+#endif /* CLKDBG_PM_DOMAIN */
+
+void reg_pdrv(const char *pdname)
+{
+#if CLKDBG_PM_DOMAIN
+	reg_pdev_drv(pdname, NULL);
+#endif
+}
+
+void unreg_pdrv(const char *pdname)
+{
+#if CLKDBG_PM_DOMAIN
+	unreg_pdev_drv(pdname, NULL);
+#endif
+}
+
+/*
+ * Suspend / resume handler
+ */
+
+#include <linux/suspend.h>
+#include <linux/syscore_ops.h>
+
+struct provider_clk_state {
+	struct provider_clk *pvdck;
+	bool prepared;
+	bool enabled;
+	unsigned int enable_count;
+	unsigned long rate;
+	struct clk *parent;
+};
+
+struct save_point {
+	u32 spm_pwr_status;
+	struct provider_clk_state clks_states[512];
+#if CLKDBG_PM_DOMAIN
+	struct genpd_state genpd_states[20];
+	struct genpd_dev_state genpd_dev_states[100];
+#endif
+};
+
+static struct save_point save_point_1;
+static struct save_point save_point_2;
+static struct save_point save_point_3;
+
+static void save_pwr_status(u32 *spm_pwr_status)
+{
+	*spm_pwr_status = read_spm_pwr_status();
+}
+
+static void save_all_clks_state(struct provider_clk_state *clks_states,
+				u32 spm_pwr_status)
+{
+	struct provider_clk *pvdck = get_all_provider_clks();
+	struct provider_clk_state *st = clks_states;
+
+	for (; pvdck->ck != NULL; pvdck++, st++) {
+		struct clk *c = pvdck->ck;
+		struct clk_hw *c_hw = __clk_get_hw(c);
+
+		st->pvdck = pvdck;
+		st->prepared = clk_hw_is_prepared(c_hw);
+		st->enabled = clk_hw_pwr_is_on(c_hw, spm_pwr_status,
+							pvdck->pwr_mask);
+		st->enable_count = __clk_get_enable_count(c);
+		st->rate = clk_hw_get_rate(c_hw);
+		st->parent = IS_ERR_OR_NULL(c) ? NULL : clk_get_parent(c);
+	}
+}
+
+static void show_provider_clk_state(struct provider_clk_state *st)
+{
+	struct provider_clk *pvdck = st->pvdck;
+	struct clk_hw *c_hw = __clk_get_hw(pvdck->ck);
+
+	pr_info("[%10s: %-17s: %3s, %3d, %3d, %10ld, %17s]\n",
+		pvdck->provider_name != NULL ? pvdck->provider_name : "/ ",
+		clk_hw_get_name(c_hw),
+		st->enabled ? "ON" : "off",
+		st->prepared,
+		st->enable_count,
+		st->rate,
+		st->parent != NULL ?
+			clk_hw_get_name(__clk_get_hw(st->parent)) : "- ");
+	mdelay(20);
+}
+
+static void dump_provider_clk_state(struct provider_clk_state *st,
+					struct seq_file *s)
+{
+	struct provider_clk *pvdck = st->pvdck;
+	struct clk_hw *c_hw = __clk_get_hw(pvdck->ck);
+
+	seq_printf(s, "[%10s: %-17s: %3s, %3d, %3d, %10ld, %17s]\n",
+		pvdck->provider_name != NULL ? pvdck->provider_name : "/ ",
+		clk_hw_get_name(c_hw),
+		st->enabled ? "ON" : "off",
+		st->prepared,
+		st->enable_count,
+		st->rate,
+		st->parent != NULL ?
+			clk_hw_get_name(__clk_get_hw(st->parent)) : "- ");
+}
+
+static void show_save_point(struct save_point *sp)
+{
+	struct provider_clk_state *st = sp->clks_states;
+
+	for (; st->pvdck != NULL; st++)
+		show_provider_clk_state(st);
+
+	pr_info("\n");
+	show_pwr_status(sp->spm_pwr_status);
+
+#if CLKDBG_PM_DOMAIN
+	pr_info("\n");
+	show_genpd_state(sp->genpd_states);
+#endif
+}
+
+static void store_save_point(struct save_point *sp)
+{
+	save_pwr_status(&sp->spm_pwr_status);
+	save_all_clks_state(sp->clks_states, sp->spm_pwr_status);
+
+#if CLKDBG_PM_DOMAIN
+	save_all_genpd_state(sp->genpd_states, sp->genpd_dev_states);
+#endif
+
+	if (has_clkdbg_flag(CLKDBG_EN_LOG_SAVE_POINTS))
+		show_save_point(sp);
+}
+
+static void dump_save_point(struct save_point *sp, struct seq_file *s)
+{
+	struct provider_clk_state *st = sp->clks_states;
+
+	for (; st->pvdck != NULL; st++)
+		dump_provider_clk_state(st, s);
+
+	seq_puts(s, "\n");
+	dump_pwr_status(sp->spm_pwr_status, s);
+
+#if CLKDBG_PM_DOMAIN
+	seq_puts(s, "\n");
+	dump_genpd_state(sp->genpd_states, s);
+#endif
+}
+
+static int clkdbg_dump_suspend_clks_1(struct seq_file *s, void *v)
+{
+	dump_save_point(&save_point_1, s);
+	return 0;
+}
+
+static int clkdbg_dump_suspend_clks_2(struct seq_file *s, void *v)
+{
+	dump_save_point(&save_point_2, s);
+	return 0;
+}
+
+static int clkdbg_dump_suspend_clks_3(struct seq_file *s, void *v)
+{
+	dump_save_point(&save_point_3, s);
+	return 0;
+}
+
+static int clkdbg_dump_suspend_clks(struct seq_file *s, void *v)
+{
+	if (has_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_3) &&
+			save_point_3.spm_pwr_status != 0U)
+		return clkdbg_dump_suspend_clks_3(s, v);
+	else if (has_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_2) &&
+			save_point_2.spm_pwr_status != 0U)
+		return clkdbg_dump_suspend_clks_2(s, v);
+	else if (has_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_1) &&
+			save_point_1.spm_pwr_status != 0U)
+		return clkdbg_dump_suspend_clks_1(s, v);
+
+	return 0;
+}
+
+static int clkdbg_pm_event_handler(struct notifier_block *nb,
+					unsigned long event, void *ptr)
+{
+	switch (event) {
+	case PM_HIBERNATION_PREPARE:
+	case PM_SUSPEND_PREPARE:
+		/* suspend */
+		if (has_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_1)) {
+			store_save_point(&save_point_1);
+			return NOTIFY_OK;
+		}
+
+		break;
+	case PM_POST_HIBERNATION:
+	case PM_POST_SUSPEND:
+		/* resume */
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block clkdbg_pm_notifier = {
+	.notifier_call = clkdbg_pm_event_handler,
+};
+
+static int clkdbg_syscore_suspend(void)
+{
+	if (has_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_2))
+		store_save_point(&save_point_2);
+
+	return 0;
+}
+
+static void clkdbg_syscore_resume(void)
+{
+}
+
+static struct syscore_ops clkdbg_syscore_ops = {
+	.suspend = clkdbg_syscore_suspend,
+	.resume = clkdbg_syscore_resume,
+};
+
+static int __init clkdbg_pm_init(void)
+{
+	int r;
+
+	register_syscore_ops(&clkdbg_syscore_ops);
+	r = register_pm_notifier(&clkdbg_pm_notifier);
+	if (r != 0)
+		pr_warn("%s(): register_pm_notifier(%d)\n", __func__, r);
+
+	return r;
+}
+subsys_initcall(clkdbg_pm_init);
+
+static int clkdbg_suspend_ops_valid(suspend_state_t state)
+{
+	return state == PM_SUSPEND_MEM ? 1 : 0;
+}
+
+static int clkdbg_suspend_ops_begin(suspend_state_t state)
+{
+	return 0;
+}
+
+static int clkdbg_suspend_ops_prepare(void)
+{
+	return 0;
+}
+
+static int clkdbg_suspend_ops_enter(suspend_state_t state)
+{
+	if (has_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_3))
+		store_save_point(&save_point_3);
+
+	return 0;
+}
+
+static void clkdbg_suspend_ops_finish(void)
+{
+}
+
+static void clkdbg_suspend_ops_end(void)
+{
+}
+
+static const struct platform_suspend_ops clkdbg_suspend_ops = {
+	.valid = clkdbg_suspend_ops_valid,
+	.begin = clkdbg_suspend_ops_begin,
+	.prepare = clkdbg_suspend_ops_prepare,
+	.enter = clkdbg_suspend_ops_enter,
+	.finish = clkdbg_suspend_ops_finish,
+	.end = clkdbg_suspend_ops_end,
+};
+
+static int clkdbg_suspend_set_ops(struct seq_file *s, void *v)
+{
+	suspend_set_ops(&clkdbg_suspend_ops);
+
+	return 0;
+}
+
+static const struct cmd_fn *custom_cmds;
+
+void set_custom_cmds(const struct cmd_fn *cmds)
+{
+	custom_cmds = cmds;
+}
+
+static int clkdbg_cmds(struct seq_file *s, void *v);
+
+static const struct cmd_fn common_cmds[] = {
+	CMDFN("dump_regs", seq_print_regs),
+	CMDFN("dump_regs2", clkdbg_dump_regs2),
+	CMDFN("dump_state", clkdbg_dump_state_all),
+	CMDFN("dump_clks", clkdbg_dump_provider_clks),
+	CMDFN("dump_muxes", clkdbg_dump_muxes),
+	CMDFN("fmeter", seq_print_fmeter_all),
+	CMDFN("pwr_status", clkdbg_pwr_status),
+	CMDFN("prepare", clkdbg_prepare),
+	CMDFN("unprepare", clkdbg_unprepare),
+	CMDFN("enable", clkdbg_enable),
+	CMDFN("disable", clkdbg_disable),
+	CMDFN("prepare_enable", clkdbg_prepare_enable),
+	CMDFN("disable_unprepare", clkdbg_disable_unprepare),
+	CMDFN("prepare_enable_provider", clkdbg_prepare_enable_provider),
+	CMDFN("disable_unprepare_provider", clkdbg_disable_unprepare_provider),
+	CMDFN("set_parent", clkdbg_set_parent),
+	CMDFN("set_rate", clkdbg_set_rate),
+	CMDFN("reg_read", clkdbg_reg_read),
+	CMDFN("reg_write", clkdbg_reg_write),
+	CMDFN("reg_set", clkdbg_reg_set),
+	CMDFN("reg_clr", clkdbg_reg_clr),
+	CMDFN("show_flags", clkdbg_show_flags),
+	CMDFN("set_flag", clkdbg_set_flag),
+	CMDFN("clr_flag", clkdbg_clr_flag),
+#if CLKDBG_PM_DOMAIN
+	CMDFN("dump_genpd", clkdbg_dump_genpd),
+	CMDFN("pm_runtime_enable", clkdbg_pm_runtime_enable),
+	CMDFN("pm_runtime_disable", clkdbg_pm_runtime_disable),
+	CMDFN("pm_runtime_get_sync", clkdbg_pm_runtime_get_sync),
+	CMDFN("pm_runtime_put_sync", clkdbg_pm_runtime_put_sync),
+	CMDFN("pwr_on", clkdbg_pwr_on),
+	CMDFN("pwr_off", clkdbg_pwr_off),
+	CMDFN("reg_pdrv", clkdbg_reg_pdrv),
+	CMDFN("unreg_pdrv", clkdbg_unreg_pdrv),
+#endif /* CLKDBG_PM_DOMAIN */
+	CMDFN("suspend_set_ops", clkdbg_suspend_set_ops),
+	CMDFN("dump_suspend_clks", clkdbg_dump_suspend_clks),
+	CMDFN("dump_suspend_clks_1", clkdbg_dump_suspend_clks_1),
+	CMDFN("dump_suspend_clks_2", clkdbg_dump_suspend_clks_2),
+	CMDFN("dump_suspend_clks_3", clkdbg_dump_suspend_clks_3),
+	CMDFN("cmds", clkdbg_cmds),
+	{}
+};
+
+static int clkdbg_cmds(struct seq_file *s, void *v)
+{
+	const struct cmd_fn *cf;
+
+	for (cf = common_cmds; cf->cmd != NULL; cf++)
+		seq_printf(s, "%s\n", cf->cmd);
+
+	for (cf = custom_cmds; cf != NULL && cf->cmd != NULL; cf++)
+		seq_printf(s, "%s\n", cf->cmd);
+
+	seq_puts(s, "\n");
+
+	return 0;
+}
+
+static int clkdbg_show(struct seq_file *s, void *v)
+{
+	const struct cmd_fn *cf;
+	char cmd[sizeof(last_cmd)];
+
+	strncpy(cmd, last_cmd, sizeof(cmd));
+	cmd[sizeof(cmd) - 1UL] = '\0';
+
+	for (cf = custom_cmds; cf != NULL && cf->cmd != NULL; cf++) {
+		char *c = cmd;
+		char *token = strsep(&c, " ");
+
+		if (strcmp(cf->cmd, token) == 0)
+			return cf->fn(s, v);
+	}
+
+	for (cf = common_cmds; cf->cmd != NULL; cf++) {
+		char *c = cmd;
+		char *token = strsep(&c, " ");
+
+		if (strcmp(cf->cmd, token) == 0)
+			return cf->fn(s, v);
+	}
+
+	return 0;
+}
+
+static int clkdbg_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, clkdbg_show, NULL);
+}
+
+static ssize_t clkdbg_write(
+		struct file *file,
+		const char __user *buffer,
+		size_t count,
+		loff_t *data)
+{
+	size_t len = 0;
+
+	len = (count < (sizeof(last_cmd) - 1UL)) ?
+				count : (sizeof(last_cmd) - 1UL);
+	if (copy_from_user(last_cmd, buffer, len) != 0UL)
+		return 0;
+
+	last_cmd[len] = '\0';
+
+	if (last_cmd[len - 1UL] == '\n')
+		last_cmd[len - 1UL] = '\0';
+
+	return (ssize_t)len;
+}
+
+static const struct file_operations clkdbg_fops = {
+	.owner		= THIS_MODULE,
+	.open		= clkdbg_open,
+	.read		= seq_read,
+	.write		= clkdbg_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+/*
+ * init functions
+ */
+
+static int __init clkdbg_debug_init(void)
+{
+	struct proc_dir_entry *entry;
+
+	entry = proc_create("clkdbg", 0644, NULL, &clkdbg_fops);
+	if (entry == 0)
+		return -ENOMEM;
+
+	set_clkdbg_flag(CLKDBG_EN_SUSPEND_SAVE_3);
+
+	return 0;
+}
+module_init(clkdbg_debug_init);
diff --git a/drivers/clk/mediatek/clkdbg.h b/drivers/clk/mediatek/clkdbg.h
new file mode 100644
index 000000000000..b9cddf3445ff
--- /dev/null
+++ b/drivers/clk/mediatek/clkdbg.h
@@ -0,0 +1,83 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Weiyi Lu <weiyi.lu@mediatek.com>
+ */
+
+struct seq_file;
+
+#define clk_readl(addr)		readl(addr)
+#define clk_writel(addr, val)	\
+	do { writel(val, addr); wmb(); } while (0) /* sync write */
+#define clk_setl(addr, val)	clk_writel(addr, clk_readl(addr) | (val))
+#define clk_clrl(addr, val)	clk_writel(addr, clk_readl(addr) & ~(val))
+
+enum FMETER_TYPE {
+	FT_NULL,
+	ABIST,
+	CKGEN
+};
+
+struct fmeter_clk {
+	enum FMETER_TYPE type;
+	u32 id;
+	const char *name;
+};
+
+struct regbase {
+	u32 phys;
+	void __iomem *virt;
+	const char *name;
+};
+
+struct regname {
+	struct regbase *base;
+	u32 ofs;
+	const char *name;
+};
+
+#define ADDR(rn)	(rn->base->virt + rn->ofs)
+#define PHYSADDR(rn)	(rn->base->phys + rn->ofs)
+
+struct cmd_fn {
+	const char	*cmd;
+	int (*fn)(struct seq_file *s, void *v);
+};
+
+#define CMDFN(_cmd, _fn) {	\
+	.cmd = _cmd,		\
+	.fn = _fn,		\
+}
+
+struct provider_clk {
+	const char *provider_name;
+	u32 idx;
+	struct clk *ck;
+	u32 pwr_mask;
+};
+
+struct clkdbg_ops {
+	const struct fmeter_clk *(*get_all_fmeter_clks)(void);
+	void *(*prepare_fmeter)(void);
+	void (*unprepare_fmeter)(void *data);
+	u32 (*fmeter_freq)(const struct fmeter_clk *fclk);
+	const struct regname *(*get_all_regnames)(void);
+	const char * const *(*get_all_clk_names)(void);
+	const char * const *(*get_pwr_names)(void);
+	void (*setup_provider_clk)(struct provider_clk *pvdck);
+	u32 (*get_spm_pwr_status)(void);
+};
+
+void set_clkdbg_ops(const struct clkdbg_ops *ops);
+void set_custom_cmds(const struct cmd_fn *cmds);
+
+struct provider_clk *get_all_provider_clks(void);
+const char *get_last_cmd(void);
+
+void reg_pdrv(const char *pdname);
+void unreg_pdrv(const char *pdname);
+void prepare_enable_provider(const char *pvd);
+void disable_unprepare_provider(const char *pvd);
+
+void print_regs(void);
+void print_fmeter_all(void);
diff --git a/drivers/gpu/drm/mediatek/mtk_mipi_tx.h b/drivers/gpu/drm/mediatek/mtk_mipi_tx.h
new file mode 100644
index 000000000000..af83023e81cf
--- /dev/null
+++ b/drivers/gpu/drm/mediatek/mtk_mipi_tx.h
@@ -0,0 +1,52 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Jitao Shi <jitao.shi@mediatek.com>
+ */
+
+#ifndef _MTK_MIPI_TX_H
+#define _MTK_MIPI_TX_H
+
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/phy/phy.h>
+
+struct mtk_mipitx_data {
+	const u32 mppll_preserve;
+	const struct clk_ops *mipi_tx_clk_ops;
+	void (*mipi_tx_enable_signal)(struct phy *phy);
+	void (*mipi_tx_disable_signal)(struct phy *phy);
+};
+
+struct mtk_mipi_tx {
+	struct device *dev;
+	void __iomem *regs;
+	u32 data_rate;
+	struct clk *ref_clk;
+	const struct mtk_mipitx_data *driver_data;
+	struct clk_hw pll_hw;
+	struct clk *pll;
+};
+
+struct mtk_mipi_tx *mtk_mipi_tx_from_clk_hw(struct clk_hw *hw);
+void mtk_mipi_tx_clear_bits(struct mtk_mipi_tx *mipi_tx, u32 offset, u32 bits);
+void mtk_mipi_tx_set_bits(struct mtk_mipi_tx *mipi_tx, u32 offset, u32 bits);
+void mtk_mipi_tx_update_bits(struct mtk_mipi_tx *mipi_tx, u32 offset, u32 mask,
+			     u32 data);
+long mtk_mipi_tx_pll_round_rate(struct clk_hw *hw, unsigned long rate,
+				unsigned long *prate);
+int mtk_mipi_tx_pll_set_rate(struct clk_hw *hw, unsigned long rate,
+			     unsigned long parent_rate);
+unsigned long mtk_mipi_tx_pll_recalc_rate(struct clk_hw *hw,
+					  unsigned long parent_rate);
+
+extern const struct mtk_mipitx_data mt2701_mipitx_data;
+extern const struct mtk_mipitx_data mt8173_mipitx_data;
+extern const struct mtk_mipitx_data mt8183_mipitx_data;
+
+#endif
diff --git a/drivers/gpu/drm/mediatek/mtk_mt8173_mipi_tx.c b/drivers/gpu/drm/mediatek/mtk_mt8173_mipi_tx.c
new file mode 100644
index 000000000000..943650cfed46
--- /dev/null
+++ b/drivers/gpu/drm/mediatek/mtk_mt8173_mipi_tx.c
@@ -0,0 +1,283 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: jitao.shi <jitao.shi@mediatek.com>
+ */
+
+#include "mtk_mipi_tx.h"
+
+#define MIPITX_DSI_CON		0x00
+#define RG_DSI_LDOCORE_EN		BIT(0)
+#define RG_DSI_CKG_LDOOUT_EN		BIT(1)
+#define RG_DSI_BCLK_SEL			(3 << 2)
+#define RG_DSI_LD_IDX_SEL		(7 << 4)
+#define RG_DSI_PHYCLK_SEL		(2 << 8)
+#define RG_DSI_DSICLK_FREQ_SEL		BIT(10)
+#define RG_DSI_LPTX_CLMP_EN		BIT(11)
+
+#define MIPITX_DSI_CLOCK_LANE	0x04
+#define MIPITX_DSI_DATA_LANE0	0x08
+#define MIPITX_DSI_DATA_LANE1	0x0c
+#define MIPITX_DSI_DATA_LANE2	0x10
+#define MIPITX_DSI_DATA_LANE3	0x14
+#define RG_DSI_LNTx_LDOOUT_EN		BIT(0)
+#define RG_DSI_LNTx_CKLANE_EN		BIT(1)
+#define RG_DSI_LNTx_LPTX_IPLUS1		BIT(2)
+#define RG_DSI_LNTx_LPTX_IPLUS2		BIT(3)
+#define RG_DSI_LNTx_LPTX_IMINUS		BIT(4)
+#define RG_DSI_LNTx_LPCD_IPLUS		BIT(5)
+#define RG_DSI_LNTx_LPCD_IMINUS		BIT(6)
+#define RG_DSI_LNTx_RT_CODE		(0xf << 8)
+
+#define MIPITX_DSI_TOP_CON	0x40
+#define RG_DSI_LNT_INTR_EN		BIT(0)
+#define RG_DSI_LNT_HS_BIAS_EN		BIT(1)
+#define RG_DSI_LNT_IMP_CAL_EN		BIT(2)
+#define RG_DSI_LNT_TESTMODE_EN		BIT(3)
+#define RG_DSI_LNT_IMP_CAL_CODE		(0xf << 4)
+#define RG_DSI_LNT_AIO_SEL		(7 << 8)
+#define RG_DSI_PAD_TIE_LOW_EN		BIT(11)
+#define RG_DSI_DEBUG_INPUT_EN		BIT(12)
+#define RG_DSI_PRESERVE			(7 << 13)
+
+#define MIPITX_DSI_BG_CON	0x44
+#define RG_DSI_BG_CORE_EN		BIT(0)
+#define RG_DSI_BG_CKEN			BIT(1)
+#define RG_DSI_BG_DIV			(0x3 << 2)
+#define RG_DSI_BG_FAST_CHARGE		BIT(4)
+#define RG_DSI_VOUT_MSK			(0x3ffff << 5)
+#define RG_DSI_V12_SEL			(7 << 5)
+#define RG_DSI_V10_SEL			(7 << 8)
+#define RG_DSI_V072_SEL			(7 << 11)
+#define RG_DSI_V04_SEL			(7 << 14)
+#define RG_DSI_V032_SEL			(7 << 17)
+#define RG_DSI_V02_SEL			(7 << 20)
+#define RG_DSI_BG_R1_TRIM		(0xf << 24)
+#define RG_DSI_BG_R2_TRIM		(0xf << 28)
+
+#define MIPITX_DSI_PLL_CON0	0x50
+#define RG_DSI_MPPLL_PLL_EN		BIT(0)
+#define RG_DSI_MPPLL_DIV_MSK		(0x1ff << 1)
+#define RG_DSI_MPPLL_PREDIV		(3 << 1)
+#define RG_DSI_MPPLL_TXDIV0		(3 << 3)
+#define RG_DSI_MPPLL_TXDIV1		(3 << 5)
+#define RG_DSI_MPPLL_POSDIV		(7 << 7)
+#define RG_DSI_MPPLL_MONVC_EN		BIT(10)
+#define RG_DSI_MPPLL_MONREF_EN		BIT(11)
+#define RG_DSI_MPPLL_VOD_EN		BIT(12)
+
+#define MIPITX_DSI_PLL_CON1	0x54
+#define RG_DSI_MPPLL_SDM_FRA_EN		BIT(0)
+#define RG_DSI_MPPLL_SDM_SSC_PH_INIT	BIT(1)
+#define RG_DSI_MPPLL_SDM_SSC_EN		BIT(2)
+#define RG_DSI_MPPLL_SDM_SSC_PRD	(0xffff << 16)
+
+#define MIPITX_DSI_PLL_CON2	0x58
+
+#define MIPITX_DSI_PLL_TOP	0x64
+#define RG_DSI_MPPLL_PRESERVE		(0xff << 8)
+
+#define MIPITX_DSI_PLL_PWR	0x68
+#define RG_DSI_MPPLL_SDM_PWR_ON		BIT(0)
+#define RG_DSI_MPPLL_SDM_ISO_EN		BIT(1)
+#define RG_DSI_MPPLL_SDM_PWR_ACK	BIT(8)
+
+#define MIPITX_DSI_SW_CTRL	0x80
+#define SW_CTRL_EN			BIT(0)
+
+#define MIPITX_DSI_SW_CTRL_CON0	0x84
+#define SW_LNTC_LPTX_PRE_OE		BIT(0)
+#define SW_LNTC_LPTX_OE			BIT(1)
+#define SW_LNTC_LPTX_P			BIT(2)
+#define SW_LNTC_LPTX_N			BIT(3)
+#define SW_LNTC_HSTX_PRE_OE		BIT(4)
+#define SW_LNTC_HSTX_OE			BIT(5)
+#define SW_LNTC_HSTX_ZEROCLK		BIT(6)
+#define SW_LNT0_LPTX_PRE_OE		BIT(7)
+#define SW_LNT0_LPTX_OE			BIT(8)
+#define SW_LNT0_LPTX_P			BIT(9)
+#define SW_LNT0_LPTX_N			BIT(10)
+#define SW_LNT0_HSTX_PRE_OE		BIT(11)
+#define SW_LNT0_HSTX_OE			BIT(12)
+#define SW_LNT0_LPRX_EN			BIT(13)
+#define SW_LNT1_LPTX_PRE_OE		BIT(14)
+#define SW_LNT1_LPTX_OE			BIT(15)
+#define SW_LNT1_LPTX_P			BIT(16)
+#define SW_LNT1_LPTX_N			BIT(17)
+#define SW_LNT1_HSTX_PRE_OE		BIT(18)
+#define SW_LNT1_HSTX_OE			BIT(19)
+#define SW_LNT2_LPTX_PRE_OE		BIT(20)
+#define SW_LNT2_LPTX_OE			BIT(21)
+#define SW_LNT2_LPTX_P			BIT(22)
+#define SW_LNT2_LPTX_N			BIT(23)
+#define SW_LNT2_HSTX_PRE_OE		BIT(24)
+#define SW_LNT2_HSTX_OE			BIT(25)
+
+static int mtk_mipi_tx_pll_prepare(struct clk_hw *hw)
+{
+	struct mtk_mipi_tx *mipi_tx = mtk_mipi_tx_from_clk_hw(hw);
+	u8 txdiv, txdiv0, txdiv1;
+	u64 pcw;
+
+	dev_dbg(mipi_tx->dev, "prepare: %u Hz\n", mipi_tx->data_rate);
+
+	if (mipi_tx->data_rate >= 500000000) {
+		txdiv = 1;
+		txdiv0 = 0;
+		txdiv1 = 0;
+	} else if (mipi_tx->data_rate >= 250000000) {
+		txdiv = 2;
+		txdiv0 = 1;
+		txdiv1 = 0;
+	} else if (mipi_tx->data_rate >= 125000000) {
+		txdiv = 4;
+		txdiv0 = 2;
+		txdiv1 = 0;
+	} else if (mipi_tx->data_rate > 62000000) {
+		txdiv = 8;
+		txdiv0 = 2;
+		txdiv1 = 1;
+	} else if (mipi_tx->data_rate >= 50000000) {
+		txdiv = 16;
+		txdiv0 = 2;
+		txdiv1 = 2;
+	} else {
+		return -EINVAL;
+	}
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_BG_CON,
+				RG_DSI_VOUT_MSK |
+				RG_DSI_BG_CKEN | RG_DSI_BG_CORE_EN,
+				(4 << 20) | (4 << 17) | (4 << 14) |
+				(4 << 11) | (4 << 8) | (4 << 5) |
+				RG_DSI_BG_CKEN | RG_DSI_BG_CORE_EN);
+
+	usleep_range(30, 100);
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_TOP_CON,
+				RG_DSI_LNT_IMP_CAL_CODE | RG_DSI_LNT_HS_BIAS_EN,
+				(8 << 4) | RG_DSI_LNT_HS_BIAS_EN);
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_DSI_CON,
+			     RG_DSI_CKG_LDOOUT_EN | RG_DSI_LDOCORE_EN);
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_PLL_PWR,
+				RG_DSI_MPPLL_SDM_PWR_ON |
+				RG_DSI_MPPLL_SDM_ISO_EN,
+				RG_DSI_MPPLL_SDM_PWR_ON);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_PLL_CON0,
+			       RG_DSI_MPPLL_PLL_EN);
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_PLL_CON0,
+				RG_DSI_MPPLL_TXDIV0 | RG_DSI_MPPLL_TXDIV1 |
+				RG_DSI_MPPLL_PREDIV,
+				(txdiv0 << 3) | (txdiv1 << 5));
+
+	/*
+	 * PLL PCW config
+	 * PCW bit 24~30 = integer part of pcw
+	 * PCW bit 0~23 = fractional part of pcw
+	 * pcw = data_Rate*4*txdiv/(Ref_clk*2);
+	 * Post DIV =4, so need data_Rate*4
+	 * Ref_clk is 26MHz
+	 */
+	pcw = div_u64(((u64)mipi_tx->data_rate * 2 * txdiv) << 24,
+		      26000000);
+	writel(pcw, mipi_tx->regs + MIPITX_DSI_PLL_CON2);
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_DSI_PLL_CON1,
+			     RG_DSI_MPPLL_SDM_FRA_EN);
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_DSI_PLL_CON0, RG_DSI_MPPLL_PLL_EN);
+
+	usleep_range(20, 100);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_PLL_CON1,
+			       RG_DSI_MPPLL_SDM_SSC_EN);
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_PLL_TOP,
+				RG_DSI_MPPLL_PRESERVE,
+				mipi_tx->driver_data->mppll_preserve);
+
+	return 0;
+}
+
+static void mtk_mipi_tx_pll_unprepare(struct clk_hw *hw)
+{
+	struct mtk_mipi_tx *mipi_tx = mtk_mipi_tx_from_clk_hw(hw);
+
+	dev_dbg(mipi_tx->dev, "unprepare\n");
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_PLL_CON0,
+			       RG_DSI_MPPLL_PLL_EN);
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_PLL_TOP,
+				RG_DSI_MPPLL_PRESERVE, 0);
+
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_DSI_PLL_PWR,
+				RG_DSI_MPPLL_SDM_ISO_EN |
+				RG_DSI_MPPLL_SDM_PWR_ON,
+				RG_DSI_MPPLL_SDM_ISO_EN);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_TOP_CON,
+			       RG_DSI_LNT_HS_BIAS_EN);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_CON,
+			       RG_DSI_CKG_LDOOUT_EN | RG_DSI_LDOCORE_EN);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_BG_CON,
+			       RG_DSI_BG_CKEN | RG_DSI_BG_CORE_EN);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_PLL_CON0,
+			       RG_DSI_MPPLL_DIV_MSK);
+}
+
+static const struct clk_ops mtk_mipi_tx_pll_ops = {
+	.prepare = mtk_mipi_tx_pll_prepare,
+	.unprepare = mtk_mipi_tx_pll_unprepare,
+	.round_rate = mtk_mipi_tx_pll_round_rate,
+	.set_rate = mtk_mipi_tx_pll_set_rate,
+	.recalc_rate = mtk_mipi_tx_pll_recalc_rate,
+};
+
+static void mtk_mipi_tx_power_on_signal(struct phy *phy)
+{
+	struct mtk_mipi_tx *mipi_tx = phy_get_drvdata(phy);
+	u32 reg;
+
+	for (reg = MIPITX_DSI_CLOCK_LANE;
+	     reg <= MIPITX_DSI_DATA_LANE3; reg += 4)
+		mtk_mipi_tx_set_bits(mipi_tx, reg, RG_DSI_LNTx_LDOOUT_EN);
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_DSI_TOP_CON,
+			       RG_DSI_PAD_TIE_LOW_EN);
+}
+
+static void mtk_mipi_tx_power_off_signal(struct phy *phy)
+{
+	struct mtk_mipi_tx *mipi_tx = phy_get_drvdata(phy);
+	u32 reg;
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_DSI_TOP_CON,
+			     RG_DSI_PAD_TIE_LOW_EN);
+
+	for (reg = MIPITX_DSI_CLOCK_LANE;
+	     reg <= MIPITX_DSI_DATA_LANE3; reg += 4)
+		mtk_mipi_tx_clear_bits(mipi_tx, reg, RG_DSI_LNTx_LDOOUT_EN);
+}
+
+const struct mtk_mipitx_data mt2701_mipitx_data = {
+	.mppll_preserve = (3 << 8),
+	.mipi_tx_clk_ops = &mtk_mipi_tx_pll_ops,
+	.mipi_tx_enable_signal = mtk_mipi_tx_power_on_signal,
+	.mipi_tx_disable_signal = mtk_mipi_tx_power_off_signal,
+};
+
+const struct mtk_mipitx_data mt8173_mipitx_data = {
+	.mppll_preserve = (0 << 8),
+	.mipi_tx_clk_ops = &mtk_mipi_tx_pll_ops,
+	.mipi_tx_enable_signal = mtk_mipi_tx_power_on_signal,
+	.mipi_tx_disable_signal = mtk_mipi_tx_power_off_signal,
+};
+
diff --git a/drivers/gpu/drm/mediatek/mtk_mt8183_mipi_tx.c b/drivers/gpu/drm/mediatek/mtk_mt8183_mipi_tx.c
new file mode 100644
index 000000000000..a1399568b8d5
--- /dev/null
+++ b/drivers/gpu/drm/mediatek/mtk_mt8183_mipi_tx.c
@@ -0,0 +1,154 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: jitao.shi <jitao.shi@mediatek.com>
+ */
+
+#include "mtk_mipi_tx.h"
+
+#define MIPITX_LANE_CON		0x000c
+#define RG_DSI_CPHY_T1DRV_EN		BIT(0)
+#define RG_DSI_ANA_CK_SEL		BIT(1)
+#define RG_DSI_PHY_CK_SEL		BIT(2)
+#define RG_DSI_CPHY_EN			BIT(3)
+#define RG_DSI_PHYCK_INV_EN		BIT(4)
+#define RG_DSI_PWR04_EN			BIT(5)
+#define RG_DSI_BG_LPF_EN		BIT(6)
+#define RG_DSI_BG_CORE_EN		BIT(7)
+#define RG_DSI_PAD_TIEL_SEL		BIT(8)
+
+#define MIPITX_PLL_PWR	0x0028
+#define MIPITX_PLL_CON0	0x002c
+#define MIPITX_PLL_CON1	0x0030
+#define MIPITX_PLL_CON2	0x0034
+#define MIPITX_PLL_CON3	0x0038
+#define MIPITX_PLL_CON4	0x003c
+#define RG_DSI_PLL_IBIAS		(3 << 10)
+
+#define MIPITX_D2_SW_CTL_EN	0x0144
+#define MIPITX_D0_SW_CTL_EN	0x0244
+#define MIPITX_CK_CKMODE_EN	0x0328
+#define DSI_CK_CKMODE_EN		BIT(0)
+#define MIPITX_CK_SW_CTL_EN	0x0344
+#define MIPITX_D1_SW_CTL_EN	0x0444
+#define MIPITX_D3_SW_CTL_EN	0x0544
+#define DSI_SW_CTL_EN			BIT(0)
+#define AD_DSI_PLL_SDM_PWR_ON		BIT(0)
+#define AD_DSI_PLL_SDM_ISO_EN		BIT(1)
+
+#define RG_DSI_PLL_EN			BIT(4)
+#define RG_DSI_PLL_POSDIV		(0x7 << 8)
+
+static int mtk_mipi_tx_pll_prepare(struct clk_hw *hw)
+{
+	struct mtk_mipi_tx *mipi_tx = mtk_mipi_tx_from_clk_hw(hw);
+	unsigned int txdiv, txdiv0;
+	u64 pcw;
+	int ret;
+
+	dev_dbg(mipi_tx->dev, "prepare: %u bps\n", mipi_tx->data_rate);
+
+	if (mipi_tx->data_rate >= 2000000000) {
+		txdiv = 1;
+		txdiv0 = 0;
+	} else if (mipi_tx->data_rate >= 1000000000) {
+		txdiv = 2;
+		txdiv0 = 1;
+	} else if (mipi_tx->data_rate >= 500000000) {
+		txdiv = 4;
+		txdiv0 = 2;
+	} else if (mipi_tx->data_rate > 250000000) {
+		txdiv = 8;
+		txdiv0 = 3;
+	} else if (mipi_tx->data_rate >= 125000000) {
+		txdiv = 16;
+		txdiv0 = 4;
+	} else {
+		return -EINVAL;
+	}
+
+	ret = clk_prepare_enable(mipi_tx->ref_clk);
+	if (ret < 0) {
+		dev_err(mipi_tx->dev,
+			"can't prepare and enable mipi_tx ref_clk %d\n", ret);
+		return ret;
+	}
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_PLL_CON4, RG_DSI_PLL_IBIAS);
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_PLL_PWR, AD_DSI_PLL_SDM_PWR_ON);
+	usleep_range(30, 100);
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_PLL_PWR, AD_DSI_PLL_SDM_ISO_EN);
+	pcw = div_u64(((u64)mipi_tx->data_rate * txdiv) << 24, 26000000);
+	writel(pcw, mipi_tx->regs + MIPITX_PLL_CON0);
+	mtk_mipi_tx_update_bits(mipi_tx, MIPITX_PLL_CON1, RG_DSI_PLL_POSDIV,
+				txdiv0 << 8);
+	usleep_range(1000, 2000);
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_PLL_CON1, RG_DSI_PLL_EN);
+
+	return 0;
+}
+
+static void mtk_mipi_tx_pll_unprepare(struct clk_hw *hw)
+{
+	struct mtk_mipi_tx *mipi_tx = mtk_mipi_tx_from_clk_hw(hw);
+
+	dev_dbg(mipi_tx->dev, "unprepare\n");
+
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_PLL_CON1, RG_DSI_PLL_EN);
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_PLL_PWR, AD_DSI_PLL_SDM_ISO_EN);
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_PLL_PWR, AD_DSI_PLL_SDM_PWR_ON);
+	clk_disable_unprepare(mipi_tx->ref_clk);
+}
+
+static const struct clk_ops mtk_mipi_tx_pll_ops = {
+	.prepare = mtk_mipi_tx_pll_prepare,
+	.unprepare = mtk_mipi_tx_pll_unprepare,
+	.round_rate = mtk_mipi_tx_pll_round_rate,
+	.set_rate = mtk_mipi_tx_pll_set_rate,
+	.recalc_rate = mtk_mipi_tx_pll_recalc_rate,
+};
+
+static void mtk_mipi_tx_power_on_signal(struct phy *phy)
+{
+	struct mtk_mipi_tx *mipi_tx = phy_get_drvdata(phy);
+
+	/* BG_LPF_EN / BG_CORE_EN */
+	writel(RG_DSI_PAD_TIEL_SEL | RG_DSI_BG_CORE_EN,
+	       mipi_tx->regs + MIPITX_LANE_CON);
+	usleep_range(30, 100);
+	writel(RG_DSI_BG_CORE_EN | RG_DSI_BG_LPF_EN,
+	       mipi_tx->regs + MIPITX_LANE_CON);
+
+	/* Switch OFF each Lane */
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_D0_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_D1_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_D2_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_D3_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_clear_bits(mipi_tx, MIPITX_CK_SW_CTL_EN, DSI_SW_CTL_EN);
+
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_CK_CKMODE_EN, DSI_CK_CKMODE_EN);
+}
+
+static void mtk_mipi_tx_power_off_signal(struct phy *phy)
+{
+	struct mtk_mipi_tx *mipi_tx = phy_get_drvdata(phy);
+
+	/* Switch ON each Lane */
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_D0_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_D1_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_D2_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_D3_SW_CTL_EN, DSI_SW_CTL_EN);
+	mtk_mipi_tx_set_bits(mipi_tx, MIPITX_CK_SW_CTL_EN, DSI_SW_CTL_EN);
+
+	writel(RG_DSI_PAD_TIEL_SEL | RG_DSI_BG_CORE_EN,
+	       mipi_tx->regs + MIPITX_LANE_CON);
+	writel(RG_DSI_PAD_TIEL_SEL, mipi_tx->regs + MIPITX_LANE_CON);
+}
+
+const struct mtk_mipitx_data mt8183_mipitx_data = {
+	.mipi_tx_clk_ops = &mtk_mipi_tx_pll_ops,
+	.mipi_tx_enable_signal = mtk_mipi_tx_power_on_signal,
+	.mipi_tx_disable_signal = mtk_mipi_tx_power_off_signal,
+};
diff --git a/drivers/mailbox/mtk-cmdq-debug.c b/drivers/mailbox/mtk-cmdq-debug.c
new file mode 100644
index 000000000000..61985342d564
--- /dev/null
+++ b/drivers/mailbox/mtk-cmdq-debug.c
@@ -0,0 +1,582 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mailbox/mtk-cmdq-mailbox.h>
+#include <linux/workqueue.h>
+#include "mtk-cmdq-debug.h"
+#if CONFIG_MTK_CMDQ_DEBUG_SOC == 8173
+#include <dt-bindings/gce/mt8173-gce.h>
+#elif CONFIG_MTK_CMDQ_DEBUG_SOC == 8183
+#include <dt-bindings/gce/mt8183-gce.h>
+#else
+static int __error__[-1]; /* Complle error if SOC is not set. */
+#endif
+
+#define CMDQ_OP_CODE_MASK			(0xff << CMDQ_OP_CODE_SHIFT)
+#define CMDQ_NUM_CMD(t)				(t->cmd_buf_size / CMDQ_INST_SIZE)
+#define CMDQ_GET_32B_VALUE(arg_b, arg_c)	((u32)((arg_b) << 16) | (arg_c))
+#define CMDQ_REG_IDX_PREFIX(type)		((type) ? "" : "Reg Index ")
+
+struct cmdq_instruction {
+	s16 arg_c:16;
+	s16 arg_b:16;
+	s16 arg_a:16;
+	u8 s_op:5;
+	u8 arg_c_type:1;
+	u8 arg_b_type:1;
+	u8 arg_a_type:1;
+	u8 op:8;
+};
+
+void cmdq_buf_print_write(struct device *dev, u32 offset,
+			  struct cmdq_instruction *cmdq_inst)
+{
+	u32 addr = ((u32)(cmdq_inst->arg_a |
+		    (cmdq_inst->s_op << CMDQ_SUBSYS_SHIFT)));
+
+	dev_err(dev, "0x%08x [Write | Store] %s0x%08x = %s0x%08x\n",
+		offset, cmdq_inst->arg_a_type ? "*Reg Index " : "SubSys Reg ",
+		addr, CMDQ_REG_IDX_PREFIX(!cmdq_inst->arg_b_type),
+		cmdq_inst->arg_b_type ? cmdq_inst->arg_b :
+		CMDQ_GET_32B_VALUE(cmdq_inst->arg_b, cmdq_inst->arg_c));
+}
+
+static void cmdq_buf_print_wfe(struct device *dev, u32 offset,
+			       struct cmdq_instruction *cmdq_inst)
+{
+	const char *event_str;
+	u32 cmd = CMDQ_GET_32B_VALUE(cmdq_inst->arg_b, cmdq_inst->arg_c);
+
+	switch (cmdq_inst->arg_a) {
+#if CONFIG_MTK_CMDQ_DEBUG_SOC == 8173
+	case CMDQ_EVENT_DISP_OVL0_SOF:
+		event_str = "CMDQ_EVENT_DISP_OVL0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL1_SOF:
+		event_str = "CMDQ_EVENT_DISP_OVL1_SOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA0_SOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA1_SOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA1_SOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA2_SOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA2_SOF";
+		break;
+	case CMDQ_EVENT_DISP_WDMA0_SOF:
+		event_str = "CMDQ_EVENT_DISP_WDMA0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_WDMA1_SOF:
+		event_str = "CMDQ_EVENT_DISP_WDMA1_SOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_EOF:
+		event_str = "CMDQ_EVENT_DISP_OVL0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL1_EOF:
+		event_str = "CMDQ_EVENT_DISP_OVL1_EOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA0_EOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA1_EOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA1_EOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA2_EOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA2_EOF";
+		break;
+	case CMDQ_EVENT_DISP_WDMA0_EOF:
+		event_str = "CMDQ_EVENT_DISP_WDMA0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_WDMA1_EOF:
+		event_str = "CMDQ_EVENT_DISP_WDMA1_EOF";
+		break;
+	case CMDQ_EVENT_MUTEX0_STREAM_EOF:
+		event_str = "CMDQ_EVENT_MUTEX0_STREAM_EOF";
+		break;
+	case CMDQ_EVENT_MUTEX1_STREAM_EOF:
+		event_str = "CMDQ_EVENT_MUTEX1_STREAM_EOF";
+		break;
+	case CMDQ_EVENT_MUTEX2_STREAM_EOF:
+		event_str = "CMDQ_EVENT_MUTEX2_STREAM_EOF";
+		break;
+	case CMDQ_EVENT_MUTEX3_STREAM_EOF:
+		event_str = "CMDQ_EVENT_MUTEX3_STREAM_EOF";
+		break;
+	case CMDQ_EVENT_MUTEX4_STREAM_EOF:
+		event_str = "CMDQ_EVENT_MUTEX4_STREAM_EOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA0_UNDERRUN:
+		event_str = "CMDQ_EVENT_DISP_RDMA0_UNDERRUN";
+		break;
+	case CMDQ_EVENT_DISP_RDMA1_UNDERRUN:
+		event_str = "CMDQ_EVENT_DISP_RDMA1_UNDERRUN";
+		break;
+	case CMDQ_EVENT_DISP_RDMA2_UNDERRUN:
+		event_str = "CMDQ_EVENT_DISP_RDMA2_UNDERRUN";
+		break;
+#elif CONFIG_MTK_CMDQ_DEBUG_SOC == 8183
+	case CMDQ_EVENT_DISP_RDMA0_SOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA1_SOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA1_SOF";
+		break;
+	case CMDQ_EVENT_MDP_RDMA0_SOF:
+		event_str = "CMDQ_EVENT_MDP_RDMA0_SOF";
+		break;
+	case CMDQ_EVENT_MDP_RSZ0_SOF:
+		event_str = "CMDQ_EVENT_MDP_RSZ0_SOF";
+		break;
+	case CMDQ_EVENT_MDP_RSZ1_SOF:
+		event_str = "CMDQ_EVENT_MDP_RSZ1_SOF";
+		break;
+	case CMDQ_EVENT_MDP_TDSHP_SOF:
+		event_str = "CMDQ_EVENT_MDP_TDSHP_SOF";
+		break;
+	case CMDQ_EVENT_MDP_WROT0_SOF:
+		event_str = "CMDQ_EVENT_MDP_WROT0_SOF";
+		break;
+	case CMDQ_EVENT_MDP_WDMA0_SOF:
+		event_str = "CMDQ_EVENT_MDP_WDMA0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_SOF:
+		event_str = "CMDQ_EVENT_DISP_OVL0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_2L_SOF:
+		event_str = "CMDQ_EVENT_DISP_OVL0_2L_SOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL1_2L_SOF:
+		event_str = "CMDQ_EVENT_DISP_OVL1_2L_SOF";
+		break;
+	case CMDQ_EVENT_DISP_WDMA0_SOF:
+		event_str = "CMDQ_EVENT_DISP_WDMA0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_COLOR0_SOF:
+		event_str = "CMDQ_EVENT_DISP_COLOR0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_CCORR0_SOF:
+		event_str = "CMDQ_EVENT_DISP_CCORR0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_AAL0_SOF:
+		event_str = "CMDQ_EVENT_DISP_AAL0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_GAMMA0_SOF:
+		event_str = "CMDQ_EVENT_DISP_GAMMA0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_DITHER0_SOF:
+		event_str = "CMDQ_EVENT_DISP_DITHER0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_PWM0_SOF:
+		event_str = "CMDQ_EVENT_DISP_PWM0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_DSI0_SOF:
+		event_str = "CMDQ_EVENT_DISP_DSI0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_DPI0_SOF:
+		event_str = "CMDQ_EVENT_DISP_DPI0_SOF";
+		break;
+	case CMDQ_EVENT_DISP_RSZ_SOF:
+		event_str = "CMDQ_EVENT_DISP_RSZ_SOF";
+		break;
+	case CMDQ_EVENT_MDP_AAL_SOF:
+		event_str = "CMDQ_EVENT_MDP_AAL_SOF";
+		break;
+	case CMDQ_EVENT_MDP_CCORR_SOF:
+		event_str = "CMDQ_EVENT_MDP_CCORR_SOF";
+		break;
+	case CMDQ_EVENT_DISP_DBI_SOF:
+		event_str = "CMDQ_EVENT_DISP_DBI_SOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA0_EOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_RDMA1_EOF:
+		event_str = "CMDQ_EVENT_DISP_RDMA1_EOF";
+		break;
+	case CMDQ_EVENT_MDP_RDMA0_EOF:
+		event_str = "CMDQ_EVENT_MDP_RDMA0_EOF";
+		break;
+	case CMDQ_EVENT_MDP_RSZ0_EOF:
+		event_str = "CMDQ_EVENT_MDP_RSZ0_EOF";
+		break;
+	case CMDQ_EVENT_MDP_RSZ1_EOF:
+		event_str = "CMDQ_EVENT_MDP_RSZ1_EOF";
+		break;
+	case CMDQ_EVENT_MDP_TDSHP_EOF:
+		event_str = "CMDQ_EVENT_MDP_TDSHP_EOF";
+		break;
+	case CMDQ_EVENT_MDP_WROT0_EOF:
+		event_str = "CMDQ_EVENT_MDP_WROT0_EOF";
+		break;
+	case CMDQ_EVENT_MDP_WDMA0_EOF:
+		event_str = "CMDQ_EVENT_MDP_WDMA0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_EOF:
+		event_str = "CMDQ_EVENT_DISP_OVL0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_2L_EOF:
+		event_str = "CMDQ_EVENT_DISP_OVL0_2L_EOF";
+		break;
+	case CMDQ_EVENT_DISP_OVL1_2L_EOF:
+		event_str = "CMDQ_EVENT_DISP_OVL1_2L_EOF";
+		break;
+	case CMDQ_EVENT_DISP_WDMA0_EOF:
+		event_str = "CMDQ_EVENT_DISP_WDMA0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_COLOR0_EOF:
+		event_str = "CMDQ_EVENT_DISP_COLOR0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_CCORR0_EOF:
+		event_str = "CMDQ_EVENT_DISP_CCORR0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_AAL0_EOF:
+		event_str = "CMDQ_EVENT_DISP_AAL0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_GAMMA0_EOF:
+		event_str = "CMDQ_EVENT_DISP_GAMMA0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_DITHER0_EOF:
+		event_str = "CMDQ_EVENT_DISP_DITHER0_EOF";
+		break;
+	case CMDQ_EVENT_DSI0_EOF:
+		event_str = "CMDQ_EVENT_DSI0_EOF";
+		break;
+	case CMDQ_EVENT_DPI0_EOF:
+		event_str = "CMDQ_EVENT_DPI0_EOF";
+		break;
+	case CMDQ_EVENT_DISP_RSZ_EOF:
+		event_str = "CMDQ_EVENT_DISP_RSZ_EOF";
+		break;
+	case CMDQ_EVENT_MDP_AAL_EOF:
+		event_str = "CMDQ_EVENT_MDP_AAL_EOF";
+		break;
+	case CMDQ_EVENT_MDP_CCORR_EOF:
+		event_str = "CMDQ_EVENT_MDP_CCORR_EOF";
+		break;
+	case CMDQ_EVENT_DBI_EOF:
+		event_str = "CMDQ_EVENT_DBI_EOF";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE0:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE0";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE1:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE1";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE2:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE2";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE3:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE3";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE4:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE4";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE5:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE5";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE6:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE6";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE7:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE7";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE8:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE8";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE9:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE9";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE10:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE10";
+		break;
+	case CMDQ_EVENT_MUTEX_STREAM_DONE11:
+		event_str = "CMDQ_EVENT_MUTEX_STREAM_DONE11";
+		break;
+	case CMDQ_EVENT_DISP_RDMA0_BUF_UNDERRUN_EVEN:
+		event_str = "CMDQ_EVENT_DISP_RDMA0_BUF_UNDERRUN_EVEN";
+		break;
+	case CMDQ_EVENT_DISP_RDMA1_BUF_UNDERRUN_EVEN:
+		event_str = "CMDQ_EVENT_DISP_RDMA1_BUF_UNDERRUN_EVEN";
+		break;
+	case CMDQ_EVENT_DSI0_TE_EVENT:
+		event_str = "CMDQ_EVENT_DSI0_TE_EVENT";
+		break;
+	case CMDQ_EVENT_DSI0_IRQ_EVENT:
+		event_str = "CMDQ_EVENT_DSI0_IRQ_EVENT";
+		break;
+	case CMDQ_EVENT_DSI0_DONE_EVENT:
+		event_str = "CMDQ_EVENT_DSI0_DONE_EVENT";
+		break;
+	case CMDQ_EVENT_DISP_WDMA0_SW_RST_DONE:
+		event_str = "CMDQ_EVENT_DISP_WDMA0_SW_RST_DONE";
+		break;
+	case CMDQ_EVENT_MDP_WDMA_SW_RST_DONE:
+		event_str = "CMDQ_EVENT_MDP_WDMA_SW_RST_DONE";
+		break;
+	case CMDQ_EVENT_MDP_WROT0_SW_RST_DONE:
+		event_str = "CMDQ_EVENT_MDP_WROT0_SW_RST_DONE";
+		break;
+	case CMDQ_EVENT_MDP_RDMA0_SW_RST_DONE:
+		event_str = "CMDQ_EVENT_MDP_RDMA0_SW_RST_DONE";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_FRAME_RST_DONE_PULE:
+		event_str = "CMDQ_EVENT_DISP_OVL0_FRAME_RST_DONE_PULE";
+		break;
+	case CMDQ_EVENT_DISP_OVL0_2L_FRAME_RST_DONE_ULSE:
+		event_str = "CMDQ_EVENT_DISP_OVL0_2L_FRAME_RST_DONE_ULSE";
+		break;
+	case CMDQ_EVENT_DISP_OVL1_2L_FRAME_RST_DONE_ULSE:
+		event_str = "CMDQ_EVENT_DISP_OVL1_2L_FRAME_RST_DONE_ULSE";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_0:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_0";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_1:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_1";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_2:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_2";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_3:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_3";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_4:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_4";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_5:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_5";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_6:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_6";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_7:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_7";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_8:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_8";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_9:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_9";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_10:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_10";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_11:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_11";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_12:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_12";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_13:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_13";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_14:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_14";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_15:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_15";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_16:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_16";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_17:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_17";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_P2_18:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_P2_18";
+		break;
+	case CMDQ_EVENT_AMD_FRAME_DONE:
+		event_str = "CMDQ_EVENT_AMD_FRAME_DONE";
+		break;
+	case CMDQ_EVENT_DVE_DONE:
+		event_str = "CMDQ_EVENT_DVE_DONE";
+		break;
+	case CMDQ_EVENT_WMFE_DONE:
+		event_str = "CMDQ_EVENT_WMFE_DONE";
+		break;
+	case CMDQ_EVENT_RSC_DONE:
+		event_str = "CMDQ_EVENT_RSC_DONE";
+		break;
+	case CMDQ_EVENT_MFB_DONE:
+		event_str = "CMDQ_EVENT_MFB_DONE";
+		break;
+	case CMDQ_EVENT_WPE_A_DONE:
+		event_str = "CMDQ_EVENT_WPE_A_DONE";
+		break;
+	case CMDQ_EVENT_SPE_B_DONE:
+		event_str = "CMDQ_EVENT_SPE_B_DONE";
+		break;
+	case CMDQ_EVENT_OCC_DONE:
+		event_str = "CMDQ_EVENT_OCC_DONE";
+		break;
+	case CMDQ_EVENT_VENC_CMDQ_FRAME_DONE:
+		event_str = "CMDQ_EVENT_VENC_CMDQ_FRAME_DONE";
+		break;
+	case CMDQ_EVENT_JPG_ENC_CMDQ_DONE:
+		event_str = "CMDQ_EVENT_JPG_ENC_CMDQ_DONE";
+		break;
+	case CMDQ_EVENT_JPG_DEC_CMDQ_DONE:
+		event_str = "CMDQ_EVENT_JPG_DEC_CMDQ_DONE";
+		break;
+	case CMDQ_EVENT_VENC_CMDQ_MB_DONE:
+		event_str = "CMDQ_EVENT_VENC_CMDQ_MB_DONE";
+		break;
+	case CMDQ_EVENT_VENC_CMDQ_128BYTE_DONE:
+		event_str = "CMDQ_EVENT_VENC_CMDQ_128BYTE_DONE";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_A:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_A";
+		break;
+	case CMDQ_EVENT_ISP_FRAME_DONE_B:
+		event_str = "CMDQ_EVENT_ISP_FRAME_DONE_B";
+		break;
+	case CMDQ_EVENT_CAMSV0_PASS1_DONE:
+		event_str = "CMDQ_EVENT_CAMSV0_PASS1_DONE";
+		break;
+	case CMDQ_EVENT_CAMSV1_PASS1_DONE:
+		event_str = "CMDQ_EVENT_CAMSV1_PASS1_DONE";
+		break;
+	case CMDQ_EVENT_CAMSV2_PASS1_DONE:
+		event_str = "CMDQ_EVENT_CAMSV2_PASS1_DONE";
+		break;
+	case CMDQ_EVENT_TSF_DONE:
+		event_str = "CMDQ_EVENT_TSF_DONE";
+		break;
+	case CMDQ_EVENT_SENINF_CAM0_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM0_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM1_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM1_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM2_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM2_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM3_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM3_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM4_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM4_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM5_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM5_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM6_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM6_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_SENINF_CAM7_FIFO_FULL:
+		event_str = "CMDQ_EVENT_SENINF_CAM7_FIFO_FULL";
+		break;
+	case CMDQ_EVENT_IPU_CORE0_DONE0:
+		event_str = "CMDQ_EVENT_IPU_CORE0_DONE0";
+		break;
+	case CMDQ_EVENT_IPU_CORE0_DONE1:
+		event_str = "CMDQ_EVENT_IPU_CORE0_DONE1";
+		break;
+	case CMDQ_EVENT_IPU_CORE0_DONE2:
+		event_str = "CMDQ_EVENT_IPU_CORE0_DONE2";
+		break;
+	case CMDQ_EVENT_IPU_CORE0_DONE3:
+		event_str = "CMDQ_EVENT_IPU_CORE0_DONE3";
+		break;
+	case CMDQ_EVENT_IPU_CORE1_DONE0:
+		event_str = "CMDQ_EVENT_IPU_CORE1_DONE0";
+		break;
+	case CMDQ_EVENT_IPU_CORE1_DONE1:
+		event_str = "CMDQ_EVENT_IPU_CORE1_DONE1";
+		break;
+	case CMDQ_EVENT_IPU_CORE1_DONE2:
+		event_str = "CMDQ_EVENT_IPU_CORE1_DONE2";
+		break;
+	case CMDQ_EVENT_IPU_CORE1_DONE3:
+		event_str = "CMDQ_EVENT_IPU_CORE1_DONE3";
+		break;
+#endif
+
+	default:
+		event_str = "UNKNOWN";
+		break;
+	}
+
+	dev_err(dev, "0x%08x %s event %u\n", offset,
+		(cmd && CMDQ_WFE_OPTION) ? "wait for" : "clear",
+		cmdq_inst->arg_a);
+}
+
+void cmdq_buf_print_mask(struct device *dev, u32 offset,
+			 struct cmdq_instruction *cmdq_inst)
+{
+	u32 mask = CMDQ_GET_32B_VALUE(cmdq_inst->arg_b, cmdq_inst->arg_c);
+
+	dev_err(dev, "0x%08x mask 0x%08x\n", offset, ~mask);
+}
+
+void cmdq_buf_print_misc(struct device *dev, u32 offset,
+			 struct cmdq_instruction *cmdq_inst)
+{
+	char *cmd_str;
+
+	switch (cmdq_inst->op) {
+	case CMDQ_CODE_JUMP:
+		cmd_str = "jump";
+		break;
+	case CMDQ_CODE_EOC:
+		cmd_str = "eoc";
+		break;
+	case CMDQ_CODE_POLL:
+		cmd_str = "polling";
+		break;
+	default:
+		cmd_str = "unknown";
+		break;
+	}
+
+	dev_err(dev, "0x%08x %s\n", offset, cmd_str);
+}
+
+void cmdq_debug_buf_dump_work(struct work_struct *work_item)
+{
+	struct cmdq_buf_dump *buf_dump = container_of(work_item,
+			struct cmdq_buf_dump, dump_work);
+	struct device *dev = buf_dump->dev;
+	struct cmdq_instruction *cmdq_inst =
+		(struct cmdq_instruction *)buf_dump->cmd_buf;
+	u32 i, offset = 0;
+
+	dev_err(dev, "dump %s task start ----------\n",
+		buf_dump->timeout ? "timeout" : "error");
+	for (i = 0; i < CMDQ_NUM_CMD(buf_dump); i++) {
+		if (offset == buf_dump->pa_offset)
+			dev_err(dev,
+				"\e[1;31;40m==========ERROR==========\e[0m\n");
+		switch (cmdq_inst[i].op) {
+		case CMDQ_CODE_WRITE:
+			cmdq_buf_print_write(dev, offset, &cmdq_inst[i]);
+			break;
+		case CMDQ_CODE_WFE:
+			cmdq_buf_print_wfe(dev, offset, &cmdq_inst[i]);
+			break;
+		case CMDQ_CODE_MASK:
+			cmdq_buf_print_mask(dev, offset, &cmdq_inst[i]);
+			break;
+		default:
+			cmdq_buf_print_misc(dev, offset, &cmdq_inst[i]);
+			break;
+		}
+		if (offset == buf_dump->pa_offset)
+			dev_err(dev,
+				"\e[1;31;40m==========ERROR==========\e[0m\n");
+		offset += CMDQ_INST_SIZE;
+	}
+	dev_err(dev, "dump %s task end   ----------\n",
+		buf_dump->timeout ? "timeout" : "error");
+
+	kfree(buf_dump->cmd_buf);
+	kfree(buf_dump);
+}
+EXPORT_SYMBOL(cmdq_debug_buf_dump_work);
+
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/mailbox/mtk-cmdq-debug.h b/drivers/mailbox/mtk-cmdq-debug.h
new file mode 100644
index 000000000000..5392b00c9394
--- /dev/null
+++ b/drivers/mailbox/mtk-cmdq-debug.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ *
+ */
+
+#ifndef MTK_CMDQ_DEBUG_H
+#define MTK_CMDQ_DEBUG_H
+
+struct cmdq_buf_dump {
+	struct device		*dev; /* device of cmdq controller */
+	struct work_struct	dump_work;
+	bool			timeout; /* 0: error, 1: timeout */
+	void			*cmd_buf;
+	size_t			cmd_buf_size;
+	u32			pa_offset; /* pa_curr - pa_base */
+};
+
+void cmdq_debug_buf_dump_work(struct work_struct *work_item);
+
+#endif /* MTK_CMDQ_DEBUG_H */
diff --git a/drivers/media/common/videobuf2/videobuf2-core.c b/drivers/media/common/videobuf2/videobuf2-core.c
index 9cf9b49e3ace..b754aca45a23 100644
--- a/drivers/media/common/videobuf2/videobuf2-core.c
+++ b/drivers/media/common/videobuf2/videobuf2-core.c
@@ -1726,6 +1726,14 @@ static void __vb2_dqbuf(struct vb2_buffer *vb)
 
 	vb->state = VB2_BUF_STATE_DEQUEUED;
 
+	/* sync buffers */
+	for (i = 0; i < vb->num_planes; ++i) {
+		if (!vb->planes[i].mem_priv)
+			continue;
+		call_void_memop(vb, finish, vb->planes[i].mem_priv);
+	}
+	vb->synced = false;
+
 	if (q->memory == VB2_MEMORY_USERPTR) {
 		call_void_vb_qop(vb, buf_cleanup, vb);
 
diff --git a/drivers/media/common/videobuf2/videobuf2-dma-contig.c b/drivers/media/common/videobuf2/videobuf2-dma-contig.c
index aff0ab7bf83d..101e14b31459 100644
--- a/drivers/media/common/videobuf2/videobuf2-dma-contig.c
+++ b/drivers/media/common/videobuf2/videobuf2-dma-contig.c
@@ -62,6 +62,29 @@ static unsigned long vb2_dc_get_contiguous_size(struct sg_table *sgt)
 	return size;
 }
 
+static struct sg_table *vb2_dc_get_base_sgt(struct vb2_dc_buf *buf)
+{
+	int ret;
+	struct sg_table *sgt;
+
+	sgt = kmalloc(sizeof(*sgt), GFP_KERNEL);
+	if (!sgt) {
+		dev_err(buf->dev, "failed to alloc sg table\n");
+		return NULL;
+	}
+
+	ret = dma_get_sgtable_attrs(buf->dev, sgt, buf->cookie, buf->dma_addr,
+		buf->size, buf->attrs);
+	if (ret < 0) {
+		dev_err(buf->dev, "failed to get scatterlist from DMA API\n");
+		kfree(sgt);
+		return NULL;
+	}
+
+	return sgt;
+}
+
+
 /*********************************************/
 /*         callbacks for all buffers         */
 /*********************************************/
@@ -130,6 +153,10 @@ static void vb2_dc_put(void *buf_priv)
 		sg_free_table(buf->sgt_base);
 		kfree(buf->sgt_base);
 	}
+	if (buf->dma_sgt) {
+		sg_free_table(buf->dma_sgt);
+		kfree(buf->dma_sgt);
+	}
 	dma_free_attrs(buf->dev, buf->size, buf->cookie, buf->dma_addr,
 		       buf->attrs);
 	put_device(buf->dev);
@@ -171,6 +198,10 @@ static void *vb2_dc_alloc(struct device *dev, unsigned long attrs,
 	buf->handler.put = vb2_dc_put;
 	buf->handler.arg = buf;
 
+	if (!(buf->attrs & DMA_ATTR_NO_KERNEL_MAPPING) &&
+	    (buf->attrs &DMA_ATTR_NON_CONSISTENT))
+		buf->dma_sgt = vb2_dc_get_base_sgt(buf);
+
 	refcount_set(&buf->refcount, 1);
 
 	return buf;
@@ -206,6 +237,11 @@ static int vb2_dc_mmap(void *buf_priv, struct vm_area_struct *vma)
 
 	vma->vm_ops->open(vma);
 
+	if ((buf->attrs & DMA_ATTR_NO_KERNEL_MAPPING) &&
+	    (buf->attrs & DMA_ATTR_NON_CONSISTENT) &&
+	    !buf->dma_sgt)
+		buf->dma_sgt = vb2_dc_get_base_sgt(buf);
+
 	pr_debug("%s: mapped dma addr 0x%08lx at 0x%08lx, size %ld\n",
 		__func__, (unsigned long)buf->dma_addr, vma->vm_start,
 		buf->size);
@@ -363,28 +399,6 @@ static const struct dma_buf_ops vb2_dc_dmabuf_ops = {
 	.release = vb2_dc_dmabuf_ops_release,
 };
 
-static struct sg_table *vb2_dc_get_base_sgt(struct vb2_dc_buf *buf)
-{
-	int ret;
-	struct sg_table *sgt;
-
-	sgt = kmalloc(sizeof(*sgt), GFP_KERNEL);
-	if (!sgt) {
-		dev_err(buf->dev, "failed to alloc sg table\n");
-		return NULL;
-	}
-
-	ret = dma_get_sgtable_attrs(buf->dev, sgt, buf->cookie, buf->dma_addr,
-		buf->size, buf->attrs);
-	if (ret < 0) {
-		dev_err(buf->dev, "failed to get scatterlist from DMA API\n");
-		kfree(sgt);
-		return NULL;
-	}
-
-	return sgt;
-}
-
 static struct dma_buf *vb2_dc_get_dmabuf(void *buf_priv, unsigned long flags)
 {
 	struct vb2_dc_buf *buf = buf_priv;
diff --git a/drivers/media/common/videobuf2/videobuf2-v4l2.c b/drivers/media/common/videobuf2/videobuf2-v4l2.c
index aa4f0b45e505..2f3b3ca5bde6 100644
--- a/drivers/media/common/videobuf2/videobuf2-v4l2.c
+++ b/drivers/media/common/videobuf2/videobuf2-v4l2.c
@@ -721,6 +721,7 @@ int vb2_create_bufs(struct vb2_queue *q, struct v4l2_create_buffers *create)
 		requested_sizes[0] = f->fmt.sdr.buffersize;
 		break;
 	case V4L2_BUF_TYPE_META_CAPTURE:
+	case V4L2_BUF_TYPE_META_OUTPUT:
 		requested_sizes[0] = f->fmt.meta.buffersize;
 		break;
 	default:
diff --git a/drivers/media/i2c/Kconfig b/drivers/media/i2c/Kconfig
index 63c9ac2c6a5f..7f6e4d35d985 100644
--- a/drivers/media/i2c/Kconfig
+++ b/drivers/media/i2c/Kconfig
@@ -17,6 +17,32 @@ config VIDEO_IR_I2C
 
 	  In doubt, say Y.
 
+config VIDEO_OV2685
+	tristate "OmniVision OV2685 sensor support"
+	depends on I2C && VIDEO_V4L2 && VIDEO_V4L2_SUBDEV_API
+	depends on MEDIA_CAMERA_SUPPORT
+	depends on MEDIA_CONTROLLER
+	select V4L2_FWNODE
+	---help---
+	  This is a Video4Linux2 sensor-level driver for the OmniVision
+	  OV2685 camera.
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called ov2685.
+
+config VIDEO_OV5695
+	tristate "OmniVision OV5695 sensor support"
+	depends on I2C && VIDEO_V4L2 && VIDEO_V4L2_SUBDEV_API
+	depends on MEDIA_CAMERA_SUPPORT
+	depends on MEDIA_CONTROLLER
+	select V4L2_FWNODE
+	---help---
+	  This is a Video4Linux2 sensor-level driver for the OmniVision
+	  OV5695 camera.
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called ov5695.
+
 #
 # Encoder / Decoder module configuration
 #
diff --git a/drivers/media/i2c/ov2685.c b/drivers/media/i2c/ov2685.c
index 385c1886a947..2d35d920e737 100644
--- a/drivers/media/i2c/ov2685.c
+++ b/drivers/media/i2c/ov2685.c
@@ -35,7 +35,7 @@
 #define OV2685_REG_VTS			0x380e
 #define OV2685_VTS_MAX			0x7fff
 
-#define OV2685_REG_GAIN			0x350a
+#define OV2685_REG_GAIN			0x350b
 #define OV2685_GAIN_MIN			0
 #define OV2685_GAIN_MAX			0x07ff
 #define OV2685_GAIN_STEP		0x1
@@ -103,12 +103,12 @@ struct ov2685 {
 #define to_ov2685(sd) container_of(sd, struct ov2685, subdev)
 
 /* PLL settings bases on 24M xvclk */
+#if 1
 static struct regval ov2685_1600x1200_regs[] = {
 	{0x0103, 0x01},
-	{0x0100, 0x00},
 	{0x3002, 0x00},
 	{0x3016, 0x1c},
-	{0x3018, 0x44},
+	{0x3018, 0x84},
 	{0x301d, 0xf0},
 	{0x3020, 0x00},
 	{0x3082, 0x37},
@@ -116,10 +116,10 @@ static struct regval ov2685_1600x1200_regs[] = {
 	{0x3084, 0x09},
 	{0x3085, 0x04},
 	{0x3086, 0x00},
-	{0x3087, 0x00},
+	{0x3087, 0x01},
 	{0x3501, 0x4e},
 	{0x3502, 0xe0},
-	{0x3503, 0x27},
+	{0x3503, 0x03},
 	{0x350b, 0x36},
 	{0x3600, 0xb4},
 	{0x3603, 0x35},
@@ -168,6 +168,7 @@ static struct regval ov2685_1600x1200_regs[] = {
 	{0x3819, 0x04},
 	{0x3820, 0xc0},
 	{0x3821, 0x00},
+	//{0x382d, 0x02}, //louis add
 	{0x3a06, 0x01},
 	{0x3a07, 0x84},
 	{0x3a08, 0x01},
@@ -189,7 +190,105 @@ static struct regval ov2685_1600x1200_regs[] = {
 	{0x4602, 0x02},
 	{0x481b, 0x40},
 	{0x481f, 0x40},
-	{0x4837, 0x18},
+	{0x4837, 0x18}, //0x30
+	{0x5000, 0x1f},
+	{0x5001, 0x05},
+	{0x5002, 0x30},
+	{0x5003, 0x04},
+	{0x5004, 0x00},
+	{0x5005, 0x0c},
+	{0x0100, 0x01},
+	{REG_NULL, 0x00}
+};
+#else //upstream
+static struct regval ov2685_1600x1200_regs[] = {
+	{0x0103, 0x01},
+	/*{0x0100, 0x00},*/
+	{0x3002, 0x00},
+	{0x3016, 0x1c},
+	{0x3018, 0x84}, //0x44 //0x84 //louis
+	{0x301d, 0xf0},
+	{0x3020, 0x00},
+	{0x3082, 0x37},
+	{0x3083, 0x03},
+	{0x3084, 0x09},
+	{0x3085, 0x04},
+	{0x3086, 0x00},
+	{0x3087, 0x01}, //0x00
+	{0x3501, 0x4e},
+	{0x3502, 0xe0},
+	{0x3503, 0x00}, //0x27
+	{0x350b, 0x36},
+	{0x3600, 0xb4},
+	{0x3603, 0x35},
+	{0x3604, 0x24},
+	{0x3605, 0x00},
+	{0x3620, 0x24},
+	{0x3621, 0x34},
+	{0x3622, 0x03},
+	{0x3628, 0x10},
+	{0x3705, 0x3c},
+	{0x370a, 0x21},
+	{0x370c, 0x50},
+	{0x370d, 0xc0},
+	{0x3717, 0x58},
+	{0x3718, 0x80},
+	{0x3720, 0x00},
+	{0x3721, 0x09},
+	{0x3722, 0x06},
+	{0x3723, 0x59},
+	{0x3738, 0x99},
+	{0x3781, 0x80},
+	{0x3784, 0x0c},
+	{0x3789, 0x60},
+	{0x3800, 0x00},
+	{0x3801, 0x00},
+	{0x3802, 0x00},
+	{0x3803, 0x00},
+	{0x3804, 0x06},
+	{0x3805, 0x4f},
+	{0x3806, 0x04},
+	{0x3807, 0xbf},
+	{0x3808, 0x06},
+	{0x3809, 0x40},
+	{0x380a, 0x04},
+	{0x380b, 0xb0},
+	{0x380c, 0x06},
+	{0x380d, 0xa4},
+	{0x380e, 0x05},
+	{0x380f, 0x0e},
+	{0x3810, 0x00},
+	{0x3811, 0x08},
+	{0x3812, 0x00},
+	{0x3813, 0x08},
+	{0x3814, 0x11},
+	{0x3815, 0x11},
+	{0x3819, 0x04},
+	{0x3820, 0xc0},
+	{0x3821, 0x00},
+	{0x3a06, 0x01},
+	{0x3a07, 0x84},
+	{0x3a08, 0x01},
+	{0x3a09, 0x43},
+	{0x3a0a, 0x24},
+	{0x3a0b, 0x60},
+	{0x3a0c, 0x28},
+	{0x3a0d, 0x60},
+	{0x3a0e, 0x04},
+	{0x3a0f, 0x8c},
+	{0x3a10, 0x05},
+	{0x3a11, 0x0c},
+	{0x4000, 0x81},
+	{0x4001, 0x40},
+	{0x4008, 0x02},
+	{0x4009, 0x09},
+	{0x4300, 0x00},
+	{0x430e, 0x00},
+	{0x4602, 0x02},
+	{0x481b, 0x40},
+	{0x481f, 0x40},
+	{0x4837, 0x14}, //0x18  //0x14(0x409054,0x64004b0) //0x12(0x1ff9055,0x64000a5)
+	//0x15 (0x40907c, 0x64004ae) //0x16 (0x40907c,0x64004b0)
 	{0x5000, 0x1f},
 	{0x5001, 0x05},
 	{0x5002, 0x30},
@@ -204,8 +303,10 @@ static struct regval ov2685_1600x1200_regs[] = {
 	{0x5285, 0x1c},
 	{0x5286, 0x20},
 	{0x5287, 0x10},
+	{0x0100, 0x00},	//move here
 	{REG_NULL, 0x00}
 };
+#endif
 
 #define OV2685_LINK_FREQ_330MHZ		330000000
 static const s64 link_freq_menu_items[] = {
@@ -249,6 +350,8 @@ static int ov2685_write_reg(struct i2c_client *client, u16 reg,
 	u8 buf[6];
 	u8 *val_p;
 	__be32 val_be;
+	u32 ret;
+	u8 retry_cnt = 5;
 
 	if (len > 4)
 		return -EINVAL;
@@ -264,8 +367,20 @@ static int ov2685_write_reg(struct i2c_client *client, u16 reg,
 	while (val_i < 4)
 		buf[buf_i++] = val_p[val_i++];
 
-	if (i2c_master_send(client, buf, len + 2) != len + 2)
+	do {
+		ret = i2c_master_send(client, buf, len + 2);
+		if (ret != len + 2)
+			pr_err("i2c_master_send fail:%d retry:%d\n", ret, retry_cnt);
+		else
+			break;
+		retry_cnt--;
+	} while(retry_cnt != 0);
+
+	if (retry_cnt == 0)
+	{
+		pr_err("i2c write fail(%d)\n", ret);
 		return -EIO;
+	}
 
 	return 0;
 }
@@ -413,7 +528,7 @@ static int __ov2685_power_on(struct ov2685 *ov2685)
 	gpiod_set_value_cansleep(ov2685->reset_gpio, 0);
 	/* 8192 xvclk cycles prior to the first SCCB transaction */
 	delay_us = ov2685_cal_delay(8192);
-	usleep_range(delay_us, delay_us * 2);
+	usleep_range(delay_us * 2, delay_us * 4);
 
 	/* HACK: ov2685 would output messy data after reset(R0103),
 	 * writing register before .s_stream() as a workaround
@@ -450,10 +565,12 @@ static int ov2685_s_stream(struct v4l2_subdev *sd, int on)
 	int ret = 0;
 
 	mutex_lock(&ov2685->mutex);
-
+#if 0
 	on = !!on;
 	if (on == ov2685->streaming)
 		goto unlock_and_return;
+#endif
+	pr_err("ov2685_s_stream %d\n", on);
 
 	if (on) {
 		ret = pm_runtime_get_sync(&ov2685->client->dev);
@@ -519,6 +636,12 @@ static int __maybe_unused ov2685_runtime_suspend(struct device *dev)
 	struct v4l2_subdev *sd = i2c_get_clientdata(client);
 	struct ov2685 *ov2685 = to_ov2685(sd);
 
+	if(ov2685->streaming == 1)
+	{
+		ov2685_write_reg(ov2685->client, REG_SC_CTRL_MODE,
+				OV2685_REG_VALUE_08BIT, SC_CTRL_MODE_STANDBY);
+		ov2685->streaming = 0;
+	}
 	__ov2685_power_off(ov2685);
 
 	return 0;
@@ -716,7 +839,7 @@ static int ov2685_probe(struct i2c_client *client,
 	struct device *dev = &client->dev;
 	struct ov2685 *ov2685;
 	int ret;
-
+	printk("ov2685 probe ++\n");
 	ov2685 = devm_kzalloc(dev, sizeof(*ov2685), GFP_KERNEL);
 	if (!ov2685)
 		return -ENOMEM;
@@ -784,7 +907,7 @@ static int ov2685_probe(struct i2c_client *client,
 	pm_runtime_set_active(dev);
 	pm_runtime_enable(dev);
 	pm_runtime_idle(dev);
-
+	printk("ov2685 probe --\n");
 	return 0;
 
 err_clean_entity:
diff --git a/drivers/media/i2c/ov5695.c b/drivers/media/i2c/ov5695.c
index 9a80decd93d3..1b63d26cb563 100644
--- a/drivers/media/i2c/ov5695.c
+++ b/drivers/media/i2c/ov5695.c
@@ -709,6 +709,8 @@ static int ov5695_write_reg(struct i2c_client *client, u16 reg,
 	u8 buf[6];
 	u8 *val_p;
 	__be32 val_be;
+	u32 ret;
+	u8 retry_cnt = 5;
 
 	if (len > 4)
 		return -EINVAL;
@@ -724,8 +726,20 @@ static int ov5695_write_reg(struct i2c_client *client, u16 reg,
 	while (val_i < 4)
 		buf[buf_i++] = val_p[val_i++];
 
-	if (i2c_master_send(client, buf, len + 2) != len + 2)
+	do {
+		ret = i2c_master_send(client, buf, len + 2);
+		if (ret != len + 2)
+			pr_err("i2c_master_send fail:%d retry:%d\n", ret, retry_cnt);
+		else
+			break;
+		retry_cnt--;
+	} while(retry_cnt != 0);
+
+	if (retry_cnt == 0)
+	{
+		pr_err("i2c write fail(%d) len(%d)\n", ret, len + 2);
 		return -EIO;
+	}
 
 	return 0;
 }
@@ -925,8 +939,10 @@ static int __ov5695_start_stream(struct ov5695 *ov5695)
 	/* In case these controls are set before streaming */
 	ret = __v4l2_ctrl_handler_setup(&ov5695->ctrl_handler);
 	if (ret)
+	{
+		pr_err("__v4l2_ctrl_handler_setup fail %d\n", ret);
 		return ret;
-
+	}
 	return ov5695_write_reg(ov5695->client, OV5695_REG_CTRL_MODE,
 				OV5695_REG_VALUE_08BIT, OV5695_MODE_STREAMING);
 }
@@ -943,11 +959,13 @@ static int ov5695_s_stream(struct v4l2_subdev *sd, int on)
 	struct i2c_client *client = ov5695->client;
 	int ret = 0;
 
+	pr_err("ov5695 s_stream-(%d)\n", on);
 	mutex_lock(&ov5695->mutex);
+#if 0
 	on = !!on;
 	if (on == ov5695->streaming)
 		goto unlock_and_return;
-
+#endif
 	if (on) {
 		ret = pm_runtime_get_sync(&client->dev);
 		if (ret < 0) {
@@ -1004,7 +1022,7 @@ static int __ov5695_power_on(struct ov5695 *ov5695)
 
 	/* 8192 cycles prior to first SCCB transaction */
 	delay_us = ov5695_cal_delay(8192);
-	usleep_range(delay_us, delay_us * 2);
+	usleep_range(delay_us  * 2, delay_us * 4);
 
 	return 0;
 
@@ -1018,6 +1036,7 @@ static void __ov5695_power_off(struct ov5695 *ov5695)
 {
 	clk_disable_unprepare(ov5695->xvclk);
 	gpiod_set_value_cansleep(ov5695->reset_gpio, 1);
+
 	regulator_bulk_disable(OV5695_NUM_SUPPLIES, ov5695->supplies);
 }
 
@@ -1036,6 +1055,11 @@ static int __maybe_unused ov5695_runtime_suspend(struct device *dev)
 	struct v4l2_subdev *sd = i2c_get_clientdata(client);
 	struct ov5695 *ov5695 = to_ov5695(sd);
 
+	if(ov5695->streaming == 1)
+	{
+		__ov5695_stop_stream(ov5695);
+		ov5695->streaming = 0;
+	}
 	__ov5695_power_off(ov5695);
 
 	return 0;
@@ -1268,10 +1292,14 @@ static int ov5695_probe(struct i2c_client *client,
 	struct v4l2_subdev *sd;
 	int ret;
 
+	printk("ov5695 probe ++ #9\n");
+
+
 	ov5695 = devm_kzalloc(dev, sizeof(*ov5695), GFP_KERNEL);
 	if (!ov5695)
 		return -ENOMEM;
 
+	ov5695->streaming = 0;
 	ov5695->client = client;
 	ov5695->cur_mode = &supported_modes[0];
 
@@ -1280,6 +1308,7 @@ static int ov5695_probe(struct i2c_client *client,
 		dev_err(dev, "Failed to get xvclk\n");
 		return -EINVAL;
 	}
+
 	ret = clk_set_rate(ov5695->xvclk, OV5695_XVCLK_FREQ);
 	if (ret < 0) {
 		dev_err(dev, "Failed to set xvclk rate (24MHz)\n");
@@ -1337,7 +1366,7 @@ static int ov5695_probe(struct i2c_client *client,
 	pm_runtime_set_active(dev);
 	pm_runtime_enable(dev);
 	pm_runtime_idle(dev);
-
+	printk("ov5695 probe --\n");
 	return 0;
 
 err_clean_entity:
diff --git a/drivers/media/media-device.c b/drivers/media/media-device.c
index b8ec88612df7..f42082990c2e 100644
--- a/drivers/media/media-device.c
+++ b/drivers/media/media-device.c
@@ -502,6 +502,7 @@ static long media_device_enum_links32(struct media_device *mdev,
 {
 	struct media_links_enum links;
 	compat_uptr_t pads_ptr, links_ptr;
+	int ret;
 
 	memset(&links, 0, sizeof(links));
 
@@ -513,7 +514,15 @@ static long media_device_enum_links32(struct media_device *mdev,
 	links.pads = compat_ptr(pads_ptr);
 	links.links = compat_ptr(links_ptr);
 
-	return media_device_enum_links(mdev, &links);
+	ret = media_device_enum_links(mdev, &links);
+	if (ret)
+		return ret;
+
+	if (copy_to_user(ulinks->reserved, &links.reserved,
+			 sizeof(links.reserved)))
+		return -EFAULT;
+
+	return 0;
 }
 
 #define MEDIA_IOC_ENUM_LINKS32		_IOWR('|', 0x02, struct media_links_enum32)
diff --git a/drivers/media/platform/Kconfig b/drivers/media/platform/Kconfig
index 0dfb22114c49..919129eef895 100644
--- a/drivers/media/platform/Kconfig
+++ b/drivers/media/platform/Kconfig
@@ -32,6 +32,8 @@ source "drivers/media/platform/davinci/Kconfig"
 
 source "drivers/media/platform/omap/Kconfig"
 
+source "drivers/media/platform/mtk-isp/Kconfig"
+
 config VIDEO_SH_VOU
 	tristate "SuperH VOU video output driver"
 	depends on MEDIA_CAMERA_SUPPORT
@@ -224,6 +226,24 @@ config VIDEO_MEDIATEK_MDP
 	    To compile this driver as a module, choose M here: the
 	    module will be called mtk-mdp.
 
+config VIDEO_MEDIATEK_MDP3
+	tristate "Mediatek MDP v3 driver"
+	depends on MTK_IOMMU || COMPILE_TEST
+	depends on VIDEO_DEV && VIDEO_V4L2
+	depends on ARCH_MEDIATEK || COMPILE_TEST
+	depends on HAS_DMA
+	select VIDEOBUF2_DMA_CONTIG
+	select V4L2_MEM2MEM_DEV
+	select VIDEO_MEDIATEK_VPU
+	select MTK_CMDQ
+	default n
+	help
+	    It is a v4l2 driver and present in Mediatek MT8183 SoC.
+	    The driver supports for scaling and color space conversion.
+
+	    To compile this driver as a module, choose M here: the
+	    module will be called mtk-mdp3.
+
 config VIDEO_MEDIATEK_VCODEC
 	tristate "Mediatek Video Codec driver"
 	depends on MTK_IOMMU || COMPILE_TEST
diff --git a/drivers/media/platform/Makefile b/drivers/media/platform/Makefile
index 41322ab65802..bb29deb0d1f2 100644
--- a/drivers/media/platform/Makefile
+++ b/drivers/media/platform/Makefile
@@ -70,6 +70,8 @@ obj-$(CONFIG_VIDEO_ROCKCHIP_RGA)	+= rockchip/rga/
 
 obj-y	+= omap/
 
+obj-y	+= mtk-isp/
+
 obj-$(CONFIG_VIDEO_AM437X_VPFE)		+= am437x/
 
 obj-$(CONFIG_VIDEO_XILINX)		+= xilinx/
@@ -86,6 +88,7 @@ obj-$(CONFIG_VIDEO_MEDIATEK_VPU)	+= mtk-vpu/
 obj-$(CONFIG_VIDEO_MEDIATEK_VCODEC)	+= mtk-vcodec/
 
 obj-$(CONFIG_VIDEO_MEDIATEK_MDP)	+= mtk-mdp/
+obj-$(CONFIG_VIDEO_MEDIATEK_MDP3)	+= mtk-mdp3/
 
 obj-$(CONFIG_VIDEO_MEDIATEK_JPEG)	+= mtk-jpeg/
 
diff --git a/drivers/media/platform/mtk-isp/Kconfig b/drivers/media/platform/mtk-isp/Kconfig
new file mode 100644
index 000000000000..56ac26204b9e
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/Kconfig
@@ -0,0 +1,109 @@
+config VIDEO_MEDIATEK_ISP_DIP_SUPPORT
+	bool "Mediatek digital image processing function"
+	select DMA_SHARED_BUFFER
+	select VIDEO_V4L2_SUBDEV_API
+	select VIDEOBUF2_DMA_CONTIG
+	select VIDEOBUF2_CORE
+	select VIDEOBUF2_V4L2
+	select VIDEOBUF2_MEMOPS
+	select VIDEOBUF2_VMALLOC
+	select MEDIA_CONTROLLER
+
+	default n
+	---help---
+	    Support the basic digital image processing feature.
+
+	    DIP driver provide image format, resize, and rotate through
+	    low power hardware. It can support 2 or more output with
+	    different effect at the same time.
+
+config VIDEO_MEDIATEK_ISP_PASS1_SUPPORT
+	bool "Mediatek pass 1 image processing function"
+
+	select DMA_SHARED_BUFFER
+	select VIDEO_V4L2_SUBDEV_API
+	select VIDEOBUF2_DMA_CONTIG
+	select VIDEOBUF2_CORE
+	select VIDEOBUF2_V4L2
+	select VIDEOBUF2_MEMOPS
+	select VIDEOBUF2_VMALLOC
+	select MEDIA_CONTROLLER
+
+	default n
+	help
+		Pass 1 driver controls 3A (autofocus, exposure,
+		and white balance) with tuning feature and output
+		the first capture image buffer in Mediatek's camera system.
+
+		Choose y if you want to use Mediatek SoCs to create image
+		vcapture application such as video recording and still image
+		capture.
+
+config VIDEO_MEDIATEK_ISP_FD_SUPPORT
+	bool "Mediatek face detection processing function"
+	default n
+	---help---
+	    Support the basic hardware accelerated face detectioin feature.
+
+	    FD driver provide face detection function, it can detect
+	    faces of Rotation-in-Plane from -180 degrees to +180 degrees
+	    and Rotation-off-Plane from -90 degrees to +90 degrees.
+
+config VIDEO_MEDIATEK_ISP_CAMSV_SUPPORT
+	bool "Mediatek CamSV function"
+	default n
+	help
+	    CamSV driver provide TG info and output image or statistic data.
+	    It can support 2 or more output with
+	    different effect at the same time.
+
+config MTK_SENINF
+	tristate "Mediatek mipi csi2 driver"
+	depends on VIDEO_V4L2 && VIDEO_V4L2_SUBDEV_API
+	depends on MEDIA_CAMERA_SUPPORT
+	select V4L2_FWNODE
+	---help---
+	    This driver provides a mipi-csi2 host driver used as a
+	    interface to connect camera with Mediatek's
+	    MT8183 SOCs. It is able to handle multiple cameras
+	    simultaneously.
+
+
+	    To compile this driver as a module, choose M here: the
+	    module will be called mtk_seninf.
+
+	    Choose y if you want to use Mediatek SoCs to create image
+	    capture application such as video recording and still image
+	    capture.
+
+config VIDEO_MEDIATEK_ISP_FD_SUPPORT
+	bool "Mediatek face detection processing function"
+	default n
+	---help---
+	    Support the basic hardware accelerated face detectioin feature.
+
+	    FD driver provide face detection function, it can detect
+	    faces of Rotation-in-Plane from -180 degrees to +180 degrees
+	    and Rotation-off-Plane from -90 degrees to +90 degrees.
+
+config VIDEO_MEDIATEK_ISP_CAMSV_SUPPORT
+	bool "Mediatek CamSV function"
+	default n
+	help
+	    CamSV driver provide TG info and output image or statistic data.
+	    It can support 2 or more output with
+	    different effect at the same time.
+
+config MTK_SENINF
+	tristate "Mediatek mipi csi2 driver"
+	depends on VIDEO_V4L2 && VIDEO_V4L2_SUBDEV_API
+	depends on MEDIA_CAMERA_SUPPORT
+	select V4L2_FWNODE
+	---help---
+	    This driver provides a mipi-csi2 host driver used as a
+	    interface to connect camera with Mediatek's
+	    MT8183 SOCs. It is able to handle multiple cameras
+	    simultaneously.
+
+	    To compile this driver as a module, choose M here: the
+	    module will be called mtk_seninf.
diff --git a/drivers/media/platform/mtk-isp/Makefile b/drivers/media/platform/mtk-isp/Makefile
new file mode 100644
index 000000000000..111e241231c3
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/Makefile
@@ -0,0 +1,16 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+
+obj-y += isp_50/
+
+obj-$(CONFIG_VIDEO_MEDIATEK_ISP_FD_SUPPORT) += fd/
diff --git a/drivers/media/platform/mtk-isp/common/Makefile b/drivers/media/platform/mtk-isp/common/Makefile
new file mode 100644
index 000000000000..ce715fb08bff
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/Makefile
@@ -0,0 +1,32 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+
+# To Provides alloc context managing memory shared
+# between CPU and ISP coprocessor
+mtk_isp_smem-objs := mtk_isp-smem-drv.o
+
+obj-$(CONFIG_VIDEO_MEDIATEK_ISP_COMMON) += mtk_isp_smem.o
+
+# Common utilits to provide frame-based streaming model
+# with v4l2 user interfaces
+mtk_isp_util-objs := \
+mtk_isp-dev.o \
+mtk_isp-v4l2.o \
+mtk_isp-dev-ctx-core.o \
+mtk_isp-ctrl.o \
+
+ccflags-y += -I$(srctree)/drivers/media/platform/mtk-isp/
+
+obj-$(CONFIG_VIDEO_MEDIATEK_ISP_COMMON) +=mtk_isp_util.o
+
+
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.c b/drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.c
new file mode 100644
index 000000000000..a6822e00064a
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.c
@@ -0,0 +1,318 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include "mtk_isp-dev.h"
+#include "mtk_isp-ctrl.h"
+
+#define CONFIG_MTK_ISP_COMMON_UT
+
+static void handle_buf_usage_config(struct v4l2_ctrl *ctrl);
+static void handle_buf_rotate_config(struct v4l2_ctrl *ctrl);
+static int mtk_isp_ctx_s_ctrl(struct v4l2_ctrl *ctrl);
+
+static void handle_buf_usage_config(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx_queue *queue =
+		container_of(ctrl->handler,
+	struct mtk_isp_ctx_queue, ctrl_handler);
+
+	if (ctrl->val < MTK_ISP_V4l2_BUF_USAGE_DEFAULT
+		|| ctrl->val >= MTK_ISP_V4l2_BUF_USAGE_NONE) {
+		pr_err("Invalid buffer usage id %d", ctrl->val);
+		return;
+	}
+	queue->buffer_usage = ctrl->val;
+}
+
+static void handle_buf_rotate_config(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx_queue *queue =
+		container_of(ctrl->handler,
+	struct mtk_isp_ctx_queue, ctrl_handler);
+
+	if (ctrl->val != 0 || ctrl->val != 90||
+			ctrl->val != 180 || ctrl->val != 270) {
+		pr_err("Invalid buffer rotation %d", ctrl->val);
+		return;
+	}
+	queue->rotation = ctrl->val;
+}
+
+
+static const struct v4l2_ctrl_ops mtk_isp_ctx_ctrl_ops = {
+	.s_ctrl = mtk_isp_ctx_s_ctrl,
+};
+
+#ifdef CONFIG_MTK_ISP_COMMON_UT
+static void handle_ctrl_common_util_ut_start(struct v4l2_ctrl *ctrl);
+static void handle_ctrl_common_util_ut_open(struct v4l2_ctrl *ctrl);
+static void handle_ctrl_common_util_ut_close(struct v4l2_ctrl *ctrl);
+static void handle_ctrl_common_util_ut_streamon(struct v4l2_ctrl *ctrl);
+static void handle_ctrl_common_util_ut_streamoff(struct v4l2_ctrl *ctrl);
+
+static void handle_ctrl_common_util_ut_streamon(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx *dev_ctx
+		= container_of(ctrl->handler, struct mtk_isp_ctx, ctrl_handler);
+	struct mtk_isp_dev *isp_dev
+		=	container_of(dev_ctx, struct mtk_isp_dev, ctx);
+	int ret = 0;
+	char *dev_name = "unknown";
+	struct mtk_isp_ctx_streamon_param params = {0};
+
+	if (dev_ctx->device_name != NULL)
+		dev_name = dev_ctx->device_name;
+
+	dev_dbg(&isp_dev->pdev->dev,
+		"[%s]streamon: v4l2-pdev(%llx),ctx(%d)\n",
+		dev_name,
+		(unsigned long long) isp_dev->pdev,
+		dev_ctx->ctx_id);
+	ret = dev_ctx->ops->streamon(dev_ctx, &params);
+	dev_dbg(&isp_dev->pdev->dev, "[%s]streamon: ret(%d)\n",
+		dev_name,
+		ret);
+}
+
+static void handle_ctrl_common_util_ut_streamoff(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx *dev_ctx
+		= container_of(ctrl->handler, struct mtk_isp_ctx, ctrl_handler);
+	struct mtk_isp_dev *isp_dev
+		=	container_of(dev_ctx, struct mtk_isp_dev, ctx);
+	int ret = 0;
+	char *dev_name = "unknown";
+	struct mtk_isp_ctx_streamoff_param params = {0};
+
+	if (dev_ctx->device_name != NULL)
+		dev_name = dev_ctx->device_name;
+
+	dev_dbg(&isp_dev->pdev->dev, "[%s]streamoff: v4l2-pdev(%llx), ctx(%d)\n",
+		dev_name,
+		(unsigned long long) isp_dev->pdev,
+		dev_ctx->ctx_id);
+	ret = dev_ctx->ops->streamoff(dev_ctx, &params);
+	dev_dbg(&isp_dev->pdev->dev, "[%s]streamoff: ret(%d)\n",
+		dev_name,
+		ret);
+}
+
+static void handle_ctrl_common_util_ut_start(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx *dev_ctx
+		= container_of(ctrl->handler, struct mtk_isp_ctx, ctrl_handler);
+	struct device *dev = &dev_ctx->pdev->dev;
+	int ret = 0;
+	struct mtk_isp_ctx_start_param param;
+	struct mtk_isp_ctx_frame_bundle bundle;
+	char *dev_name = "unknown";
+
+	if (dev_ctx->device_name != NULL)
+		dev_name = dev_ctx->device_name;
+
+	memset(&param, 0, sizeof(struct mtk_isp_ctx_start_param));
+	memset(&bundle, 0, sizeof(struct mtk_isp_ctx_frame_bundle));
+
+	bundle.id
+		= mtk_isp_ctx_next_global_frame_sequence
+			(dev_ctx, dev_ctx->ctx_id);
+	param.frame_bundle = &bundle;
+	ret = dev_ctx->ops->start(dev_ctx, &param);
+	dev_dbg(dev, "Empty frame enqueue test, frame(%d), ret(%d)\n",
+		bundle.id, ret);
+}
+
+static void handle_ctrl_common_util_ut_open(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx *dev_ctx
+		= container_of(ctrl->handler, struct mtk_isp_ctx, ctrl_handler);
+	struct mtk_isp_dev *isp_dev
+		=	container_of(dev_ctx, struct mtk_isp_dev, ctx);
+	struct device *dev = &dev_ctx->pdev->dev;
+	char *dev_name = "unknown";
+	struct mtk_isp_ctx_open_param params = {0};
+
+	if (dev_ctx->device_name != NULL)
+		dev_name = dev_ctx->device_name;
+
+	dev_dbg(dev, "[%s]open: v4l2-pdev(%llx), ctx(%d)\n",
+		dev_name,
+		(unsigned long long) isp_dev->pdev,
+		dev_ctx->ctx_id);
+
+	dev_ctx->ops->open(dev_ctx, &params);
+}
+
+static void handle_ctrl_common_util_ut_close(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx *dev_ctx
+		= container_of(ctrl->handler, struct mtk_isp_ctx, ctrl_handler);
+	struct device *dev = &dev_ctx->pdev->dev;
+	char *dev_name = "unknown";
+	struct mtk_isp_ctx_release_param params = {0};
+
+	if (dev_ctx->device_name != NULL)
+		dev_name = dev_ctx->device_name;
+
+	dev_dbg(dev, "[%s]close: v4l2-pdev(%llx),ctx(%d)\n",
+		dev_name,
+		(unsigned long long)dev,
+		dev_ctx->ctx_id);
+	dev_ctx->ops->release(dev_ctx, &params);
+}
+
+static void handle_ctrl_common_util_ut_set_debug_mode
+	(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_isp_ctx *dev_ctx =
+		container_of(ctrl->handler, struct mtk_isp_ctx, ctrl_handler);
+	dev_ctx->mode = ctrl->val;
+	dev_dbg(&dev_ctx->pdev->dev, "Set ctx(id = %d) mode to %d\n",
+			dev_ctx->ctx_id, dev_ctx->mode);
+}
+
+static const struct v4l2_ctrl_config mtk_isp_ut_config = {
+	.ops	= &mtk_isp_ctx_ctrl_ops,
+	.id	= V4L2_CID_PRIVATE_UT_NUM,
+	.name	= "MTK ISP Common Util UT number",
+	.type	= V4L2_CTRL_TYPE_INTEGER,
+	.min	= 0,
+	.max	= 200,
+	.step	= 1,
+	.def	= 0,
+	.flags	= V4L2_CTRL_FLAG_SLIDER | V4L2_CTRL_FLAG_EXECUTE_ON_WRITE,
+};
+
+static const struct v4l2_ctrl_config mtk_isp_mode_config = {
+	.ops	= &mtk_isp_ctx_ctrl_ops,
+	.id	= V4L2_CID_PRIVATE_SET_CTX_MODE_NUM,
+	.name	= "MTK ISP UNIT TEST CASE",
+	.type	= V4L2_CTRL_TYPE_INTEGER,
+	.min	= 0,
+	.max	= 65535,
+	.step	= 1,
+	.def	= 0,
+	.flags	= V4L2_CTRL_FLAG_SLIDER | V4L2_CTRL_FLAG_EXECUTE_ON_WRITE,
+};
+#endif /* CONFIG_MTK_ISP_COMMON_UT */
+
+static int mtk_isp_ctx_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	switch (ctrl->id) {
+	#ifdef CONFIG_MTK_ISP_COMMON_UT
+	case V4L2_CID_PRIVATE_UT_NUM: {
+		if (ctrl->val == MTK_ISP_COMMON_UTIL_UT_OPEN)
+			handle_ctrl_common_util_ut_open(ctrl);
+		else if (ctrl->val == MTK_ISP_COMMON_UTIL_UT_CLOSE)
+			handle_ctrl_common_util_ut_close(ctrl);
+		else if (ctrl->val == MTK_ISP_COMMON_UTIL_UT_START)
+			handle_ctrl_common_util_ut_start(ctrl);
+		else if (ctrl->val == MTK_ISP_COMMON_UTIL_UT_STREAMON)
+			handle_ctrl_common_util_ut_streamon(ctrl);
+		else if (ctrl->val == MTK_ISP_COMMON_UTIL_UT_STREAMOFF)
+			handle_ctrl_common_util_ut_streamoff(ctrl);
+	}
+		break;
+	case V4L2_CID_PRIVATE_SET_CTX_MODE_NUM:
+		handle_ctrl_common_util_ut_set_debug_mode(ctrl);
+		break;
+	#endif /* CONFIG_MTK_ISP_COMMON_UT */
+	default:
+			break;
+	}
+	return 0;
+}
+
+static int mtk_isp_ctx_queue_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	switch (ctrl->id) {
+	case V4L2_CID_PRIVATE_SET_BUFFER_USAGE:
+		handle_buf_usage_config(ctrl);
+		break;
+	case V4L2_CID_ROTATE:
+		handle_buf_rotate_config(ctrl);
+		break;
+	default:
+			break;
+	}
+	return 0;
+}
+
+static const struct v4l2_ctrl_ops mtk_isp_ctx_queue_ctrl_ops = {
+	.s_ctrl = mtk_isp_ctx_queue_s_ctrl,
+};
+
+static const struct v4l2_ctrl_config mtk_isp_buf_usage_config = {
+	.ops	= &mtk_isp_ctx_queue_ctrl_ops,
+	.id	= V4L2_CID_PRIVATE_SET_BUFFER_USAGE,
+	.name	= "MTK ISP SET BUFFER USAGE",
+	.type	= V4L2_CTRL_TYPE_INTEGER,
+	.min	= MTK_ISP_V4l2_BUF_USAGE_DEFAULT,
+	.max	= MTK_ISP_V4l2_BUF_USAGE_POSTPROC,
+	.step	= 1,
+	.def	= MTK_ISP_V4l2_BUF_USAGE_DEFAULT,
+	.flags	= V4L2_CTRL_FLAG_SLIDER | V4L2_CTRL_FLAG_EXECUTE_ON_WRITE,
+	};
+
+int mtk_isp_ctrl_init(struct mtk_isp_ctx *ctx)
+{
+	struct v4l2_ctrl_handler *hdl = &ctx->ctrl_handler;
+	int i = 0;
+
+	/* Initialized HW controls, allow V4L2_CID_MTK_ISP_MAX ctrls */
+	v4l2_ctrl_handler_init(hdl, V4L2_CID_MTK_ISP_MAX);
+	if (hdl->error) {
+		pr_err("Failed in v4l2_ctrl_handler_init\n");
+		return hdl->error;
+}
+
+#ifdef CONFIG_MTK_ISP_COMMON_UT
+if (v4l2_ctrl_new_custom(hdl, &mtk_isp_ut_config, NULL) == NULL) {
+	pr_err("Failed in v4l2_ctrl_new_custom: mtk_isp_ut_config\n");
+	return hdl->error;
+}
+
+if (v4l2_ctrl_new_custom(hdl, &mtk_isp_mode_config, NULL) == NULL) {
+	pr_err("Failed in v4l2_ctrl_new_custom: mtk_isp_mode_config\n");
+	return hdl->error;
+}
+#endif /* CONFIG_MTK_ISP_COMMON_UT */
+
+/* Enumerate all nodes and setup the node specified ctrl */
+for (i = 0; i < ctx->queues_attr.total_num; i++) {
+	struct v4l2_ctrl_handler *node_hdl =
+		&ctx->queue[i].ctrl_handler;
+
+	if (node_hdl == NULL) {
+		pr_err("ctrl_handler can't be NULL\n");
+	} else {
+		v4l2_ctrl_handler_init(node_hdl, V4L2_CID_MTK_ISP_MAX);
+
+		if (v4l2_ctrl_new_custom(node_hdl,
+			  &mtk_isp_buf_usage_config, NULL) == NULL)
+			pr_err("Node (%d) create buf_usage_config ctrl failed:(%d)",
+			i, node_hdl->error);
+		if (v4l2_ctrl_new_std(&ctx->ctrl_handler,
+			  	&mtk_isp_ctx_queue_ctrl_ops,
+			  	V4L2_CID_ROTATE, 0, 270, 90, 0)	== NULL)
+			pr_err("Node (%d) create rotate ctrl failed:(%d)",
+			i, node_hdl->error);
+	}
+}
+
+return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctrl_init);
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.h b/drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.h
new file mode 100644
index 000000000000..dade294d6a3b
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-ctrl.h
@@ -0,0 +1,42 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_ISP_CTRL_H__
+#define __MTK_ISP_CTRL_H__
+
+#include <media/v4l2-ctrls.h>
+
+#define V4L2_CID_PRIVATE_UT_NUM  (V4L2_CID_USER_BASE | 0x1001)
+#define V4L2_CID_PRIVATE_SET_CTX_MODE_NUM \
+	(V4L2_CID_PRIVATE_UT_NUM + 1)
+#define V4L2_CID_PRIVATE_SET_BUFFER_USAGE \
+	(V4L2_CID_PRIVATE_UT_NUM + 2)
+#define V4L2_CID_MTK_ISP_MAX 100
+
+#define MTK_ISP_COMMON_UTIL_UT_OPEN (0)
+#define MTK_ISP_COMMON_UTIL_UT_CLOSE (1)
+#define MTK_ISP_COMMON_UTIL_UT_START (2)
+#define MTK_ISP_COMMON_UTIL_UT_STREAMON (3)
+#define MTK_ISP_COMMON_UTIL_UT_STREAMOFF (4)
+
+enum mtk_isp_v4l2_buffer_usage {
+		MTK_ISP_V4l2_BUF_USAGE_DEFAULT = 0,
+		MTK_ISP_V4l2_BUF_USAGE_FD,
+		MTK_ISP_V4l2_BUF_USAGE_POSTPROC,
+		MTK_ISP_V4l2_BUF_USAGE_NONE,
+};
+
+int mtk_isp_ctrl_init(struct mtk_isp_ctx *ctx);
+
+#endif /*__MTK_ISP_CTRL_H__*/
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-ctx.h b/drivers/media/platform/mtk-isp/common/mtk_isp-ctx.h
new file mode 100644
index 000000000000..3a5820a3fcf1
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-ctx.h
@@ -0,0 +1,341 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+
+#ifndef __MTK_ISP_CTX_H__
+#define __MTK_ISP_CTX_H__
+
+#include <linux/types.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ctrls.h>
+#include <media/videobuf2-core.h>
+#include <media/v4l2-subdev.h>
+#include "mtk_isp-v4l2.h"
+
+#define MTK_ISP_CTX_QUEUES (16)
+#define MTK_ISP_CTX_FRAME_BUNDLE_BUFFER_MAX (MTK_ISP_CTX_QUEUES)
+#define MTK_ISP_CTX_DESC_MAX (MTK_ISP_CTX_QUEUES)
+
+#define MTK_ISP_CTX_MODE_DEBUG_OFF (0)
+#define MTK_ISP_CTX_MODE_DEBUG_BYPASS_JOB_TRIGGER (1)
+#define MTK_ISP_CTX_MODE_DEBUG_BYPASS_ALL (2)
+
+#define MTK_ISP_GET_CTX_ID_FROM_SEQUENCE(sequence) \
+	(sequence>>16 & 0x0000FFFF)
+
+#define MTK_ISP_CTX_META_BUF_DEFAULT_SIZE (1110 * 1024)
+
+struct mtk_isp_ctx;
+struct mtk_isp_ctx_open_param;
+struct mtk_isp_ctx_release_param;
+struct mtk_isp_ctx_streamon_param;
+struct mtk_isp_ctx_streamoff_param;
+struct mtk_isp_ctx_start_param;
+struct mtk_isp_ctx_finish_param;
+
+/* struct mtk_isp_ctx_ops - background hardware driving ops */
+/* sdefines background driver specific callback APIs  */
+struct mtk_isp_ctx_ops {
+	int (*open)(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_open_param *param);
+	int (*release)(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_release_param *param);
+	int (*start)(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_start_param *param);
+	int (*finish)(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_finish_param *param);
+	int (*streamon)(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_streamon_param *param);
+	int (*streamoff)(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_streamoff_param *param);
+};
+
+/* Attributes setup by device context owner */
+struct mtk_isp_ctx_queue_desc {
+	int id;	/* id of the context queue */
+	char *name;
+	/* Will be exported to media entity name */
+	bool capture;
+	/* true for capture queue (device to user), false for output queue */
+	/* (from user to device) */
+	bool image;
+	/* true for image, false for meta data */
+	unsigned int dma_port; /*The dma port associated to the buffer*/
+	/* Supported format */
+	struct mtk_isp_ctx_format *fmts;
+	int num_fmts;
+	/* Default format of this queue */
+	int default_fmt_idx;
+};
+
+/* Supported format and the information used for */
+/* size calculation */
+struct mtk_isp_ctx_meta_format {
+	u32 dataformat;
+	u32 max_buffer_size;
+	u8 flags;
+};
+
+/* MDP module's private format definitation */
+/* (the same as struct mdp_format) */
+/* It will be removed and changed to MDP's external interface */
+/* after the integration with MDP module. */
+struct mtk_isp_ctx_mdp_format {
+	u32	pixelformat;
+	u32	mdp_color;
+	u8	depth[VIDEO_MAX_PLANES];
+	u8	row_depth[VIDEO_MAX_PLANES];
+	u8	num_planes;
+	u8	walign;
+	u8	halign;
+	u8	salign;
+	u32	flags;
+};
+
+struct mtk_isp_ctx_format {
+	union {
+		struct mtk_isp_ctx_meta_format meta;
+		struct mtk_isp_ctx_mdp_format img;
+	} fmt;
+};
+
+union mtk_v4l2_fmt {
+	struct v4l2_pix_format_mplane pix_mp;
+	struct v4l2_meta_format	meta;
+};
+
+/* Attributes setup by device context owner */
+struct mtk_isp_ctx_queues_setting {
+	int master;
+	/* The master input node to trigger the frame data enqueue */
+	struct mtk_isp_ctx_queue_desc *output_queue_descs;
+	int total_output_queues;
+	struct mtk_isp_ctx_queue_desc *capture_queue_descs;
+	int total_capture_queues;
+};
+
+
+struct mtk_isp_ctx_queue_attr {
+	int master;
+	int input_offset;
+	int total_num;
+};
+
+/* Video node context. Since we use */
+/* mtk_isp_ctx_frame_bundle to manage enqueued */
+/* buffers by frame now, we don't use bufs filed of */
+/* mtk_isp_ctx_queue now */
+struct mtk_isp_ctx_queue {
+	union mtk_v4l2_fmt fmt;
+	struct mtk_isp_ctx_format *ctx_fmt;
+	/* Currently we used in standard v4l2 image format */
+	/* in the device context */
+	unsigned int width_pad;	/* bytesperline, reserved */
+	struct mtk_isp_ctx_queue_desc desc;
+	struct v4l2_ctrl_handler ctrl_handler; /* Ctrl handler of the queue */
+	unsigned int buffer_usage; /* Current buffer usage of the queue */
+	int rotation;
+	struct list_head bufs; /* Reserved, not used now */
+};
+
+enum mtk_isp_ctx_frame_bundle_state {
+	MTK_ISP_CTX_FRAME_NEW,	/* Not allocated */
+	MTK_ISP_CTX_FRAME_PREPARED, /* Allocated but has not be processed */
+	MTK_ISP_CTX_FRAME_PROCESSING,	/* Queued, waiting to be filled */
+};
+
+/* The definiation is compatible with DIP driver's state definiation */
+/* currently and will be decoupled after further integration */
+enum mtk_isp_ctx_frame_data_state {
+	MTK_ISP_CTX_FRAME_DATA_EMPTY = 0, /* FRAME_STATE_INIT */
+	MTK_ISP_CTX_FRAME_DATA_DONE = 3, /* FRAME_STATE_DONE */
+	MTK_ISP_CTX_FRAME_DATA_STREAMOFF_DONE = 4, /*FRAME_STATE_STREAMOFF*/
+	MTK_ISP_CTX_FRAME_DATA_ERROR = 5, /*FRAME_STATE_ERROR*/
+};
+
+struct mtk_isp_ctx_frame_bundle {
+	struct mtk_isp_ctx_buffer*
+		buffers[MTK_ISP_CTX_FRAME_BUNDLE_BUFFER_MAX];
+	int id;
+	int num_img_capture_bufs;
+	int num_img_output_bufs;
+	int num_meta_capture_bufs;
+	int num_meta_output_bufs;
+	int last_index;
+	int state;
+	struct list_head list;
+};
+
+struct mtk_isp_ctx_frame_bundle_list {
+	struct list_head list;
+};
+
+struct mtk_isp_ctx {
+	struct platform_device *pdev;
+	struct platform_device *smem_device;
+	struct v4l2_ctrl_handler ctrl_handler;
+	/* buffer queues will be added later */
+	unsigned short ctx_id;
+	char *device_name;
+	const struct mtk_isp_ctx_ops *ops;
+	struct mtk_isp_dev_node_mapping *mtk_isp_dev_node_map;
+	unsigned int dev_node_num;
+	/* mtk_isp_ctx_queue is the context for the video nodes */
+	struct mtk_isp_ctx_queue queue[MTK_ISP_CTX_QUEUES];
+	struct mtk_isp_ctx_queue_attr queues_attr;
+	atomic_t frame_param_sequence;
+	bool streaming;
+	void *img_vb2_alloc_ctx;
+	void *smem_vb2_alloc_ctx;
+	struct v4l2_subdev_fh *fh;
+	struct mtk_isp_ctx_frame_bundle frame_bundles[VB2_MAX_FRAME];
+	struct mtk_isp_ctx_frame_bundle_list processing_frames;
+	struct mtk_isp_ctx_frame_bundle_list free_frames;
+	int enabled_dma_ports;
+	int num_frame_bundle;
+	int mode; /* Reserved for debug */
+	spinlock_t qlock;
+};
+
+enum mtk_isp_ctx_buffer_state {
+	MTK_ISP_CTX_BUFFER_NEW,
+	MTK_ISP_CTX_BUFFER_PROCESSING,
+	MTK_ISP_CTX_BUFFER_DONE,
+	MTK_ISP_CTX_BUFFER_FAILED,
+};
+
+struct mtk_isp_ctx_buffer {
+	union mtk_v4l2_fmt fmt;
+	struct mtk_isp_ctx_format *ctx_fmt;
+	bool capture;
+	bool image;
+	int frame_id;
+	int user_sequence; /* Sequence number assigned by user */
+	dma_addr_t daddr;
+	void *vaddr;
+	phys_addr_t paddr;
+	unsigned int queue;
+	unsigned int buffer_usage;
+	enum mtk_isp_ctx_buffer_state state;
+	int rotation;
+	struct list_head list;
+};
+
+struct mtk_isp_ctx_setting {
+	struct mtk_isp_ctx_ops *ops;
+	char *device_name;
+};
+
+struct mtk_isp_ctx_desc {
+	char *proc_dev_phandle;
+	/* The context device's compatble string name in device tree*/
+	int (*init)(struct mtk_isp_ctx *ctx);
+	/* configure the core functions of the device context */
+};
+
+struct mtk_isp_ctx_init_table {
+	int total_dev_ctx;
+	struct mtk_isp_ctx_desc *ctx_desc_tbl;
+};
+
+
+struct mtk_isp_ctx_open_param {
+	/* Bitmask used to notify that the DMA port is enabled or not */
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_isp_ctx_streamon_param {
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_isp_ctx_streamoff_param {
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_isp_ctx_start_param {
+	/* carry buffer information of the frame */
+	struct mtk_isp_ctx_frame_bundle *frame_bundle;
+};
+
+struct mtk_isp_ctx_release_param {
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_isp_ctx_start_param_wrapper {
+	struct mtk_isp_ctx_start_param param;
+	/* Private fields */
+	/* Don't change any field outside mtk_isp-dev-ctx-core */
+	/* Since it may corrupt the common framework */
+	struct mtk_isp_ctx *ctx;
+};
+
+struct mtk_isp_ctx_finish_param {
+	unsigned int frame_id;
+	uint64_t timestamp;
+	unsigned int state;
+};
+
+extern bool mtk_isp_ctx_is_streaming(struct mtk_isp_ctx *ctx);
+extern int mtk_isp_ctx_core_job_finish(struct mtk_isp_ctx *ctx,
+		struct mtk_isp_ctx_finish_param *param);
+extern int mtk_isp_ctx_core_init(struct mtk_isp_ctx *ctx,
+	struct platform_device *pdev, int ctx_id,
+	struct mtk_isp_ctx_desc *ctx_desc,
+	struct platform_device *proc_pdev,
+	struct platform_device *smem_pdev);
+extern int mtk_isp_ctx_core_exit(struct mtk_isp_ctx *ctx);
+extern void mtk_isp_ctx_buf_init(struct mtk_isp_ctx_buffer *b,
+	unsigned int queue, dma_addr_t daddr);
+extern enum mtk_isp_ctx_buffer_state
+	mtk_isp_ctx_get_buffer_state(struct mtk_isp_ctx_buffer *b);
+extern int mtk_isp_ctx_next_global_frame_sequence
+	(struct mtk_isp_ctx *ctx, int locked);
+extern int mtk_isp_ctx_core_steup
+	(struct mtk_isp_ctx *ctx, struct mtk_isp_ctx_setting *ctx_setting);
+extern int mtk_isp_ctx_core_queue_setup(struct mtk_isp_ctx *ctx,
+	struct mtk_isp_ctx_queues_setting *queues_setting);
+extern int mtk_isp_ctx_core_finish_param_init(void *param,
+	int frame_id, int state);
+extern int mtk_isp_ctx_param_queue_event_dev_state
+	(struct mtk_isp_ctx_start_param *s_param,
+	struct mtk_isp_dev_stat_event_data *stat);
+int mtk_isp_ctx_queue_event_dev_state(
+	struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_dev_stat_event_data *stat);
+extern int mtk_isp_ctx_finish_frame(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *frame_bundle, int done);
+extern int mtk_isp_ctx_frame_bundle_init
+	(struct mtk_isp_ctx_frame_bundle *frame_bundle);
+extern void mtk_isp_ctx_frame_bundle_add(struct mtk_isp_ctx *ctx,
+	struct mtk_isp_ctx_frame_bundle *bundle,
+	struct mtk_isp_ctx_buffer *ctx_buf);
+extern int mtk_isp_ctx_trigger_job
+	(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *bundle_data);
+extern int mtk_isp_ctx_fmt_set_img
+	(struct mtk_isp_ctx *dev_ctx, int queue_id,
+	struct v4l2_pix_format_mplane *user_fmt,
+	struct v4l2_pix_format_mplane *node_fmt);
+extern int mtk_isp_ctx_fmt_set_meta
+	(struct mtk_isp_ctx *dev_ctx, int queue_id,
+	struct v4l2_meta_format *user_fmt,
+	struct v4l2_meta_format *node_fmt);
+extern int mtk_isp_ctx_format_load_default_fmt(
+	struct mtk_isp_ctx_queue *queue,
+	struct v4l2_format *fmt_to_fill);
+extern int mtk_isp_ctx_streamon(struct mtk_isp_ctx *dev_ctx);
+extern int mtk_isp_ctx_streamoff(struct mtk_isp_ctx *dev_ctx);
+extern int mtk_isp_ctx_release(struct mtk_isp_ctx *dev_ctx);
+extern int mtk_isp_ctx_open(struct mtk_isp_ctx *dev_ctx);
+#endif /*__MTK_ISP_CTX_H__*/
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-dev-ctx-core.c b/drivers/media/platform/mtk-isp/common/mtk_isp-dev-ctx-core.c
new file mode 100644
index 000000000000..5c0b5ae4ffea
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-dev-ctx-core.c
@@ -0,0 +1,1045 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include <linux/dma-mapping.h>
+#include <media/v4l2-event.h>
+
+#include "mtk_isp-dev.h"
+#include "mtk_isp-v4l2.h"
+#include "mtk_isp-smem.h"
+
+#if KERNEL_VERSION(4, 8, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+#include <linux/dma-attrs.h>
+#endif
+
+
+static struct mtk_isp_ctx_format *mtk_isp_ctx_find_fmt(
+	struct mtk_isp_ctx_queue *queue,
+	u32 format);
+
+static int mtk_isp_ctx_process_frame(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *frame_bundle);
+
+static int mtk_isp_ctx_free_frame(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *frame_bundle);
+
+static struct mtk_isp_ctx_frame_bundle *mtk_isp_ctx_get_free_frame
+	(struct mtk_isp_ctx *dev_ctx);
+
+static struct mtk_isp_ctx_frame_bundle *mtk_isp_ctx_get_processing_frame
+(struct mtk_isp_ctx *dev_ctx, int frame_id);
+
+static int mtk_isp_ctx_init_frame_bundles(struct mtk_isp_ctx *dev_ctx);
+
+static void mtk_isp_ctx_queue_event_frame_done
+	(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_dev_frame_done_event_data *fdone);
+
+static void debug_bundle(struct mtk_isp_ctx_frame_bundle
+	*bundle_data);
+
+struct vb2_v4l2_buffer *mtk_isp_ctx_buffer_get_vb2_v4l2_buffer
+(struct mtk_isp_ctx_buffer *ctx_buf)
+{
+	struct mtk_isp_dev_buffer *dev_buf = NULL;
+
+	if (ctx_buf == NULL) {
+		pr_err("Failed to convert ctx_buf to dev_buf: Null pointer\n");
+		return NULL;
+	}
+
+	dev_buf	= mtk_isp_ctx_buf_to_dev_buf(ctx_buf);
+
+	return &dev_buf->m2m2_buf.vbb;
+}
+
+/* The helper to configure the device context */
+int mtk_isp_ctx_core_steup(struct mtk_isp_ctx *ctx,
+	struct mtk_isp_ctx_setting *ctx_setting)
+{
+	if (ctx == NULL || ctx_setting == NULL)
+		return -EINVAL;
+
+	ctx->ops = ctx_setting->ops;
+	ctx->device_name = ctx_setting->device_name;
+
+	return 0;
+}
+
+
+int mtk_isp_ctx_core_queue_setup(struct mtk_isp_ctx *ctx,
+	struct mtk_isp_ctx_queues_setting *queues_setting)
+{
+	int queue_idx = 0;
+	int i = 0;
+
+	for (i = 0; i < queues_setting->total_output_queues; i++) {
+		struct mtk_isp_ctx_queue_desc *queue_desc =
+			queues_setting->output_queue_descs + i;
+
+		if (queue_desc == NULL)
+			return -EINVAL;
+
+		/* Since the *ctx->queue has been initialized to 0 */
+		/* when it is allocated with mtk_isp_dev , */
+		/* I don't initialize the struct here */
+		ctx->queue[queue_idx].desc = *queue_desc;
+		queue_idx++;
+	}
+
+	ctx->queues_attr.input_offset = queue_idx;
+
+	/* Setup the capture queue */
+	for (i = 0; i < queues_setting->total_capture_queues; i++) {
+		struct mtk_isp_ctx_queue_desc *queue_desc =
+			queues_setting->capture_queue_descs + i;
+
+		if (!queue_desc)
+			return -EINVAL;
+
+		/* Since the *ctx->queue has been initialized to 0 */
+		/* when allocating the memory, I don't */
+		/* reinitialied the struct here */
+		ctx->queue[queue_idx].desc = *queue_desc;
+		queue_idx++;
+	}
+
+	ctx->queues_attr.master = queues_setting->master;
+	ctx->queues_attr.total_num = queue_idx;
+	ctx->dev_node_num = ctx->queues_attr.total_num;
+	return 0;
+}
+
+/* Mediatek ISP context core initialization */
+int mtk_isp_ctx_core_init(struct mtk_isp_ctx *ctx,
+	struct platform_device *pdev, int ctx_id,
+	struct mtk_isp_ctx_desc *ctx_desc,
+	struct platform_device *proc_pdev,
+	struct platform_device *smem_pdev)
+{
+	/* Initialize main data structure */
+	int r = 0;
+
+#if KERNEL_VERSION(4, 8, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	ctx->smem_vb2_alloc_ctx =
+		vb2_dma_contig_init_ctx(&smem_pdev->dev);
+	ctx->img_vb2_alloc_ctx =
+		vb2_dma_contig_init_ctx(&pdev->dev);
+#else
+	ctx->smem_vb2_alloc_ctx = &smem_pdev->dev;
+	ctx->img_vb2_alloc_ctx = &pdev->dev;
+#endif
+	if (IS_ERR((__force void *)ctx->smem_vb2_alloc_ctx))
+		pr_err("Failed to alloc vb2 dma context: smem_vb2_alloc_ctx");
+
+	if (IS_ERR((__force void *)ctx->img_vb2_alloc_ctx))
+		pr_err("Failed to alloc vb2 dma context: img_vb2_alloc_ctx");
+
+	ctx->pdev = pdev;
+	ctx->ctx_id = ctx_id;
+	/* keep th smem pdev to use related iommu functions */
+	ctx->smem_device = smem_pdev;
+
+	/* Will set default enabled after passing the unit test */
+	ctx->mode = MTK_ISP_CTX_MODE_DEBUG_OFF;
+
+	/* initialized the global frame index of the device context */
+	atomic_set(&ctx->frame_param_sequence, 0);
+	spin_lock_init(&ctx->qlock);
+
+	/* setup the core operation of the device context */
+	if (ctx_desc && ctx_desc->init)
+		r = ctx_desc->init(ctx);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_core_init);
+
+int mtk_isp_ctx_core_exit(struct mtk_isp_ctx *ctx)
+{
+#if KERNEL_VERSION(4, 8, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	vb2_dma_contig_cleanup_ctx(ctx->smem_vb2_alloc_ctx);
+	vb2_dma_contig_cleanup_ctx(ctx->img_vb2_alloc_ctx);
+#else
+	ctx->smem_vb2_alloc_ctx = NULL;
+	ctx->img_vb2_alloc_ctx = NULL;
+#endif
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_core_exit);
+
+/* Get the corrospnd FH of a specific buffer */
+int mtk_isp_ctx_next_global_frame_sequence(struct mtk_isp_ctx *ctx,
+	int locked)
+{
+	int global_frame_sequence =
+		atomic_inc_return(&ctx->frame_param_sequence);
+
+	if (!locked)
+		spin_lock(&ctx->qlock);
+
+	global_frame_sequence =
+		(global_frame_sequence & 0x0000FFFF) | (ctx->ctx_id << 16);
+
+	if (!locked)
+		spin_unlock(&ctx->qlock);
+
+	return global_frame_sequence;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_next_global_frame_sequence);
+
+static void mtk_isp_ctx_buffer_done
+	(struct mtk_isp_ctx_buffer *ctx_buf, int state)
+{
+		if (ctx_buf == NULL ||
+			state != MTK_ISP_CTX_BUFFER_DONE ||
+			state != MTK_ISP_CTX_BUFFER_FAILED)
+			return;
+
+		ctx_buf->state = state;
+}
+
+int mtk_isp_ctx_core_job_finish(struct mtk_isp_ctx *dev_ctx,
+		struct mtk_isp_ctx_finish_param *param)
+{
+	int i = 0;
+	struct platform_device *pdev = dev_ctx->pdev;
+	struct mtk_isp_ctx_finish_param *fram_param =
+		(struct mtk_isp_ctx_finish_param *)param;
+	struct mtk_isp_dev *isp_dev = NULL;
+	struct mtk_isp_ctx_frame_bundle *frame = NULL;
+	enum vb2_buffer_state vbf_state = VB2_BUF_STATE_DONE;
+	enum mtk_isp_ctx_buffer_state ctxf_state =
+		MTK_ISP_CTX_BUFFER_DONE;
+	int master_queue = 0;
+	int user_sequence = 0;
+	struct mtk_isp_dev_frame_done_event_data fdone;
+	const int ctx_id =
+		MTK_ISP_GET_CTX_ID_FROM_SEQUENCE(fram_param->frame_id);
+	u64 timestamp = 0;
+
+	pr_debug("mtk_isp_ctx_core_job_finish_cb: param (%llx), platform_device(%llx)\n",
+		(unsigned long long)param, (unsigned long long)pdev);
+
+	if (dev_ctx == NULL)
+		pr_err("dev_ctx can't be null, can't release the frame\n");
+
+	isp_dev = mtk_isp_ctx_to_dev(dev_ctx);
+
+	if (fram_param != NULL) {
+		dev_info(&isp_dev->pdev->dev,
+			"CB recvied from ctx(%d), frame(%d), state(%d), isp_dev(%llx)\n",
+			ctx_id, fram_param->frame_id,
+			fram_param->state, (long long) isp_dev);
+	} else {
+		dev_err(&isp_dev->pdev->dev,
+			"CB recvied from ctx(%d), frame param is NULL\n",
+			ctx_id);
+			return -EINVAL;
+	}
+
+	/* Get the buffers of the processed frame */
+	frame = mtk_isp_ctx_get_processing_frame(&isp_dev->ctx,
+		fram_param->frame_id);
+
+	if (frame == NULL) {
+		pr_err("Can't find the frame boundle, Frame(%d)\n",
+			fram_param->frame_id);
+			return -EINVAL;
+	}
+
+	if (fram_param->state == MTK_ISP_CTX_FRAME_DATA_ERROR) {
+		vbf_state = VB2_BUF_STATE_ERROR;
+		ctxf_state = MTK_ISP_CTX_BUFFER_FAILED;
+	}
+
+	/* Set the buffer's VB2 status so that the user can dequeue */
+	/* the buffer */
+	timestamp = ktime_get_ns();
+	for (i = 0; i <= frame->last_index; i++) {
+		struct mtk_isp_ctx_buffer *ctx_buf = frame->buffers[i];
+
+		if (!ctx_buf) {
+			dev_dbg(&isp_dev->pdev->dev,
+				"ctx_buf(queue id= %d) of frame(%d)is NULL\n",
+				i, fram_param->frame_id);
+			continue;
+		} else {
+			struct vb2_v4l2_buffer *b =
+				mtk_isp_ctx_buffer_get_vb2_v4l2_buffer(ctx_buf);
+			b->vb2_buf.timestamp = ktime_get_ns();
+			user_sequence = ctx_buf->user_sequence;
+			mtk_isp_ctx_buffer_done(ctx_buf, ctxf_state);
+			mtk_isp_v4l2_buffer_done(&b->vb2_buf, vbf_state);
+		}
+	}
+
+	master_queue = isp_dev->ctx.queues_attr.master;
+
+	if (frame->buffers[master_queue] != NULL)
+		fdone.user_sequence =
+			frame->buffers[master_queue]->user_sequence;
+	else
+		fdone.user_sequence = user_sequence;
+
+	fdone.frame_id = frame->id;
+
+	/* Notify the user frame process done */
+	mtk_isp_ctx_queue_event_frame_done(&isp_dev->ctx, &fdone);
+	mtk_isp_ctx_free_frame(&isp_dev->ctx, frame);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_core_job_finish);
+
+
+/* structure mtk_isp_ctx_finish_param must be the first elemt of param */
+/* So that the buffer can be return to vb2 queue successfully */
+int mtk_isp_ctx_core_finish_param_init(void *param, int frame_id, int state)
+{
+	struct mtk_isp_ctx_finish_param *fram_param =
+		(struct mtk_isp_ctx_finish_param *)param;
+	fram_param->frame_id = frame_id;
+	fram_param->state = state;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_core_finish_param_init);
+
+void mtk_isp_ctx_frame_bundle_add(struct mtk_isp_ctx *ctx,
+	struct mtk_isp_ctx_frame_bundle *bundle,
+	struct mtk_isp_ctx_buffer *ctx_buf)
+{
+	int queue_id = 0;
+	struct mtk_isp_ctx_queue *ctx_queue = NULL;
+
+	if (!bundle || !ctx_buf) {
+		pr_warn("Add buffer to frame bundle failed, bundle(%llx),buf(%llx)\n",
+			(long long)bundle, (long long)ctx_buf);
+		return;
+	}
+
+	queue_id = ctx_buf->queue;
+
+	if (bundle->buffers[queue_id] != NULL)
+		pr_warn("Queue(%d) buffer has alreay in this bundle, overwrite happen\n",
+			queue_id);
+
+	pr_debug("Add queue(%d) buffer%llx\n",
+		queue_id, (unsigned long long)ctx_buf);
+		bundle->buffers[queue_id] = ctx_buf;
+
+	/* Fill context queue related information */
+	ctx_queue = &ctx->queue[queue_id];
+
+	if (!ctx_queue) {
+		pr_err("Can't find ctx queue (%d)\n", queue_id);
+		return;
+	}
+
+	if (ctx->queue[ctx_buf->queue].desc.image) {
+		if (ctx->queue[ctx_buf->queue].desc.capture)
+			bundle->num_img_capture_bufs++;
+		else
+			bundle->num_img_output_bufs++;
+	} else{
+		if (ctx->queue[ctx_buf->queue].desc.capture)
+			bundle->num_meta_capture_bufs++;
+		else
+			bundle->num_meta_output_bufs++;
+	}
+
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_frame_bundle_add);
+
+static void debug_bundle(struct mtk_isp_ctx_frame_bundle *bundle_data)
+{
+	int i = 0;
+
+	if (bundle_data == NULL) {
+		pr_warn("bundle_data is NULL\n");
+		return;
+	}
+
+	pr_debug("bundle buf nums (%d, %d,%d,%d)\n",
+		bundle_data->num_img_capture_bufs,
+		bundle_data->num_img_output_bufs,
+		bundle_data->num_meta_capture_bufs,
+		bundle_data->num_meta_output_bufs);
+
+	for (i = 0; i < 16 ; i++) {
+		pr_debug("Bundle, buf[%d] = %llx\n",
+		i,
+		(unsigned long long)bundle_data->buffers[i]);
+	}
+
+	pr_debug("Bundle last idx: %d\n", bundle_data->last_index);
+}
+
+int mtk_isp_ctx_trigger_job(struct mtk_isp_ctx  *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *bundle_data)
+{
+
+	/* Scan all buffers and filled the ipi frame data*/
+	int i = 0;
+	struct mtk_isp_ctx_start_param s_param;
+	struct mtk_isp_ctx_finish_param fram_param;
+
+	struct mtk_isp_ctx_frame_bundle *bundle
+		= mtk_isp_ctx_get_free_frame(dev_ctx);
+
+	pr_debug("Clear mtk_isp_ctx_start_param\n");
+	memset(&s_param, 0,
+		sizeof(struct mtk_isp_ctx_start_param));
+
+	pr_debug("Bundle data: mtk_isp_ctx_start_param, ctx id:%d\n",
+		 dev_ctx->ctx_id);
+
+	debug_bundle(bundle_data);
+
+	if (bundle == NULL) {
+		pr_err("bundle can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+	if (bundle_data == NULL) {
+		pr_err("bundle_data can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	if (bundle_data->buffers == NULL) {
+		pr_err("bundle_data->buffers can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	pr_debug("Copy bundle_data->buffers to bundle->buffers\n");
+	memcpy(bundle->buffers, bundle_data->buffers,
+		sizeof(struct mtk_isp_ctx_buffer *)
+			* MTK_ISP_CTX_FRAME_BUNDLE_BUFFER_MAX);
+
+	pr_debug("bundle setup (%d, %d,%d,%d)\n",
+		bundle_data->num_img_capture_bufs,
+		bundle_data->num_img_output_bufs,
+		bundle_data->num_meta_capture_bufs,
+		bundle_data->num_meta_output_bufs);
+
+	bundle->num_img_capture_bufs =
+		bundle_data->num_img_capture_bufs;
+	bundle->num_img_output_bufs =
+		 bundle_data->num_img_output_bufs;
+	bundle->num_meta_capture_bufs =
+		bundle_data->num_meta_capture_bufs;
+	bundle->num_meta_output_bufs =
+		bundle_data->num_meta_output_bufs;
+	bundle->id
+		= mtk_isp_ctx_next_global_frame_sequence(dev_ctx,
+		dev_ctx->ctx_id);
+	bundle->last_index = dev_ctx->queues_attr.total_num - 1;
+
+	pr_debug("Bundle:\n");
+	debug_bundle(bundle);
+
+	s_param.frame_bundle = bundle;
+
+	pr_debug("Fill Address data\n");
+	for (i = 0; i <= bundle->last_index; i++) {
+		struct mtk_isp_ctx_buffer *ctx_buf = bundle->buffers[i];
+		struct vb2_v4l2_buffer *b = NULL;
+
+		pr_debug("Process queue[%d], ctx_buf:(%llx)\n",
+			i, (unsigned long long)ctx_buf);
+
+		if (ctx_buf == NULL) {
+			pr_warn("queue[%d], ctx_buf is NULL!!\n", i);
+			continue;
+		}
+
+		pr_debug("Get VB2 V4L2 buffer\n");
+		b = mtk_isp_ctx_buffer_get_vb2_v4l2_buffer(ctx_buf);
+
+		ctx_buf->image = dev_ctx->queue[ctx_buf->queue].desc.image;
+		ctx_buf->capture = dev_ctx->queue[ctx_buf->queue].desc.capture;
+		/* copy the fmt setting for queue's fmt*/
+		ctx_buf->fmt = dev_ctx->queue[ctx_buf->queue].fmt;
+		ctx_buf->ctx_fmt = dev_ctx->queue[ctx_buf->queue].ctx_fmt;
+			ctx_buf->frame_id = bundle->id;
+		ctx_buf->daddr =
+			vb2_dma_contig_plane_dma_addr(&b->vb2_buf, 0);
+		pr_debug("%s:vb2_buf: type(%d),idx(%d),mem(%d)\n",
+					  __func__, 
+					  b->vb2_buf.type,
+					  b->vb2_buf.index,
+					  b->vb2_buf.memory);
+		ctx_buf->vaddr = vb2_plane_vaddr(&b->vb2_buf, 0);
+		ctx_buf->buffer_usage = dev_ctx->queue[i].buffer_usage;
+		ctx_buf->rotation = dev_ctx->queue[i].rotation;
+		
+		pr_debug("Buf: queue(%d), vaddr(%llx), daddr(%llx)",
+			ctx_buf->queue, (unsigned long long) ctx_buf->vaddr,
+			(unsigned long long) ctx_buf->daddr);
+
+		if (!ctx_buf->image) {
+			ctx_buf->paddr =
+				mtk_isp_smem_iova_to_phys(
+					&dev_ctx->smem_device->dev,
+					ctx_buf->daddr);
+		} else {
+			pr_debug("No pa: it is a image buffer\n");
+			ctx_buf->paddr = 0;
+		}
+		ctx_buf->state = MTK_ISP_CTX_BUFFER_PROCESSING;
+	}
+
+	if (mtk_isp_ctx_process_frame(dev_ctx, bundle)) {
+		pr_err("mtk_isp_ctx_process_frame failed: frame(%d)\n",
+			bundle->id);
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	if (dev_ctx->ops->start) {
+		if (dev_ctx->mode ==
+				MTK_ISP_CTX_MODE_DEBUG_BYPASS_JOB_TRIGGER) {
+			memset(&fram_param, 0,
+				sizeof(struct mtk_isp_ctx_finish_param));
+			fram_param.frame_id = bundle->id;
+			fram_param.state = MTK_ISP_CTX_FRAME_DATA_DONE;
+			pr_debug("Ctx(%d) in HW bypass mode, will not trigger hw\n",
+				dev_ctx->ctx_id);
+
+			if (dev_ctx->ops->finish)
+				dev_ctx->ops->finish(dev_ctx,
+					(void *)&fram_param);
+			else
+				dev_err(&dev_ctx->pdev->dev, "No finish op registered\n");
+			return 0;
+
+		} else {
+			if (dev_ctx->ops->start(dev_ctx,
+				&s_param))
+				goto FAILE_JOB_NOT_TRIGGER;
+		}
+	} else{
+		pr_err("Ctx(%d)'s start op can't be NULL\n", dev_ctx->ctx_id);
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+	return 0;
+
+FAILE_JOB_NOT_TRIGGER:
+	pr_debug("FAILE_JOB_NOT_TRIGGER: init fram_param: %llx\n",
+		(unsigned long long) &fram_param);
+	memset(&fram_param, 0, sizeof(struct mtk_isp_ctx_finish_param));
+	fram_param.frame_id = bundle->id;
+	fram_param.state = MTK_ISP_CTX_FRAME_DATA_ERROR;
+	pr_debug("Call mtk_isp_ctx_core_job_finish_cb: fram_param: %llx",
+	(unsigned long long)&fram_param);
+	if (dev_ctx->ops->finish)
+		dev_ctx->ops->finish(dev_ctx, (void *)&fram_param);
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_trigger_job);
+
+void mtk_isp_ctx_buf_init(struct mtk_isp_ctx_buffer *b,
+	unsigned int queue, dma_addr_t daddr)
+{
+	b->state = MTK_ISP_CTX_BUFFER_NEW;
+	b->queue = queue;
+	b->daddr = daddr;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_buf_init);
+
+enum mtk_isp_ctx_buffer_state
+	mtk_isp_ctx_get_buffer_state(struct mtk_isp_ctx_buffer *b)
+{
+	return b->state;
+}
+
+bool mtk_isp_ctx_is_streaming(struct mtk_isp_ctx *ctx)
+{
+	return ctx->streaming;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_is_streaming);
+
+
+int mtk_isp_ctx_init_frame_bundles(struct mtk_isp_ctx *dev_ctx)
+{
+	int i = 0;
+
+	dev_ctx->num_frame_bundle = VB2_MAX_FRAME;
+
+	spin_lock(&dev_ctx->qlock);
+
+	/* Reset the queue*/
+	INIT_LIST_HEAD(&dev_ctx->processing_frames.list);
+	INIT_LIST_HEAD(&dev_ctx->free_frames.list);
+
+	for (i = 0; i < dev_ctx->num_frame_bundle; i++) {
+		struct mtk_isp_ctx_frame_bundle *frame_bundle =
+			&dev_ctx->frame_bundles[i];
+		frame_bundle->state = MTK_ISP_CTX_FRAME_NEW;
+		list_add_tail(&frame_bundle->list, &dev_ctx->free_frames.list);
+	}
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return 0;
+}
+
+static int mtk_isp_ctx_process_frame(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *frame_bundle)
+{
+	spin_lock(&dev_ctx->qlock);
+
+	frame_bundle->state = MTK_ISP_CTX_FRAME_PROCESSING;
+	list_del(&frame_bundle->list);
+	list_add_tail(&frame_bundle->list, &dev_ctx->processing_frames.list);
+
+	spin_unlock(&dev_ctx->qlock);
+	return 0;
+}
+
+
+/* Since the ISP physical doesn't guanartee FIFO order when processing */
+/* the frame, for example, flushing buffers when streaming off, */
+/* we search the list to get the frame by frame id */
+struct mtk_isp_ctx_frame_bundle *mtk_isp_ctx_get_processing_frame
+(struct mtk_isp_ctx *dev_ctx, int frame_id)
+{
+	struct mtk_isp_ctx_frame_bundle *frame_bundle = NULL;
+
+	spin_lock(&dev_ctx->qlock);
+
+	list_for_each_entry(frame_bundle,
+		&dev_ctx->processing_frames.list, list) {
+		if (frame_bundle->id == frame_id) {
+			spin_unlock(&dev_ctx->qlock);
+			return frame_bundle;
+		}
+	}
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return NULL;
+}
+
+static int mtk_isp_ctx_free_frame(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *frame_bundle)
+{
+
+	spin_lock(&dev_ctx->qlock);
+
+	frame_bundle->state = MTK_ISP_CTX_FRAME_NEW;
+	list_del(&frame_bundle->list);
+	list_add_tail(&frame_bundle->list, &dev_ctx->free_frames.list);
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return 0;
+}
+
+static struct mtk_isp_ctx_frame_bundle *mtk_isp_ctx_get_free_frame
+	(struct mtk_isp_ctx *dev_ctx)
+{
+	struct mtk_isp_ctx_frame_bundle *frame_bundle = NULL;
+
+	spin_lock(&dev_ctx->qlock);
+	list_for_each_entry(frame_bundle,
+		&dev_ctx->free_frames.list, list){
+		pr_debug("Check frame: state %d, new should be %d\n",
+			frame_bundle->state, MTK_ISP_CTX_FRAME_NEW);
+		if (frame_bundle->state == MTK_ISP_CTX_FRAME_NEW) {
+			frame_bundle->state = MTK_ISP_CTX_FRAME_PREPARED;
+			pr_debug("Found free frame\n");
+			spin_unlock(&dev_ctx->qlock);
+			return frame_bundle;
+		}
+	}
+	spin_unlock(&dev_ctx->qlock);
+	pr_err("Can't found any bundle is MTK_ISP_CTX_FRAME_NEW\n");
+	return NULL;
+}
+
+int mtk_isp_ctx_finish_frame(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_ctx_frame_bundle *frame_bundle, int done)
+{
+	spin_lock(&dev_ctx->qlock);
+	frame_bundle->state = MTK_ISP_CTX_FRAME_PROCESSING;
+	list_add_tail(&frame_bundle->list, &dev_ctx->processing_frames.list);
+	spin_unlock(&dev_ctx->qlock);
+	return 0;
+}
+
+/* Replaced by mtk_isp_ctx_queue_event_dev_state */
+int mtk_isp_ctx_param_queue_event_dev_state(
+	struct mtk_isp_ctx_start_param *s_param,
+	struct mtk_isp_dev_stat_event_data *stat)
+{
+		pr_err("%s: is deprecated\n", __func__);
+		return -EINVAL;
+}
+
+int mtk_isp_ctx_queue_event_dev_state(
+	struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_dev_stat_event_data *stat)
+{
+	struct v4l2_event event;
+	struct mtk_isp_dev_stat_event_data *evt_stat_data
+		= (void *)event.u.data;
+
+	memset(&event, 0, sizeof(event));
+	evt_stat_data->frame_number = stat->frame_number;
+	evt_stat_data->irq_status_mask = stat->irq_status_mask;
+	evt_stat_data->dma_status_mask = stat->dma_status_mask;
+
+	event.type = V4L2_EVENT_MTK_ISP_ENGINE_STATE;
+	v4l2_event_queue_fh(&dev_ctx->fh->vfh, &event);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_param_queue_event_dev_state);
+
+static void mtk_isp_ctx_queue_event_frame_done
+	(struct mtk_isp_ctx *dev_ctx,
+	struct mtk_isp_dev_frame_done_event_data *fdone)
+{
+
+	struct v4l2_event event;
+	/* Carried the frame done information in */
+	/* data field of event */
+	struct mtk_isp_dev_frame_done_event_data *evt_frame_data
+		= (void *)event.u.data;
+
+	memset(&event, 0, sizeof(event));
+
+	evt_frame_data->frame_id = fdone->frame_id;
+	evt_frame_data->user_sequence = fdone->user_sequence;
+
+	event.type = V4L2_EVENT_MTK_ISP_FRAME_DONE;
+	v4l2_event_queue_fh(&dev_ctx->fh->vfh, &event);
+}
+
+static void set_img_fmt(struct v4l2_pix_format_mplane *mfmt_to_fill,
+	struct mtk_isp_ctx_format *ctx_fmt)
+{
+	int i = 0;
+
+	mfmt_to_fill->pixelformat = ctx_fmt->fmt.img.pixelformat;
+	mfmt_to_fill->num_planes = ctx_fmt->fmt.img.num_planes;
+
+	pr_info("%s: Fmt(%d),w(%d),h(%d)\n",
+			    __func__,
+			    mfmt_to_fill->pixelformat,
+			    mfmt_to_fill->width,
+			    mfmt_to_fill->height);
+
+	/* The implementation wil be adjust after integrating MDP module */
+	/* since it provides the common format suppporting function */
+	for (i = 0 ; i < mfmt_to_fill->num_planes; ++i) {
+
+		int bpl =
+			(mfmt_to_fill->width * ctx_fmt->fmt.img.row_depth[i])/8;
+		int sizeimage = (mfmt_to_fill->width * mfmt_to_fill->height *
+			ctx_fmt->fmt.img.depth[i]) / 8;
+
+		mfmt_to_fill->plane_fmt[i].bytesperline = bpl;
+
+		mfmt_to_fill->plane_fmt[i].sizeimage = sizeimage;
+
+		pr_info("plane(%d):bpl(%d),sizeimage(%u)\n",
+					i,  bpl, mfmt_to_fill->plane_fmt[i].sizeimage);
+	}
+}
+
+static void set_meta_fmt(struct v4l2_meta_format *metafmt_to_fill,
+	struct mtk_isp_ctx_format *ctx_fmt)
+{
+
+	metafmt_to_fill->dataformat = ctx_fmt->fmt.meta.dataformat;
+
+	if (ctx_fmt->fmt.meta.max_buffer_size <= 0 ||
+			ctx_fmt->fmt.meta.max_buffer_size
+				> MTK_ISP_CTX_META_BUF_DEFAULT_SIZE){
+		pr_warn("buf size of meta(%u) can't be 0, use default %u\n",
+			ctx_fmt->fmt.meta.dataformat,
+			MTK_ISP_CTX_META_BUF_DEFAULT_SIZE);
+		metafmt_to_fill->buffersize = MTK_ISP_CTX_META_BUF_DEFAULT_SIZE;
+	} else {
+		pr_info("Load the meta size setting %u\n",
+			ctx_fmt->fmt.meta.max_buffer_size);
+		metafmt_to_fill->buffersize = ctx_fmt->fmt.meta.max_buffer_size;
+	}
+}
+
+/* Get the default format setting */
+int mtk_isp_ctx_format_load_default_fmt(
+	struct mtk_isp_ctx_queue *queue,
+	struct v4l2_format *fmt_to_fill)
+{
+	struct mtk_isp_ctx_format *ctx_fmt = NULL;
+
+	if (queue->desc.num_fmts == 0)
+		return 0; /* no format support list associated to this queue */
+
+	if (queue->desc.default_fmt_idx >= queue->desc.num_fmts) {
+		pr_warn("Queue(%s) err: default idx(%d) must < num_fmts(%d)\n",
+			queue->desc.name, queue->desc.default_fmt_idx,
+			queue->desc.num_fmts);
+		queue->desc.default_fmt_idx = 0;
+		pr_warn("Queue(%s) : reset default idx(%d)\n",
+			queue->desc.name, queue->desc.default_fmt_idx);
+	}
+
+
+	ctx_fmt	= &queue->desc.fmts[queue->desc.default_fmt_idx];
+
+	/* Check the type of the buffer */
+	if (queue->desc.image) {
+		struct v4l2_pix_format_mplane *node_fmt
+			= &fmt_to_fill->fmt.pix_mp;
+
+		if (queue->desc.capture) {
+			fmt_to_fill->type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+			node_fmt->width = MTK_ISP_OUTPUT_MAX_WIDTH;
+			node_fmt->height = MTK_ISP_OUTPUT_MAX_HEIGHT;
+		} else{
+			fmt_to_fill->type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+			node_fmt->width = MTK_ISP_INPUT_MAX_WIDTH;
+			node_fmt->height = MTK_ISP_INPUT_MAX_HEIGHT;
+		}
+		set_img_fmt(node_fmt, ctx_fmt);
+	}	else {
+		/* meta buffer type */
+		struct v4l2_meta_format *node_fmt = &fmt_to_fill->fmt.meta;
+
+		if (queue->desc.capture)
+			fmt_to_fill->type = V4L2_BUF_TYPE_META_CAPTURE;
+		else
+			fmt_to_fill->type = V4L2_BUF_TYPE_META_OUTPUT;
+
+		set_meta_fmt(node_fmt, ctx_fmt);
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_format_load_default_fmt);
+
+static struct mtk_isp_ctx_format *mtk_isp_ctx_find_fmt(
+	struct mtk_isp_ctx_queue *queue,
+	u32 format)
+{
+	int i;
+	struct mtk_isp_ctx_format *ctx_fmt;
+
+	pr_debug("fmt to find(%x)\n", format);
+	for (i = 0; i < queue->desc.num_fmts; i++) {
+		ctx_fmt = &queue->desc.fmts[i];
+		if (queue->desc.image) {
+			pr_debug("idx(%d), pixelformat(%x), fmt(%x)\n",
+				i, ctx_fmt->fmt.img.pixelformat, format);
+			if (ctx_fmt->fmt.img.pixelformat == format)
+				return ctx_fmt;
+		} else {
+			if (ctx_fmt->fmt.meta.dataformat == format)
+				return ctx_fmt;
+		}
+	}
+	return NULL;
+}
+
+
+int mtk_isp_ctx_fmt_set_meta(struct mtk_isp_ctx *dev_ctx,
+	int queue_id,
+	struct v4l2_meta_format *user_fmt,
+	struct v4l2_meta_format *node_fmt
+	)
+{
+	struct mtk_isp_ctx_queue *queue = NULL;
+	struct mtk_isp_ctx_format *ctx_fmt;
+
+	if (queue_id >= dev_ctx->queues_attr.total_num) {
+		pr_err("Invalid queue id:%d\n", queue_id);
+		return -EINVAL;
+	}
+
+	queue = &dev_ctx->queue[queue_id];
+
+	if (!user_fmt || !node_fmt)
+		return -EINVAL;
+
+	ctx_fmt = mtk_isp_ctx_find_fmt(queue, user_fmt->dataformat);
+
+	if (!ctx_fmt)
+		return -EINVAL;
+
+	queue->ctx_fmt = ctx_fmt;
+	set_meta_fmt(node_fmt, ctx_fmt);
+	*user_fmt = *node_fmt;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_fmt_set_meta);
+
+int mtk_isp_ctx_fmt_set_img(struct mtk_isp_ctx *dev_ctx,
+	int queue_id,
+	struct v4l2_pix_format_mplane *user_fmt,
+	struct v4l2_pix_format_mplane *node_fmt)
+{
+	struct mtk_isp_ctx_queue *queue = NULL;
+	struct mtk_isp_ctx_format *ctx_fmt;
+
+	if (queue_id >= dev_ctx->queues_attr.total_num) {
+		pr_err("Invalid queue id:%d\n", queue_id);
+		return -EINVAL;
+	}
+
+	queue = &dev_ctx->queue[queue_id];
+
+	if (!user_fmt || !node_fmt)
+		return -EINVAL;
+
+	ctx_fmt = mtk_isp_ctx_find_fmt(queue, user_fmt->pixelformat);
+
+	if (!ctx_fmt)
+		return -EINVAL;
+
+	queue->ctx_fmt = ctx_fmt;
+	node_fmt->width = user_fmt->width;
+	node_fmt->height = user_fmt->height;
+
+	set_img_fmt(node_fmt, ctx_fmt);
+
+	*user_fmt = *node_fmt;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_fmt_set_img);
+
+int mtk_isp_ctx_streamon(struct mtk_isp_ctx *dev_ctx)
+{
+	int ret = 0;
+	struct mtk_isp_ctx_streamon_param params = {0};
+
+	if (dev_ctx->streaming) {
+		pr_warn("stream on failed, pdev(%llx), ctx(%d) already stream on\n",
+		 (long long)dev_ctx->pdev, dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	pr_debug("streamon: pdev(%llx), ctx(%d)\n",
+		 (long long)dev_ctx->pdev, dev_ctx->ctx_id);
+
+	params.enabled_dma_ports = dev_ctx->enabled_dma_ports;
+
+	ret = dev_ctx->ops->streamon(dev_ctx,
+		&params);
+
+	if (ret) {
+		pr_err("streamon: ctx(%d) failed, notified by context\n",
+			dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	dev_ctx->streaming = true;
+
+	ret = mtk_isp_dev_queue_buffers(mtk_isp_ctx_to_dev(dev_ctx),
+		true);
+
+	if (ret)
+		pr_err("failed to queue initial buffers (%d)", ret);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_streamon);
+
+int mtk_isp_ctx_streamoff(struct mtk_isp_ctx *dev_ctx)
+{
+	int ret = 0;
+	struct mtk_isp_ctx_streamoff_param params = {0};
+
+	if (!dev_ctx->streaming) {
+		pr_warn("Do nothing, pdev(%llx), ctx(%d) is already stream off\n",
+		 (long long)dev_ctx->pdev, dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	pr_debug("streamoff: pdev(%llx), ctx(%d)\n",
+		 (long long)dev_ctx->pdev, dev_ctx->ctx_id);
+
+	params.enabled_dma_ports = dev_ctx->enabled_dma_ports;
+
+	ret = dev_ctx->ops->streamoff(dev_ctx, &params);
+
+	if (ret) {
+		pr_warn("streamoff: ctx(%d) failed, notified by context\n",
+			dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	dev_ctx->streaming = false;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_streamoff);
+
+int mtk_isp_ctx_open(struct mtk_isp_ctx *dev_ctx)
+{
+	struct mtk_isp_dev *isp_dev = mtk_isp_ctx_to_dev(dev_ctx);
+	struct mtk_isp_ctx_open_param params = {0};
+	int i = 0;
+
+	if (dev_ctx == NULL || dev_ctx->ops == NULL
+		||	dev_ctx->ops->finish == NULL
+		||	dev_ctx->ops->open == NULL)
+		return -EINVAL;
+
+	/* Get the enabled DMA ports */
+	for (i = 0; i < isp_dev->mem2mem2.num_nodes; i++) {
+		if (isp_dev->mem2mem2.nodes[i].enabled)
+			params.enabled_dma_ports |=
+				dev_ctx->queue[i].desc.dma_port;
+	}
+
+	dev_ctx->enabled_dma_ports = params.enabled_dma_ports;
+
+	dev_dbg(&isp_dev->pdev->dev, "open device: (%llx)\n",
+		 (long long)&isp_dev->pdev->dev);
+
+	/* Workaround for SCP EMI access */
+	mtk_isp_smem_enable_mpu(&dev_ctx->smem_device->dev);
+
+	dev_ctx->ops->open(dev_ctx, &params);
+
+	/* Init the frame bundle pool */
+	mtk_isp_ctx_init_frame_bundles(dev_ctx);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_open);
+
+int mtk_isp_ctx_release(struct mtk_isp_ctx *dev_ctx)
+{
+	struct device *dev = &dev_ctx->pdev->dev;
+
+	struct mtk_isp_ctx_release_param params = {0};
+
+	if (dev_ctx == NULL || dev_ctx->ops == NULL
+		|| dev_ctx->ops->release == NULL)
+		return -EINVAL;
+
+	dev_dbg(dev, "release: (%llx)\n",
+		(long long)dev);
+
+	params.enabled_dma_ports = dev_ctx->enabled_dma_ports;
+
+	dev_ctx->ops->release(dev_ctx, &params);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_ctx_release);
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-dev.c b/drivers/media/platform/mtk-isp/common/mtk_isp-dev.c
new file mode 100644
index 000000000000..3f407f29f104
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-dev.c
@@ -0,0 +1,372 @@
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ * Copyright (C) 2017 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_ISP-dev is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk_isp-dev.h"
+#include "mtk_isp-ctrl.h"
+
+static struct platform_device *mtk_isp_dev_of_find_smem_dev(
+	struct platform_device *pdev);
+
+/* Initliaze a mtk_isp_dev representing a completed HW ISP */
+/* device */
+int mtk_isp_dev_init(struct mtk_isp_dev *isp_dev,
+	struct platform_device *pdev,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	int r = 0;
+
+	isp_dev->pdev = pdev;
+
+	mutex_init(&isp_dev->lock);
+	atomic_set(&isp_dev->qbuf_barrier, 0);
+	init_waitqueue_head(&isp_dev->buf_drain_wq);
+
+	r = mtk_isp_ctrl_init(&isp_dev->ctx);
+
+	if (r) {
+		dev_err(&isp_dev->pdev->dev,
+			"failed to initialize ctrls (%d)\n", r);
+		goto failed_ctrl;
+	}
+
+	/* v4l2 sub-device registration */
+	r = mtk_isp_dev_mem2mem2_init(isp_dev, media_dev, v4l2_dev);
+
+	if (r) {
+		dev_err(&isp_dev->pdev->dev,
+			"failed to create V4L2 devices (%d)\n", r);
+		goto failed_mem2mem2;
+	}
+
+	return 0;
+
+failed_ctrl:
+failed_mem2mem2:
+	mutex_destroy(&isp_dev->lock);
+	return r;
+}
+
+int mtk_isp_dev_get_total_node(struct mtk_isp_dev *mtk_isp_dev)
+{
+	return mtk_isp_dev->ctx.queues_attr.total_num;
+}
+
+int mtk_isp_dev_mem2mem2_init(struct mtk_isp_dev *isp_dev,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	int r, i;
+	const int queue_master = isp_dev->ctx.queues_attr.master;
+
+	pr_info("mem2mem2.name: %s\n", isp_dev->ctx.device_name);
+	isp_dev->mem2mem2.name = isp_dev->ctx.device_name;
+	isp_dev->mem2mem2.model = isp_dev->ctx.device_name;
+	isp_dev->mem2mem2.num_nodes =
+		mtk_isp_dev_get_total_node(isp_dev);
+	isp_dev->mem2mem2.vb2_mem_ops = &vb2_dma_contig_memops;
+	isp_dev->mem2mem2.buf_struct_size =
+		sizeof(struct mtk_isp_dev_buffer);
+
+	/* support UT only currently */
+	isp_dev->mem2mem2.ctrl_handler =
+		&isp_dev->ctx.ctrl_handler;
+
+	isp_dev->mem2mem2.nodes = isp_dev->mem2mem2_nodes;
+	isp_dev->mem2mem2.dev = &isp_dev->pdev->dev;
+
+	for (i = 0; i < isp_dev->ctx.dev_node_num; i++) {
+		isp_dev->mem2mem2.nodes[i].name =
+			mtk_isp_dev_get_node_name(isp_dev, i);
+		isp_dev->mem2mem2.nodes[i].output =
+				i < isp_dev->ctx.queues_attr.input_offset;
+		isp_dev->mem2mem2.nodes[i].immutable = false;
+		isp_dev->mem2mem2.nodes[i].enabled = false;
+		atomic_set(&isp_dev->mem2mem2.nodes[i].sequence, 0);
+	}
+
+	/* Master queue is always enabled */
+	isp_dev->mem2mem2.nodes[queue_master].immutable = true;
+	isp_dev->mem2mem2.nodes[queue_master].enabled = true;
+
+	pr_info("register v4l2 for %llx\n",
+		(unsigned long long)isp_dev);
+	r = mtk_isp_mem2mem2_v4l2_register(isp_dev, media_dev, v4l2_dev);
+
+	if (r) {
+		pr_err("v4l2 init failed, dev(ctx:%d)\n",
+		isp_dev->ctx.ctx_id);
+		return r;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_mem2mem2_init);
+
+
+void mtk_isp_dev_mem2mem2_exit(struct mtk_isp_dev *isp_dev)
+{
+	mtk_isp_v4l2_unregister(isp_dev);
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_mem2mem2_exit);
+
+char *mtk_isp_dev_get_node_name
+	(struct mtk_isp_dev *isp_dev, int node)
+{
+	struct mtk_isp_ctx_queue_desc *mapped_queue_desc =
+		&isp_dev->ctx.queue[node].desc;
+
+	return mapped_queue_desc->name;
+}
+
+/* Get a free buffer from a video node */
+static struct mtk_isp_ctx_buffer __maybe_unused *mtk_isp_dev_queue_getbuf
+	(struct mtk_isp_dev *isp_dev, int node)
+{
+	struct mtk_isp_dev_buffer *buf;
+	int queue = -1;
+
+	if (node > isp_dev->ctx.dev_node_num || node < 0) {
+		dev_err(&isp_dev->pdev->dev, "Invalid mtk_isp_dev node.\n");
+		return NULL;
+	}
+
+	/* Get the corrosponding queue id of the video node */
+	/* Currently the queue id is the same as the node number */
+	queue = node;
+
+	if (queue < 0) {
+		dev_err(&isp_dev->pdev->dev, "Invalid mtk_isp_dev node.\n");
+		return NULL;
+	}
+
+	/* Find first free buffer from the node */
+	list_for_each_entry(buf, &isp_dev->mem2mem2.nodes[node].buffers,
+				m2m2_buf.list) {
+		if (mtk_isp_ctx_get_buffer_state(&buf->ctx_buf)
+			== MTK_ISP_CTX_BUFFER_NEW)
+			return &buf->ctx_buf;
+	}
+
+	/* There were no free buffers*/
+	return NULL;
+}
+
+int mtk_isp_dev_get_queue_id_of_dev_node(
+	struct mtk_isp_dev *isp_dev,
+	struct mtk_isp_dev_video_device *node
+)
+{
+	return (node - isp_dev->mem2mem2.nodes);
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_get_queue_id_of_dev_node);
+
+int mtk_isp_dev_queue_buffers(struct mtk_isp_dev *isp_dev,
+	bool initial)
+{
+	unsigned int node;
+	int r = 0;
+	struct mtk_isp_dev_buffer *ibuf;
+	struct mtk_isp_ctx_frame_bundle bundle;
+	const int mtk_isp_dev_node_num = mtk_isp_dev_get_total_node(isp_dev);
+	const int queue_master = isp_dev->ctx.queues_attr.master;
+
+	memset(&bundle, 0, sizeof(struct mtk_isp_ctx_frame_bundle));
+
+	pr_info("%s, init(%d)\n", __func__, initial);
+
+	if (!mtk_isp_ctx_is_streaming(&isp_dev->ctx)) {
+		pr_info("%s: stream is off, no hw enqueue triggered\n", __func__);
+		return 0;
+	}
+
+	mutex_lock(&isp_dev->lock);
+
+	/* Buffer set is queued to background driver (e.g. DIP, FD, and P1) */
+	/* only when master input buffer is ready */
+	if (!mtk_isp_dev_queue_getbuf(isp_dev, queue_master)) {
+		mutex_unlock(&isp_dev->lock);
+		return 0;
+	}
+
+	/* Check all node from the node after the master node */
+	for (node = (queue_master + 1) % mtk_isp_dev_node_num;
+		1; node = (node + 1) % mtk_isp_dev_node_num) {
+		pr_info("Check node(%d), queue enabled(%d), node enabled(%d)\n",
+			node, isp_dev->queue_enabled[node],
+			isp_dev->mem2mem2.nodes[node].enabled);
+
+		/* May skip some node according the scenario in the future */
+		if (isp_dev->queue_enabled[node] ||
+				isp_dev->mem2mem2.nodes[node].enabled) {
+			struct mtk_isp_ctx_buffer *buf =
+				mtk_isp_dev_queue_getbuf(isp_dev, node);
+			char *node_name =
+				mtk_isp_dev_get_node_name(isp_dev, node);
+
+			if (!buf) {
+				dev_dbg(&isp_dev->pdev->dev,
+					"No free buffer of enabled node %s\n",
+					node_name);
+				break;
+			}
+
+			/* To show the debug message */
+			ibuf = container_of(buf,
+					struct mtk_isp_dev_buffer, ctx_buf);
+			dev_dbg(&isp_dev->pdev->dev,
+				"may queue user %s buffer idx(%d) to ctx\n",
+				node_name,
+				ibuf->m2m2_buf.vbb.vb2_buf.index);
+			mtk_isp_ctx_frame_bundle_add(&isp_dev->ctx,
+				&bundle, buf);
+		}
+
+		/* Stop if there is no free buffer in master input node */
+		if (node == queue_master) {
+			if (mtk_isp_dev_queue_getbuf(isp_dev, queue_master)) {
+				/* Has collected all buffer required */
+				mtk_isp_ctx_trigger_job(&isp_dev->ctx, &bundle);
+			} else {
+				pr_debug("no new buffer found in master node, not trigger job\n");
+				break;
+			}
+		}
+	}
+	mutex_unlock(&isp_dev->lock);
+
+	if (r && r != -EBUSY)
+		goto failed;
+
+	return 0;
+
+failed:
+	/*
+	 * On error, mark all buffers as failed which are not
+	 * yet queued to CSS
+	 */
+	dev_err(&isp_dev->pdev->dev,
+		"failed to queue buffer to ctx on queue %i (%d)\n",
+		node, r);
+
+	if (initial)
+		/* If we were called from streamon(), no need to finish bufs */
+		return r;
+
+	for (node = 0; node < mtk_isp_dev_node_num; node++) {
+		struct mtk_isp_dev_buffer *buf, *buf0;
+
+		if (!isp_dev->queue_enabled[node])
+			continue;	/* Skip disabled queues */
+
+		mutex_lock(&isp_dev->lock);
+		list_for_each_entry_safe(buf, buf0,
+			&isp_dev->mem2mem2.nodes[node].buffers,
+			m2m2_buf.list) {
+			if (mtk_isp_ctx_get_buffer_state(&buf->ctx_buf) ==
+				MTK_ISP_CTX_BUFFER_PROCESSING)
+				continue;	/* Was already queued, skip */
+
+			mtk_isp_v4l2_buffer_done(&buf->m2m2_buf.vbb.vb2_buf,
+						VB2_BUF_STATE_ERROR);
+		}
+		mutex_unlock(&isp_dev->lock);
+	}
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_queue_buffers);
+
+int mtk_isp_dev_core_init(struct platform_device *pdev,
+	struct mtk_isp_dev *isp_dev,
+	struct mtk_isp_ctx_desc *ctx_desc)
+{
+	return mtk_isp_dev_core_init_ext(pdev,
+		isp_dev, ctx_desc, NULL, NULL);
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_core_init);
+
+int mtk_isp_dev_core_init_ext(struct platform_device *pdev,
+	struct mtk_isp_dev *isp_dev,
+	struct mtk_isp_ctx_desc *ctx_desc,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	int r;
+	struct platform_device *smem_dev = NULL;
+
+	smem_dev = mtk_isp_dev_of_find_smem_dev(pdev);
+
+	if (!smem_dev)
+		dev_err(&pdev->dev, "failed to find smem_dev\n");
+
+	/* Device context must be initialized before device instance */
+	r = mtk_isp_ctx_core_init(&isp_dev->ctx, pdev,
+			0, ctx_desc, pdev, smem_dev);
+
+	dev_info(&pdev->dev, "init isp_dev: %llx\n",
+		(unsigned long long)isp_dev );
+	/* init other device level members */
+	mtk_isp_dev_init(isp_dev, pdev, media_dev, v4l2_dev);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_core_init_ext);
+
+int mtk_isp_dev_core_release(
+	struct platform_device *pdev, struct mtk_isp_dev *isp_dev)
+{
+	mtk_isp_dev_mem2mem2_exit(isp_dev);
+	v4l2_ctrl_handler_free(&isp_dev->ctx.ctrl_handler);
+	mtk_isp_ctx_core_exit(&isp_dev->ctx);
+	mutex_destroy(&isp_dev->lock);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_dev_core_release);
+
+static struct platform_device *mtk_isp_dev_of_find_smem_dev(
+	struct platform_device *pdev)
+{
+	struct device_node *smem_dev_node = NULL;
+
+	if (!pdev) {
+		pr_err("Find_smem_dev failed, pdev can't be NULL\n");
+		return NULL;
+	}
+
+	smem_dev_node = of_parse_phandle(pdev->dev.of_node,
+		"smem_device", 0);
+
+	if (smem_dev_node == NULL) {
+		dev_err(&pdev->dev,
+			"failed to find isp smem device for (%s)\n",
+			pdev->name);
+		return NULL;
+	}
+
+	dev_dbg(&pdev->dev, "smem of node found, try to discovery device\n");
+	return of_find_device_by_node(smem_dev_node);
+}
+
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-dev.h b/drivers/media/platform/mtk-isp/common/mtk_isp-dev.h
new file mode 100644
index 000000000000..b20a6f8dc33f
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-dev.h
@@ -0,0 +1,194 @@
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_ISP-dev is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#ifndef __MTK_ISP_DEV_H__
+#define __MTK_ISP_DEV_H__
+
+#include <linux/platform_device.h>
+#include <linux/version.h>
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+#include "mtk_isp-ctx.h"
+
+/* Added the macro for early stage verification */
+/* based on kernel 4.4 environment. */
+/* I will remove the version check after getting */
+/* the devlopment platform based on 4.14 */
+#define MTK_ISP_KERNEL_BASE_VERSION KERNEL_VERSION(4, 14, 0)
+
+#define MTK_ISP_DEV_NODE_MAX			(MTK_ISP_CTX_QUEUES)
+
+
+#define MTK_ISP_INPUT_MIN_WIDTH		0U
+#define MTK_ISP_INPUT_MIN_HEIGHT		0U
+#define MTK_ISP_INPUT_MAX_WIDTH		480U
+#define MTK_ISP_INPUT_MAX_HEIGHT		640U
+#define MTK_ISP_OUTPUT_MIN_WIDTH		2U
+#define MTK_ISP_OUTPUT_MIN_HEIGHT		2U
+#define MTK_ISP_OUTPUT_MAX_WIDTH		480U
+#define MTK_ISP_OUTPUT_MAX_HEIGHT		640U
+
+
+#define file_to_mtk_isp_node(__file) \
+	container_of(video_devdata(__file),\
+	struct mtk_isp_dev_video_device, vdev)
+
+#define mtk_isp_ctx_to_dev(__ctx) \
+	container_of(__ctx,\
+	struct mtk_isp_dev, ctx)
+
+#define mtk_isp_m2m_to_dev(__m2m) \
+	container_of(__m2m,\
+	struct mtk_isp_dev, mem2mem2)
+
+#define mtk_isp_subdev_to_dev(__sd) \
+	container_of(__sd, \
+	struct mtk_isp_dev, mem2mem2.subdev)
+
+#define mtk_isp_vbq_to_isp_node(__vq) \
+	container_of(__vq, \
+	struct mtk_isp_dev_video_device, vbq)
+
+#define mtk_isp_ctx_buf_to_dev_buf(__ctx_buf) \
+	container_of(__ctx_buf, \
+	struct mtk_isp_dev_buffer, ctx_buf)
+
+#define mtk_isp_vb2_buf_to_dev_buf(__vb) \
+	container_of(vb, \
+	struct mtk_isp_dev_buffer, \
+	m2m2_buf.vbb.vb2_buf)
+
+#define mtk_isp_vb2_buf_to_m2m_buf(__vb) \
+	container_of(__vb, \
+	struct mtk_isp_mem2mem2_buffer, \
+	vbb.vb2_buf)
+
+#define mtk_isp_subdev_to_m2m(__sd) \
+	container_of(__sd, \
+	struct mtk_isp_mem2mem2_device, subdev)
+
+struct mtk_isp_mem2mem2_device;
+
+struct mtk_isp_mem2mem2_buffer {
+	struct vb2_v4l2_buffer vbb;
+	struct list_head list;
+};
+
+struct mtk_isp_dev_buffer {
+	struct mtk_isp_mem2mem2_buffer m2m2_buf;
+	/* Intenal part */
+	struct mtk_isp_ctx_buffer ctx_buf;
+};
+
+struct mtk_isp_dev_video_device {
+	const char *name;
+	bool output;
+	bool immutable;
+	bool enabled;
+	int queued;
+	struct v4l2_format vdev_fmt;
+	struct video_device vdev;
+	struct media_pad vdev_pad;
+	struct v4l2_mbus_framefmt pad_fmt;
+	struct vb2_queue vbq;
+	struct list_head buffers;
+	struct mutex lock;
+	atomic_t sequence;
+};
+
+struct mtk_isp_mem2mem2_device {
+	const char *name;
+	const char *model;
+	struct device *dev;
+	int num_nodes;
+	struct mtk_isp_dev_video_device *nodes;
+	const struct vb2_mem_ops *vb2_mem_ops;
+	unsigned int buf_struct_size;
+	bool streaming;
+	struct v4l2_ctrl_handler *ctrl_handler;
+	struct v4l2_device *v4l2_dev;
+	struct media_device *media_dev;
+	struct media_pipeline pipeline;
+	struct v4l2_subdev subdev;
+	struct media_pad *subdev_pads;
+	struct v4l2_file_operations v4l2_file_ops;
+	const struct file_operations fops;
+};
+
+struct mtk_isp_dev {
+	struct platform_device *pdev;
+	struct mtk_isp_dev_video_device mem2mem2_nodes[MTK_ISP_DEV_NODE_MAX];
+	bool queue_enabled[MTK_ISP_DEV_NODE_MAX];
+	struct mtk_isp_mem2mem2_device mem2mem2;
+	struct v4l2_device v4l2_dev;
+	struct media_device media_dev;
+	struct mtk_isp_ctx ctx;
+	struct mutex lock;
+	atomic_t qbuf_barrier;
+	struct {
+		struct v4l2_rect eff;
+		struct v4l2_rect bds;
+		struct v4l2_rect gdc;
+	} rect;
+	bool suspend_in_stream;
+	wait_queue_head_t buf_drain_wq;
+};
+
+extern int mtk_isp_media_register(struct device *dev,
+																  struct media_device *media_dev,
+																  const char *model);
+extern int mtk_isp_v4l2_register(struct device *dev,
+													struct media_device *media_dev,
+													struct v4l2_device *v4l2_dev,
+													struct v4l2_ctrl_handler *ctrl_handler);
+extern int mtk_isp_v4l2_unregister(struct mtk_isp_dev *dev);
+extern int mtk_isp_mem2mem2_v4l2_register(struct mtk_isp_dev *dev,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev);
+
+extern void mtk_isp_v4l2_buffer_done(struct vb2_buffer *vb,
+	enum vb2_buffer_state state);
+extern int mtk_isp_dev_queue_buffers
+	(struct mtk_isp_dev *dev, bool initial);
+extern int mtk_isp_dev_get_total_node
+	(struct mtk_isp_dev *mtk_isp_dev);
+extern char *mtk_isp_dev_get_node_name
+	(struct mtk_isp_dev *mtk_isp_dev_obj, int node);
+extern int mtk_isp_dev_init(struct mtk_isp_dev *isp_dev,
+										 struct platform_device *pdev,
+										 struct media_device *media_dev,
+										 struct v4l2_device *v4l2_dev);
+extern void mtk_isp_dev_mem2mem2_exit
+	(struct mtk_isp_dev *mtk_isp_dev_obj);
+int mtk_isp_dev_mem2mem2_init(struct mtk_isp_dev *isp_dev,
+															struct media_device *media_dev,
+															struct v4l2_device *v4l2_dev);
+extern int mtk_isp_dev_get_queue_id_of_dev_node(
+	struct mtk_isp_dev *mtk_isp_dev_obj,
+	struct mtk_isp_dev_video_device *node);
+extern int mtk_isp_dev_core_init(struct platform_device *pdev,
+	struct mtk_isp_dev *isp_dev,
+	struct mtk_isp_ctx_desc *ctx_desc);
+extern int mtk_isp_dev_core_init_ext(struct platform_device *pdev,
+																		 struct mtk_isp_dev *isp_dev,
+																		 struct mtk_isp_ctx_desc *ctx_desc,
+																		 struct media_device *media_dev,
+																		 struct v4l2_device *v4l2_dev);
+extern int mtk_isp_dev_core_release
+(struct platform_device *pdev, struct mtk_isp_dev *isp_dev);
+
+#endif /* __MTK_ISP_DEV_H__ */
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-smem-drv.c b/drivers/media/platform/mtk-isp/common/mtk_isp-smem-drv.c
new file mode 100644
index 000000000000..236bdfae2365
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-smem-drv.c
@@ -0,0 +1,805 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_fdt.h>
+#include <linux/of_platform.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/dma-contiguous.h>
+#include <linux/cma.h>
+#include <linux/memblock.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <asm/dma-contiguous.h>
+#include <linux/iommu.h>
+#include <linux/cma.h>
+
+
+#define MTK_ISP_SMEM_DEV_NAME			"MTK-ISP-SMEM"
+
+struct mtk_isp_smem_drv {
+	struct platform_device *pdev;
+	struct sg_table sgt;
+	struct page **smem_pages;
+	int num_smem_pages;
+	phys_addr_t smem_base;
+	dma_addr_t smem_dma_base;
+	int smem_size;
+};
+
+/* Recored the allocated CMA buffer */
+struct mtk_isp_smem_dma_buffer {
+	struct list_head list;
+	unsigned long size;
+	dma_addr_t dma;
+	void *virt;
+};
+
+static struct cma *mtk_isp_smem_cam_area;
+static struct reserved_mem *isp_reserved_smem;
+
+static int mtk_isp_smem_setup_dma_ops(struct device *smem_dev,
+	const struct dma_map_ops *smem_ops);
+
+/* Default dma_map_ops of iommu dones't support */
+/* CMA in Kernel 4.4 so I have to replace the following */
+/* ops to allocate continuous physical address for */
+/* ISP and coprossor's shared memory */
+
+/* We are still testing the driver with internal android */
+/* device and kernel 4.4. The MTK only codes */
+/* are wrapped by MTK_INTERNAL_PHONE_VERIFICATION and */
+/* will be removed after we migrate to kernel 4.14 and */
+/* chrome environment */
+#ifdef MTK_INTERNAL_PHONE_VERIFICATION
+static int mtk_isp_smem_mmap_attrs(struct device *dev,
+	struct vm_area_struct *vma,
+	void *cpu_addr, dma_addr_t dma_addr, size_t size,
+	struct dma_attrs *attrs);
+static void mtk_isp_smem_free_attrs(struct device *dev,
+	size_t size, void *cpu_addr,
+	dma_addr_t handle, struct dma_attrs *attrs);
+static void *mtk_isp_smem_alloc_attrs(struct device *dev,
+	size_t size, dma_addr_t *handle,
+	gfp_t gfp, struct dma_attrs *attrs);
+static ssize_t mtk_isp_smem_dma_write_test(struct device *smem_dev,
+	long size_kb);
+static int mtk_isp_smem_get_sgtable(struct device *dev,
+	struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, struct dma_attrs *attrs);
+static const struct dma_map_ops smem_dma_ops = {
+	.alloc = mtk_isp_smem_alloc_attrs,
+	.free = mtk_isp_smem_free_attrs,
+	.mmap = mtk_isp_smem_mmap_attrs,
+	.get_sgtable = mtk_isp_smem_get_sgtable,
+};
+#else
+static int mtk_isp_smem_get_sgtable(struct device *dev,
+	struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, unsigned long attrs);
+static const struct dma_map_ops smem_dma_ops = {
+	.get_sgtable = mtk_isp_smem_get_sgtable,
+};
+#endif /* MTK_INTERNAL_PHONE_VERIFICATION */
+
+static int mtk_isp_smem_init(
+	struct mtk_isp_smem_drv **mtk_isp_smem_drv_out,
+	struct platform_device *pdev)
+{
+	struct mtk_isp_smem_drv *isp_sys = NULL;
+	struct device *dev = &pdev->dev;
+
+	isp_sys = devm_kzalloc(dev,
+		sizeof(*isp_sys), GFP_KERNEL);
+
+	isp_sys->pdev = pdev;
+
+	*mtk_isp_smem_drv_out = isp_sys;
+
+	return 0;
+}
+
+static int mtk_isp_smem_drv_probe(struct platform_device *pdev)
+{
+	struct mtk_isp_smem_drv *smem_drv = NULL;
+	int r = 0;
+	struct device *dev = &pdev->dev;
+
+	dev_info(dev, "probe mtk_isp_smem_drv\n");
+
+	r = mtk_isp_smem_init(&smem_drv, pdev);
+
+	if (smem_drv == NULL)
+		return -ENOMEM;
+
+	/* Put the instance of the ISP system to the driver data */
+	dev_set_drvdata(dev, smem_drv);
+
+	if (mtk_isp_smem_cam_area) {
+		dev_dbg(dev, "register CAM with dev_set_cma_area\n");
+		dev_set_cma_area(dev, mtk_isp_smem_cam_area);
+		smem_drv->smem_base = cma_get_base(mtk_isp_smem_cam_area);
+		smem_drv->smem_size = cma_get_size(mtk_isp_smem_cam_area);
+	} else {
+		dev_dbg(dev, "No cma area initialized\n");
+		if (isp_reserved_smem) {
+			dma_addr_t dma_addr;
+			phys_addr_t addr;
+			struct iommu_domain *smem_dom;
+			int i = 0;
+			int size_align = 0;
+			struct page **pages = NULL;
+			int n_pages = 0;
+			struct sg_table *sgt = &smem_drv->sgt;
+
+			size_align = round_down(isp_reserved_smem->size,
+				PAGE_SIZE);
+			n_pages = size_align >> PAGE_SHIFT;
+
+			pages = kmalloc_array(n_pages, sizeof(struct page *),
+				GFP_KERNEL);
+			if (!pages)
+				return -ENOMEM;
+
+			for (i = 0; i < n_pages; i++)
+				pages[i] = phys_to_page(isp_reserved_smem->base
+					+ i * PAGE_SIZE);
+
+			r = sg_alloc_table_from_pages(sgt,
+				pages, n_pages,
+				0, size_align, GFP_KERNEL);
+
+			if (r) {
+				dev_err(dev, "failed to get alloca sg table\n");
+				return -ENOMEM;
+			}
+
+			dma_map_sg_attrs(dev, sgt->sgl, sgt->nents,
+					 DMA_BIDIRECTIONAL,
+					 DMA_ATTR_SKIP_CPU_SYNC);
+			dma_addr = sg_dma_address(sgt->sgl);
+			smem_dom =	iommu_get_domain_for_dev(dev);
+			addr = iommu_iova_to_phys(smem_dom, dma_addr);
+
+			if (addr != isp_reserved_smem->base)
+				dev_err(dev,
+				"incorrect pa(%llx) from iommu_iova_to_phys, should be %llx\n",
+				(unsigned long long)addr,
+				(unsigned long long)isp_reserved_smem->base);
+
+			r = dma_declare_coherent_memory(dev,
+				isp_reserved_smem->base,
+				dma_addr, size_align, DMA_MEMORY_EXCLUSIVE);
+
+			dev_dbg(dev,
+				"Coherent mem base(%llx,%llx),size(%lx),ret(%d)\n",
+				isp_reserved_smem->base,
+				dma_addr, size_align, r);
+
+			smem_drv->smem_base = isp_reserved_smem->base;
+			smem_drv->smem_size = size_align;
+			smem_drv->smem_pages = pages;
+			smem_drv->num_smem_pages = n_pages;
+			smem_drv->smem_dma_base = dma_addr;
+
+			dev_dbg(dev, "smem_drv setting (%llx,%lx,%llx,%d)\n",
+				smem_drv->smem_base, smem_drv->smem_size,
+				(unsigned long long)smem_drv->smem_pages,
+				smem_drv->num_smem_pages);
+
+		}
+	}
+
+
+	r = mtk_isp_smem_setup_dma_ops(dev, &smem_dma_ops);
+
+#ifdef MTK_INTERNAL_PHONE_VERIFICATION
+	if (mtk_isp_smem_dma_write_test(dev, 1) > 0)
+		dev_info(dev, "dma alloc self-test success\n");
+	else
+		dev_warn(dev, "dma alloc self-test failed\n");
+#endif
+
+	return r;
+
+}
+
+
+phys_addr_t mtk_isp_smem_iova_to_phys(struct device *dev,
+	dma_addr_t iova)
+{
+		struct iommu_domain *smem_dom;
+		phys_addr_t addr;
+		phys_addr_t limit;
+		struct mtk_isp_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+
+		if (smem_dev == NULL)
+			return 0;
+
+		smem_dom =	iommu_get_domain_for_dev(dev);
+
+		if (smem_dom == NULL)
+			return 0;
+
+		addr = iommu_iova_to_phys(smem_dom, iova);
+
+		limit = smem_dev->smem_base + smem_dev->smem_size;
+
+		if (addr < smem_dev->smem_base || addr >= limit) {
+			dev_err(dev,
+				"Unexpected smem paddr %pa (must >= %pa and <%pa)\n",
+				&addr, &smem_dev->smem_base, &limit);
+			return 0;
+		}
+		dev_dbg(dev, "Pa verifcation pass: %pa(>=%pa, <%pa\n",
+				&addr, &smem_dev->smem_base, &limit);
+		return addr;
+
+}
+
+static int mtk_isp_smem_drv_remove(struct platform_device *pdev)
+{
+	struct mtk_isp_smem_drv *smem_drv =
+		dev_get_drvdata(&pdev->dev);
+
+	kfree(smem_drv->smem_pages);
+	return 0;
+}
+
+static int mtk_isp_smem_drv_suspend(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_isp_smem_drv_resume(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_isp_smem_drv_dummy_cb(struct device *dev)
+{
+	return 0;
+}
+
+
+static const struct dev_pm_ops mtk_isp_smem_drv_pm_ops = {
+	SET_RUNTIME_PM_OPS(&mtk_isp_smem_drv_dummy_cb,
+		&mtk_isp_smem_drv_dummy_cb, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS
+		(&mtk_isp_smem_drv_suspend, &mtk_isp_smem_drv_resume)
+};
+
+static const struct of_device_id mtk_isp_smem_drv_of_match[] = {
+	{
+	 .compatible = "mediatek,isp_smem",
+	 },
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, mtk_isp_smem_drv_of_match);
+
+static struct platform_driver mtk_isp_smem_driver = {
+	.probe = mtk_isp_smem_drv_probe,
+	.remove = mtk_isp_smem_drv_remove,
+	.driver = {
+			.name = MTK_ISP_SMEM_DEV_NAME,
+			.of_match_table =
+				of_match_ptr(mtk_isp_smem_drv_of_match),
+			.pm = &mtk_isp_smem_drv_pm_ops,
+			},
+};
+
+#ifdef CONFIG_VIDEO_MEDIATEK_ISP_SMEM_CMA
+static int __init mtk_isp_smem_cma_setup(struct reserved_mem
+	*rmem)
+{
+	int err;
+	struct cma *cma;
+	phys_addr_t alignment;
+	phys_addr_t start;
+	phys_addr_t end;
+
+	phys_addr_t cma_size = 1024 * 1024 * 50;
+	int is_region_reserved = 0;
+
+	pr_debug("V4L2 reserved memory init base: %llx, size: %lld\n",
+			rmem->base, rmem->size);
+
+	/* I use dma_declare_contiguous and the memory blcok */
+	/* will be reserved by this function. */
+	is_region_reserved =
+		memblock_is_region_reserved(rmem->base, rmem->size);
+
+	if (is_region_reserved) {
+		pr_warn("The memblock is already reserved base(%llx), size(%llx)\n",
+			rmem->base, rmem->size);
+	}
+
+	/* Align for CMA allocator */
+	alignment = PAGE_SIZE << max(MAX_ORDER - 1, pageblock_order);
+	start = ALIGN(rmem->base, alignment);
+	cma_size = ALIGN(cma_size, alignment);
+	end = start + cma_size;
+
+	pr_debug("Reserve mem in DTS - [%pa - %pa]\n", &rmem->base, &end);
+	pr_debug("Aligned reserved mem pass to cma init - [%pa - %pa]\n",
+		&start, &end);
+
+	if (is_region_reserved) {
+		if (start < rmem->base) {
+			pr_warn("Reserve fail due to insufficient memory\n");
+			pr_warn("Reserve mem in DTS - [%pa - %pa]\n",
+				&rmem->base, &end);
+			pr_warn("Aligned reserved mem pass to cma init - [%pa - %pa]\n",
+			&start, &end);
+			return -ENOMEM;
+		}
+
+		/* If the memory region is alread reserved, */
+		/* try to init the CAM */
+
+#ifdef MTK_INTERNAL_PHONE_VERIFICATION
+		err = cma_init_reserved_mem(start,
+			cma_size, 0, &cma);
+#else /* MTK_INTERNAL_PHONE_VERIFICATION */
+		err = cma_init_reserved_mem(start,
+			cma_size, 0, rmem->name, &cma);
+#endif /*MTK_INTERNAL_PHONE_VERIFICATION*/
+
+
+		if (err) {
+			pr_warn("cma_init_reserved_mem failed ret: %d\n",  err);
+			return err;
+		}
+
+			dma_contiguous_early_fixup(start, cma_size);
+
+		if (rmem->size > 0) {
+			memblock_free(rmem->base, rmem->size);
+			memblock_add(rmem->base, rmem->size);
+		}
+
+	} else {
+		/* use dma_contiguous_reserve_area to reserve the region */
+		/* before init CMA */
+		pr_debug("Call dma_contiguous_reserve_area: start");
+		err = dma_contiguous_reserve_area(cma_size,
+			rmem->base, rmem->base + rmem->size,
+			&cma, true);
+		if (err) {
+			pr_err("dma_contiguous_reserve_area failed (%d)\n",
+				err);
+			return err;
+		}
+		pr_debug("Call dma_contiguous_reserve_area: pass");
+	}
+
+	mtk_isp_smem_cam_area = cma;
+	pr_debug("Reserved memory: private CMA for ISP v4l2 at %pa, size %ld MiB\n",
+		&rmem->base, (unsigned long)cma_size/SZ_1M);
+	return 0;
+}
+
+RESERVEDMEM_OF_DECLARE(isp_v4l2_smem,
+	"mediatek,reserve-memory-isp_smem",
+	mtk_isp_smem_cma_setup);
+
+#else /*#ifdef CONFIG_VIDEO_MEDIATEK_ISP_SMEM_CMA*/
+
+static int __init mtk_isp_smem_dma_setup(struct reserved_mem
+	*rmem)
+{
+	unsigned long node = rmem->fdt_node;
+
+	if (of_get_flat_dt_prop(node, "reusable", NULL))
+		return -EINVAL;
+
+	if (!of_get_flat_dt_prop(node, "no-map", NULL)) {
+		pr_err("Reserved memory: regions without no-map are not yet supported\n");
+		return -EINVAL;
+	}
+
+	isp_reserved_smem = rmem;
+
+	pr_debug("Reserved memory: created DMA memory pool at %pa, size %ld MiB\n",
+		&rmem->base, (unsigned long)rmem->size / SZ_1M);
+	return 0;
+
+}
+RESERVEDMEM_OF_DECLARE(isp_v4l2_smem,
+	"mediatek,reserve-memory-isp_smem",
+	mtk_isp_smem_dma_setup);
+
+#endif /*#ifdef CONFIG_VIDEO_MEDIATEK_ISP_SMEM_CMA*/
+
+int __init mtk_isp_smem_drv_init(void)
+{
+	int ret = 0;
+
+	pr_debug("platform_driver_register: mtk_isp_smem_driver\n");
+	ret = platform_driver_register(&mtk_isp_smem_driver);
+
+	if (ret)
+		pr_warn("isp smem drv init failed, driver didn't probe\n");
+
+	return ret;
+}
+subsys_initcall(mtk_isp_smem_drv_init);
+
+void __exit mtk_isp_smem_drv_ext(void)
+{
+	platform_driver_unregister(&mtk_isp_smem_driver);
+}
+module_exit(mtk_isp_smem_drv_ext);
+
+#ifdef MTK_INTERNAL_PHONE_VERIFICATION
+
+#include <linux/gfp.h>
+#include <linux/acpi.h>
+#include <linux/export.h>
+#include <linux/slab.h>
+#include <linux/genalloc.h>
+#include <linux/dma-mapping.h>
+#include <linux/dma-contiguous.h>
+#include <linux/vmalloc.h>
+#include <linux/swiotlb.h>
+#include <linux/dma-iommu.h>
+#include <linux/platform_device.h>
+#include <linux/amba/bus.h>
+#include <asm/cacheflush.h>
+#include "scp_helper.h"
+#include <mt_emi_api.h>
+
+
+void mtk_isp_smem_enable_mpu(struct device *dev)
+{
+	struct cma *smem_cma = NULL;
+	phys_addr_t cma_base;
+	phys_addr_t cma_limit;
+	struct emi_region_info_t region_info;
+
+	smem_cma = dev_get_cma_area(dev);
+
+	if (smem_cma == NULL) {
+		pr_err("set_isp_smem_mpu need CMA\n");
+		return;
+	}
+	cma_base = cma_get_base(smem_cma);
+	cma_limit = cma_base + cma_get_size(smem_cma);
+
+	region_info.start = cma_base;
+	region_info.end = cma_limit - 0x1;
+	/* For open MM development, we can use 28 or 29 */
+	region_info.region = 28;
+	SET_ACCESS_PERMISSION(region_info.apc, UNLOCK,
+		FORBIDDEN, FORBIDDEN, FORBIDDEN, FORBIDDEN,
+		FORBIDDEN, FORBIDDEN, FORBIDDEN, FORBIDDEN,
+		FORBIDDEN, FORBIDDEN, FORBIDDEN, NO_PROTECTION,
+		NO_PROTECTION, FORBIDDEN, FORBIDDEN, NO_PROTECTION);
+	emi_mpu_set_protection(&region_info);
+	dev_dbg(dev, "Start protect ISP SMEM Share region<%d:%08llx:%08llx>\n",
+			region_info.region, region_info.start, region_info.end);
+}
+
+static pgprot_t __get_dma_pgprot(struct dma_attrs *attrs, pgprot_t prot,
+				 bool coherent)
+{
+	if (!coherent || dma_get_attr(DMA_ATTR_WRITE_COMBINE, attrs))
+		return pgprot_writecombine(prot);
+	return prot;
+}
+
+static void *mtk_isp_smem_alloc_attrs(struct device *dev, size_t size,
+				 dma_addr_t *handle, gfp_t gfp,
+				 struct dma_attrs *attrs)
+{
+	bool coherent = is_device_dma_coherent(dev);
+	int ioprot = dma_direction_to_prot(DMA_BIDIRECTIONAL, coherent);
+	size_t iosize = size;
+	void *addr;
+
+	pr_debug(__func__ "alloc %zu\n", size);
+	if (WARN(!dev, "cannot create IOMMU mapping for unknown device\n"))
+		return NULL;
+
+
+	size = PAGE_ALIGN(size);
+
+	/*
+	 * Some drivers rely on this, and we probably don't want the
+	 * possibility of stale kernel data being read by devices anyway.
+	 */
+	gfp |= __GFP_ZERO;
+
+	if (!gfpflags_allow_blocking(gfp)) {
+		pr_err(__func__ "needs ___GFP_DIRECT_RECLAIM:%zu\n", size);
+	} else if (dev_get_cma_area(dev)) {
+		pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL, coherent);
+		struct page *page;
+
+		page = dma_alloc_from_contiguous(dev, size >> PAGE_SHIFT,
+						 get_order(size));
+		if (!page)
+			return NULL;
+
+		*handle = iommu_dma_map_page(dev, page, 0, iosize, ioprot);
+		if (iommu_dma_mapping_error(dev, *handle)) {
+			dma_release_from_contiguous(dev, page,
+				size >> PAGE_SHIFT);
+			return NULL;
+		}
+		if (!coherent) {
+			void *addr = page_address(page);
+
+			__dma_flush_range(addr, addr + iosize);
+			pr_debug("__dma_flush_area: %llx, %lld\n",
+				(unsigned long long)addr,
+				(unsigned long long)(addr + iosize));
+		}
+
+		addr = dma_common_contiguous_remap(page, size, VM_USERMAP,
+			prot, __builtin_return_address(0));
+		if (!addr) {
+			iommu_dma_unmap_page(dev,
+				*handle, iosize, 0, attrs);
+			dma_release_from_contiguous(dev,
+				page, size >> PAGE_SHIFT);
+		}
+	} else {
+		pr_err(__func__ "need a CMA for dma memory allocation\n");
+		return NULL;
+	}
+	return addr;
+}
+
+static void mtk_isp_smem_free_attrs(struct device *dev,
+	size_t size, void *cpu_addr,
+	dma_addr_t handle, struct dma_attrs *attrs)
+{
+	size_t iosize = size;
+
+	size = PAGE_ALIGN(size);
+
+	if (dev_get_cma_area(dev)) {
+		struct page *page = vmalloc_to_page(cpu_addr);
+
+		iommu_dma_unmap_page(dev, handle, iosize, 0, attrs);
+		dma_release_from_contiguous(dev, page, size >> PAGE_SHIFT);
+		dma_common_free_remap(cpu_addr, size, VM_USERMAP);
+	} else {
+		pr_err("mtk_isp_smem need a CMA for dma memory allocation\n");
+	}
+}
+
+static int __swiotlb_mmap_pfn(struct vm_area_struct *vma,
+						unsigned long pfn, size_t size)
+{
+	int ret = -ENXIO;
+	unsigned long nr_vma_pages = (vma->vm_end - vma->vm_start) >>
+					PAGE_SHIFT;
+	unsigned long nr_pages = PAGE_ALIGN(size) >> PAGE_SHIFT;
+	unsigned long off = vma->vm_pgoff;
+
+	if (off < nr_pages && nr_vma_pages <= (nr_pages - off)) {
+		ret = remap_pfn_range(vma,
+			vma->vm_start, pfn + off,
+			vma->vm_end - vma->vm_start,
+			vma->vm_page_prot);
+	}
+
+	return ret;
+}
+
+
+static int mtk_isp_smem_mmap_attrs(struct device *dev,
+	struct vm_area_struct *vma,
+	void *cpu_addr, dma_addr_t dma_addr, size_t size,
+	struct dma_attrs *attrs)
+{
+	int ret;
+
+	vma->vm_page_prot = __get_dma_pgprot(attrs,
+		vma->vm_page_prot,
+		is_device_dma_coherent(dev));
+
+	if (dma_mmap_from_coherent(dev, vma, cpu_addr, size, &ret))
+		return ret;
+
+	if (dev_get_cma_area(dev)) {
+		unsigned long pfn = vmalloc_to_pfn(cpu_addr);
+
+		return __swiotlb_mmap_pfn(vma, pfn, size);
+	}
+
+	pr_err("mtk_isp_smem need a CMA for dma memory allocation\n");
+	return -ENXIO;
+}
+
+
+static int mtk_isp_smem_get_sgtable(struct device *dev,
+	struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, struct dma_attrs *attrs)
+{
+	if (dev_get_cma_area(dev)) {
+		int ret = 0;
+		struct page *page = NULL;
+
+		page = vmalloc_to_page(cpu_addr);
+		ret = sg_alloc_table(sgt, 1, GFP_KERNEL);
+
+		if (!ret)
+			sg_set_page(sgt->sgl, page, PAGE_ALIGN(size), 0);
+
+		return ret;
+	}
+	pr_err("mtk_isp_smem need a CMA for dma memory allocation\n");
+	return -ENXIO;
+}
+
+static int mtk_isp_smem_setup_dma_ops(struct device *smem_dev,
+	const struct dma_map_ops *smem_ops)
+{
+	const struct dma_map_ops *default_ops = smem_dev->archdata.dma_ops;
+
+	if (!default_ops) {
+		pr_err("smem need the defulat iommu_ops to be set but it is NULL now\n");
+		return -EINVAL;
+	}
+
+	*smem_ops = *default_ops;
+
+	smem_ops->alloc = mtk_isp_smem_alloc_attrs;
+	smem_ops->free = mtk_isp_smem_free_attrs;
+	smem_ops->mmap = mtk_isp_smem_mmap_attrs;
+	smem_ops->get_sgtable = mtk_isp_smem_get_sgtable;
+
+	smem_dev->archdata.dma_ops = smem_ops;
+
+	return 0;
+}
+
+/* Self-test to check if the CMA allocation works */
+static ssize_t mtk_isp_smem_dma_write_test(struct device *smem_dev,
+	long size_kb)
+{
+	struct mtk_isp_smem_dma_buffer *alloc;
+
+	alloc = kmalloc(sizeof(*alloc), GFP_KERNEL);
+	if (!alloc)
+		return -ENOMEM;
+
+	alloc->size = size_kb;
+
+	if (alloc->size > (ULONG_MAX << PAGE_SHIFT))
+		return -EOVERFLOW;
+
+	alloc->size *= SZ_1K;
+	dev_info(smem_dev, "alloc by dma_alloc_coherent\n");
+	alloc->virt = dma_alloc_coherent(smem_dev, alloc->size,
+		&alloc->dma, GFP_KERNEL);
+
+	if (alloc->virt != NULL) {
+		dev_dbg(smem_dev,
+			"allocated at virtual address: 0x%p,DMA address: 0x%p size:%luKiB\n",
+			alloc->virt, (void *)alloc->dma, alloc->size / SZ_1K);
+
+		dma_free_coherent(smem_dev, alloc->size,
+				alloc->virt, alloc->dma);
+		dev_dbg(smem_dev,
+			"release at virtual address: 0x%p,DMA address: 0x%p size:%luKiB\n",
+			alloc->virt, (void *)alloc->dma, alloc->size / SZ_1K);
+		return size_kb;
+	}
+
+	dev_err(smem_dev, "dma_alloc_coherent failed: no va\n");
+	kfree(alloc);
+	return -ENOSPC;
+}
+#else
+
+static int mtk_isp_smem_get_sgtable(struct device *dev,
+	struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, unsigned long attrs)
+{
+	struct mtk_isp_smem_drv *smem_dev = dev_get_drvdata(dev);
+	int n_pages_align = 0;
+	int size_align = 0;
+	int page_start = 0;
+	unsigned long long offset_p = 0;
+	unsigned long long offset_d = 0;
+
+	phys_addr_t paddr = mtk_isp_smem_iova_to_phys(dev, dma_addr);
+
+	offset_d = (unsigned long long)dma_addr -
+		(unsigned long long)smem_dev->smem_dma_base;
+
+	offset_p = (unsigned long long)paddr -
+		(unsigned long long)smem_dev->smem_base;
+
+	dev_dbg(dev, "%s:dma_addr:%llx,cpu_addr:%llx,pa:%llx,size:%d\n",
+		__func__,
+		(unsigned long long)dma_addr,
+		(unsigned long long)cpu_addr,
+		(unsigned long long)paddr,
+		size
+		);
+
+	dev_dbg(dev, "%s:offset p:%llx,offset d:%llx\n",
+		__func__,
+		(unsigned long long)offset_p,
+		(unsigned long long)offset_d
+		);
+
+	size_align = round_up(size, PAGE_SIZE);
+	n_pages_align = size_align >> PAGE_SHIFT;
+	page_start = offset_p >> PAGE_SHIFT;
+
+	dev_dbg(dev,
+		"%s:page idx:%d,page pa:%llx,pa:%llx, aligned size:%d\n",
+		__func__,
+		page_start,
+		(unsigned long long)page_to_phys(*(smem_dev->smem_pages
+			+ page_start)),
+		(unsigned long long)paddr,
+		size_align
+		);
+
+	if (!smem_dev) {
+		dev_err(dev, "can't get sgtable from smem_dev\n");
+		return -EINVAL;
+	}
+
+	dev_dbg(dev, "get sgt of the smem: %d pages\n", n_pages_align);
+
+	return sg_alloc_table_from_pages(sgt,
+		smem_dev->smem_pages + page_start,
+		n_pages_align,
+		0, size_align, GFP_KERNEL);
+}
+
+static int mtk_isp_smem_setup_dma_ops(struct device *smem_dev,
+	const struct dma_map_ops *smem_ops)
+{
+	if (!smem_dev->dma_ops)
+		return -EINVAL;
+
+	memcpy((void *)smem_ops, smem_dev->dma_ops, sizeof(*smem_ops));
+
+	((struct dma_map_ops *)smem_ops)->get_sgtable
+		= mtk_isp_smem_get_sgtable;
+
+	smem_dev->dma_ops = smem_ops;
+
+	return 0;
+}
+
+void mtk_isp_smem_enable_mpu(struct device *smem_dev)
+{
+		pr_warn("MPU enabling func is not ready now\n");
+}
+#endif /* MTK_INTERNAL_PHONE_VERIFICATION */
+
+MODULE_AUTHOR("Frederic Chen <frederic.chen@mediatek.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Mediatek ISP V4L2 shared memory driver");
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-smem.h b/drivers/media/platform/mtk-isp/common/mtk_isp-smem.h
new file mode 100644
index 000000000000..5527d7345647
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-smem.h
@@ -0,0 +1,24 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_ISP_SMEM_H__
+#define __MTK_ISP_SMEM_H__
+
+#include <linux/dma-mapping.h>
+
+extern phys_addr_t mtk_isp_smem_iova_to_phys(struct device *smem_dev,
+	dma_addr_t iova);
+extern void mtk_isp_smem_enable_mpu(struct device *smem_dev);
+#endif /*__MTK_ISP_SMEM_H__*/
+
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.c b/drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.c
new file mode 100644
index 000000000000..736b3732c5a8
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.c
@@ -0,0 +1,1632 @@
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_ISP-v4l2 is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/pm_runtime.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf2-dma-contig.h>
+#include <media/v4l2-subdev.h>
+#include <media/v4l2-event.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+
+#include "mtk_isp-dev.h"
+#include "mtk_isp-v4l2.h"
+
+#define ISP_SIZES 7
+
+/* Sizes must be in increasing order */
+static const struct v4l2_frmsize_discrete isp_sizes[ISP_SIZES] = {
+	{  320, 240 },
+	{  640, 480 },
+	{ 1280, 720 },
+	{ 1280, 960 },
+	{ 1600, 1200 },
+	{ 1920, 1080 },
+	{ 2592, 1944 },
+};
+
+static long mtk_isp_v4l2_compat_ioctl32(struct file *file,
+		unsigned int cmd, unsigned long arg);
+
+static u32 mtk_isp_node_get_v4l2_cap
+	(struct mtk_isp_ctx_queue *node_ctx);
+
+static int mtk_isp_videoc_s_meta_fmt(struct file *file,
+	 void *fh, struct v4l2_format *f);
+
+
+static int mtk_isp_subdev_open(struct v4l2_subdev *sd,
+	struct v4l2_subdev_fh *fh)
+{
+	struct mtk_isp_dev *isp_dev = mtk_isp_subdev_to_dev(sd);
+
+	isp_dev->ctx.fh = fh;
+
+	return mtk_isp_ctx_open(&isp_dev->ctx);
+}
+
+static int mtk_isp_subdev_close(struct v4l2_subdev *sd,
+	struct v4l2_subdev_fh *fh)
+{
+	struct mtk_isp_dev *isp_dev = mtk_isp_subdev_to_dev(sd);
+
+	return mtk_isp_ctx_release(&isp_dev->ctx);
+}
+
+static int mtk_isp_subdev_s_stream(struct v4l2_subdev *sd,
+	int enable)
+{
+	int ret = 0;
+
+	struct mtk_isp_dev *isp_dev = mtk_isp_subdev_to_dev(sd);
+
+	if (enable) {
+		ret = mtk_isp_ctx_streamon(&isp_dev->ctx);
+
+		if (!ret)
+			ret = mtk_isp_dev_queue_buffers(
+				mtk_isp_ctx_to_dev(&isp_dev->ctx), true);
+		if (ret)
+			pr_err("failed to queue initial buffers (%d)", ret);
+	}	else {
+		ret = mtk_isp_ctx_streamoff(&isp_dev->ctx);
+	}
+
+	if (!ret)
+		isp_dev->mem2mem2.streaming = enable;
+
+	return ret;
+}
+
+static void v4l2_event_merge(const struct v4l2_event *old,
+				struct v4l2_event *new)
+{
+	struct mtk_isp_dev_stat_event_data *old_evt_stat_data
+		= (void *)old->u.data;
+	struct mtk_isp_dev_stat_event_data *new_evt_stat_data
+		= (void *)new->u.data;
+
+	if (old->type == V4L2_EVENT_MTK_ISP_ENGINE_STATE &&
+			new->type == V4L2_EVENT_MTK_ISP_ENGINE_STATE) {
+		pr_debug("%s, merge IRQ, old(type(0x%x) frame no(%d) IRQ(0x%x) DMA(0x%x)), new(type(0x%x) frame_number(%d) IRQ(0x%x) DMA(0x%x))",
+			__func__,
+			old->type,
+			old_evt_stat_data->frame_number,
+			old_evt_stat_data->irq_status_mask,
+			old_evt_stat_data->dma_status_mask,
+			new->type,
+			new_evt_stat_data->frame_number,
+			new_evt_stat_data->irq_status_mask,
+			new_evt_stat_data->dma_status_mask);
+
+		/* merge IRQ event */
+		new_evt_stat_data->irq_status_mask |=
+			old_evt_stat_data->irq_status_mask;
+		new_evt_stat_data->dma_status_mask |=
+			old_evt_stat_data->dma_status_mask;
+	}
+}
+
+static void v4l2_event_replace(struct v4l2_event *old,
+				const struct v4l2_event *new)
+{
+	struct mtk_isp_dev_stat_event_data *old_evt_stat_data
+		= (void *)old->u.data;
+	struct mtk_isp_dev_stat_event_data *new_evt_stat_data
+		= (void *)new->u.data;
+
+	pr_debug("%s, old(frame no(%d) IRQ(0x%x) DMA(0x%x)), new(frame_number(%d) IRQ(0x%x) DMA(0x%x))",
+		__func__,
+		old_evt_stat_data->frame_number,
+		old_evt_stat_data->irq_status_mask,
+		old_evt_stat_data->dma_status_mask,
+		new_evt_stat_data->frame_number,
+		new_evt_stat_data->irq_status_mask,
+		new_evt_stat_data->dma_status_mask);
+
+	old_evt_stat_data->frame_number = new_evt_stat_data->frame_number;
+	old_evt_stat_data->irq_status_mask = new_evt_stat_data->irq_status_mask;
+	old_evt_stat_data->dma_status_mask = new_evt_stat_data->dma_status_mask;
+}
+
+static const struct v4l2_subscribed_event_ops v4l2_event_ops = {
+	.merge = v4l2_event_merge,
+	.replace = v4l2_event_replace,
+};
+
+int mtk_isp_subdev_subscribe_event(struct v4l2_subdev *subdev,
+					struct v4l2_fh *fh,
+					struct v4l2_event_subscription *sub)
+{
+	pr_info("sub type(%x)", sub->type);
+	if (sub->type != V4L2_EVENT_PRIVATE_START &&
+			sub->type != V4L2_EVENT_MTK_ISP_ENGINE_STATE &&
+			sub->type != V4L2_EVENT_MTK_ISP_FRAME_DONE)
+		return -EINVAL;
+	/* currently we use the default depth of event queue */
+	if (sub->type == V4L2_EVENT_MTK_ISP_ENGINE_STATE)
+		return v4l2_event_subscribe(fh, sub, 2, &v4l2_event_ops);
+
+	return v4l2_event_subscribe(fh, sub, 0, NULL);
+}
+
+int mtk_isp_subdev_unsubscribe_event(struct v4l2_subdev *subdev,
+	struct v4l2_fh *fh,
+	struct v4l2_event_subscription *sub)
+{
+	return v4l2_event_unsubscribe(fh, sub);
+}
+
+static int mtk_isp_link_setup(struct media_entity *entity,
+	const struct media_pad *local,
+	const struct media_pad *remote, u32 flags)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 =
+			container_of(entity,
+			struct mtk_isp_mem2mem2_device, subdev.entity);
+	struct mtk_isp_dev *isp_dev =
+		container_of(m2m2, struct mtk_isp_dev, mem2mem2);
+
+	u32 pad = local->index;
+
+	pr_info("link setup: %d --> %d\n", pad, remote->index);
+
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	WARN_ON(entity->type != MEDIA_ENT_T_V4L2_SUBDEV);
+#else
+	WARN_ON(entity->obj_type != MEDIA_ENTITY_TYPE_V4L2_SUBDEV);
+#endif
+
+	WARN_ON(pad >= m2m2->num_nodes);
+
+	m2m2->nodes[pad].enabled = !!(flags & MEDIA_LNK_FL_ENABLED);
+
+	/* queue_enable can be phase out in the future since */
+	/* we don't have internal queue of each node in */
+	/* v4l2 common module */
+	isp_dev->queue_enabled[pad] = m2m2->nodes[pad].enabled;
+
+	return 0;
+}
+
+static void mtk_isp_vb2_buf_queue(struct vb2_buffer *vb)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = vb2_get_drv_priv(vb->vb2_queue);
+
+	struct mtk_isp_dev *mtk_isp_dev = mtk_isp_m2m_to_dev(m2m2);
+
+	struct device *dev = &(mtk_isp_dev->pdev->dev);
+
+	struct mtk_isp_dev_buffer *buf = NULL;
+
+	struct vb2_v4l2_buffer *v4l2_buf = NULL;
+
+	struct mtk_isp_dev_video_device *node =
+		mtk_isp_vbq_to_isp_node(vb->vb2_queue);
+
+	int queue = mtk_isp_dev_get_queue_id_of_dev_node(mtk_isp_dev, node);
+
+	dev_dbg(dev,
+		"queue vb2_buf: Node(%s) queue id(%d)\n",
+		node->name,
+		queue);
+
+	if (queue < 0) {
+		dev_err(m2m2->dev, "Invalid mtk_isp_dev node.\n");
+		return;
+	}
+
+	if (mtk_isp_dev->ctx.mode == MTK_ISP_CTX_MODE_DEBUG_BYPASS_ALL) {
+		dev_dbg(m2m2->dev, "By pass mode, just loop back the buffer\n");
+		vb2_buffer_done(vb, VB2_BUF_STATE_DONE);
+		return;
+	}
+
+	if (vb == NULL)
+		pr_err("VB can't be null\n");
+
+	buf = mtk_isp_vb2_buf_to_dev_buf(vb);
+
+	if (buf == NULL)
+		pr_err("buf can't be null\n");
+
+	v4l2_buf = to_vb2_v4l2_buffer(vb);
+
+	if (v4l2_buf == NULL)
+		pr_err("v4l2_buf can't be null\n");
+
+	mutex_lock(&mtk_isp_dev->lock);
+
+	pr_err("init  mtk_isp_ctx_buf, sequence(%d)\n", v4l2_buf->sequence);
+
+	/* the dma address will be filled in later frame buffer handling*/
+	mtk_isp_ctx_buf_init(&buf->ctx_buf, queue, (dma_addr_t)0);
+	pr_info("set mtk_isp_ctx_buf_init: user seq=%d\n",
+		buf->ctx_buf.user_sequence);
+
+	/* Added the buffer into the tracking list */
+	list_add_tail(&buf->m2m2_buf.list,
+			&m2m2->nodes[node - m2m2->nodes].buffers);
+	mutex_unlock(&mtk_isp_dev->lock);
+
+	/* Enqueue the buffer */
+	if (mtk_isp_dev->mem2mem2.streaming) {
+		pr_info("%s: mtk_isp_dev_queue_buffers\n",
+		node->name);
+		mtk_isp_dev_queue_buffers(mtk_isp_dev, false);
+	}
+
+}
+
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+static int mtk_isp_vb2_queue_setup(struct vb2_queue *vq,
+				const void *parg,
+				unsigned int *num_buffers,
+				unsigned int *num_planes,
+				unsigned int sizes[], void *alloc_ctxs[])
+#else
+static int mtk_isp_vb2_queue_setup(struct vb2_queue *vq,
+				unsigned int *num_buffers,
+				unsigned int *num_planes,
+				unsigned int sizes[],
+				struct device *alloc_devs[])
+#endif
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_isp_dev_video_device *node =
+		mtk_isp_vbq_to_isp_node(vq);
+	struct mtk_isp_dev *isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	void *buf_alloc_ctx = NULL;
+
+	/* Get V4L2 format with the following method */
+	const struct v4l2_format *fmt = &node->vdev_fmt;
+
+	*num_planes = 1;
+	*num_buffers = clamp_val(*num_buffers, 1, VB2_MAX_FRAME);
+
+	if (vq->type == V4L2_BUF_TYPE_META_CAPTURE ||
+			vq->type == V4L2_BUF_TYPE_META_OUTPUT) {
+		sizes[0] = fmt->fmt.meta.buffersize;
+		buf_alloc_ctx = isp_dev->ctx.smem_vb2_alloc_ctx;
+		pr_info("Select smem_vb2_alloc_ctx(%llx)\n",
+			(unsigned long long) buf_alloc_ctx);
+	} else {
+		sizes[0] = fmt->fmt.pix_mp.plane_fmt[0].sizeimage;
+		buf_alloc_ctx = isp_dev->ctx.img_vb2_alloc_ctx;
+		pr_info("Select img_vb2_alloc_ctx(%llx)\n",
+			(unsigned long long) buf_alloc_ctx);
+	}
+
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	alloc_ctxs[0] = buf_alloc_ctx;
+#else
+	alloc_devs[0] = (struct device *)buf_alloc_ctx;
+#endif
+
+	pr_info("mtk_isp_vb2_queue_setup:type(%d),size(%d),ctx(%llx)\n",
+		vq->type, sizes[0], (unsigned long long)buf_alloc_ctx);
+
+	/* Initialize buffer queue */
+	INIT_LIST_HEAD(&node->buffers);
+
+	return 0;
+}
+
+static bool
+	mtk_isp_all_nodes_streaming(struct mtk_isp_mem2mem2_device *m2m2,
+	struct mtk_isp_dev_video_device *except)
+{
+	int i;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		struct mtk_isp_dev_video_device *node = &m2m2->nodes[i];
+
+		if (node == except)
+			continue;
+		if (node->enabled && !vb2_start_streaming_called(&node->vbq))
+			return false;
+	}
+
+	return true;
+}
+
+static void mtk_isp_return_all_buffers(struct mtk_isp_mem2mem2_device *m2m2,
+					struct mtk_isp_dev_video_device *node,
+					enum vb2_buffer_state state)
+{
+	struct mtk_isp_dev *mtk_isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	struct mtk_isp_mem2mem2_buffer *b, *b0;
+
+	/* Return all buffers */
+	mutex_lock(&mtk_isp_dev->lock);
+	list_for_each_entry_safe(b, b0, &node->buffers, list) {
+		list_del(&b->list);
+		vb2_buffer_done(&b->vbb.vb2_buf, state);
+	}
+	mutex_unlock(&mtk_isp_dev->lock);
+}
+
+static int mtk_isp_vb2_start_streaming(struct vb2_queue *vq, unsigned int count)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_isp_dev_video_device *node =
+		mtk_isp_vbq_to_isp_node(vq);
+	int r;
+
+	if (m2m2->streaming) {
+		r = -EBUSY;
+		goto fail_return_bufs;
+	}
+
+	if (!node->enabled) {
+		pr_err("Node (%ld) is not enable\n", node - m2m2->nodes);
+		r = -EINVAL;
+		goto fail_return_bufs;
+	}
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	r = media_entity_pipeline_start(&node->vdev.entity, &m2m2->pipeline);
+#else
+	r = media_pipeline_start(&node->vdev.entity, &m2m2->pipeline);
+#endif
+	if (r < 0) {
+		pr_err("Node (%ld) media_pipeline_start failed\n",
+			node - m2m2->nodes);
+		goto fail_return_bufs;
+	}
+
+	if (!mtk_isp_all_nodes_streaming(m2m2, node))
+		return 0;
+
+	/* Start streaming of the whole pipeline now */
+
+	r = v4l2_subdev_call(&m2m2->subdev, video, s_stream, 1);
+	if (r < 0) {
+		pr_err("Node (%ld) v4l2_subdev_call s_stream failed\n",
+			node - m2m2->nodes);
+		goto fail_stop_pipeline;
+	}
+	return 0;
+
+fail_stop_pipeline:
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	media_entity_pipeline_stop(&node->vdev.entity);
+#else
+	media_pipeline_stop(&node->vdev.entity);
+#endif
+fail_return_bufs:
+	mtk_isp_return_all_buffers(m2m2, node, VB2_BUF_STATE_QUEUED);
+
+	return r;
+}
+
+static void mtk_isp_vb2_stop_streaming(struct vb2_queue *vq)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_isp_dev_video_device *node =
+		mtk_isp_vbq_to_isp_node(vq);
+	int r;
+
+	WARN_ON(!node->enabled);
+
+	/* Was this the first node with streaming disabled? */
+	if (mtk_isp_all_nodes_streaming(m2m2, node)) {
+		/* Yes, really stop streaming now */
+		r = v4l2_subdev_call(&m2m2->subdev, video, s_stream, 0);
+		if (r)
+			dev_err(m2m2->dev, "failed to stop streaming\n");
+	}
+
+	mtk_isp_return_all_buffers(m2m2, node, VB2_BUF_STATE_ERROR);
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	media_entity_pipeline_stop(&node->vdev.entity);
+#else
+	media_pipeline_stop(&node->vdev.entity);
+#endif
+}
+
+static int mtk_isp_videoc_querycap(struct file *file, void *fh,
+					struct v4l2_capability *cap)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+	struct mtk_isp_dev *isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	int queue_id =
+		mtk_isp_dev_get_queue_id_of_dev_node(isp_dev, node);
+	struct mtk_isp_ctx_queue *node_ctx = &isp_dev->ctx.queue[queue_id];
+
+	strlcpy(cap->driver, m2m2->name, sizeof(cap->driver));
+	strlcpy(cap->card, m2m2->model, sizeof(cap->card));
+	snprintf(cap->bus_info, sizeof(cap->bus_info), "platform:%s", node->name);
+
+	cap->device_caps =
+		mtk_isp_node_get_v4l2_cap(node_ctx) | V4L2_CAP_STREAMING;
+	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
+
+	return 0;
+}
+
+/* Propagate forward always the format from the CIO2 subdev */
+static int mtk_isp_videoc_g_fmt(struct file *file, void *fh,
+						 struct v4l2_format *f)
+{
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+static int mtk_isp_videoc_try_fmt(struct file *file,
+	 void *fh,
+	 struct v4l2_format *f)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_isp_dev *isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	struct mtk_isp_ctx *dev_ctx = &isp_dev->ctx;
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+	int queue_id =
+		mtk_isp_dev_get_queue_id_of_dev_node(isp_dev, node);
+	int ret = 0;
+
+	ret = mtk_isp_ctx_fmt_set_img(dev_ctx, queue_id,
+		&f->fmt.pix_mp,
+		&node->vdev_fmt.fmt.pix_mp);
+
+	/* Simply set the format to the node context in the initial version */
+	if (ret) {
+		pr_warn("Fmt(%d) not support for queue(%d), will load default fmt\n",
+			f->fmt.pix_mp.pixelformat, queue_id);
+
+		ret =	mtk_isp_ctx_format_load_default_fmt
+			(&dev_ctx->queue[queue_id], f);
+	}
+
+	if (!ret) {
+		node->vdev_fmt.fmt.pix_mp = f->fmt.pix_mp;
+		dev_ctx->queue[queue_id].fmt.pix_mp = node->vdev_fmt.fmt.pix_mp;
+	}
+
+	return ret;
+}
+
+static int mtk_isp_videoc_s_fmt(struct file *file, void *fh,
+						 struct v4l2_format *f)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_isp_dev *isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	struct mtk_isp_ctx *dev_ctx = &isp_dev->ctx;
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+	int queue_id = mtk_isp_dev_get_queue_id_of_dev_node(isp_dev, node);
+	int ret = 0;
+
+	ret = mtk_isp_ctx_fmt_set_img(dev_ctx, queue_id,
+		&f->fmt.pix_mp,
+		&node->vdev_fmt.fmt.pix_mp);
+
+	/* Simply set the format to the node context in the initial version */
+	if (!ret)
+		dev_ctx->queue[queue_id].fmt.pix_mp = node->vdev_fmt.fmt.pix_mp;
+	else
+		dev_warn(&isp_dev->pdev->dev,
+		"s_fmt, format not support\n");
+
+	return ret;
+}
+
+static int mtk_isp_enum_framesizes(struct file *filp, void *priv,
+		struct v4l2_frmsizeenum *sizes)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = video_drvdata(filp);
+	struct mtk_isp_dev *isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	int i;
+
+	dev_info(&isp_dev->pdev->dev, "%s", __func__);
+
+	if (sizes->index >= ARRAY_SIZE(isp_sizes))
+		return -EINVAL;
+
+	for (i = 0; i < ARRAY_SIZE(isp_sizes); i++) {
+		/* TODO: support pixel format judge */
+		dev_info(&isp_dev->pdev->dev,
+			"enum_framesizes, i(%d), sizes->index(%d)",
+			i, sizes->index);
+
+		if (sizes->index == i) {
+			sizes->type = V4L2_FRMSIZE_TYPE_DISCRETE;
+			sizes->discrete.width =
+				isp_sizes[i].width;
+			sizes->discrete.height =
+				isp_sizes[i].height;
+			return 0;
+		}
+	}
+
+	return 0;
+}
+
+static int mtk_isp_meta_enum_format(struct file *file,
+	 void *fh, struct v4l2_fmtdesc *f)
+{
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+
+	if (f->index > 0 || f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->pixelformat = node->vdev_fmt.fmt.meta.dataformat;
+
+	return 0;
+}
+
+static int mtk_isp_videoc_s_meta_fmt(struct file *file,
+	 void *fh, struct v4l2_format *f)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_isp_dev *isp_dev = mtk_isp_m2m_to_dev(m2m2);
+	struct mtk_isp_ctx *dev_ctx = &isp_dev->ctx;
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+	int queue_id = mtk_isp_dev_get_queue_id_of_dev_node(isp_dev, node);
+
+	int ret = 0;
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	ret = mtk_isp_ctx_format_load_default_fmt(&dev_ctx->queue[queue_id], f);
+
+	if (!ret) {
+		node->vdev_fmt.fmt.meta = f->fmt.meta;
+		dev_ctx->queue[queue_id].fmt.meta = node->vdev_fmt.fmt.meta;
+	} else {
+		dev_warn(&isp_dev->pdev->dev,
+		"s_meta_fm failed, format not support\n");
+	}
+
+	return ret;
+}
+
+static int mtk_isp_videoc_g_meta_fmt(struct file *file,
+	 void *fh, struct v4l2_format *f)
+{
+	struct mtk_isp_dev_video_device *node = file_to_mtk_isp_node(file);
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+int mtk_isp_videoc_qbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct video_device *vdev = video_devdata(file);
+	struct vb2_buffer *vb;
+	struct mtk_isp_dev_buffer *db;
+	int r = 0;
+
+	/* check if vb2 queue is busy */
+	if (vdev->queue->owner
+			&& vdev->queue->owner != file->private_data)
+		return -EBUSY;
+
+	/* Keep the value of sequence in v4l2_buffer */
+	/* in ctx buf since vb2_qbuf will set it to 0 */
+	vb = vdev->queue->bufs[p->index];
+
+	if (vb) {
+		db = mtk_isp_vb2_buf_to_dev_buf(vb);
+		pr_info("qbuf: p:%llx,vb:%llx, db:%llx\n",
+			(unsigned long long)p,
+			(unsigned long long)vb,
+			(unsigned long long)db);
+		db->ctx_buf.user_sequence = p->sequence;
+	}
+
+	r = vb2_qbuf(vdev->queue, vdev->v4l2_dev->mdev, p);
+
+	if (r)
+		pr_err("vb2_qbuf failed(err=%d): buf idx(%d)\n",
+		r, p->index);
+
+	return r;
+
+}
+EXPORT_SYMBOL_GPL(mtk_isp_videoc_qbuf);
+
+/******************** function pointers ********************/
+
+/* subdev internal operations */
+static const struct v4l2_subdev_internal_ops mtk_isp_subdev_internal_ops = {
+	.open = mtk_isp_subdev_open,
+	.close = mtk_isp_subdev_close,
+};
+
+static const struct v4l2_subdev_core_ops mtk_isp_subdev_core_ops = {
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	.g_ext_ctrls = v4l2_subdev_g_ext_ctrls,
+	.try_ext_ctrls = v4l2_subdev_try_ext_ctrls,
+	.s_ext_ctrls = v4l2_subdev_s_ext_ctrls,
+	.g_ctrl = v4l2_subdev_g_ctrl,
+	.s_ctrl = v4l2_subdev_s_ctrl,
+	.queryctrl = v4l2_subdev_queryctrl,
+	.querymenu = v4l2_subdev_querymenu,
+#endif
+	.subscribe_event = mtk_isp_subdev_subscribe_event,
+	.unsubscribe_event = mtk_isp_subdev_unsubscribe_event,
+};
+
+static const struct v4l2_subdev_video_ops mtk_isp_subdev_video_ops = {
+	.s_stream = mtk_isp_subdev_s_stream,
+};
+
+static const struct v4l2_subdev_ops mtk_isp_subdev_ops = {
+	.core = &mtk_isp_subdev_core_ops,
+	.video = &mtk_isp_subdev_video_ops,
+};
+
+static const struct media_entity_operations mtk_isp_media_ops = {
+	.link_setup = mtk_isp_link_setup,
+	.link_validate = v4l2_subdev_link_validate,
+};
+
+static const struct vb2_ops mtk_isp_vb2_ops = {
+	.buf_queue = mtk_isp_vb2_buf_queue,
+	.queue_setup = mtk_isp_vb2_queue_setup,
+	.start_streaming = mtk_isp_vb2_start_streaming,
+	.stop_streaming = mtk_isp_vb2_stop_streaming,
+	.wait_prepare = vb2_ops_wait_prepare,
+	.wait_finish = vb2_ops_wait_finish,
+};
+
+static const struct v4l2_file_operations mtk_isp_v4l2_fops = {
+	.unlocked_ioctl = video_ioctl2,
+	.open = v4l2_fh_open,
+	.release = vb2_fop_release,
+	.poll = vb2_fop_poll,
+	.mmap = vb2_fop_mmap,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl32 = v4l2_compat_ioctl32,
+#endif
+};
+
+static const struct v4l2_ioctl_ops mtk_isp_v4l2_ioctl_ops = {
+	.vidioc_querycap = mtk_isp_videoc_querycap,
+	.vidioc_enum_framesizes = mtk_isp_enum_framesizes,
+
+	.vidioc_g_fmt_vid_cap_mplane = mtk_isp_videoc_g_fmt,
+	.vidioc_s_fmt_vid_cap_mplane = mtk_isp_videoc_s_fmt,
+	.vidioc_try_fmt_vid_cap_mplane = mtk_isp_videoc_try_fmt,
+
+	.vidioc_g_fmt_vid_out_mplane = mtk_isp_videoc_g_fmt,
+	.vidioc_s_fmt_vid_out_mplane = mtk_isp_videoc_s_fmt,
+	.vidioc_try_fmt_vid_out_mplane = mtk_isp_videoc_try_fmt,
+
+	/* buffer queue management */
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = mtk_isp_videoc_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static const struct v4l2_ioctl_ops mtk_isp_v4l2_meta_ioctl_ops = {
+	.vidioc_querycap = mtk_isp_videoc_querycap,
+
+	.vidioc_enum_fmt_meta_cap = mtk_isp_meta_enum_format,
+	.vidioc_g_fmt_meta_cap = mtk_isp_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_cap = mtk_isp_videoc_s_meta_fmt,
+	.vidioc_try_fmt_meta_cap = mtk_isp_videoc_g_meta_fmt,
+
+	.vidioc_enum_fmt_meta_out = mtk_isp_meta_enum_format,
+	.vidioc_g_fmt_meta_out = mtk_isp_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_out = mtk_isp_videoc_s_meta_fmt,
+	.vidioc_try_fmt_meta_out = mtk_isp_videoc_g_meta_fmt,
+
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = mtk_isp_videoc_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static u32 mtk_isp_node_get_v4l2_cap(struct mtk_isp_ctx_queue *node_ctx)
+{
+	u32 cap = 0;
+
+	if (node_ctx->desc.capture)
+		if (node_ctx->desc.image)
+			cap = V4L2_CAP_VIDEO_CAPTURE_MPLANE;
+		else
+			cap = V4L2_CAP_META_CAPTURE;
+	else
+		if (node_ctx->desc.image)
+			cap = V4L2_CAP_VIDEO_OUTPUT_MPLANE;
+		else
+			cap = V4L2_CAP_META_OUTPUT;
+
+	return cap;
+}
+
+static u32 mtk_isp_node_get_format_type(struct mtk_isp_ctx_queue *node_ctx)
+{
+	u32 type;
+
+	if (node_ctx->desc.capture)
+		if (node_ctx->desc.image)
+			type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+		else
+			type = V4L2_BUF_TYPE_META_CAPTURE;
+	else
+		if (node_ctx->desc.image)
+			type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+		else
+			type = V4L2_BUF_TYPE_META_OUTPUT;
+
+	return type;
+}
+
+
+static const struct v4l2_ioctl_ops *mtk_isp_node_get_ioctl_ops
+	(struct mtk_isp_ctx_queue *node_ctx)
+{
+	const struct v4l2_ioctl_ops *ops = NULL;
+
+	if (node_ctx->desc.image)
+		ops = &mtk_isp_v4l2_ioctl_ops;
+	else
+		ops = &mtk_isp_v4l2_meta_ioctl_ops;
+	return ops;
+}
+
+/* Config node's video properties */
+/* according to the device context requirement */
+static void mtk_isp_node_to_v4l2(struct mtk_isp_dev *isp_dev, u32 node,
+struct video_device *vdev, struct v4l2_format *f)
+{
+	u32 cap;
+	struct mtk_isp_ctx *device_ctx = &isp_dev->ctx;
+	struct mtk_isp_ctx_queue *node_ctx = &device_ctx->queue[node];
+
+	WARN_ON(node >= mtk_isp_dev_get_total_node(isp_dev));
+	WARN_ON(node_ctx == NULL);
+
+	/* set cap of the node */
+	cap = mtk_isp_node_get_v4l2_cap(node_ctx);
+	f->type = mtk_isp_node_get_format_type(node_ctx);
+	vdev->ioctl_ops = mtk_isp_node_get_ioctl_ops(node_ctx);
+
+	if (mtk_isp_ctx_format_load_default_fmt(&device_ctx->queue[node], f)) {
+		dev_err(&isp_dev->pdev->dev,
+		"Can't load default for node (%d): (%s)",
+		node, device_ctx->queue[node].desc.name);
+	}	else {
+		if (device_ctx->queue[node].desc.image) {
+			dev_dbg(&isp_dev->pdev->dev,
+			"Node (%d): (%s), dfmt (f:0x%x w:%d: h:%d s:%d)\n",
+			node, device_ctx->queue[node].desc.name,
+			f->fmt.pix_mp.pixelformat,
+			f->fmt.pix_mp.width,
+			f->fmt.pix_mp.height,
+			f->fmt.pix_mp.plane_fmt[0].sizeimage
+			);
+			node_ctx->fmt.pix_mp = f->fmt.pix_mp;
+		} else {
+			dev_info(&isp_dev->pdev->dev,
+			"Node (%d): (%s), dfmt (f:0x%x s:%u)\n",
+			node, device_ctx->queue[node].desc.name,
+			f->fmt.meta.dataformat,
+			f->fmt.meta.buffersize
+			);
+			node_ctx->fmt.meta = f->fmt.meta;
+		}
+	}
+
+#if KERNEL_VERSION(4, 7, 0) < MTK_ISP_KERNEL_BASE_VERSION
+	/* device_caps was supported after 4.7 */
+	vdev->device_caps = V4L2_CAP_STREAMING | cap;
+#endif
+}
+
+int mtk_isp_media_register(struct device *dev,
+	struct media_device *media_dev,
+	const char *model)
+{
+	int r = 0;
+
+	media_dev->dev = dev;
+	dev_info(dev, "setup media_dev.dev: %llx\n",
+					(unsigned long long) media_dev->dev);
+
+	strlcpy(media_dev->model, model,
+		sizeof(media_dev->model));
+	dev_info(dev, "setup media_dev.model: %s\n",
+		media_dev->model);
+
+	snprintf(media_dev->bus_info, sizeof(media_dev->bus_info),
+		 "%s", dev_name(dev));
+	dev_info(dev, "setup media_dev.bus_info: %s\n",
+		media_dev->bus_info);
+
+	media_dev->hw_revision = 0;
+	dev_info(dev, "setup media_dev.hw_revision: %d\n",
+		media_dev->hw_revision);
+
+#if KERNEL_VERSION(4, 5, 0) <= MTK_ISP_KERNEL_BASE_VERSION
+	dev_info(dev, "media_device_init: media_dev:%llx\n",
+		(unsigned long long)media_dev);
+	media_device_init(media_dev);
+#endif
+
+	pr_info("Register media device: %s, %llx",
+		media_dev->model,
+		(unsigned long long)media_dev);
+
+	r = media_device_register(media_dev);
+
+	if (r) {
+		dev_err(dev, "failed to register media device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_ISP_KERNEL_BASE_VERSION
+	media_device_cleanup(media_dev);
+#endif
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_media_register);
+
+int mtk_isp_v4l2_register(struct device *dev,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev,
+	struct v4l2_ctrl_handler *ctrl_handler
+	)
+{
+	int r = 0;
+	/* Set up v4l2 device */
+	v4l2_dev->mdev = media_dev;
+	dev_info(dev, "setup v4l2_dev->mdev: %llx",
+		(unsigned long long)v4l2_dev->mdev);
+	v4l2_dev->ctrl_handler = ctrl_handler;
+	dev_info(dev, "setup v4l2_dev->ctrl_handler: %llx",
+		(unsigned long long)v4l2_dev->ctrl_handler);
+
+	pr_info("Register v4l2 device: %llx",
+		(unsigned long long)v4l2_dev);
+
+	r = v4l2_device_register(dev, v4l2_dev);
+
+	if (r) {
+		dev_err(dev, "failed to register V4L2 device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_ISP_KERNEL_BASE_VERSION
+	media_device_cleanup(media_dev);
+#endif
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_v4l2_register);
+
+int mtk_isp_mem2mem2_v4l2_register(struct mtk_isp_dev *dev,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = &dev->mem2mem2;
+
+	int i, r;
+
+	/* If media_dev or v4l2_dev is not set, */
+	/* use the default one in mtk_isp_dev */
+	if (media_dev == NULL) {
+		m2m2->media_dev = &dev->media_dev;
+		r = mtk_isp_media_register(&dev->pdev->dev,
+		m2m2->media_dev,
+		m2m2->model);
+
+	if (r) {
+		dev_err(m2m2->dev, "failed to register media device (%d)\n", r);
+		goto fail_media_dev;
+	}
+	} else {
+		m2m2->media_dev = media_dev;
+	}
+
+	if (v4l2_dev == NULL) {
+		m2m2->v4l2_dev = &dev->v4l2_dev;
+		m2m2->v4l2_dev->ctrl_handler = &dev->ctx.ctrl_handler;
+		r = mtk_isp_v4l2_register(&dev->pdev->dev,
+			m2m2->media_dev,
+			m2m2->v4l2_dev,
+			m2m2->v4l2_dev->ctrl_handler);
+
+	if (r) {
+		dev_err(m2m2->dev, "failed to register V4L2 device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+	} else {
+		m2m2->v4l2_dev = v4l2_dev;
+	}
+
+	/* Initialize miscellaneous variables */
+	m2m2->streaming = false;
+	m2m2->v4l2_file_ops = mtk_isp_v4l2_fops;
+
+	/* Initialize subdev media entity */
+	m2m2->subdev_pads = kzalloc(sizeof(*m2m2->subdev_pads) *
+					m2m2->num_nodes, GFP_KERNEL);
+	if (!m2m2->subdev_pads) {
+		r = -ENOMEM;
+		goto fail_subdev_pads;
+	}
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+	r = media_entity_init(&m2m2->subdev.entity, m2m2->num_nodes,
+						m2m2->subdev_pads, 0);
+#else
+	r = media_entity_pads_init(&m2m2->subdev.entity, m2m2->num_nodes,
+					 m2m2->subdev_pads);
+#endif
+	if (r) {
+		dev_err(m2m2->dev,
+			"failed initialize subdev media entity (%d)\n", r);
+		goto fail_media_entity;
+	}
+
+	/* Initialize subdev */
+	v4l2_subdev_init(&m2m2->subdev, &mtk_isp_subdev_ops);
+
+	m2m2->subdev.entity.function =
+		MEDIA_ENT_F_PROC_VIDEO_PIXEL_FORMATTER;
+
+	m2m2->subdev.entity.ops = &mtk_isp_media_ops;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		m2m2->subdev_pads[i].flags = m2m2->nodes[i].output ?
+			MEDIA_PAD_FL_SINK : MEDIA_PAD_FL_SOURCE;
+	}
+
+	m2m2->subdev.flags
+		= V4L2_SUBDEV_FL_HAS_DEVNODE | V4L2_SUBDEV_FL_HAS_EVENTS;
+	snprintf(m2m2->subdev.name, sizeof(m2m2->subdev.name),
+		 "%s", m2m2->name);
+	v4l2_set_subdevdata(&m2m2->subdev, m2m2);
+	m2m2->subdev.ctrl_handler = &dev->ctx.ctrl_handler;
+	m2m2->subdev.internal_ops = &mtk_isp_subdev_internal_ops;
+
+	pr_info("register subdev: %s\n", m2m2->subdev.name);
+	r = v4l2_device_register_subdev(m2m2->v4l2_dev, &m2m2->subdev);
+	if (r) {
+		dev_err(m2m2->dev, "failed initialize subdev (%d)\n", r);
+		goto fail_subdev;
+	}
+	r = v4l2_device_register_subdev_nodes(m2m2->v4l2_dev);
+	if (r) {
+		dev_err(m2m2->dev, "failed to register subdevs (%d)\n", r);
+		goto fail_subdevs;
+	}
+
+	/* Create video nodes and links */
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		struct mtk_isp_dev_video_device *node = &m2m2->nodes[i];
+		struct video_device *vdev = &node->vdev;
+		struct vb2_queue *vbq = &node->vbq;
+		u32 flags;
+
+		/* Initialize miscellaneous variables */
+		mutex_init(&node->lock);
+		INIT_LIST_HEAD(&node->buffers);
+
+		/* Initialize formats to default values */
+		mtk_isp_node_to_v4l2(dev, i, vdev, &node->vdev_fmt);
+
+		/* Initialize media entities */
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+		r = media_entity_init(&vdev->entity, 1, &node->vdev_pad, 0);
+#else
+		r = media_entity_pads_init(&vdev->entity, 1, &node->vdev_pad);
+#endif
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed initialize media entity (%d)\n", r);
+			goto fail_vdev_media_entity;
+		}
+		node->vdev_pad.flags = node->output ?
+			MEDIA_PAD_FL_SOURCE : MEDIA_PAD_FL_SINK;
+		vdev->entity.ops = NULL;
+
+		/* Initialize vbq */
+		vbq->type = node->vdev_fmt.type;
+		vbq->io_modes = VB2_MMAP | VB2_DMABUF;
+		vbq->ops = &mtk_isp_vb2_ops;
+		vbq->mem_ops = m2m2->vb2_mem_ops;
+		m2m2->buf_struct_size = sizeof(struct mtk_isp_dev_buffer);
+		vbq->buf_struct_size = m2m2->buf_struct_size;
+		vbq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;
+		vbq->min_buffers_needed = 0;	/* Can streamon w/o buffers */
+		/* Put the process hub sub device in the vb2 private data*/
+		vbq->drv_priv = m2m2;
+		vbq->lock = &node->lock;
+		r = vb2_queue_init(vbq);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed to initialize video queue (%d)\n", r);
+			goto fail_vdev;
+		}
+
+		/* Initialize vdev */
+		snprintf(vdev->name, sizeof(vdev->name), "%s %s",
+			 m2m2->name, node->name);
+		vdev->release = video_device_release_empty;
+		vdev->fops = &m2m2->v4l2_file_ops;
+		vdev->lock = &node->lock;
+		vdev->ctrl_handler = &dev->ctx.queue[i].ctrl_handler;
+		vdev->v4l2_dev = m2m2->v4l2_dev;
+		vdev->queue = &node->vbq;
+		vdev->vfl_dir = node->output ? VFL_DIR_TX : VFL_DIR_RX;
+		video_set_drvdata(vdev, m2m2);
+		pr_info("register vdev: %s\n", vdev->name);
+		r = video_register_device(vdev, VFL_TYPE_GRABBER, -1);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed to register video device (%d)\n", r);
+			goto fail_vdev;
+		}
+
+		if (vdev->cdev->ops) {
+			memcpy((void *)&m2m2->fops, vdev->cdev->ops,
+				sizeof(m2m2->fops));
+			((struct file_operations *)&m2m2->fops)->compat_ioctl =
+				mtk_isp_v4l2_compat_ioctl32;
+			vdev->cdev->ops = &m2m2->fops;
+		}
+
+		/* Create link between video node and the subdev pad */
+		flags = 0;
+		if (node->enabled)
+			flags |= MEDIA_LNK_FL_ENABLED;
+		if (node->immutable)
+			flags |= MEDIA_LNK_FL_IMMUTABLE;
+		if (node->output) {
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+			r = media_entity_create_link(
+#else
+			r = media_create_pad_link(
+#endif
+						 &vdev->entity, 0,
+						 &m2m2->subdev.entity,
+						 i, flags);
+		} else {
+#if KERNEL_VERSION(4, 5, 0) >= MTK_ISP_KERNEL_BASE_VERSION
+			r = media_entity_create_link(
+#else
+			r = media_create_pad_link(
+#endif
+						 &m2m2->subdev.entity,
+						 i, &vdev->entity, 0,
+						 flags);
+		}
+		if (r)
+			goto fail_link;
+
+	}
+
+	return 0;
+
+	for (; i >= 0; i--) {
+fail_link:
+		video_unregister_device(&m2m2->nodes[i].vdev);
+fail_vdev:
+		media_entity_cleanup(&m2m2->nodes[i].vdev.entity);
+fail_vdev_media_entity:
+		mutex_destroy(&m2m2->nodes[i].lock);
+	}
+fail_subdevs:
+	v4l2_device_unregister_subdev(&m2m2->subdev);
+fail_subdev:
+	media_entity_cleanup(&m2m2->subdev.entity);
+fail_media_entity:
+	kfree(m2m2->subdev_pads);
+fail_subdev_pads:
+	v4l2_device_unregister(m2m2->v4l2_dev);
+fail_v4l2_dev:
+fail_media_dev:
+	pr_err("fail_v4l2_dev: media_device_unregister and clenaup:%llx",
+	(unsigned long long)m2m2->media_dev);
+	media_device_unregister(m2m2->media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_ISP_KERNEL_BASE_VERSION
+	media_device_cleanup(m2m2->media_dev);
+#endif
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_mem2mem2_v4l2_register);
+
+int mtk_isp_v4l2_unregister(struct mtk_isp_dev *dev)
+{
+	struct mtk_isp_mem2mem2_device *m2m2 = &dev->mem2mem2;
+	unsigned int i;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		video_unregister_device(&m2m2->nodes[i].vdev);
+		media_entity_cleanup(&m2m2->nodes[i].vdev.entity);
+		mutex_destroy(&m2m2->nodes[i].lock);
+	}
+
+	v4l2_device_unregister_subdev(&m2m2->subdev);
+	media_entity_cleanup(&m2m2->subdev.entity);
+	kfree(m2m2->subdev_pads);
+	v4l2_device_unregister(m2m2->v4l2_dev);
+	media_device_unregister(m2m2->media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_ISP_KERNEL_BASE_VERSION
+	media_device_cleanup(m2m2->media_dev);
+#endif
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_isp_v4l2_unregister);
+
+void mtk_isp_v4l2_buffer_done(struct vb2_buffer *vb,
+				 enum vb2_buffer_state state)
+{
+	struct mtk_isp_mem2mem2_buffer *b =
+		container_of(vb, struct mtk_isp_mem2mem2_buffer, vbb.vb2_buf);
+
+	list_del(&b->list);
+	vb2_buffer_done(&b->vbb.vb2_buf, state);
+}
+EXPORT_SYMBOL_GPL(mtk_isp_v4l2_buffer_done);
+
+
+/* We use sequence number in v4l2_buffer but it is */
+/* not copied from userspace in v4l2_compat_ioctl32 handling */
+/* flow. Therefore, I add the following 32 bits ioctl */
+/* hanlding flow. */
+#include <linux/compat.h>
+
+/* Use the same argument order as copy_in_user */
+#define assign_in_user(to, from)					\
+({									\
+	typeof(*from) __assign_tmp;					\
+									\
+	get_user(__assign_tmp, from) || put_user(__assign_tmp, to);	\
+})
+
+struct v4l2_buffer32 {
+	__u32			index;
+	__u32			type;	/* enum v4l2_buf_type */
+	__u32			bytesused;
+	__u32			flags;
+	__u32			field;	/* enum v4l2_field */
+	struct compat_timeval	timestamp;
+	struct v4l2_timecode	timecode;
+	__u32			sequence;
+
+	/* memory location */
+	__u32			memory;	/* enum v4l2_memory */
+	union {
+		__u32           offset;
+		compat_long_t   userptr;
+		compat_caddr_t  planes;
+		__s32		fd;
+	} m;
+	__u32			length;
+	__u32			reserved2;
+	__u32			reserved;
+};
+
+struct v4l2_plane32 {
+	__u32			bytesused;
+	__u32			length;
+	union {
+		__u32		mem_offset;
+		compat_long_t	userptr;
+		__s32		fd;
+	} m;
+	__u32			data_offset;
+	__u32			reserved[11];
+};
+
+static long native_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	long ret = -ENOIOCTLCMD;
+
+	if (file->f_op->unlocked_ioctl)
+		ret = file->f_op->unlocked_ioctl(file, cmd, arg);
+
+	return ret;
+}
+
+static int bufsize_v4l2_buffer(struct v4l2_buffer32 __user *up, u32 *size)
+{
+	u32 type;
+	u32 length;
+
+	if (!access_ok(VERIFY_READ, up, sizeof(*up)) ||
+	    get_user(type, &up->type) ||
+	    get_user(length, &up->length))
+		return -EFAULT;
+
+	if (V4L2_TYPE_IS_MULTIPLANAR(type)) {
+		if (length > VIDEO_MAX_PLANES)
+			return -EINVAL;
+
+		*size = length * sizeof(struct v4l2_plane);
+	} else {
+		*size = 0;
+	}
+	return 0;
+}
+
+static int get_v4l2_plane32(struct v4l2_plane __user *up,
+			    struct v4l2_plane32 __user *up32,
+			    enum v4l2_memory memory)
+{
+	compat_ulong_t p;
+
+	if (copy_in_user(up, up32, 2 * sizeof(__u32)) ||
+	    copy_in_user(&up->data_offset, &up32->data_offset,
+			 sizeof(up->data_offset)))
+		return -EFAULT;
+
+	switch (memory) {
+	case V4L2_MEMORY_MMAP:
+	case V4L2_MEMORY_OVERLAY:
+		if (copy_in_user(&up->m.mem_offset, &up32->m.mem_offset,
+				 sizeof(up32->m.mem_offset)))
+			return -EFAULT;
+		break;
+	case V4L2_MEMORY_USERPTR:
+		if (get_user(p, &up32->m.userptr) ||
+		    put_user((unsigned long)compat_ptr(p), &up->m.userptr))
+			return -EFAULT;
+		break;
+	case V4L2_MEMORY_DMABUF:
+		if (copy_in_user(&up->m.fd, &up32->m.fd, sizeof(up32->m.fd)))
+			return -EFAULT;
+		break;
+	}
+
+	return 0;
+}
+
+static int put_v4l2_plane32(struct v4l2_plane __user *up,
+			    struct v4l2_plane32 __user *up32,
+			    enum v4l2_memory memory)
+{
+	unsigned long p;
+
+	if (copy_in_user(up32, up, 2 * sizeof(__u32)) ||
+	    copy_in_user(&up32->data_offset, &up->data_offset,
+			 sizeof(up->data_offset)))
+		return -EFAULT;
+
+	switch (memory) {
+	case V4L2_MEMORY_MMAP:
+	case V4L2_MEMORY_OVERLAY:
+		if (copy_in_user(&up32->m.mem_offset, &up->m.mem_offset,
+				 sizeof(up->m.mem_offset)))
+			return -EFAULT;
+		break;
+	case V4L2_MEMORY_USERPTR:
+		if (get_user(p, &up->m.userptr) ||
+		    put_user((compat_ulong_t)ptr_to_compat((__force void *)p),
+			     &up32->m.userptr))
+			return -EFAULT;
+		break;
+	case V4L2_MEMORY_DMABUF:
+		if (copy_in_user(&up32->m.fd, &up->m.fd, sizeof(up->m.fd)))
+			return -EFAULT;
+		break;
+	}
+
+	return 0;
+}
+
+static int get_v4l2_buffer32(struct v4l2_buffer __user *kp,
+			     struct v4l2_buffer32 __user *up,
+			     void __user *aux_buf, u32 aux_space)
+{
+	u32 type;
+	u32 length;
+	enum v4l2_memory memory;
+	struct v4l2_plane32 __user *uplane32;
+	struct v4l2_plane __user *uplane;
+	compat_caddr_t p;
+	int ret;
+
+	pr_debug("%s start, sequence: %u,%u\n",
+		__func__, up->sequence, kp->sequence);
+
+	if (!access_ok(VERIFY_READ, up, sizeof(*up)) ||
+	    assign_in_user(&kp->index, &up->index) ||
+	    get_user(type, &up->type) ||
+	    put_user(type, &kp->type) ||
+	    assign_in_user(&kp->flags, &up->flags) ||
+	    get_user(memory, &up->memory) ||
+	    put_user(memory, &kp->memory) ||
+	    get_user(length, &up->length) ||
+	    put_user(length, &kp->length) ||
+	    assign_in_user(&kp->sequence, &up->sequence))
+		return -EFAULT;
+
+	if (V4L2_TYPE_IS_OUTPUT(type))
+		if (assign_in_user(&kp->bytesused, &up->bytesused) ||
+		    assign_in_user(&kp->field, &up->field) ||
+		    assign_in_user(&kp->timestamp.tv_sec,
+				   &up->timestamp.tv_sec) ||
+		    assign_in_user(&kp->timestamp.tv_usec,
+				   &up->timestamp.tv_usec))
+			return -EFAULT;
+
+	if (V4L2_TYPE_IS_MULTIPLANAR(type)) {
+		u32 num_planes = length;
+
+		if (num_planes == 0) {
+			/*
+			 * num_planes == 0 is legal, e.g. when userspace doesn't
+			 * need planes array on DQBUF
+			 */
+			return put_user(NULL, &kp->m.planes);
+		}
+		if (num_planes > VIDEO_MAX_PLANES)
+			return -EINVAL;
+
+		if (get_user(p, &up->m.planes))
+			return -EFAULT;
+
+		uplane32 = compat_ptr(p);
+		if (!access_ok(VERIFY_READ, uplane32,
+			       num_planes * sizeof(*uplane32)))
+			return -EFAULT;
+
+		if (aux_space < num_planes * sizeof(*uplane))
+			return -EFAULT;
+
+		uplane = aux_buf;
+		if (put_user((__force struct v4l2_plane *)uplane,
+			     &kp->m.planes))
+			return -EFAULT;
+
+		while (num_planes--) {
+			ret = get_v4l2_plane32(uplane, uplane32, memory);
+			if (ret)
+				return ret;
+			uplane++;
+			uplane32++;
+		}
+	} else {
+		switch (memory) {
+		case V4L2_MEMORY_MMAP:
+		case V4L2_MEMORY_OVERLAY:
+			if (assign_in_user(&kp->m.offset, &up->m.offset))
+				return -EFAULT;
+			break;
+		case V4L2_MEMORY_USERPTR: {
+			compat_ulong_t userptr;
+
+			if (get_user(userptr, &up->m.userptr) ||
+			    put_user((unsigned long)compat_ptr(userptr),
+				     &kp->m.userptr))
+				return -EFAULT;
+			break;
+		}
+		case V4L2_MEMORY_DMABUF:
+			if (assign_in_user(&kp->m.fd, &up->m.fd))
+				return -EFAULT;
+			break;
+		}
+	}
+
+	return 0;
+}
+
+static int put_v4l2_buffer32(struct v4l2_buffer __user *kp,
+			     struct v4l2_buffer32 __user *up)
+{
+	u32 type;
+	u32 length;
+	enum v4l2_memory memory;
+	struct v4l2_plane32 __user *uplane32;
+	struct v4l2_plane __user *uplane;
+	compat_caddr_t p;
+	int ret;
+
+	if (!access_ok(VERIFY_WRITE, up, sizeof(*up)) ||
+	    assign_in_user(&up->index, &kp->index) ||
+	    get_user(type, &kp->type) ||
+	    put_user(type, &up->type) ||
+	    assign_in_user(&up->flags, &kp->flags) ||
+	    get_user(memory, &kp->memory) ||
+	    put_user(memory, &up->memory))
+		return -EFAULT;
+
+	if (assign_in_user(&up->bytesused, &kp->bytesused) ||
+	    assign_in_user(&up->field, &kp->field) ||
+	    assign_in_user(&up->timestamp.tv_sec, &kp->timestamp.tv_sec) ||
+	    assign_in_user(&up->timestamp.tv_usec, &kp->timestamp.tv_usec) ||
+	    copy_in_user(&up->timecode, &kp->timecode, sizeof(kp->timecode)) ||
+	    assign_in_user(&up->sequence, &kp->sequence) ||
+	    assign_in_user(&up->reserved2, &kp->reserved2) ||
+	    assign_in_user(&up->reserved, &kp->reserved) ||
+	    get_user(length, &kp->length) ||
+	    put_user(length, &up->length))
+		return -EFAULT;
+
+	if (V4L2_TYPE_IS_MULTIPLANAR(type)) {
+		u32 num_planes = length;
+
+		if (num_planes == 0)
+			return 0;
+
+		if (get_user(uplane,
+			((__force struct v4l2_plane __user **)&kp->m.planes)))
+			return -EFAULT;
+		if (get_user(p, &up->m.planes))
+			return -EFAULT;
+		uplane32 = compat_ptr(p);
+
+		while (num_planes--) {
+			ret = put_v4l2_plane32(uplane, uplane32, memory);
+			if (ret)
+				return ret;
+			++uplane;
+			++uplane32;
+		}
+	} else {
+		switch (memory) {
+		case V4L2_MEMORY_MMAP:
+		case V4L2_MEMORY_OVERLAY:
+			if (assign_in_user(&up->m.offset, &kp->m.offset))
+				return -EFAULT;
+			break;
+		case V4L2_MEMORY_USERPTR:
+			if (assign_in_user(&up->m.userptr, &kp->m.userptr))
+				return -EFAULT;
+			break;
+		case V4L2_MEMORY_DMABUF:
+			if (assign_in_user(&up->m.fd, &kp->m.fd))
+				return -EFAULT;
+			break;
+		}
+	}
+
+	return 0;
+}
+
+#define VIDIOC_QUERYBUF32	_IOWR('V',  9, struct v4l2_buffer32)
+#define VIDIOC_QBUF32		_IOWR('V', 15, struct v4l2_buffer32)
+#define VIDIOC_DQBUF32		_IOWR('V', 17, struct v4l2_buffer32)
+#define VIDIOC_PREPARE_BUF32	_IOWR('V', 93, struct v4l2_buffer32)
+
+
+static int alloc_userspace(unsigned int size, u32 aux_space,
+			   void __user **up_native)
+{
+	*up_native = compat_alloc_user_space(size + aux_space);
+	if (!*up_native)
+		return -ENOMEM;
+	if (clear_user(*up_native, size))
+		return -EFAULT;
+	return 0;
+}
+
+static long do_video_ioctl_with_v4l2_buffer(struct file *file,
+	unsigned int cmd, unsigned long arg)
+{
+	void __user *up = compat_ptr(arg);
+	void __user *up_native = NULL;
+	void __user *aux_buf;
+	u32 aux_space;
+	int compatible_arg = 1;
+	long err = 0;
+
+	pr_debug("%s, cmd:%d", __func__, cmd);
+
+	switch (cmd) {
+	case VIDIOC_QUERYBUF32:
+		cmd = VIDIOC_QUERYBUF;
+		break;
+	case VIDIOC_QBUF32:
+		cmd = VIDIOC_QBUF;
+		break;
+	case VIDIOC_DQBUF32:
+		cmd = VIDIOC_DQBUF;
+		break;
+	case VIDIOC_PREPARE_BUF32:
+		cmd = VIDIOC_PREPARE_BUF;
+		break;
+	default:
+		pr_err("%s can't support CMD(%d)\n", __func__, cmd);
+		return -EINVAL;
+	}
+
+	err = bufsize_v4l2_buffer(up, &aux_space);
+	if (!err)
+		err = alloc_userspace(sizeof(struct v4l2_buffer),
+				      aux_space, &up_native);
+	if (!err) {
+		aux_buf = up_native + sizeof(struct v4l2_buffer);
+		err = get_v4l2_buffer32(up_native, up,
+					aux_buf, aux_space);
+	}
+	compatible_arg = 0;
+
+	if (err)
+		return err;
+
+	if (compatible_arg)
+		err = native_ioctl(file, cmd, (unsigned long)up);
+	else
+		err = native_ioctl(file, cmd, (unsigned long)up_native);
+
+	if (err == -ENOTTY)
+		return err;
+
+	err = put_v4l2_buffer32(up_native, up);
+
+	return err;
+}
+
+static long mtk_isp_v4l2_compat_ioctl32(struct file *file,
+		unsigned int cmd, unsigned long arg)
+{
+	struct video_device *vdev = video_devdata(file);
+	long ret = -ENOIOCTLCMD;
+
+	pr_debug("Called from 32 bits user prorgam: %s\n", __func__);
+
+	if (cmd == VIDIOC_QUERYBUF32 ||
+			cmd == VIDIOC_QBUF32 ||
+			cmd == VIDIOC_DQBUF32 ||
+			cmd == VIDIOC_PREPARE_BUF32) {
+		if (!file->f_op->unlocked_ioctl)
+			return ret;
+
+		if (_IOC_TYPE(cmd) == 'V' && _IOC_NR(cmd) < BASE_VIDIOC_PRIVATE)
+			ret = do_video_ioctl_with_v4l2_buffer(file, cmd, arg);
+		else if (vdev->fops->compat_ioctl32)
+			ret = vdev->fops->compat_ioctl32(file, cmd, arg);
+
+		if (ret == -ENOIOCTLCMD)
+			pr_debug("compat_ioctl32: unknown ioctl '%c', dir=%d, #%d (0x%08x)\n",
+				 _IOC_TYPE(cmd), _IOC_DIR(cmd),
+				 _IOC_NR(cmd), cmd);
+	} else {
+		pr_info("Call v4l2_compat_ioctl32, no v4l2_buffer conversion\n");
+		ret = v4l2_compat_ioctl32(file, cmd, arg);
+	}
+	return ret;
+}
+
diff --git a/drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.h b/drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.h
new file mode 100644
index 000000000000..1e253effced3
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/common/mtk_isp-v4l2.h
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_ISP_DEV_V4L2_H__
+#define __MTK_ISP_DEV_V4L2_H__
+
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+
+
+/*
+ * Events
+ *
+ * V4L2_EVENT_MTK_ISP_ENGINE_STATE: AF statistics data ready
+ * V4L2_EVENT_MTK_ISP_FRAME_DONE: Hardware has finished a frame
+ */
+
+#define V4L2_EVENT_MTK_ISP_CLASS	\
+	(V4L2_EVENT_PRIVATE_START | 0x200)
+#define V4L2_EVENT_MTK_ISP_ENGINE_STATE	\
+	(V4L2_EVENT_MTK_ISP_CLASS | 0x1)
+#define V4L2_EVENT_MTK_ISP_FRAME_DONE	\
+	(V4L2_EVENT_MTK_ISP_CLASS | 0x2)
+
+/* For v4l2 event data, must smaller than 64 bytes */
+struct mtk_isp_dev_stat_event_data {
+	__u32 frame_number;
+	__u32 irq_status_mask;
+	__u32 dma_status_mask;
+};
+
+struct mtk_isp_dev_frame_done_event_data {
+	__u32 frame_id;	/* The frame id of mtk_isp_ctx_buf */
+	__u32 user_sequence;	/* Sequence number assigned by user, */
+				/* for example, p1's magic number */
+};
+
+#endif /* __MTK_ISP_DEV_V4L2_H__ */
diff --git a/drivers/media/platform/mtk-isp/fd/Makefile b/drivers/media/platform/mtk-isp/fd/Makefile
new file mode 100644
index 000000000000..0001fdfd4b6c
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/Makefile
@@ -0,0 +1,38 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+
+$(info "FD: makefile start srctree: $(srctree)")
+ccflags-y += -I$(srctree)/drivers/media/platform/mtk-vpu
+ccflags-y += -I$(srctree)/drivers/media/platform/mtk-isp/fd
+#ccflags-y += -I$(srctree)/drivers/media/platform/mtk-isp/common
+
+obj-y += mtk_fd.o
+obj-y += mtk_fd-v4l2.o
+
+# To provide alloc context managing memory shared
+# between CPU and ISP coprocessor
+mtk_fd_smem-objs := \
+mtk_fd-smem-drv.o
+
+obj-y += mtk_fd_smem.o
+
+# Utilits to provide frame-based streaming model
+# with v4l2 user interfaces
+mtk_fd_util-objs := \
+mtk_fd-dev.o \
+mtk_fd-v4l2-util.o \
+mtk_fd-dev-ctx-core.o
+
+obj-y += mtk_fd_util.o
+
+$(info "FD: makefile end")
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-core.h b/drivers/media/platform/mtk-isp/fd/mtk_fd-core.h
new file mode 100644
index 000000000000..2aab4ab53826
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-core.h
@@ -0,0 +1,157 @@
+/* SPDX-License-Identifier: GPL-2.0
+ * Copyright (C) 2015 MediaTek Inc.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_FD_CORE_H__
+#define __MTK_FD_CORE_H__
+
+#define SIG_ERESTARTSYS 512
+
+#ifndef CONFIG_MTK_CLKMGR
+#include <linux/clk.h>
+#endif
+
+#ifdef CONFIG_MTK_CLKMGR
+#include <mach/mt_clkmgr.h>
+#endif
+
+#include "mtk_fd-dev.h"
+#include "mtk_fd-ctx.h"
+
+#include <linux/io.h>
+
+#define FD_WR32(v, a) \
+do { \
+	__raw_writel((v), (void __force __iomem *)((a))); \
+	mb(); /* ensure written */ \
+} while (0)
+
+#define FD_RD32(addr)                  ioread32((void *)addr)
+
+#define	FD_INT_EN	(0x15c)
+#define	FD_INT		(0x168)
+#define	FD_RESULT	(0x178)
+#define FD_IRQ_MASK	(0x001)
+
+#define RS_BUF_SIZE_MAX	(2288788)
+#define VA_OFFSET	(0xffff000000000000)
+
+enum fd_irq {
+	FD_IRQ_IDX = 0,
+	FD_IRQ_IDX_NUM
+};
+
+enum fd_state {
+	FD_INI,
+	FD_ENQ,
+	FD_CBD,
+};
+
+enum stream_stat {
+	STREAM_OFF,
+	STREAM_ON,
+};
+
+struct ipi_fd_enq_param {
+	u8 source_img_fmt;
+	struct fd_buffer output_addr;
+	struct fd_buffer src_y;
+	struct fd_buffer src_uv;
+	struct fd_buffer config_addr;
+} __packed;
+
+struct fd_manager_ctx {
+	struct fd_buffer learn_data_buf[2][LEARNDATA_NUM];
+	struct fd_buffer fd_config;
+	struct fd_buffer rs_config;
+	struct fd_buffer fd_result;
+	struct fd_buffer rs_result;
+	struct fd_buffer src_img;
+} __packed;
+
+struct mtk_fd_drv_ctx {
+	struct sg_table sgtable;
+	u32 frame_id;
+	struct fd_buffer rs_result;
+	struct fd_buffer scp_mem;
+	struct platform_device *vpu_pdev;
+	struct rproc *rproc_handle;
+	atomic_t fd_enque_cnt;
+	atomic_t fd_stream_cnt;
+	atomic_t fd_user_cnt;
+};
+
+struct mtk_fd_drv_dev {
+	struct platform_device *pdev;
+
+	dev_t fd_devno;
+	struct cdev   fd_cdev;
+	struct class *fd_class;
+	struct mtk_fd_drv_ctx fd_ctx;
+
+	struct device *larb_dev;
+	struct clk *fd_clk;
+	enum fd_state state;
+	enum stream_stat streaming;
+
+	wait_queue_head_t wq;
+	u32 fd_irq_result;
+
+	void __iomem *fd_base;
+};
+
+struct mtk_isp_fd_drv_data {
+	struct mtk_fd_dev fd_dev;
+	struct mtk_fd_drv_dev fd_hw_dev;
+} __packed;
+
+static inline struct mtk_fd_drv_dev *get_fd_hw_device(struct device *dev)
+{
+	struct mtk_isp_fd_drv_data *drv_data =
+		dev_get_drvdata(dev);
+	if (drv_data)
+		return &drv_data->fd_hw_dev;
+	else
+		return NULL;
+}
+
+#define mtk_fd_us_to_jiffies(us) \
+	((((unsigned long)(us) / 1000) * HZ + 512) >> 10)
+
+#define mtk_fd_hw_dev_to_drv(__fd_hw_dev) \
+	container_of(__fd_hw_dev, \
+	struct mtk_isp_fd_drv_data, fd_hw_dev)
+
+#define mtk_fd_ctx_to_drv(__fd_ctx) \
+	container_of(__fd_ctx, \
+	struct mtk_isp_fd_drv_data, fd_hw_dev.fd_ctx)
+
+enum fd_scp_cmd {
+	FD_CMD_INIT,
+	FD_CMD_ENQ,
+	FD_CMD_EXIT,
+};
+
+enum fd_clk {
+	clock_off = 0,
+	clock_on,
+};
+
+struct ipi_message {
+	u8 cmd_id;
+	union {
+		struct fd_buffer fd_manager;
+		struct v4l2_fd_param fd_param;
+	};
+} __packed;
+
+#endif/*__MTK_FD_CORE_H__*/
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-ctx.h b/drivers/media/platform/mtk-isp/fd/mtk_fd-ctx.h
new file mode 100644
index 000000000000..d78a3afe12e4
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-ctx.h
@@ -0,0 +1,299 @@
+/* SPDX-License-Identifier: GPL-2.0
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_FD_CTX_H__
+#define __MTK_FD_CTX_H__
+
+#include <linux/types.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ctrls.h>
+#include <media/videobuf2-core.h>
+#include <media/v4l2-subdev.h>
+
+#define MTK_FD_CTX_QUEUES (16)
+#define MTK_FD_CTX_FRAME_BUNDLE_BUFFER_MAX (MTK_FD_CTX_QUEUES)
+#define MTK_FD_CTX_DESC_MAX (MTK_FD_CTX_QUEUES)
+
+#define MTK_FD_CTX_MODE_DEBUG_OFF (0)
+#define MTK_FD_CTX_MODE_DEBUG_BYPASS_JOB_TRIGGER (1)
+#define MTK_FD_CTX_MODE_DEBUG_BYPASS_ALL (2)
+
+#define MTK_FD_GET_CTX_ID_FROM_SEQUENCE(sequence) \
+	((sequence) >> 16 & 0x0000FFFF)
+
+#define MTK_FD_CTX_META_BUF_DEFAULT_SIZE (1110 * 1024)
+
+struct mtk_fd_ctx;
+struct mtk_fd_ctx_finish_param;
+
+/**
+ * Attributes setup by device context owner
+ */
+struct mtk_fd_ctx_queue_desc {
+	int id;
+	/* id of the context queue */
+	char *name;
+	/* Will be exported to media entity name */
+	int capture;
+	/**
+	 * 1 for capture queue (device to user),
+	 * 0 for output queue (from user to device)
+	 */
+	int image;
+	/* 1 for image, 0 for meta data */
+	unsigned int dma_port;
+	/*The dma port associated to the buffer*/
+	struct mtk_fd_ctx_format *fmts;
+	int num_fmts;
+	/* Default format of this queue */
+	int default_fmt_idx;
+};
+
+/**
+ * Supported format and the information used for
+ * size calculation
+ */
+struct mtk_fd_ctx_meta_format {
+	u32 dataformat;
+	u32 max_buffer_size;
+	u8 flags;
+};
+
+/**
+ * MDP module's private format definitation
+ * (the same as struct mdp_format)
+ * It will be removed and changed to MDP's external interface
+ * after the integration with MDP module.
+ */
+struct mtk_fd_ctx_mdp_format {
+	u32	pixelformat;
+	u32	mdp_color;
+	u8	depth[VIDEO_MAX_PLANES];
+	u8	row_depth[VIDEO_MAX_PLANES];
+	u8	num_planes;
+	u8	walign;
+	u8	halign;
+	u8	salign;
+	u32	flags;
+};
+
+struct mtk_fd_ctx_format {
+	union {
+		struct mtk_fd_ctx_meta_format meta;
+		struct mtk_fd_ctx_mdp_format img;
+	} fmt;
+};
+
+union mtk_v4l2_fmt {
+	struct v4l2_pix_format_mplane pix_mp;
+	struct v4l2_meta_format	meta;
+};
+
+/* Attributes setup by device context owner */
+struct mtk_fd_ctx_queues_setting {
+	int master;
+	/* The master input node to trigger the frame data enqueue */
+	struct mtk_fd_ctx_queue_desc *output_queue_descs;
+	int total_output_queues;
+	struct mtk_fd_ctx_queue_desc *capture_queue_descs;
+	int total_capture_queues;
+};
+
+struct mtk_fd_ctx_queue_attr {
+	int master;
+	int input_offset;
+	int total_num;
+};
+
+/**
+ * Video node context. Since we use
+ * mtk_fd_ctx_frame_bundle to manage enqueued
+ * buffers by frame now, we don't use bufs filed of
+ * mtk_fd_ctx_queue now
+ */
+struct mtk_fd_ctx_queue {
+	union mtk_v4l2_fmt fmt;
+	struct mtk_fd_ctx_format *ctx_fmt;
+
+	unsigned int width_pad;
+	/* bytesperline, reserved */
+	struct mtk_fd_ctx_queue_desc desc;
+	unsigned int buffer_usage;
+	/* Current buffer usage of the queue */
+	int rotation;
+	struct list_head bufs;
+	/* Reserved, not used now */
+};
+
+enum mtk_fd_ctx_frame_bundle_state {
+	MTK_FD_CTX_FRAME_NEW,
+	/* Not allocated */
+	MTK_FD_CTX_FRAME_PREPARED,
+	/* Allocated but has not be processed */
+	MTK_FD_CTX_FRAME_PROCESSING,
+	/* Queued, waiting to be filled */
+};
+
+/**
+ * The definiation is compatible with FD driver's state definiation
+ * currently and will be decoupled after further integration
+ */
+enum mtk_fd_ctx_frame_data_state {
+	MTK_FD_CTX_FRAME_DATA_EMPTY = 0, /* FRAME_STATE_INIT */
+	MTK_FD_CTX_FRAME_DATA_DONE = 3, /* FRAME_STATE_DONE */
+	MTK_FD_CTX_FRAME_DATA_STREAMOFF_DONE = 4, /*FRAME_STATE_STREAMOFF*/
+	MTK_FD_CTX_FRAME_DATA_ERROR = 5, /*FRAME_STATE_ERROR*/
+};
+
+struct mtk_fd_ctx_frame_bundle {
+	struct mtk_fd_ctx_buffer*
+		buffers[MTK_FD_CTX_FRAME_BUNDLE_BUFFER_MAX];
+	int id;
+	int num_img_capture_bufs;
+	int num_img_output_bufs;
+	int num_meta_capture_bufs;
+	int num_meta_output_bufs;
+	int last_index;
+	int state;
+	struct list_head list;
+};
+
+struct mtk_fd_ctx_frame_bundle_list {
+	struct list_head list;
+};
+
+struct mtk_fd_ctx {
+	struct platform_device *pdev;
+	struct platform_device *smem_device;
+	unsigned short ctx_id;
+	char device_name[12];
+	const struct mtk_fd_ctx_ops *ops;
+	struct mtk_fd_dev_node_mapping *mtk_fd_dev_node_map;
+	unsigned int dev_node_num;
+	struct mtk_fd_ctx_queue queue[MTK_FD_CTX_QUEUES];
+	struct mtk_fd_ctx_queue_attr queues_attr;
+	atomic_t frame_param_sequence;
+	int streaming;
+	void *img_vb2_alloc_ctx;
+	void *smem_vb2_alloc_ctx;
+	struct v4l2_subdev_fh *fh;
+	struct mtk_fd_ctx_frame_bundle frame_bundles[VB2_MAX_FRAME];
+	struct mtk_fd_ctx_frame_bundle_list processing_frames;
+	struct mtk_fd_ctx_frame_bundle_list free_frames;
+	int enabled_dma_ports;
+	int num_frame_bundle;
+	int mode; /* Reserved for debug */
+	spinlock_t qlock;
+};
+
+enum mtk_fd_ctx_buffer_state {
+	MTK_FD_CTX_BUFFER_NEW,
+	MTK_FD_CTX_BUFFER_PROCESSING,
+	MTK_FD_CTX_BUFFER_DONE,
+	MTK_FD_CTX_BUFFER_FAILED,
+};
+
+struct mtk_fd_ctx_buffer {
+	union mtk_v4l2_fmt fmt;
+	struct mtk_fd_ctx_format *ctx_fmt;
+	int capture;
+	int image;
+	int frame_id;
+	int user_sequence; /* Sequence number assigned by user */
+	dma_addr_t daddr;
+	void *vaddr;
+	phys_addr_t paddr;
+	unsigned int queue;
+	unsigned int buffer_usage;
+	enum mtk_fd_ctx_buffer_state state;
+	int rotation;
+	struct list_head list;
+};
+
+struct mtk_fd_ctx_desc {
+	char *proc_dev_phandle;
+	/* The context device's compatble string name in device tree*/
+	int (*init)(struct mtk_fd_ctx *ctx);
+	/* configure the core functions of the device context */
+};
+
+struct mtk_fd_ctx_init_table {
+	int total_dev_ctx;
+	struct mtk_fd_ctx_desc *ctx_desc_tbl;
+};
+
+struct mtk_fd_ctx_finish_param {
+	unsigned int frame_id;
+	u64 timestamp;
+	unsigned int state;
+};
+
+bool mtk_fd_ctx_is_streaming(struct mtk_fd_ctx *ctx);
+
+int mtk_fd_ctx_core_job_finish(struct mtk_fd_ctx *ctx,
+			       struct mtk_fd_ctx_finish_param *param);
+
+int mtk_fd_ctx_core_init(struct mtk_fd_ctx *ctx,
+			 struct platform_device *pdev, int ctx_id,
+			 struct mtk_fd_ctx_desc *ctx_desc,
+			 struct platform_device *proc_pdev,
+			 struct platform_device *smem_pdev);
+
+int mtk_fd_ctx_core_exit(struct mtk_fd_ctx *ctx);
+
+void mtk_fd_ctx_buf_init(struct mtk_fd_ctx_buffer *b, unsigned int queue,
+			 dma_addr_t daddr);
+
+enum mtk_fd_ctx_buffer_state
+	mtk_fd_ctx_get_buffer_state(struct mtk_fd_ctx_buffer *b);
+
+int mtk_fd_ctx_next_global_frame_sequence(struct mtk_fd_ctx *ctx, int locked);
+
+int mtk_fd_ctx_core_queue_setup
+	(struct mtk_fd_ctx *ctx,
+	 struct mtk_fd_ctx_queues_setting *queues_setting);
+
+int mtk_fd_ctx_core_finish_param_init(void *param, int frame_id, int state);
+
+int mtk_fd_ctx_finish_frame(struct mtk_fd_ctx *dev_ctx,
+			    struct mtk_fd_ctx_frame_bundle *frame_bundle,
+			    int done);
+
+int mtk_fd_ctx_frame_bundle_init(struct mtk_fd_ctx_frame_bundle *frame_bundle);
+
+void mtk_fd_ctx_frame_bundle_add(struct mtk_fd_ctx *ctx,
+				 struct mtk_fd_ctx_frame_bundle *bundle,
+				 struct mtk_fd_ctx_buffer *ctx_buf);
+
+int mtk_fd_ctx_trigger_job(struct mtk_fd_ctx *dev_ctx,
+			   struct mtk_fd_ctx_frame_bundle *bundle_data);
+
+int mtk_fd_ctx_fmt_set_img(struct mtk_fd_ctx *dev_ctx, int queue_id,
+			   struct v4l2_pix_format_mplane *user_fmt,
+			   struct v4l2_pix_format_mplane *node_fmt);
+
+int mtk_fd_ctx_fmt_set_meta(struct mtk_fd_ctx *dev_ctx, int queue_id,
+			    struct v4l2_meta_format *user_fmt,
+			    struct v4l2_meta_format *node_fmt);
+
+int mtk_fd_ctx_format_load_default_fmt(struct mtk_fd_ctx_queue *queue,
+				       struct v4l2_format *fmt_to_fill);
+
+int mtk_fd_ctx_streamon(struct mtk_fd_ctx *dev_ctx);
+int mtk_fd_ctx_streamoff(struct mtk_fd_ctx *dev_ctx);
+int mtk_fd_ctx_release(struct mtk_fd_ctx *dev_ctx);
+int mtk_fd_ctx_open(struct mtk_fd_ctx *dev_ctx);
+int mtk_fd_ctx_fd_init(struct mtk_fd_ctx *ctx);
+
+#endif /*__MTK_FD_CTX_H__*/
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-dev-ctx-core.c b/drivers/media/platform/mtk-isp/fd/mtk_fd-dev-ctx-core.c
new file mode 100644
index 000000000000..731443691fd6
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-dev-ctx-core.c
@@ -0,0 +1,912 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include <linux/dma-mapping.h>
+
+#include "mtk_fd.h"
+#include "mtk_fd-dev.h"
+#include "mtk_fd-smem.h"
+#include "mtk_fd-v4l2.h"
+
+#if KERNEL_VERSION(4, 8, 0) >= MTK_FD_KERNEL_BASE_VERSION
+#include <linux/dma-attrs.h>
+#endif
+
+struct vb2_v4l2_buffer *mtk_fd_ctx_buffer_get_vb2_v4l2_buffer
+(struct mtk_fd_ctx_buffer *ctx_buf)
+{
+	struct mtk_fd_dev_buffer *dev_buf = NULL;
+
+	if (!ctx_buf) {
+		pr_err("Failed to convert ctx_buf to dev_buf: Null pointer\n");
+		return NULL;
+	}
+
+	dev_buf	= mtk_fd_ctx_buf_to_dev_buf(ctx_buf);
+
+	return &dev_buf->m2m2_buf.vbb;
+}
+
+int mtk_fd_ctx_core_queue_setup(struct mtk_fd_ctx *ctx,
+				struct mtk_fd_ctx_queues_setting *
+				queues_setting)
+{
+	int queue_idx = 0;
+	int i = 0;
+
+	for (i = 0; i < queues_setting->total_output_queues; i++) {
+		struct mtk_fd_ctx_queue_desc *queue_desc =
+			&queues_setting->output_queue_descs[i];
+		ctx->queue[queue_idx].desc = *queue_desc;
+		queue_idx++;
+	}
+
+	/* Setup the capture queue */
+	for (i = 0; i < queues_setting->total_capture_queues; i++) {
+		struct mtk_fd_ctx_queue_desc *queue_desc =
+			&queues_setting->capture_queue_descs[i];
+		ctx->queue[queue_idx].desc = *queue_desc;
+		queue_idx++;
+	}
+
+	ctx->queues_attr.master = queues_setting->master;
+	ctx->queues_attr.total_num = queue_idx;
+	ctx->dev_node_num = ctx->queues_attr.total_num;
+	strcpy(ctx->device_name, MTK_FD_DEV_NAME);
+	return 0;
+}
+
+/* Mediatek FD context core initialization */
+int mtk_fd_ctx_core_init(struct mtk_fd_ctx *ctx,
+			 struct platform_device *pdev, int ctx_id,
+			 struct mtk_fd_ctx_desc *ctx_desc,
+			 struct platform_device *proc_pdev,
+			 struct platform_device *smem_pdev)
+{
+	/* Initialize main data structure */
+	int r = 0;
+
+#if KERNEL_VERSION(4, 8, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	ctx->smem_vb2_alloc_ctx =
+		vb2_dma_contig_init_ctx(&smem_pdev->dev);
+	ctx->img_vb2_alloc_ctx =
+		vb2_dma_contig_init_ctx(&pdev->dev);
+#else
+	ctx->smem_vb2_alloc_ctx = &smem_pdev->dev;
+	ctx->img_vb2_alloc_ctx = &pdev->dev;
+#endif
+	if (IS_ERR((__force void *)ctx->smem_vb2_alloc_ctx))
+		pr_err("Failed to alloc vb2 dma context: smem_vb2_alloc_ctx");
+
+	if (IS_ERR((__force void *)ctx->img_vb2_alloc_ctx))
+		pr_err("Failed to alloc vb2 dma context: img_vb2_alloc_ctx");
+
+	ctx->pdev = pdev;
+	ctx->ctx_id = ctx_id;
+	/* keep th smem pdev to use related iommu functions */
+	ctx->smem_device = smem_pdev;
+
+	/* Will set default enabled after passing the unit test */
+	ctx->mode = MTK_FD_CTX_MODE_DEBUG_OFF;
+
+	/* initialized the global frame index of the device context */
+	atomic_set(&ctx->frame_param_sequence, 0);
+	spin_lock_init(&ctx->qlock);
+
+	/* setup the core operation of the device context */
+	if (ctx_desc && ctx_desc->init)
+		r = ctx_desc->init(ctx);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_core_init);
+
+int mtk_fd_ctx_core_exit(struct mtk_fd_ctx *ctx)
+{
+#if KERNEL_VERSION(4, 8, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	vb2_dma_contig_cleanup_ctx(ctx->smem_vb2_alloc_ctx);
+	vb2_dma_contig_cleanup_ctx(ctx->img_vb2_alloc_ctx);
+#else
+	ctx->smem_vb2_alloc_ctx = NULL;
+	ctx->img_vb2_alloc_ctx = NULL;
+#endif
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_core_exit);
+
+int mtk_fd_ctx_next_global_frame_sequence(struct mtk_fd_ctx *ctx, int locked)
+{
+	int global_frame_sequence =
+		atomic_inc_return(&ctx->frame_param_sequence);
+
+	if (!locked)
+		spin_lock(&ctx->qlock);
+
+	global_frame_sequence =
+		(global_frame_sequence & 0x0000FFFF) | (ctx->ctx_id << 16);
+
+	if (!locked)
+		spin_unlock(&ctx->qlock);
+
+	return global_frame_sequence;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_next_global_frame_sequence);
+
+static void mtk_fd_ctx_buffer_done
+	(struct mtk_fd_ctx_buffer *ctx_buf, int state)
+{
+		if (!ctx_buf || state != MTK_FD_CTX_BUFFER_DONE ||
+		    state != MTK_FD_CTX_BUFFER_FAILED)
+			return;
+
+		ctx_buf->state = state;
+}
+
+struct mtk_fd_ctx_frame_bundle *mtk_fd_ctx_get_processing_frame
+(struct mtk_fd_ctx *dev_ctx, int frame_id)
+{
+	struct mtk_fd_ctx_frame_bundle *frame_bundle = NULL;
+
+	spin_lock(&dev_ctx->qlock);
+
+	list_for_each_entry(frame_bundle,
+			    &dev_ctx->processing_frames.list, list) {
+		if (frame_bundle->id == frame_id) {
+			spin_unlock(&dev_ctx->qlock);
+			return frame_bundle;
+		}
+	}
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return NULL;
+}
+
+/**
+ * structure mtk_fd_ctx_finish_param must be the first elemt of param
+ * So that the buffer can be return to vb2 queue successfully
+ */
+int mtk_fd_ctx_core_finish_param_init(void *param, int frame_id, int state)
+{
+	struct mtk_fd_ctx_finish_param *fram_param =
+		(struct mtk_fd_ctx_finish_param *)param;
+	fram_param->frame_id = frame_id;
+	fram_param->state = state;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_core_finish_param_init);
+
+void mtk_fd_ctx_frame_bundle_add(struct mtk_fd_ctx *ctx,
+				 struct mtk_fd_ctx_frame_bundle *bundle,
+				 struct mtk_fd_ctx_buffer *ctx_buf)
+{
+	int queue_id = 0;
+	struct mtk_fd_ctx_queue *ctx_queue = NULL;
+
+	if (!bundle || !ctx_buf) {
+		pr_warn("Add buffer to frame bundle failed, bundle(%llx),buf(%llx)\n",
+			(long long)bundle, (long long)ctx_buf);
+		return;
+	}
+
+	queue_id = ctx_buf->queue;
+
+	if (bundle->buffers[queue_id])
+		pr_warn("Queue(%d) buffer has alreay in this bundle, overwrite happen\n",
+			queue_id);
+
+	pr_debug("Add queue(%d) buffer%llx\n",
+		 queue_id, (unsigned long long)ctx_buf);
+		 bundle->buffers[queue_id] = ctx_buf;
+
+	/* Fill context queue related information */
+	ctx_queue = &ctx->queue[queue_id];
+
+	if (!ctx_queue) {
+		pr_err("Can't find ctx queue (%d)\n", queue_id);
+		return;
+	}
+
+	if (ctx->queue[ctx_buf->queue].desc.image) {
+		if (ctx->queue[ctx_buf->queue].desc.capture)
+			bundle->num_img_capture_bufs++;
+		else
+			bundle->num_img_output_bufs++;
+	} else {
+		if (ctx->queue[ctx_buf->queue].desc.capture)
+			bundle->num_meta_capture_bufs++;
+		else
+			bundle->num_meta_output_bufs++;
+	}
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_frame_bundle_add);
+
+void mtk_fd_ctx_buf_init(struct mtk_fd_ctx_buffer *b,
+			 unsigned int queue, dma_addr_t daddr)
+{
+	b->state = MTK_FD_CTX_BUFFER_NEW;
+	b->queue = queue;
+	b->daddr = daddr;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_buf_init);
+
+enum mtk_fd_ctx_buffer_state
+	mtk_fd_ctx_get_buffer_state(struct mtk_fd_ctx_buffer *b)
+{
+	return b->state;
+}
+
+bool mtk_fd_ctx_is_streaming(struct mtk_fd_ctx *ctx)
+{
+	return ctx->streaming;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_is_streaming);
+
+static int mtk_fd_ctx_free_frame(struct mtk_fd_ctx *dev_ctx,
+				 struct mtk_fd_ctx_frame_bundle *frame_bundle)
+{
+	spin_lock(&dev_ctx->qlock);
+
+	frame_bundle->state = MTK_FD_CTX_FRAME_NEW;
+	list_del(&frame_bundle->list);
+	list_add_tail(&frame_bundle->list, &dev_ctx->free_frames.list);
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return 0;
+}
+
+int mtk_fd_ctx_core_job_finish(struct mtk_fd_ctx *dev_ctx,
+			       struct mtk_fd_ctx_finish_param *param)
+{
+	int i = 0;
+	struct platform_device *pdev = dev_ctx->pdev;
+	struct mtk_fd_ctx_finish_param *fram_param =
+		(struct mtk_fd_ctx_finish_param *)param;
+	struct mtk_fd_dev *fd_dev = NULL;
+	struct mtk_fd_ctx_frame_bundle *frame = NULL;
+	enum vb2_buffer_state vbf_state = VB2_BUF_STATE_DONE;
+	enum mtk_fd_ctx_buffer_state ctxf_state =
+		MTK_FD_CTX_BUFFER_DONE;
+	int user_sequence = 0;
+
+	const int ctx_id =
+		MTK_FD_GET_CTX_ID_FROM_SEQUENCE(fram_param->frame_id);
+	u64 timestamp = 0;
+
+	pr_debug("mtk_fd_ctx_core_job_finish_cb: param (%llx), platform_device(%llx)\n",
+		 (unsigned long long)param, (unsigned long long)pdev);
+
+	if (!dev_ctx)
+		pr_err("dev_ctx can't be null, can't release the frame\n");
+
+	fd_dev = mtk_fd_ctx_to_dev(dev_ctx);
+
+	if (fram_param) {
+		dev_info(&fd_dev->pdev->dev,
+			 "CB recvied from ctx(%d), frame(%d), state(%d), fd_dev(%llx)\n",
+			 ctx_id, fram_param->frame_id,
+			 fram_param->state, (long long)fd_dev);
+	} else {
+		dev_err(&fd_dev->pdev->dev,
+			"CB recvied from ctx(%d), frame param is NULL\n",
+			ctx_id);
+			return -EINVAL;
+	}
+
+	/* Get the buffers of the processed frame */
+	frame = mtk_fd_ctx_get_processing_frame(&fd_dev->ctx,
+						fram_param->frame_id);
+
+	if (!frame) {
+		pr_err("Can't find the frame boundle, Frame(%d)\n",
+		       fram_param->frame_id);
+		return -EINVAL;
+	}
+
+	if (fram_param->state == MTK_FD_CTX_FRAME_DATA_ERROR) {
+		vbf_state = VB2_BUF_STATE_ERROR;
+		ctxf_state = MTK_FD_CTX_BUFFER_FAILED;
+	}
+
+	/**
+	 * Set the buffer's VB2 status so that
+	 * the user can dequeue the buffer
+	 */
+	timestamp = ktime_get_ns();
+	for (i = 0; i <= frame->last_index; i++) {
+		struct mtk_fd_ctx_buffer *ctx_buf = frame->buffers[i];
+
+		if (!ctx_buf) {
+			dev_dbg(&fd_dev->pdev->dev,
+				"ctx_buf(queue id= %d) of frame(%d)is NULL\n",
+				i, fram_param->frame_id);
+			continue;
+		} else {
+			struct vb2_v4l2_buffer *b =
+				mtk_fd_ctx_buffer_get_vb2_v4l2_buffer(ctx_buf);
+			b->vb2_buf.timestamp = ktime_get_ns();
+			user_sequence = ctx_buf->user_sequence;
+			mtk_fd_ctx_buffer_done(ctx_buf, ctxf_state);
+			mtk_fd_v4l2_buffer_done(&b->vb2_buf, vbf_state);
+		}
+	}
+
+	mtk_fd_ctx_free_frame(&fd_dev->ctx, frame);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_core_job_finish);
+
+int mtk_fd_ctx_finish_frame(struct mtk_fd_ctx *dev_ctx,
+			    struct mtk_fd_ctx_frame_bundle *frame_bundle,
+			    int done)
+{
+	spin_lock(&dev_ctx->qlock);
+	frame_bundle->state = MTK_FD_CTX_FRAME_PROCESSING;
+	list_add_tail(&frame_bundle->list, &dev_ctx->processing_frames.list);
+	spin_unlock(&dev_ctx->qlock);
+	return 0;
+}
+
+static void set_img_fmt(struct v4l2_pix_format_mplane *mfmt_to_fill,
+			struct mtk_fd_ctx_format *ctx_fmt)
+{
+	int i = 0;
+
+	mfmt_to_fill->pixelformat = ctx_fmt->fmt.img.pixelformat;
+	mfmt_to_fill->num_planes = ctx_fmt->fmt.img.num_planes;
+
+	pr_info("%s: Fmt(%d),w(%d),h(%d)\n",
+		__func__,
+		mfmt_to_fill->pixelformat,
+		mfmt_to_fill->width,
+		mfmt_to_fill->height);
+
+	/**
+	 * The implementation wil be adjust after integrating MDP module
+	 * since it provides the common format suppporting function
+	 */
+	for (i = 0 ; i < mfmt_to_fill->num_planes; ++i) {
+		int bpl = (mfmt_to_fill->width *
+			   ctx_fmt->fmt.img.row_depth[i]) / 8;
+		int sizeimage = (mfmt_to_fill->width * mfmt_to_fill->height *
+				 ctx_fmt->fmt.img.depth[i]) / 8;
+
+		mfmt_to_fill->plane_fmt[i].bytesperline = bpl;
+		mfmt_to_fill->plane_fmt[i].sizeimage = sizeimage;
+		pr_info("plane(%d):bpl(%d),sizeimage(%u)\n",
+			i, bpl, mfmt_to_fill->plane_fmt[i].sizeimage);
+	}
+}
+
+static void set_meta_fmt(struct v4l2_meta_format *metafmt_to_fill,
+			 struct mtk_fd_ctx_format *ctx_fmt)
+{
+	metafmt_to_fill->dataformat = ctx_fmt->fmt.meta.dataformat;
+
+	if (ctx_fmt->fmt.meta.max_buffer_size <= 0 ||
+	    ctx_fmt->fmt.meta.max_buffer_size >
+	    MTK_FD_CTX_META_BUF_DEFAULT_SIZE) {
+		pr_warn("buf size of meta(%u) can't be 0, use default %u\n",
+			ctx_fmt->fmt.meta.dataformat,
+			MTK_FD_CTX_META_BUF_DEFAULT_SIZE);
+		metafmt_to_fill->buffersize = MTK_FD_CTX_META_BUF_DEFAULT_SIZE;
+	} else {
+		pr_info("Load the meta size setting %u\n",
+			ctx_fmt->fmt.meta.max_buffer_size);
+		metafmt_to_fill->buffersize = ctx_fmt->fmt.meta.max_buffer_size;
+	}
+}
+
+/* Get the default format setting */
+int mtk_fd_ctx_format_load_default_fmt(struct mtk_fd_ctx_queue *queue,
+				       struct v4l2_format *fmt_to_fill)
+{
+	struct mtk_fd_ctx_format *ctx_fmt = NULL;
+
+	if (queue->desc.num_fmts == 0)
+		return 0; /* no format support list associated to this queue */
+
+	if (queue->desc.default_fmt_idx >= queue->desc.num_fmts) {
+		pr_warn("Queue(%s) err: default idx(%d) must < num_fmts(%d)\n",
+			queue->desc.name, queue->desc.default_fmt_idx,
+			queue->desc.num_fmts);
+		queue->desc.default_fmt_idx = 0;
+		pr_warn("Queue(%s) : reset default idx(%d)\n",
+			queue->desc.name, queue->desc.default_fmt_idx);
+	}
+
+	ctx_fmt	= &queue->desc.fmts[queue->desc.default_fmt_idx];
+
+	/* Check the type of the buffer */
+	if (queue->desc.image) {
+		struct v4l2_pix_format_mplane *node_fmt =
+			&fmt_to_fill->fmt.pix_mp;
+
+		if (queue->desc.capture) {
+			fmt_to_fill->type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+			node_fmt->width = MTK_FD_OUTPUT_MAX_WIDTH;
+			node_fmt->height = MTK_FD_OUTPUT_MAX_HEIGHT;
+		} else {
+			fmt_to_fill->type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+			node_fmt->width = MTK_FD_INPUT_MAX_WIDTH;
+			node_fmt->height = MTK_FD_INPUT_MAX_HEIGHT;
+		}
+		set_img_fmt(node_fmt, ctx_fmt);
+	}	else {
+		/* meta buffer type */
+		struct v4l2_meta_format *node_fmt = &fmt_to_fill->fmt.meta;
+
+		if (queue->desc.capture)
+			fmt_to_fill->type = V4L2_BUF_TYPE_META_CAPTURE;
+		else
+			fmt_to_fill->type = V4L2_BUF_TYPE_META_OUTPUT;
+
+		set_meta_fmt(node_fmt, ctx_fmt);
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_format_load_default_fmt);
+
+static struct mtk_fd_ctx_format *mtk_fd_ctx_find_fmt
+	(struct mtk_fd_ctx_queue *queue, u32 format)
+{
+	int i;
+	struct mtk_fd_ctx_format *ctx_fmt;
+
+	for (i = 0; i < queue->desc.num_fmts; i++) {
+		ctx_fmt = &queue->desc.fmts[i];
+		if (queue->desc.image) {
+			pr_debug("idx(%d), pixelformat(%x), fmt(%x)\n",
+				 i, ctx_fmt->fmt.img.pixelformat, format);
+			if (ctx_fmt->fmt.img.pixelformat == format)
+				return ctx_fmt;
+		} else {
+			if (ctx_fmt->fmt.meta.dataformat == format)
+				return ctx_fmt;
+		}
+	}
+	return NULL;
+}
+
+int mtk_fd_ctx_fmt_set_meta(struct mtk_fd_ctx *dev_ctx, int queue_id,
+			    struct v4l2_meta_format *user_fmt,
+			    struct v4l2_meta_format *node_fmt)
+{
+	struct mtk_fd_ctx_queue *queue = NULL;
+	struct mtk_fd_ctx_format *ctx_fmt;
+
+	if (queue_id >= dev_ctx->queues_attr.total_num) {
+		pr_err("Invalid queue id:%d\n", queue_id);
+		return -EINVAL;
+	}
+
+	queue = &dev_ctx->queue[queue_id];
+	if (!user_fmt || !node_fmt)
+		return -EINVAL;
+
+	ctx_fmt = mtk_fd_ctx_find_fmt(queue, user_fmt->dataformat);
+	if (!ctx_fmt)
+		return -EINVAL;
+
+	queue->ctx_fmt = ctx_fmt;
+	set_meta_fmt(node_fmt, ctx_fmt);
+	*user_fmt = *node_fmt;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_fmt_set_meta);
+
+int mtk_fd_ctx_fmt_set_img(struct mtk_fd_ctx *dev_ctx, int queue_id,
+			   struct v4l2_pix_format_mplane *user_fmt,
+			   struct v4l2_pix_format_mplane *node_fmt)
+{
+	struct mtk_fd_ctx_queue *queue = NULL;
+	struct mtk_fd_ctx_format *ctx_fmt;
+
+	if (queue_id >= dev_ctx->queues_attr.total_num) {
+		pr_err("Invalid queue id:%d\n", queue_id);
+		return -EINVAL;
+	}
+
+	queue = &dev_ctx->queue[queue_id];
+	if (!user_fmt || !node_fmt)
+		return -EINVAL;
+
+	ctx_fmt = mtk_fd_ctx_find_fmt(queue, user_fmt->pixelformat);
+	if (!ctx_fmt)
+		return -EINVAL;
+
+	queue->ctx_fmt = ctx_fmt;
+	node_fmt->width = user_fmt->width;
+	node_fmt->height = user_fmt->height;
+
+	set_img_fmt(node_fmt, ctx_fmt);
+
+	*user_fmt = *node_fmt;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_fmt_set_img);
+
+int mtk_fd_ctx_streamon(struct mtk_fd_ctx *dev_ctx)
+{
+	int ret = 0;
+
+	if (dev_ctx->streaming) {
+		pr_warn("stream on failed, pdev(%llx), ctx(%d) already stream on\n",
+			(long long)dev_ctx->pdev, dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	ret = mtk_fd_streamon(dev_ctx->pdev, dev_ctx->ctx_id);
+	if (ret) {
+		pr_err("streamon: ctx(%d) failed, notified by context\n",
+		       dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	dev_ctx->streaming = true;
+	ret = mtk_fd_dev_queue_buffers(mtk_fd_ctx_to_dev(dev_ctx), true);
+	if (ret)
+		pr_err("failed to queue initial buffers (%d)", ret);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_streamon);
+
+int mtk_fd_ctx_streamoff(struct mtk_fd_ctx *dev_ctx)
+{
+	int ret = 0;
+
+	if (!dev_ctx->streaming) {
+		pr_warn("Do nothing, pdev(%llx), ctx(%d) is already stream off\n",
+			(long long)dev_ctx->pdev, dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	ret = mtk_fd_streamoff(dev_ctx->pdev, dev_ctx->ctx_id);
+	if (ret) {
+		pr_warn("streamoff: ctx(%d) failed, notified by context\n",
+			dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	dev_ctx->streaming = false;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_streamoff);
+
+int mtk_fd_ctx_init_frame_bundles(struct mtk_fd_ctx *dev_ctx)
+{
+	int i = 0;
+
+	dev_ctx->num_frame_bundle = VB2_MAX_FRAME;
+
+	spin_lock(&dev_ctx->qlock);
+
+	/* Reset the queue*/
+	INIT_LIST_HEAD(&dev_ctx->processing_frames.list);
+	INIT_LIST_HEAD(&dev_ctx->free_frames.list);
+
+	for (i = 0; i < dev_ctx->num_frame_bundle; i++) {
+		struct mtk_fd_ctx_frame_bundle *frame_bundle =
+			&dev_ctx->frame_bundles[i];
+		frame_bundle->state = MTK_FD_CTX_FRAME_NEW;
+		list_add_tail(&frame_bundle->list, &dev_ctx->free_frames.list);
+	}
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return 0;
+}
+
+int mtk_fd_ctx_open(struct mtk_fd_ctx *dev_ctx)
+{
+	struct mtk_fd_dev *fd_dev = mtk_fd_ctx_to_dev(dev_ctx);
+	unsigned int enabled_dma_ports = 0;
+	int i = 0;
+
+	if (!dev_ctx)
+		return -EINVAL;
+
+	/* Get the enabled DMA ports */
+	for (i = 0; i < fd_dev->mem2mem2.num_nodes; i++) {
+		if (fd_dev->mem2mem2.nodes[i].enabled)
+			enabled_dma_ports |= dev_ctx->queue[i].desc.dma_port;
+	}
+
+	dev_ctx->enabled_dma_ports = enabled_dma_ports;
+
+	dev_dbg(&fd_dev->pdev->dev, "open device: (%llx)\n",
+		(long long)&fd_dev->pdev->dev);
+
+	/* Workaround for SCP EMI access */
+	mtk_fd_smem_enable_mpu(&dev_ctx->smem_device->dev);
+
+	/* Init the frame bundle pool */
+	mtk_fd_ctx_init_frame_bundles(dev_ctx);
+
+	return mtk_fd_open(dev_ctx->pdev);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_open);
+
+int mtk_fd_ctx_release(struct mtk_fd_ctx *dev_ctx)
+{
+	return mtk_fd_release(dev_ctx->pdev);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_release);
+
+static int mtk_fd_ctx_core_job_start(struct mtk_fd_ctx *dev_ctx,
+				     struct mtk_fd_ctx_frame_bundle *bundle)
+{
+	struct platform_device *pdev = dev_ctx->pdev;
+	int ret = 0;
+	struct v4l2_fd_param fd_param;
+	struct mtk_fd_ctx_buffer *ctx_buf_yuv_in = NULL;
+	struct mtk_fd_ctx_buffer *ctx_buf_meta_in = NULL;
+	struct mtk_fd_ctx_buffer *ctx_buf_meta_out = NULL;
+
+	if (!pdev || !bundle) {
+		dev_err(&pdev->dev,
+			"pdev(%llx) and param(%llx) in start can't be NULL\n",
+			(long long)pdev, (long long)bundle);
+		return -EINVAL;
+	}
+	memset(&fd_param, 0, sizeof(struct v4l2_fd_param));
+	fd_param.frame_id = bundle->id;
+
+	/* Img-in buffer */
+	ctx_buf_yuv_in = bundle->buffers[MTK_FD_CTX_FD_YUV_IN];
+	if (ctx_buf_yuv_in) {
+		fd_param.src_img.iova =	(uint32_t)ctx_buf_yuv_in->daddr;
+		fd_param.src_img.va = (uint64_t)ctx_buf_yuv_in->vaddr;
+		fd_param.src_img_h =
+			(uint16_t)ctx_buf_yuv_in->fmt.pix_mp.height;
+		fd_param.src_img_w =
+			(uint16_t)ctx_buf_yuv_in->fmt.pix_mp.width;
+	}
+
+	/* Meta-in buffer */
+	ctx_buf_meta_in = bundle->buffers[MTK_FD_CTX_FD_CONFIG_IN];
+	if (ctx_buf_meta_in) {
+		fd_param.fd_user_param.va = (uint64_t)ctx_buf_meta_in->vaddr;
+		fd_param.fd_user_param.pa = (uint32_t)ctx_buf_meta_in->paddr;
+		fd_param.fd_user_param.iova = (uint32_t)ctx_buf_meta_in->daddr;
+	} else {
+		dev_err(&pdev->dev, "meta in is null!\n");
+		fd_param.fd_user_param.pa = 0;
+		fd_param.fd_user_param.va = 0;
+		fd_param.fd_user_param.iova = 0;
+	}
+
+	/* Meta-out buffer */
+	ctx_buf_meta_out = bundle->buffers[MTK_FD_CTX_FD_OUT];
+	if (ctx_buf_meta_out) {
+		fd_param.fd_user_result.va = (uint64_t)ctx_buf_meta_out->vaddr;
+		fd_param.fd_user_result.pa = (uint32_t)ctx_buf_meta_out->paddr;
+		fd_param.fd_user_result.iova =
+					(uint32_t)ctx_buf_meta_out->daddr;
+	} else {
+		dev_err(&pdev->dev, "meta out is null!\n");
+		fd_param.fd_user_result.pa = 0;
+		fd_param.fd_user_result.va = 0;
+		fd_param.fd_user_result.iova = 0;
+	}
+
+	dev_info(&pdev->dev,
+		 "Delegate job to mtk_fd_enqueue: pdev(0x%llx), frame(%d)\n",
+		 (long long)pdev, bundle->id);
+	ret = mtk_fd_enqueue(pdev, &fd_param);
+
+	if (ret) {
+		dev_warn(&pdev->dev, "mtk_fd_enqueue failed: %d\n", ret);
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+static void debug_bundle(struct mtk_fd_ctx_frame_bundle *bundle_data)
+{
+	int i = 0;
+
+	if (!bundle_data) {
+		pr_warn("bundle_data is NULL\n");
+		return;
+	}
+
+	pr_debug("bundle buf nums (%d, %d,%d,%d)\n",
+		 bundle_data->num_img_capture_bufs,
+		 bundle_data->num_img_output_bufs,
+		 bundle_data->num_meta_capture_bufs,
+		 bundle_data->num_meta_output_bufs);
+
+	for (i = 0; i < 16 ; i++) {
+		pr_debug("Bundle, buf[%d] = %llx\n",
+			 i,
+			 (unsigned long long)bundle_data->buffers[i]);
+	}
+
+	pr_debug("Bundle last idx: %d\n", bundle_data->last_index);
+}
+
+static struct mtk_fd_ctx_frame_bundle *mtk_fd_ctx_get_free_frame
+	(struct mtk_fd_ctx *dev_ctx)
+{
+	struct mtk_fd_ctx_frame_bundle *frame_bundle = NULL;
+
+	spin_lock(&dev_ctx->qlock);
+	list_for_each_entry(frame_bundle,
+			    &dev_ctx->free_frames.list, list){
+		pr_debug("Check frame: state %d, new should be %d\n",
+			 frame_bundle->state, MTK_FD_CTX_FRAME_NEW);
+		if (frame_bundle->state == MTK_FD_CTX_FRAME_NEW) {
+			frame_bundle->state = MTK_FD_CTX_FRAME_PREPARED;
+			pr_debug("Found free frame\n");
+			spin_unlock(&dev_ctx->qlock);
+			return frame_bundle;
+		}
+	}
+	spin_unlock(&dev_ctx->qlock);
+	pr_err("Can't found any bundle is MTK_FD_CTX_FRAME_NEW\n");
+	return NULL;
+}
+
+static int mtk_fd_ctx_process_frame
+	(struct mtk_fd_ctx *dev_ctx,
+	 struct mtk_fd_ctx_frame_bundle *frame_bundle)
+{
+	spin_lock(&dev_ctx->qlock);
+
+	frame_bundle->state = MTK_FD_CTX_FRAME_PROCESSING;
+	list_del(&frame_bundle->list);
+	list_add_tail(&frame_bundle->list, &dev_ctx->processing_frames.list);
+
+	spin_unlock(&dev_ctx->qlock);
+	return 0;
+}
+
+int mtk_fd_ctx_trigger_job(struct mtk_fd_ctx  *dev_ctx,
+			   struct mtk_fd_ctx_frame_bundle *bundle_data)
+{
+	/* Scan all buffers and filled the ipi frame data*/
+	int i = 0;
+	struct mtk_fd_ctx_finish_param fram_param;
+
+	struct mtk_fd_ctx_frame_bundle *bundle =
+		mtk_fd_ctx_get_free_frame(dev_ctx);
+
+	pr_debug("Bundle data: , ctx id:%d\n",
+		 dev_ctx->ctx_id);
+
+	debug_bundle(bundle_data);
+
+	if (!bundle) {
+		pr_err("bundle can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+	if (!bundle_data) {
+		pr_err("bundle_data can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	pr_debug("Copy bundle_data->buffers to bundle->buffers\n");
+	memcpy(bundle->buffers, bundle_data->buffers,
+	       sizeof(struct mtk_fd_ctx_buffer *) *
+	       MTK_FD_CTX_FRAME_BUNDLE_BUFFER_MAX);
+
+	pr_debug("bundle setup (%d, %d,%d,%d)\n",
+		 bundle_data->num_img_capture_bufs,
+		 bundle_data->num_img_output_bufs,
+		 bundle_data->num_meta_capture_bufs,
+		 bundle_data->num_meta_output_bufs);
+
+	bundle->num_img_capture_bufs = bundle_data->num_img_capture_bufs;
+	bundle->num_img_output_bufs = bundle_data->num_img_output_bufs;
+	bundle->num_meta_capture_bufs = bundle_data->num_meta_capture_bufs;
+	bundle->num_meta_output_bufs = bundle_data->num_meta_output_bufs;
+	bundle->id = mtk_fd_ctx_next_global_frame_sequence(dev_ctx,
+							   dev_ctx->ctx_id);
+	bundle->last_index = dev_ctx->queues_attr.total_num - 1;
+
+	debug_bundle(bundle);
+
+	pr_debug("Fill Address data\n");
+	for (i = 0; i <= bundle->last_index; i++) {
+		struct mtk_fd_ctx_buffer *ctx_buf = bundle->buffers[i];
+		struct vb2_v4l2_buffer *b = NULL;
+
+		pr_debug("Process queue[%d], ctx_buf:(%llx)\n",
+			 i, (unsigned long long)ctx_buf);
+
+		if (!ctx_buf) {
+			pr_warn("queue[%d], ctx_buf is NULL!!\n", i);
+			continue;
+		}
+
+		pr_debug("Get VB2 V4L2 buffer\n");
+		b = mtk_fd_ctx_buffer_get_vb2_v4l2_buffer(ctx_buf);
+
+		ctx_buf->image = dev_ctx->queue[ctx_buf->queue].desc.image;
+		ctx_buf->capture = dev_ctx->queue[ctx_buf->queue].desc.capture;
+		/* copy the fmt setting for queue's fmt*/
+		ctx_buf->fmt = dev_ctx->queue[ctx_buf->queue].fmt;
+		ctx_buf->ctx_fmt = dev_ctx->queue[ctx_buf->queue].ctx_fmt;
+			ctx_buf->frame_id = bundle->id;
+		ctx_buf->daddr =
+			vb2_dma_contig_plane_dma_addr(&b->vb2_buf, 0);
+		pr_debug("%s:vb2_buf: type(%d),idx(%d),mem(%d)\n",
+			 __func__,
+			 b->vb2_buf.type,
+			 b->vb2_buf.index,
+			 b->vb2_buf.memory);
+		ctx_buf->vaddr = vb2_plane_vaddr(&b->vb2_buf, 0);
+		ctx_buf->buffer_usage = dev_ctx->queue[i].buffer_usage;
+		ctx_buf->rotation = dev_ctx->queue[i].rotation;
+		pr_debug("Buf: queue(%d), vaddr(%llx), daddr(%llx)",
+			 ctx_buf->queue, (unsigned long long)ctx_buf->vaddr,
+			 (unsigned long long)ctx_buf->daddr);
+
+		if (!ctx_buf->image) {
+			ctx_buf->paddr =
+				mtk_fd_smem_iova_to_phys
+					(&dev_ctx->smem_device->dev,
+					 ctx_buf->daddr);
+		} else {
+			pr_debug("No pa: it is a image buffer\n");
+			ctx_buf->paddr = 0;
+		}
+		ctx_buf->state = MTK_FD_CTX_BUFFER_PROCESSING;
+	}
+
+	if (mtk_fd_ctx_process_frame(dev_ctx, bundle)) {
+		pr_err("mtk_fd_ctx_process_frame failed: frame(%d)\n",
+		       bundle->id);
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	if (dev_ctx->mode == MTK_FD_CTX_MODE_DEBUG_BYPASS_JOB_TRIGGER) {
+		memset(&fram_param, 0, sizeof(struct mtk_fd_ctx_finish_param));
+		fram_param.frame_id = bundle->id;
+		fram_param.state = MTK_FD_CTX_FRAME_DATA_DONE;
+		pr_debug("Ctx(%d) in HW bypass mode, will not trigger hw\n",
+			 dev_ctx->ctx_id);
+
+		mtk_fd_ctx_core_job_finish(dev_ctx,	(void *)&fram_param);
+		return 0;
+	}
+
+	if (mtk_fd_ctx_core_job_start(dev_ctx, bundle))
+		goto FAILE_JOB_NOT_TRIGGER;
+	return 0;
+
+FAILE_JOB_NOT_TRIGGER:
+	pr_debug("FAILE_JOB_NOT_TRIGGER: init fram_param: %llx\n",
+		 (unsigned long long)&fram_param);
+	memset(&fram_param, 0, sizeof(struct mtk_fd_ctx_finish_param));
+	fram_param.frame_id = bundle->id;
+	fram_param.state = MTK_FD_CTX_FRAME_DATA_ERROR;
+	pr_debug("Call mtk_fd_ctx_core_job_finish_cb: fram_param: %llx",
+		 (unsigned long long)&fram_param);
+	mtk_fd_ctx_core_job_finish(dev_ctx, (void *)&fram_param);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_trigger_job);
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-dev.c b/drivers/media/platform/mtk-isp/fd/mtk_fd-dev.c
new file mode 100644
index 000000000000..7e3acf7e4bac
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-dev.c
@@ -0,0 +1,355 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ * Copyright (C) 2017 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_FD-dev is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk_fd-dev.h"
+
+static struct platform_device *mtk_fd_dev_of_find_smem_dev
+	(struct platform_device *pdev);
+
+/* Initliaze a mtk_fd_dev representing a completed HW FD */
+/* device */
+int mtk_fd_dev_init(struct mtk_fd_dev *fd_dev,
+		    struct platform_device *pdev,
+		    struct media_device *media_dev,
+		    struct v4l2_device *v4l2_dev)
+{
+	int r = 0;
+
+	fd_dev->pdev = pdev;
+
+	mutex_init(&fd_dev->lock);
+	atomic_set(&fd_dev->qbuf_barrier, 0);
+	init_waitqueue_head(&fd_dev->buf_drain_wq);
+
+	/* v4l2 sub-device registration */
+	r = mtk_fd_dev_mem2mem2_init(fd_dev, media_dev, v4l2_dev);
+
+	if (r) {
+		dev_err(&fd_dev->pdev->dev,
+			"failed to create V4L2 devices (%d)\n", r);
+		goto failed_mem2mem2;
+	}
+
+	return 0;
+
+failed_mem2mem2:
+	mutex_destroy(&fd_dev->lock);
+	return r;
+}
+
+int mtk_fd_dev_get_total_node(struct mtk_fd_dev *mtk_fd_dev)
+{
+	return mtk_fd_dev->ctx.queues_attr.total_num;
+}
+
+int mtk_fd_dev_mem2mem2_init(struct mtk_fd_dev *fd_dev,
+			     struct media_device *media_dev,
+			     struct v4l2_device *v4l2_dev)
+{
+	int r, i;
+	const int queue_master = fd_dev->ctx.queues_attr.master;
+
+	pr_info("mem2mem2.name: %s\n", fd_dev->ctx.device_name);
+	fd_dev->mem2mem2.name = fd_dev->ctx.device_name;
+	fd_dev->mem2mem2.model = fd_dev->ctx.device_name;
+	fd_dev->mem2mem2.num_nodes =
+		mtk_fd_dev_get_total_node(fd_dev);
+	fd_dev->mem2mem2.vb2_mem_ops = &vb2_dma_contig_memops;
+	fd_dev->mem2mem2.buf_struct_size =
+		sizeof(struct mtk_fd_dev_buffer);
+
+	fd_dev->mem2mem2.nodes = fd_dev->mem2mem2_nodes;
+	fd_dev->mem2mem2.dev = &fd_dev->pdev->dev;
+
+	for (i = 0; i < fd_dev->ctx.dev_node_num; i++) {
+		fd_dev->mem2mem2.nodes[i].name =
+			mtk_fd_dev_get_node_name(fd_dev, i);
+		fd_dev->mem2mem2.nodes[i].output =
+				(!fd_dev->ctx.queue[i].desc.capture);
+		fd_dev->mem2mem2.nodes[i].immutable = false;
+		fd_dev->mem2mem2.nodes[i].enabled = false;
+		atomic_set(&fd_dev->mem2mem2.nodes[i].sequence, 0);
+	}
+
+	/* Master queue is always enabled */
+	fd_dev->mem2mem2.nodes[queue_master].immutable = true;
+	fd_dev->mem2mem2.nodes[queue_master].enabled = true;
+
+	pr_info("register v4l2 for %llx\n",
+		(unsigned long long)fd_dev);
+	r = mtk_fd_mem2mem2_v4l2_register(fd_dev, media_dev, v4l2_dev);
+
+	if (r) {
+		pr_err("v4l2 init failed, dev(ctx:%d)\n", fd_dev->ctx.ctx_id);
+		return r;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_mem2mem2_init);
+
+void mtk_fd_dev_mem2mem2_exit(struct mtk_fd_dev *fd_dev)
+{
+	mtk_fd_v4l2_unregister(fd_dev);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_mem2mem2_exit);
+
+char *mtk_fd_dev_get_node_name
+	(struct mtk_fd_dev *fd_dev, int node)
+{
+	struct mtk_fd_ctx_queue_desc *mapped_queue_desc =
+		&fd_dev->ctx.queue[node].desc;
+
+	return mapped_queue_desc->name;
+}
+
+/* Get a free buffer from a video node */
+static struct mtk_fd_ctx_buffer __maybe_unused *mtk_fd_dev_queue_getbuf
+	(struct mtk_fd_dev *fd_dev, int node)
+{
+	struct mtk_fd_dev_buffer *buf;
+	int queue = -1;
+
+	if (node > fd_dev->ctx.dev_node_num || node < 0) {
+		dev_err(&fd_dev->pdev->dev, "Invalid mtk_fd_dev node.\n");
+		return NULL;
+	}
+
+	/* Get the corrosponding queue id of the video node */
+	/* Currently the queue id is the same as the node number */
+	queue = node;
+
+	if (queue < 0) {
+		dev_err(&fd_dev->pdev->dev, "Invalid mtk_fd_dev node.\n");
+		return NULL;
+	}
+
+	/* Find first free buffer from the node */
+	list_for_each_entry(buf, &fd_dev->mem2mem2.nodes[node].buffers,
+			    m2m2_buf.list) {
+		if (mtk_fd_ctx_get_buffer_state(&buf->ctx_buf)
+			== MTK_FD_CTX_BUFFER_NEW)
+			return &buf->ctx_buf;
+	}
+
+	/* There were no free buffers*/
+	return NULL;
+}
+
+int mtk_fd_dev_get_queue_id_of_dev_node(struct mtk_fd_dev *fd_dev,
+					struct mtk_fd_dev_video_device *node)
+{
+	return (node - fd_dev->mem2mem2.nodes);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_get_queue_id_of_dev_node);
+
+int mtk_fd_dev_queue_buffers(struct mtk_fd_dev *fd_dev,
+			     bool initial)
+{
+	unsigned int node;
+	int r = 0;
+	struct mtk_fd_dev_buffer *ibuf;
+	struct mtk_fd_ctx_frame_bundle bundle;
+	const int mtk_fd_dev_node_num = mtk_fd_dev_get_total_node(fd_dev);
+	const int queue_master = fd_dev->ctx.queues_attr.master;
+
+	memset(&bundle, 0, sizeof(struct mtk_fd_ctx_frame_bundle));
+
+	pr_info("%s, init(%d)\n", __func__, initial);
+
+	if (!mtk_fd_ctx_is_streaming(&fd_dev->ctx)) {
+		pr_info("%s: stream off, no hw enqueue triggered\n", __func__);
+		return 0;
+	}
+
+	mutex_lock(&fd_dev->lock);
+
+	/* Buffer set is queued to background driver (e.g. DIP, FD, and P1) */
+	/* only when master input buffer is ready */
+	if (!mtk_fd_dev_queue_getbuf(fd_dev, queue_master)) {
+		mutex_unlock(&fd_dev->lock);
+		return 0;
+	}
+
+	/* Check all node from the node after the master node */
+	for (node = (queue_master + 1) % mtk_fd_dev_node_num;
+		1; node = (node + 1) % mtk_fd_dev_node_num) {
+		pr_info("Check node(%d), queue enabled(%d), node enabled(%d)\n",
+			node, fd_dev->queue_enabled[node],
+			fd_dev->mem2mem2.nodes[node].enabled);
+
+		/* May skip some node according the scenario in the future */
+		if (fd_dev->queue_enabled[node] ||
+		    fd_dev->mem2mem2.nodes[node].enabled) {
+			struct mtk_fd_ctx_buffer *buf =
+				mtk_fd_dev_queue_getbuf(fd_dev, node);
+			char *node_name =
+				mtk_fd_dev_get_node_name(fd_dev, node);
+
+			if (!buf) {
+				dev_dbg(&fd_dev->pdev->dev,
+					"No free buffer of enabled node %s\n",
+					node_name);
+				break;
+			}
+
+			/* To show the debug message */
+			ibuf = container_of(buf,
+					    struct mtk_fd_dev_buffer, ctx_buf);
+			dev_dbg(&fd_dev->pdev->dev,
+				"may queue user %s buffer idx(%d) to ctx\n",
+				node_name,
+				ibuf->m2m2_buf.vbb.vb2_buf.index);
+			mtk_fd_ctx_frame_bundle_add(&fd_dev->ctx,
+						    &bundle, buf);
+		}
+
+		/* Stop if there is no free buffer in master input node */
+		if (node == queue_master) {
+			if (mtk_fd_dev_queue_getbuf(fd_dev, queue_master)) {
+				/* Has collected all buffer required */
+				mtk_fd_ctx_trigger_job(&fd_dev->ctx, &bundle);
+			} else {
+				pr_debug("no new buffer found in master node, not trigger job\n");
+				break;
+			}
+		}
+	}
+	mutex_unlock(&fd_dev->lock);
+
+	if (r && r != -EBUSY)
+		goto failed;
+
+	return 0;
+
+failed:
+	/*
+	 * On error, mark all buffers as failed which are not
+	 * yet queued to CSS
+	 */
+	dev_err(&fd_dev->pdev->dev,
+		"failed to queue buffer to ctx on queue %i (%d)\n",
+		node, r);
+
+	if (initial)
+		/* If we were called from streamon(), no need to finish bufs */
+		return r;
+
+	for (node = 0; node < mtk_fd_dev_node_num; node++) {
+		struct mtk_fd_dev_buffer *buf, *buf0;
+
+		if (!fd_dev->queue_enabled[node])
+			continue;	/* Skip disabled queues */
+
+		mutex_lock(&fd_dev->lock);
+		list_for_each_entry_safe
+			(buf, buf0,
+			 &fd_dev->mem2mem2.nodes[node].buffers,
+			 m2m2_buf.list) {
+			if (mtk_fd_ctx_get_buffer_state(&buf->ctx_buf) ==
+				MTK_FD_CTX_BUFFER_PROCESSING)
+				continue;	/* Was already queued, skip */
+
+			mtk_fd_v4l2_buffer_done(&buf->m2m2_buf.vbb.vb2_buf,
+						VB2_BUF_STATE_ERROR);
+		}
+		mutex_unlock(&fd_dev->lock);
+	}
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_queue_buffers);
+
+int mtk_fd_dev_core_init(struct platform_device *pdev,
+			 struct mtk_fd_dev *fd_dev,
+			 struct mtk_fd_ctx_desc *ctx_desc)
+{
+	return mtk_fd_dev_core_init_ext(pdev,
+		fd_dev, ctx_desc, NULL, NULL);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_core_init);
+
+int mtk_fd_dev_core_init_ext(struct platform_device *pdev,
+			     struct mtk_fd_dev *fd_dev,
+			     struct mtk_fd_ctx_desc *ctx_desc,
+			     struct media_device *media_dev,
+			     struct v4l2_device *v4l2_dev)
+{
+	int r;
+	struct platform_device *smem_dev = NULL;
+
+	smem_dev = mtk_fd_dev_of_find_smem_dev(pdev);
+
+	if (!smem_dev)
+		dev_err(&pdev->dev, "failed to find smem_dev\n");
+
+	/* Device context must be initialized before device instance */
+	r = mtk_fd_ctx_core_init(&fd_dev->ctx, pdev,
+				 0, ctx_desc, pdev, smem_dev);
+
+	dev_info(&pdev->dev, "init fd_dev: %llx\n",
+		 (unsigned long long)fd_dev);
+	/* init other device level members */
+	mtk_fd_dev_init(fd_dev, pdev, media_dev, v4l2_dev);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_core_init_ext);
+
+int mtk_fd_dev_core_release(struct platform_device *pdev,
+			    struct mtk_fd_dev *fd_dev)
+{
+	mtk_fd_dev_mem2mem2_exit(fd_dev);
+	mtk_fd_ctx_core_exit(&fd_dev->ctx);
+	mutex_destroy(&fd_dev->lock);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_dev_core_release);
+
+static struct platform_device *mtk_fd_dev_of_find_smem_dev
+	(struct platform_device *pdev)
+{
+	struct device_node *smem_dev_node = NULL;
+
+	if (!pdev) {
+		pr_err("Find_smem_dev failed, pdev can't be NULL\n");
+		return NULL;
+	}
+
+	smem_dev_node = of_parse_phandle(pdev->dev.of_node,
+					 "smem_device", 0);
+
+	if (!smem_dev_node) {
+		dev_err(&pdev->dev,
+			"failed to find isp smem device for (%s)\n",
+			pdev->name);
+		return NULL;
+	}
+
+	dev_dbg(&pdev->dev, "smem of node found, try to discovery device\n");
+	return of_find_device_by_node(smem_dev_node);
+}
+
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-dev.h b/drivers/media/platform/mtk-isp/fd/mtk_fd-dev.h
new file mode 100644
index 000000000000..d2b7d77fc7ec
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-dev.h
@@ -0,0 +1,198 @@
+/* SPDX-License-Identifier: GPL-2.0
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_FD-dev is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#ifndef __MTK_FD_DEV_H__
+#define __MTK_FD_DEV_H__
+
+#include <linux/platform_device.h>
+#include <linux/version.h>
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+#include "mtk_fd-ctx.h"
+
+/* Added the macro for early stage verification */
+/* based on kernel 4.4 environment. */
+/* I will remove the version check after getting */
+/* the devlopment platform based on 4.14 */
+#define MTK_FD_KERNEL_BASE_VERSION KERNEL_VERSION(4, 14, 0)
+
+#define MTK_FD_DEV_NODE_MAX			(MTK_FD_CTX_QUEUES)
+
+#define MTK_FD_INPUT_MIN_WIDTH		0U
+#define MTK_FD_INPUT_MIN_HEIGHT		0U
+#define MTK_FD_INPUT_MAX_WIDTH		480U
+#define MTK_FD_INPUT_MAX_HEIGHT		640U
+#define MTK_FD_OUTPUT_MIN_WIDTH		2U
+#define MTK_FD_OUTPUT_MIN_HEIGHT		2U
+#define MTK_FD_OUTPUT_MAX_WIDTH		480U
+#define MTK_FD_OUTPUT_MAX_HEIGHT		640U
+
+#define file_to_mtk_fd_node(__file) \
+	container_of(video_devdata(__file),\
+	struct mtk_fd_dev_video_device, vdev)
+
+#define mtk_fd_ctx_to_dev(__ctx) \
+	container_of(__ctx,\
+	struct mtk_fd_dev, ctx)
+
+#define mtk_fd_m2m_to_dev(__m2m) \
+	container_of(__m2m,\
+	struct mtk_fd_dev, mem2mem2)
+
+#define mtk_fd_subdev_to_dev(__sd) \
+	container_of(__sd, \
+	struct mtk_fd_dev, mem2mem2.subdev)
+
+#define mtk_fd_vbq_to_isp_node(__vq) \
+	container_of(__vq, \
+	struct mtk_fd_dev_video_device, vbq)
+
+#define mtk_fd_ctx_buf_to_dev_buf(__ctx_buf) \
+	container_of(__ctx_buf, \
+	struct mtk_fd_dev_buffer, ctx_buf)
+
+#define mtk_fd_vb2_buf_to_dev_buf(__vb) \
+	container_of(vb, \
+	struct mtk_fd_dev_buffer, \
+	m2m2_buf.vbb.vb2_buf)
+
+#define mtk_fd_vb2_buf_to_m2m_buf(__vb) \
+	container_of(__vb, \
+	struct mtk_fd_mem2mem2_buffer, \
+	vbb.vb2_buf)
+
+#define mtk_fd_subdev_to_m2m(__sd) \
+	container_of(__sd, \
+	struct mtk_fd_mem2mem2_device, subdev)
+
+struct mtk_fd_mem2mem2_device;
+
+struct mtk_fd_mem2mem2_buffer {
+	struct vb2_v4l2_buffer vbb;
+	struct list_head list;
+};
+
+struct mtk_fd_dev_buffer {
+	struct mtk_fd_mem2mem2_buffer m2m2_buf;
+	/* Intenal part */
+	struct mtk_fd_ctx_buffer ctx_buf;
+};
+
+struct mtk_fd_dev_video_device {
+	const char *name;
+	int output;
+	int immutable;
+	int enabled;
+	int queued;
+	struct v4l2_format vdev_fmt;
+	struct video_device vdev;
+	struct media_pad vdev_pad;
+	struct v4l2_mbus_framefmt pad_fmt;
+	struct vb2_queue vbq;
+	struct list_head buffers;
+	struct mutex lock; /* Protect node data */
+	atomic_t sequence;
+};
+
+struct mtk_fd_mem2mem2_device {
+	const char *name;
+	const char *model;
+	struct device *dev;
+	int num_nodes;
+	struct mtk_fd_dev_video_device *nodes;
+	const struct vb2_mem_ops *vb2_mem_ops;
+	unsigned int buf_struct_size;
+	int streaming;
+	struct v4l2_device *v4l2_dev;
+	struct media_device *media_dev;
+	struct media_pipeline pipeline;
+	struct v4l2_subdev subdev;
+	struct media_pad *subdev_pads;
+	struct v4l2_file_operations v4l2_file_ops;
+	const struct file_operations fops;
+};
+
+struct mtk_fd_dev {
+	struct platform_device *pdev;
+	struct mtk_fd_dev_video_device mem2mem2_nodes[MTK_FD_DEV_NODE_MAX];
+	int queue_enabled[MTK_FD_DEV_NODE_MAX];
+	struct mtk_fd_mem2mem2_device mem2mem2;
+	struct v4l2_device v4l2_dev;
+	struct media_device media_dev;
+	struct mtk_fd_ctx ctx;
+	struct mutex lock; /* queue protection */
+	atomic_t qbuf_barrier;
+	struct {
+		struct v4l2_rect eff;
+		struct v4l2_rect bds;
+		struct v4l2_rect gdc;
+	} rect;
+	int suspend_in_stream;
+	wait_queue_head_t buf_drain_wq;
+};
+
+int mtk_fd_media_register(struct device *dev,
+			  struct media_device *media_dev,
+			  const char *model);
+
+int mtk_fd_v4l2_register(struct device *dev,
+			 struct media_device *media_dev,
+			 struct v4l2_device *v4l2_dev);
+
+int mtk_fd_v4l2_unregister(struct mtk_fd_dev *dev);
+
+int mtk_fd_mem2mem2_v4l2_register(struct mtk_fd_dev *dev,
+				  struct media_device *media_dev,
+				  struct v4l2_device *v4l2_dev);
+
+void mtk_fd_v4l2_buffer_done(struct vb2_buffer *vb,
+			     enum vb2_buffer_state state);
+
+int mtk_fd_dev_queue_buffers(struct mtk_fd_dev *dev, bool initial);
+
+int mtk_fd_dev_get_total_node(struct mtk_fd_dev *mtk_fd_dev);
+
+char *mtk_fd_dev_get_node_name(struct mtk_fd_dev *mtk_fd_dev_obj, int node);
+
+int mtk_fd_dev_init(struct mtk_fd_dev *fd_dev,
+		    struct platform_device *pdev,
+		    struct media_device *media_dev,
+		    struct v4l2_device *v4l2_dev);
+
+void mtk_fd_dev_mem2mem2_exit(struct mtk_fd_dev *mtk_fd_dev_obj);
+
+int mtk_fd_dev_mem2mem2_init(struct mtk_fd_dev *fd_dev,
+			     struct media_device *media_dev,
+			     struct v4l2_device *v4l2_dev);
+
+int mtk_fd_dev_get_queue_id_of_dev_node(struct mtk_fd_dev *mtk_fd_dev_obj,
+					struct mtk_fd_dev_video_device *node);
+
+int mtk_fd_dev_core_init(struct platform_device *pdev,
+			 struct mtk_fd_dev *fd_dev,
+			 struct mtk_fd_ctx_desc *ctx_desc);
+
+int mtk_fd_dev_core_init_ext(struct platform_device *pdev,
+			     struct mtk_fd_dev *fd_dev,
+			     struct mtk_fd_ctx_desc *ctx_desc,
+			     struct media_device *media_dev,
+			     struct v4l2_device *v4l2_dev);
+
+int mtk_fd_dev_core_release(struct platform_device *pdev,
+			    struct mtk_fd_dev *fd_dev);
+
+#endif /* __MTK_FD_DEV_H__ */
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-smem-drv.c b/drivers/media/platform/mtk-isp/fd/mtk_fd-smem-drv.c
new file mode 100644
index 000000000000..99a852debc46
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-smem-drv.c
@@ -0,0 +1,452 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_fdt.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/dma-contiguous.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/iommu.h>
+#include <asm/cacheflush.h>
+
+#define MTK_FD_SMEM_DEV_NAME "MTK-FD-SMEM"
+
+struct mtk_fd_smem_drv {
+	struct platform_device *pdev;
+	struct sg_table sgt;
+	struct page **smem_pages;
+	int num_smem_pages;
+	phys_addr_t smem_base;
+	dma_addr_t smem_dma_base;
+	int smem_size;
+};
+
+static struct reserved_mem *isp_reserved_smem;
+
+static int mtk_fd_smem_setup_dma_ops(struct device *smem_dev,
+				     const struct dma_map_ops *smem_ops);
+
+static int mtk_fd_smem_get_sgtable(struct device *dev,
+				   struct sg_table *sgt,
+				   void *cpu_addr, dma_addr_t dma_addr,
+				   size_t size, unsigned long attrs);
+
+static const struct dma_map_ops smem_dma_ops = {
+	.get_sgtable = mtk_fd_smem_get_sgtable,
+};
+
+static int mtk_fd_smem_init(struct mtk_fd_smem_drv **mtk_fd_smem_drv_out,
+			    struct platform_device *pdev)
+{
+	struct mtk_fd_smem_drv *isp_sys = NULL;
+	struct device *dev = &pdev->dev;
+
+	isp_sys = devm_kzalloc(dev,
+			       sizeof(*isp_sys), GFP_KERNEL);
+
+	isp_sys->pdev = pdev;
+
+	*mtk_fd_smem_drv_out = isp_sys;
+
+	return 0;
+}
+
+static int mtk_fd_smem_drv_probe(struct platform_device *pdev)
+{
+	struct mtk_fd_smem_drv *smem_drv = NULL;
+	int r = 0;
+	struct device *dev = &pdev->dev;
+
+	dev_dbg(dev, "probe mtk_fd_smem_drv\n");
+
+	r = mtk_fd_smem_init(&smem_drv, pdev);
+
+	if (!smem_drv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, smem_drv);
+
+	if (isp_reserved_smem) {
+		dma_addr_t dma_addr;
+		phys_addr_t addr;
+		struct iommu_domain *smem_dom;
+		int i = 0;
+		int size_align = 0;
+		struct page **pages = NULL;
+		int n_pages = 0;
+		struct sg_table *sgt = &smem_drv->sgt;
+
+		size_align = round_down(isp_reserved_smem->size,
+					PAGE_SIZE);
+		n_pages = size_align >> PAGE_SHIFT;
+
+		pages = kmalloc_array(n_pages, sizeof(struct page *),
+				      GFP_KERNEL);
+
+		if (!pages)
+			return -ENOMEM;
+
+		for (i = 0; i < n_pages; i++)
+			pages[i] = phys_to_page(isp_reserved_smem->base
+						+ i * PAGE_SIZE);
+
+		r = sg_alloc_table_from_pages(sgt, pages, n_pages, 0,
+					      size_align, GFP_KERNEL);
+
+		if (r) {
+			dev_err(dev, "failed to get alloca sg table\n");
+			return -ENOMEM;
+		}
+
+		dma_map_sg_attrs(dev, sgt->sgl, sgt->nents,
+				 DMA_BIDIRECTIONAL,
+				 DMA_ATTR_SKIP_CPU_SYNC);
+
+		dma_addr = sg_dma_address(sgt->sgl);
+		smem_dom = iommu_get_domain_for_dev(dev);
+		addr = iommu_iova_to_phys(smem_dom, dma_addr);
+
+		if (addr != isp_reserved_smem->base)
+			dev_err(dev,
+				"incorrect pa(%llx) from iommu_iova_to_phys, should be %llx\n",
+			(unsigned long long)addr,
+			(unsigned long long)isp_reserved_smem->base);
+
+		r = dma_declare_coherent_memory(dev,
+						isp_reserved_smem->base,
+			dma_addr, size_align, DMA_MEMORY_EXCLUSIVE);
+
+		dev_dbg(dev,
+			"Coherent mem base(%llx,%llx),size(%lx),ret(%d)\n",
+			isp_reserved_smem->base,
+			dma_addr, size_align, r);
+
+		smem_drv->smem_base = isp_reserved_smem->base;
+		smem_drv->smem_size = size_align;
+		smem_drv->smem_pages = pages;
+		smem_drv->num_smem_pages = n_pages;
+		smem_drv->smem_dma_base = dma_addr;
+
+		dev_dbg(dev, "smem_drv setting (%llx,%lx,%llx,%d)\n",
+			smem_drv->smem_base, smem_drv->smem_size,
+			(unsigned long long)smem_drv->smem_pages,
+			smem_drv->num_smem_pages);
+	}
+
+	r = mtk_fd_smem_setup_dma_ops(dev, &smem_dma_ops);
+
+	return r;
+}
+
+phys_addr_t mtk_fd_smem_iova_to_phys(struct device *dev,
+				     dma_addr_t iova)
+{
+		struct iommu_domain *smem_dom;
+		phys_addr_t addr;
+		phys_addr_t limit;
+		struct mtk_fd_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+
+		if (!smem_dev)
+			return 0;
+
+		smem_dom = iommu_get_domain_for_dev(dev);
+
+		if (!smem_dom)
+			return 0;
+
+		addr = iommu_iova_to_phys(smem_dom, iova);
+
+		limit = smem_dev->smem_base + smem_dev->smem_size;
+
+		if (addr < smem_dev->smem_base || addr >= limit) {
+			dev_err(dev,
+				"Unexpected paddr %pa (must >= %pa and <%pa)\n",
+				&addr, &smem_dev->smem_base, &limit);
+			return 0;
+		}
+		dev_dbg(dev, "Pa verifcation pass: %pa(>=%pa, <%pa)\n",
+			&addr, &smem_dev->smem_base, &limit);
+		return addr;
+}
+
+static int mtk_fd_smem_drv_remove(struct platform_device *pdev)
+{
+	struct mtk_fd_smem_drv *smem_drv =
+		dev_get_drvdata(&pdev->dev);
+
+	kfree(smem_drv->smem_pages);
+	return 0;
+}
+
+static int mtk_fd_smem_drv_suspend(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_fd_smem_drv_resume(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_fd_smem_drv_dummy_cb(struct device *dev)
+{
+	return 0;
+}
+
+static const struct dev_pm_ops mtk_fd_smem_drv_pm_ops = {
+	SET_RUNTIME_PM_OPS(&mtk_fd_smem_drv_dummy_cb,
+			   &mtk_fd_smem_drv_dummy_cb, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS
+		(&mtk_fd_smem_drv_suspend, &mtk_fd_smem_drv_resume)
+};
+
+static const struct of_device_id mtk_fd_smem_drv_of_match[] = {
+	{
+		.compatible = "mediatek,fd_smem",
+	},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, mtk_fd_smem_drv_of_match);
+
+static struct platform_driver mtk_fd_smem_driver = {
+	.probe = mtk_fd_smem_drv_probe,
+	.remove = mtk_fd_smem_drv_remove,
+	.driver = {
+		.name = MTK_FD_SMEM_DEV_NAME,
+		.of_match_table =
+			of_match_ptr(mtk_fd_smem_drv_of_match),
+		.pm = &mtk_fd_smem_drv_pm_ops,
+	},
+};
+
+static int __init mtk_fd_smem_dma_setup(struct reserved_mem
+					*rmem)
+{
+	unsigned long node = rmem->fdt_node;
+
+	if (of_get_flat_dt_prop(node, "reusable", NULL))
+		return -EINVAL;
+
+	if (!of_get_flat_dt_prop(node, "no-map", NULL)) {
+		pr_err("Reserved memory: regions without no-map are not yet supported\n");
+		return -EINVAL;
+	}
+
+	isp_reserved_smem = rmem;
+
+	pr_debug("Reserved memory: created DMA memory pool at %pa, size %ld MiB\n",
+		 &rmem->base, (unsigned long)rmem->size / SZ_1M);
+	return 0;
+}
+
+RESERVEDMEM_OF_DECLARE(mtk_fd_smem,
+		       "mediatek,reserve-memory-fd_smem",
+		       mtk_fd_smem_dma_setup);
+
+int __init mtk_fd_smem_drv_init(void)
+{
+	int ret = 0;
+
+	pr_debug("platform_driver_register: mtk_fd_smem_driver\n");
+	ret = platform_driver_register(&mtk_fd_smem_driver);
+
+	if (ret)
+		pr_warn("fd smem drv init failed, driver didn't probe\n");
+
+	return ret;
+}
+subsys_initcall(mtk_fd_smem_drv_init);
+
+void __exit mtk_fd_smem_drv_ext(void)
+{
+	platform_driver_unregister(&mtk_fd_smem_driver);
+}
+module_exit(mtk_fd_smem_drv_ext);
+
+/********************************************
+ * MTK FD SMEM DMA ops *
+ ********************************************/
+
+struct dma_coherent_mem {
+	void		*virt_base;
+	dma_addr_t	device_base;
+	unsigned long	pfn_base;
+	int		size;
+	int		flags;
+	unsigned long	*bitmap;
+	spinlock_t	spinlock; /* protect the members in dma_coherent_mem */
+	bool		use_dev_dma_pfn_offset;
+};
+
+static struct dma_coherent_mem *dev_get_coherent_memory(struct device *dev)
+{
+	if (dev && dev->dma_mem)
+		return dev->dma_mem;
+	return NULL;
+}
+
+static int mtk_fd_smem_get_sgtable(struct device *dev,
+				   struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, unsigned long attrs)
+{
+	struct mtk_fd_smem_drv *smem_dev = dev_get_drvdata(dev);
+	int n_pages_align = 0;
+	int size_align = 0;
+	int page_start = 0;
+	unsigned long long offset_p = 0;
+	unsigned long long offset_d = 0;
+
+	phys_addr_t paddr = mtk_fd_smem_iova_to_phys(dev, dma_addr);
+
+	offset_d = (unsigned long long)dma_addr -
+		(unsigned long long)smem_dev->smem_dma_base;
+
+	offset_p = (unsigned long long)paddr -
+		(unsigned long long)smem_dev->smem_base;
+
+	dev_dbg(dev, "%s:dma_addr:%llx,cpu_addr:%llx,pa:%llx,size:%d\n",
+		__func__,
+		(unsigned long long)dma_addr,
+		(unsigned long long)cpu_addr,
+		(unsigned long long)paddr,
+		size
+		);
+
+	dev_dbg(dev, "%s:offset p:%llx,offset d:%llx\n",
+		__func__,
+		(unsigned long long)offset_p,
+		(unsigned long long)offset_d
+		);
+
+	size_align = round_up(size, PAGE_SIZE);
+	n_pages_align = size_align >> PAGE_SHIFT;
+	page_start = offset_p >> PAGE_SHIFT;
+
+	dev_dbg(dev,
+		"%s:page idx:%d,page pa:%llx,pa:%llx, aligned size:%d\n",
+		__func__,
+		page_start,
+		(unsigned long long)page_to_phys(*(smem_dev->smem_pages
+			+ page_start)),
+		(unsigned long long)paddr,
+		size_align
+		);
+
+	if (!smem_dev) {
+		dev_err(dev, "can't get sgtable from smem_dev\n");
+		return -EINVAL;
+	}
+
+	dev_dbg(dev, "get sgt of the smem: %d pages\n", n_pages_align);
+
+	return sg_alloc_table_from_pages(sgt,
+		smem_dev->smem_pages + page_start,
+		n_pages_align,
+		0, size_align, GFP_KERNEL);
+}
+
+static void *mtk_fd_smem_get_cpu_addr(struct mtk_fd_smem_drv *smem_dev,
+				      struct scatterlist *sg)
+{
+	struct device *dev = &smem_dev->pdev->dev;
+	struct dma_coherent_mem *dma_mem =
+		dev_get_coherent_memory(dev);
+
+	phys_addr_t addr = (phys_addr_t)sg_phys(sg);
+
+	if (addr < smem_dev->smem_base ||
+	    addr > smem_dev->smem_base + smem_dev->smem_size) {
+		dev_err(dev, "Invalid paddr 0x%llx from sg\n", addr);
+		return NULL;
+	}
+
+	return dma_mem->virt_base + (addr - smem_dev->smem_base);
+}
+
+static void mtk_fd_smem_sync_sg_for_cpu(struct device *dev,
+					struct scatterlist *sgl, int nelems,
+					enum dma_data_direction dir)
+{
+	struct mtk_fd_smem_drv *smem_dev =
+		dev_get_drvdata(dev);
+	void *cpu_addr;
+
+	cpu_addr = mtk_fd_smem_get_cpu_addr(smem_dev, sgl);
+
+	dev_dbg(dev,
+		"__dma_unmap_area:paddr(0x%llx),vaddr(0x%llx),size(%d)\n",
+		(unsigned long long)sg_phys(sgl),
+		(unsigned long long)cpu_addr,
+		sgl->length);
+
+	__dma_unmap_area(cpu_addr, sgl->length, dir);
+}
+
+static void mtk_fd_smem_sync_sg_for_device(struct device *dev,
+					   struct scatterlist *sgl, int nelems,
+					   enum dma_data_direction dir)
+{
+	struct mtk_fd_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+	void *cpu_addr;
+
+	cpu_addr = mtk_fd_smem_get_cpu_addr(smem_dev, sgl);
+
+	dev_dbg(dev,
+		"__dma_map_area:paddr(0x%llx),vaddr(0x%llx),size(%d)\n",
+		(unsigned long long)sg_phys(sgl),
+		(unsigned long long)cpu_addr,
+		sgl->length);
+
+	__dma_map_area(cpu_addr, sgl->length, dir);
+}
+
+static int mtk_fd_smem_setup_dma_ops(struct device *dev,
+				     const struct dma_map_ops *smem_ops)
+{
+	if (!dev->dma_ops)
+		return -EINVAL;
+
+	memcpy((void *)smem_ops, dev->dma_ops, sizeof(*smem_ops));
+
+	((struct dma_map_ops *)smem_ops)->get_sgtable =
+		mtk_fd_smem_get_sgtable;
+	((struct dma_map_ops *)smem_ops)->sync_sg_for_device =
+		mtk_fd_smem_sync_sg_for_device;
+	((struct dma_map_ops *)smem_ops)->sync_sg_for_cpu =
+		mtk_fd_smem_sync_sg_for_cpu;
+
+	dev->dma_ops = smem_ops;
+
+	return 0;
+}
+
+void mtk_fd_smem_enable_mpu(struct device *dev)
+{
+	dev_warn(dev, "MPU enabling func is not ready now\n");
+}
+
+MODULE_AUTHOR("Frederic Chen <frederic.chen@mediatek.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Mediatek FD shared memory driver");
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-smem.h b/drivers/media/platform/mtk-isp/fd/mtk_fd-smem.h
new file mode 100644
index 000000000000..a19fc376a761
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-smem.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_FD_SMEM_H__
+#define __MTK_FD_SMEM_H__
+
+#include <linux/dma-mapping.h>
+
+phys_addr_t mtk_fd_smem_iova_to_phys(struct device *smem_dev,
+				     dma_addr_t iova);
+void mtk_fd_smem_enable_mpu(struct device *smem_dev);
+
+#endif /*__MTK_FD_SMEM_H__*/
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2-util.c b/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2-util.c
new file mode 100644
index 000000000000..ab85aea422ff
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2-util.c
@@ -0,0 +1,1046 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_FD-v4l2 is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/pm_runtime.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf2-dma-contig.h>
+#include <media/v4l2-subdev.h>
+#include <media/v4l2-event.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+
+#include "mtk_fd-dev.h"
+
+static u32 mtk_fd_node_get_v4l2_cap
+	(struct mtk_fd_ctx_queue *node_ctx);
+
+static int mtk_fd_videoc_s_meta_fmt(struct file *file, void *fh,
+				    struct v4l2_format *f);
+
+static int mtk_fd_subdev_open(struct v4l2_subdev *sd,
+			      struct v4l2_subdev_fh *fh)
+{
+	struct mtk_fd_dev *fd_dev = mtk_fd_subdev_to_dev(sd);
+
+	fd_dev->ctx.fh = fh;
+
+	return mtk_fd_ctx_open(&fd_dev->ctx);
+}
+
+static int mtk_fd_subdev_close(struct v4l2_subdev *sd,
+			       struct v4l2_subdev_fh *fh)
+{
+	struct mtk_fd_dev *fd_dev = mtk_fd_subdev_to_dev(sd);
+
+	return mtk_fd_ctx_release(&fd_dev->ctx);
+}
+
+static int mtk_fd_subdev_s_stream(struct v4l2_subdev *sd, int enable)
+{
+	int ret = 0;
+
+	struct mtk_fd_dev *fd_dev = mtk_fd_subdev_to_dev(sd);
+
+	if (enable) {
+		ret = mtk_fd_ctx_streamon(&fd_dev->ctx);
+
+		if (!ret)
+			ret = mtk_fd_dev_queue_buffers
+				(mtk_fd_ctx_to_dev(&fd_dev->ctx), true);
+		if (ret)
+			pr_err("failed to queue initial buffers (%d)", ret);
+	}	else {
+		ret = mtk_fd_ctx_streamoff(&fd_dev->ctx);
+	}
+
+	if (!ret)
+		fd_dev->mem2mem2.streaming = enable;
+
+	return ret;
+}
+
+static int mtk_fd_link_setup(struct media_entity *entity,
+			     const struct media_pad *local,
+			     const struct media_pad *remote, u32 flags)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 =
+		container_of(entity, struct mtk_fd_mem2mem2_device,
+			     subdev.entity);
+	struct mtk_fd_dev *fd_dev =
+		container_of(m2m2, struct mtk_fd_dev, mem2mem2);
+
+	u32 pad = local->index;
+
+	pr_info("link setup: %d --> %d\n", pad, remote->index);
+
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	WARN_ON(entity->type != MEDIA_ENT_T_V4L2_SUBDEV);
+#else
+	WARN_ON(entity->obj_type != MEDIA_ENTITY_TYPE_V4L2_SUBDEV);
+#endif
+
+	WARN_ON(pad >= m2m2->num_nodes);
+
+	m2m2->nodes[pad].enabled = !!(flags & MEDIA_LNK_FL_ENABLED);
+
+	/**
+	 * queue_enable can be phase out in the future since
+	 * we don't have internal queue of each node in
+	 * v4l2 common module
+	 */
+	fd_dev->queue_enabled[pad] = m2m2->nodes[pad].enabled;
+
+	return 0;
+}
+
+static void mtk_fd_vb2_buf_queue(struct vb2_buffer *vb)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = vb2_get_drv_priv(vb->vb2_queue);
+	struct mtk_fd_dev *mtk_fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	struct device *dev = &mtk_fd_dev->pdev->dev;
+	struct mtk_fd_dev_buffer *buf = NULL;
+	struct vb2_v4l2_buffer *v4l2_buf = NULL;
+	struct mtk_fd_dev_video_device *node =
+		mtk_fd_vbq_to_isp_node(vb->vb2_queue);
+	int queue = mtk_fd_dev_get_queue_id_of_dev_node(mtk_fd_dev, node);
+
+	dev_dbg(dev,
+		"queue vb2_buf: Node(%s) queue id(%d)\n",
+		node->name,
+		queue);
+
+	if (queue < 0) {
+		dev_err(m2m2->dev, "Invalid mtk_fd_dev node.\n");
+		return;
+	}
+
+	if (mtk_fd_dev->ctx.mode == MTK_FD_CTX_MODE_DEBUG_BYPASS_ALL) {
+		dev_dbg(m2m2->dev, "By pass mode, just loop back the buffer\n");
+		vb2_buffer_done(vb, VB2_BUF_STATE_DONE);
+		return;
+	}
+
+	if (!vb)
+		pr_err("VB can't be null\n");
+
+	buf = mtk_fd_vb2_buf_to_dev_buf(vb);
+
+	if (!buf)
+		pr_err("buf can't be null\n");
+
+	v4l2_buf = to_vb2_v4l2_buffer(vb);
+
+	if (!v4l2_buf)
+		pr_err("v4l2_buf can't be null\n");
+
+	mutex_lock(&mtk_fd_dev->lock);
+
+	pr_err("init  mtk_fd_ctx_buf_init, sequence(%d)\n", v4l2_buf->sequence);
+
+	/* the dma address will be filled in later frame buffer handling*/
+	mtk_fd_ctx_buf_init(&buf->ctx_buf, queue, (dma_addr_t)0);
+	pr_info("set mtk_fd_ctx_buf_init: user seq=%d\n",
+		buf->ctx_buf.user_sequence);
+
+	/* Added the buffer into the tracking list */
+	list_add_tail(&buf->m2m2_buf.list,
+		      &m2m2->nodes[node - m2m2->nodes].buffers);
+	mutex_unlock(&mtk_fd_dev->lock);
+
+	/* Enqueue the buffer */
+	if (mtk_fd_dev->mem2mem2.streaming) {
+		pr_info("%s: mtk_fd_dev_queue_buffers\n", node->name);
+		mtk_fd_dev_queue_buffers(mtk_fd_dev, false);
+	}
+}
+
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+static int mtk_fd_vb2_queue_setup(struct vb2_queue *vq,
+				  const void *parg,
+				  unsigned int *num_buffers,
+				  unsigned int *num_planes,
+				  unsigned int sizes[], void *alloc_ctxs[])
+#else
+static int mtk_fd_vb2_queue_setup(struct vb2_queue *vq,
+				  unsigned int *num_buffers,
+				  unsigned int *num_planes,
+				  unsigned int sizes[],
+				  struct device *alloc_devs[])
+#endif
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_fd_dev_video_device *node = mtk_fd_vbq_to_isp_node(vq);
+	struct mtk_fd_dev *fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	void *buf_alloc_ctx = NULL;
+	int queue = mtk_fd_dev_get_queue_id_of_dev_node(fd_dev, node);
+	/* Get V4L2 format with the following method */
+	const struct v4l2_format *fmt = &node->vdev_fmt;
+
+	*num_planes = 1;
+	*num_buffers = clamp_val(*num_buffers, 1, VB2_MAX_FRAME);
+
+	vq->dma_attrs |= DMA_ATTR_NON_CONSISTENT;
+	pr_info("queue(%d): cached mmap enabled\n", queue);
+
+	if (vq->type == V4L2_BUF_TYPE_META_CAPTURE ||
+	    vq->type == V4L2_BUF_TYPE_META_OUTPUT) {
+		sizes[0] = fmt->fmt.meta.buffersize;
+		buf_alloc_ctx = fd_dev->ctx.smem_vb2_alloc_ctx;
+		pr_info("Select smem_vb2_alloc_ctx(%llx)\n",
+			(unsigned long long)buf_alloc_ctx);
+	} else {
+		sizes[0] = fmt->fmt.pix_mp.plane_fmt[0].sizeimage;
+		buf_alloc_ctx = fd_dev->ctx.img_vb2_alloc_ctx;
+		pr_info("Select img_vb2_alloc_ctx(%llx)\n",
+			(unsigned long long)buf_alloc_ctx);
+	}
+
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	alloc_ctxs[0] = buf_alloc_ctx;
+#else
+	alloc_devs[0] = (struct device *)buf_alloc_ctx;
+#endif
+
+	pr_info("mtk_fd_vb2_queue_setup:type(%d),size(%d),ctx(%llx)\n",
+		vq->type, sizes[0], (unsigned long long)buf_alloc_ctx);
+
+	/* Initialize buffer queue */
+	INIT_LIST_HEAD(&node->buffers);
+
+	return 0;
+}
+
+static bool mtk_fd_all_nodes_streaming(struct mtk_fd_mem2mem2_device *m2m2,
+				       struct mtk_fd_dev_video_device *except)
+{
+	int i;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		struct mtk_fd_dev_video_device *node = &m2m2->nodes[i];
+
+		if (node == except)
+			continue;
+		if (node->enabled && !vb2_start_streaming_called(&node->vbq))
+			return false;
+	}
+
+	return true;
+}
+
+static void mtk_fd_return_all_buffers(struct mtk_fd_mem2mem2_device *m2m2,
+				      struct mtk_fd_dev_video_device *node,
+				      enum vb2_buffer_state state)
+{
+	struct mtk_fd_dev *mtk_fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	struct mtk_fd_mem2mem2_buffer *b, *b0;
+
+	/* Return all buffers */
+	mutex_lock(&mtk_fd_dev->lock);
+	list_for_each_entry_safe(b, b0, &node->buffers, list) {
+		list_del(&b->list);
+		vb2_buffer_done(&b->vbb.vb2_buf, state);
+	}
+	mutex_unlock(&mtk_fd_dev->lock);
+}
+
+static int mtk_fd_vb2_start_streaming(struct vb2_queue *vq, unsigned int count)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_fd_dev_video_device *node =
+		mtk_fd_vbq_to_isp_node(vq);
+	int r;
+
+	if (m2m2->streaming) {
+		r = -EBUSY;
+		goto fail_return_bufs;
+	}
+
+	if (!node->enabled) {
+		pr_err("Node (%ld) is not enable\n", node - m2m2->nodes);
+		r = -EINVAL;
+		goto fail_return_bufs;
+	}
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	r = media_entity_pipeline_start(&node->vdev.entity, &m2m2->pipeline);
+#else
+	r = media_pipeline_start(&node->vdev.entity, &m2m2->pipeline);
+#endif
+	if (r < 0) {
+		pr_err("Node (%ld) media_pipeline_start failed\n",
+		       node - m2m2->nodes);
+		goto fail_return_bufs;
+	}
+
+	if (!mtk_fd_all_nodes_streaming(m2m2, node))
+		return 0;
+
+	/* Start streaming of the whole pipeline now */
+
+	r = v4l2_subdev_call(&m2m2->subdev, video, s_stream, 1);
+	if (r < 0) {
+		pr_err("Node (%ld) v4l2_subdev_call s_stream failed\n",
+		       node - m2m2->nodes);
+		goto fail_stop_pipeline;
+	}
+	return 0;
+
+fail_stop_pipeline:
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	media_entity_pipeline_stop(&node->vdev.entity);
+#else
+	media_pipeline_stop(&node->vdev.entity);
+#endif
+fail_return_bufs:
+	mtk_fd_return_all_buffers(m2m2, node, VB2_BUF_STATE_QUEUED);
+
+	return r;
+}
+
+static void mtk_fd_vb2_stop_streaming(struct vb2_queue *vq)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_fd_dev_video_device *node =
+		mtk_fd_vbq_to_isp_node(vq);
+	int r;
+
+	WARN_ON(!node->enabled);
+
+	/* Was this the first node with streaming disabled? */
+	if (mtk_fd_all_nodes_streaming(m2m2, node)) {
+		/* Yes, really stop streaming now */
+		r = v4l2_subdev_call(&m2m2->subdev, video, s_stream, 0);
+		if (r)
+			dev_err(m2m2->dev, "failed to stop streaming\n");
+	}
+
+	mtk_fd_return_all_buffers(m2m2, node, VB2_BUF_STATE_ERROR);
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	media_entity_pipeline_stop(&node->vdev.entity);
+#else
+	media_pipeline_stop(&node->vdev.entity);
+#endif
+}
+
+static int mtk_fd_videoc_querycap(struct file *file, void *fh,
+				  struct v4l2_capability *cap)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+	struct mtk_fd_dev *fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	int queue_id =
+		mtk_fd_dev_get_queue_id_of_dev_node(fd_dev, node);
+	struct mtk_fd_ctx_queue *node_ctx = &fd_dev->ctx.queue[queue_id];
+
+	strlcpy(cap->driver, m2m2->name, sizeof(cap->driver));
+	strlcpy(cap->card, m2m2->model, sizeof(cap->card));
+	snprintf(cap->bus_info, sizeof(cap->bus_info),
+		 "platform:%s", node->name);
+
+	cap->device_caps =
+		mtk_fd_node_get_v4l2_cap(node_ctx) | V4L2_CAP_STREAMING;
+	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
+
+	return 0;
+}
+
+/* Propagate forward always the format from the CIO2 subdev */
+static int mtk_fd_videoc_g_fmt(struct file *file, void *fh,
+			       struct v4l2_format *f)
+{
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+static int mtk_fd_videoc_try_fmt(struct file *file, void *fh,
+				 struct v4l2_format *f)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_fd_dev *fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	struct mtk_fd_ctx *dev_ctx = &fd_dev->ctx;
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+	int queue_id =
+		mtk_fd_dev_get_queue_id_of_dev_node(fd_dev, node);
+	int ret = 0;
+
+	ret = mtk_fd_ctx_fmt_set_img(dev_ctx, queue_id, &f->fmt.pix_mp,
+				     &node->vdev_fmt.fmt.pix_mp);
+
+	/* Simply set the format to the node context in the initial version */
+	if (ret) {
+		pr_warn("Fmt(%d) not support for queue(%d), load default fmt\n",
+			f->fmt.pix_mp.pixelformat, queue_id);
+
+		ret = mtk_fd_ctx_format_load_default_fmt
+			(&dev_ctx->queue[queue_id], f);
+	}
+
+	if (!ret) {
+		node->vdev_fmt.fmt.pix_mp = f->fmt.pix_mp;
+		dev_ctx->queue[queue_id].fmt.pix_mp = node->vdev_fmt.fmt.pix_mp;
+	}
+
+	return ret;
+}
+
+static int mtk_fd_videoc_s_fmt(struct file *file, void *fh,
+			       struct v4l2_format *f)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_fd_dev *fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	struct mtk_fd_ctx *dev_ctx = &fd_dev->ctx;
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+	int queue_id = mtk_fd_dev_get_queue_id_of_dev_node(fd_dev, node);
+	int ret = 0;
+
+	ret = mtk_fd_ctx_fmt_set_img(dev_ctx, queue_id, &f->fmt.pix_mp,
+				     &node->vdev_fmt.fmt.pix_mp);
+
+	/* Simply set the format to the node context in the initial version */
+	if (!ret)
+		dev_ctx->queue[queue_id].fmt.pix_mp = node->vdev_fmt.fmt.pix_mp;
+	else
+		dev_warn(&fd_dev->pdev->dev, "s_fmt, format not support\n");
+
+	return ret;
+}
+
+static int mtk_fd_meta_enum_format(struct file *file, void *fh,
+				   struct v4l2_fmtdesc *f)
+{
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+
+	if (f->index > 0 || f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->pixelformat = node->vdev_fmt.fmt.meta.dataformat;
+
+	return 0;
+}
+
+static int mtk_fd_videoc_s_meta_fmt(struct file *file, void *fh,
+				    struct v4l2_format *f)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_fd_dev *fd_dev = mtk_fd_m2m_to_dev(m2m2);
+	struct mtk_fd_ctx *dev_ctx = &fd_dev->ctx;
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+	int queue_id = mtk_fd_dev_get_queue_id_of_dev_node(fd_dev, node);
+
+	int ret = 0;
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	ret = mtk_fd_ctx_format_load_default_fmt(&dev_ctx->queue[queue_id], f);
+
+	if (!ret) {
+		node->vdev_fmt.fmt.meta = f->fmt.meta;
+		dev_ctx->queue[queue_id].fmt.meta = node->vdev_fmt.fmt.meta;
+	} else {
+		dev_warn(&fd_dev->pdev->dev,
+			 "s_meta_fm failed, format not support\n");
+	}
+
+	return ret;
+}
+
+static int mtk_fd_videoc_g_meta_fmt(struct file *file, void *fh,
+				    struct v4l2_format *f)
+{
+	struct mtk_fd_dev_video_device *node = file_to_mtk_fd_node(file);
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+int mtk_fd_videoc_qbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct video_device *vdev = video_devdata(file);
+	struct vb2_buffer *vb;
+	struct mtk_fd_dev_buffer *db;
+	int r = 0;
+
+	/* check if vb2 queue is busy */
+	if (vdev->queue->owner && vdev->queue->owner != file->private_data)
+		return -EBUSY;
+
+	/**
+	 * Keep the value of sequence in v4l2_buffer
+	 * in ctx buf since vb2_qbuf will set it to 0
+	 */
+	vb = vdev->queue->bufs[p->index];
+
+	if (vb) {
+		db = mtk_fd_vb2_buf_to_dev_buf(vb);
+		pr_info("qbuf: p:%llx,vb:%llx, db:%llx\n",
+			(unsigned long long)p,
+			(unsigned long long)vb,
+			(unsigned long long)db);
+		db->ctx_buf.user_sequence = p->sequence;
+	}
+	r = vb2_qbuf(vdev->queue, vdev->v4l2_dev->mdev, p);
+	if (r)
+		pr_err("vb2_qbuf failed(err=%d): buf idx(%d)\n", r, p->index);
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_videoc_qbuf);
+
+/******************** function pointers ********************/
+
+/* subdev internal operations */
+static const struct v4l2_subdev_internal_ops mtk_fd_subdev_internal_ops = {
+	.open = mtk_fd_subdev_open,
+	.close = mtk_fd_subdev_close,
+};
+
+static const struct v4l2_subdev_core_ops mtk_fd_subdev_core_ops = {
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	.g_ext_ctrls = v4l2_subdev_g_ext_ctrls,
+	.try_ext_ctrls = v4l2_subdev_try_ext_ctrls,
+	.s_ext_ctrls = v4l2_subdev_s_ext_ctrls,
+	.g_ctrl = v4l2_subdev_g_ctrl,
+	.s_ctrl = v4l2_subdev_s_ctrl,
+	.queryctrl = v4l2_subdev_queryctrl,
+	.querymenu = v4l2_subdev_querymenu,
+#endif
+};
+
+static const struct v4l2_subdev_video_ops mtk_fd_subdev_video_ops = {
+	.s_stream = mtk_fd_subdev_s_stream,
+};
+
+static const struct v4l2_subdev_ops mtk_fd_subdev_ops = {
+	.core = &mtk_fd_subdev_core_ops,
+	.video = &mtk_fd_subdev_video_ops,
+};
+
+static const struct media_entity_operations mtk_fd_media_ops = {
+	.link_setup = mtk_fd_link_setup,
+	.link_validate = v4l2_subdev_link_validate,
+};
+
+static const struct vb2_ops mtk_fd_vb2_ops = {
+	.buf_queue = mtk_fd_vb2_buf_queue,
+	.queue_setup = mtk_fd_vb2_queue_setup,
+	.start_streaming = mtk_fd_vb2_start_streaming,
+	.stop_streaming = mtk_fd_vb2_stop_streaming,
+	.wait_prepare = vb2_ops_wait_prepare,
+	.wait_finish = vb2_ops_wait_finish,
+};
+
+static const struct v4l2_file_operations mtk_fd_v4l2_fops = {
+	.unlocked_ioctl = video_ioctl2,
+	.open = v4l2_fh_open,
+	.release = vb2_fop_release,
+	.poll = vb2_fop_poll,
+	.mmap = vb2_fop_mmap,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl32 = v4l2_compat_ioctl32,
+#endif
+};
+
+static const struct v4l2_ioctl_ops mtk_fd_v4l2_ioctl_ops = {
+	.vidioc_querycap = mtk_fd_videoc_querycap,
+
+	.vidioc_g_fmt_vid_cap_mplane = mtk_fd_videoc_g_fmt,
+	.vidioc_s_fmt_vid_cap_mplane = mtk_fd_videoc_s_fmt,
+	.vidioc_try_fmt_vid_cap_mplane = mtk_fd_videoc_try_fmt,
+
+	.vidioc_g_fmt_vid_out_mplane = mtk_fd_videoc_g_fmt,
+	.vidioc_s_fmt_vid_out_mplane = mtk_fd_videoc_s_fmt,
+	.vidioc_try_fmt_vid_out_mplane = mtk_fd_videoc_try_fmt,
+
+	/* buffer queue management */
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = mtk_fd_videoc_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static const struct v4l2_ioctl_ops mtk_fd_v4l2_meta_ioctl_ops = {
+	.vidioc_querycap = mtk_fd_videoc_querycap,
+
+	.vidioc_enum_fmt_meta_cap = mtk_fd_meta_enum_format,
+	.vidioc_g_fmt_meta_cap = mtk_fd_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_cap = mtk_fd_videoc_s_meta_fmt,
+	.vidioc_try_fmt_meta_cap = mtk_fd_videoc_g_meta_fmt,
+
+	.vidioc_enum_fmt_meta_out = mtk_fd_meta_enum_format,
+	.vidioc_g_fmt_meta_out = mtk_fd_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_out = mtk_fd_videoc_s_meta_fmt,
+	.vidioc_try_fmt_meta_out = mtk_fd_videoc_g_meta_fmt,
+
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = mtk_fd_videoc_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static u32 mtk_fd_node_get_v4l2_cap(struct mtk_fd_ctx_queue *node_ctx)
+{
+	u32 cap = 0;
+
+	if (node_ctx->desc.capture)
+		if (node_ctx->desc.image)
+			cap = V4L2_CAP_VIDEO_CAPTURE_MPLANE;
+		else
+			cap = V4L2_CAP_META_CAPTURE;
+	else
+		if (node_ctx->desc.image)
+			cap = V4L2_CAP_VIDEO_OUTPUT_MPLANE;
+		else
+			cap = V4L2_CAP_META_OUTPUT;
+
+	return cap;
+}
+
+static u32 mtk_fd_node_get_format_type(struct mtk_fd_ctx_queue *node_ctx)
+{
+	u32 type;
+
+	if (node_ctx->desc.capture)
+		if (node_ctx->desc.image)
+			type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+		else
+			type = V4L2_BUF_TYPE_META_CAPTURE;
+	else
+		if (node_ctx->desc.image)
+			type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+		else
+			type = V4L2_BUF_TYPE_META_OUTPUT;
+
+	return type;
+}
+
+static const struct v4l2_ioctl_ops *mtk_fd_node_get_ioctl_ops
+	(struct mtk_fd_ctx_queue *node_ctx)
+{
+	const struct v4l2_ioctl_ops *ops = NULL;
+
+	if (node_ctx->desc.image)
+		ops = &mtk_fd_v4l2_ioctl_ops;
+	else
+		ops = &mtk_fd_v4l2_meta_ioctl_ops;
+	return ops;
+}
+
+/**
+ * Config node's video properties
+ * according to the device context requirement
+ */
+static void mtk_fd_node_to_v4l2(struct mtk_fd_dev *fd_dev, u32 node,
+				struct video_device *vdev,
+				struct v4l2_format *f)
+{
+	u32 cap;
+	struct mtk_fd_ctx *device_ctx = &fd_dev->ctx;
+	struct mtk_fd_ctx_queue *node_ctx = &device_ctx->queue[node];
+
+	WARN_ON(node >= mtk_fd_dev_get_total_node(fd_dev));
+	WARN_ON(!node_ctx);
+
+	/* set cap of the node */
+	cap = mtk_fd_node_get_v4l2_cap(node_ctx);
+	f->type = mtk_fd_node_get_format_type(node_ctx);
+	vdev->ioctl_ops = mtk_fd_node_get_ioctl_ops(node_ctx);
+
+	if (mtk_fd_ctx_format_load_default_fmt(&device_ctx->queue[node], f)) {
+		dev_err(&fd_dev->pdev->dev,
+			"Can't load default for node (%d): (%s)",
+			node, device_ctx->queue[node].desc.name);
+	} else {
+		if (device_ctx->queue[node].desc.image) {
+			dev_dbg(&fd_dev->pdev->dev,
+				"Node (%d): (%s), dfmt (f:0x%x w:%d: h:%d s:%d)\n",
+				node, device_ctx->queue[node].desc.name,
+				f->fmt.pix_mp.pixelformat,
+				f->fmt.pix_mp.width,
+				f->fmt.pix_mp.height,
+				f->fmt.pix_mp.plane_fmt[0].sizeimage);
+			node_ctx->fmt.pix_mp = f->fmt.pix_mp;
+		} else {
+			dev_info(&fd_dev->pdev->dev,
+				 "Node (%d): (%s), dfmt (f:0x%x s:%u)\n",
+				 node, device_ctx->queue[node].desc.name,
+				 f->fmt.meta.dataformat,
+				 f->fmt.meta.buffersize);
+			node_ctx->fmt.meta = f->fmt.meta;
+		}
+	}
+
+#if KERNEL_VERSION(4, 7, 0) < MTK_FD_KERNEL_BASE_VERSION
+	/* device_caps was supported after 4.7 */
+	vdev->device_caps = V4L2_CAP_STREAMING | cap;
+#endif
+}
+
+int mtk_fd_media_register(struct device *dev, struct media_device *media_dev,
+			  const char *model)
+{
+	int r = 0;
+
+	media_dev->dev = dev;
+	dev_info(dev, "setup media_dev.dev: %llx\n",
+		 (unsigned long long)media_dev->dev);
+
+	strlcpy(media_dev->model, model, sizeof(media_dev->model));
+	dev_info(dev, "setup media_dev.model: %s\n",
+		 media_dev->model);
+
+	snprintf(media_dev->bus_info, sizeof(media_dev->bus_info),
+		 "%s", dev_name(dev));
+	dev_info(dev, "setup media_dev.bus_info: %s\n",
+		 media_dev->bus_info);
+
+	media_dev->hw_revision = 0;
+	dev_info(dev, "setup media_dev.hw_revision: %d\n",
+		 media_dev->hw_revision);
+
+#if KERNEL_VERSION(4, 5, 0) <= MTK_FD_KERNEL_BASE_VERSION
+	dev_info(dev, "media_device_init: media_dev:%llx\n",
+		 (unsigned long long)media_dev);
+	media_device_init(media_dev);
+#endif
+
+	pr_info("Register media device: %s, %llx",
+		media_dev->model,
+		(unsigned long long)media_dev);
+
+	r = media_device_register(media_dev);
+
+	if (r) {
+		dev_err(dev, "failed to register media device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_FD_KERNEL_BASE_VERSION
+	media_device_cleanup(media_dev);
+#endif
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_media_register);
+
+int mtk_fd_v4l2_register(struct device *dev,
+			 struct media_device *media_dev,
+			 struct v4l2_device *v4l2_dev)
+{
+	int r = 0;
+	/* Set up v4l2 device */
+	v4l2_dev->mdev = media_dev;
+	dev_info(dev, "setup v4l2_dev->mdev: %llx",
+		 (unsigned long long)v4l2_dev->mdev);
+
+	dev_info(dev, "Register v4l2 device: %llx",
+		 (unsigned long long)v4l2_dev);
+
+	r = v4l2_device_register(dev, v4l2_dev);
+
+	if (r) {
+		dev_err(dev, "failed to register V4L2 device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_FD_KERNEL_BASE_VERSION
+	media_device_cleanup(media_dev);
+#endif
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_v4l2_register);
+
+int mtk_fd_mem2mem2_v4l2_register(struct mtk_fd_dev *dev,
+				  struct media_device *media_dev,
+				  struct v4l2_device *v4l2_dev)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = &dev->mem2mem2;
+
+	int i, r;
+
+	/**
+	 * If media_dev or v4l2_dev is not set,
+	 * use the default one in mtk_fd_dev
+	 */
+	if (!media_dev) {
+		m2m2->media_dev = &dev->media_dev;
+		r = mtk_fd_media_register(&dev->pdev->dev, m2m2->media_dev,
+					  m2m2->model);
+
+	if (r) {
+		dev_err(m2m2->dev, "failed to register media device (%d)\n", r);
+		goto fail_media_dev;
+	}
+	} else {
+		m2m2->media_dev = media_dev;
+	}
+
+	if (!v4l2_dev) {
+		m2m2->v4l2_dev = &dev->v4l2_dev;
+		r = mtk_fd_v4l2_register(&dev->pdev->dev,
+					 m2m2->media_dev,
+					 m2m2->v4l2_dev);
+	if (r) {
+		dev_err(m2m2->dev, "failed to register V4L2 device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+	} else {
+		m2m2->v4l2_dev = v4l2_dev;
+	}
+
+	/* Initialize miscellaneous variables */
+	m2m2->streaming = false;
+	m2m2->v4l2_file_ops = mtk_fd_v4l2_fops;
+
+	/* Initialize subdev media entity */
+	m2m2->subdev_pads = kcalloc(m2m2->num_nodes, sizeof(*m2m2->subdev_pads),
+				    GFP_KERNEL);
+	if (!m2m2->subdev_pads) {
+		r = -ENOMEM;
+		goto fail_subdev_pads;
+	}
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+	r = media_entity_init(&m2m2->subdev.entity, m2m2->num_nodes,
+			      m2m2->subdev_pads, 0);
+#else
+	r = media_entity_pads_init(&m2m2->subdev.entity, m2m2->num_nodes,
+				   m2m2->subdev_pads);
+#endif
+	if (r) {
+		dev_err(m2m2->dev,
+			"failed initialize subdev media entity (%d)\n", r);
+		goto fail_media_entity;
+	}
+
+	/* Initialize subdev */
+	v4l2_subdev_init(&m2m2->subdev, &mtk_fd_subdev_ops);
+
+	m2m2->subdev.entity.function =
+		MEDIA_ENT_F_PROC_VIDEO_PIXEL_FORMATTER;
+
+	m2m2->subdev.entity.ops = &mtk_fd_media_ops;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		m2m2->subdev_pads[i].flags = m2m2->nodes[i].output ?
+			MEDIA_PAD_FL_SINK : MEDIA_PAD_FL_SOURCE;
+	}
+
+	m2m2->subdev.flags =
+		V4L2_SUBDEV_FL_HAS_DEVNODE | V4L2_SUBDEV_FL_HAS_EVENTS;
+	snprintf(m2m2->subdev.name, sizeof(m2m2->subdev.name),
+		 "%s", m2m2->name);
+	v4l2_set_subdevdata(&m2m2->subdev, m2m2);
+	m2m2->subdev.internal_ops = &mtk_fd_subdev_internal_ops;
+
+	pr_info("register subdev: %s\n", m2m2->subdev.name);
+	r = v4l2_device_register_subdev(m2m2->v4l2_dev, &m2m2->subdev);
+	if (r) {
+		dev_err(m2m2->dev, "failed initialize subdev (%d)\n", r);
+		goto fail_subdev;
+	}
+	r = v4l2_device_register_subdev_nodes(m2m2->v4l2_dev);
+	if (r) {
+		dev_err(m2m2->dev, "failed to register subdevs (%d)\n", r);
+		goto fail_subdevs;
+	}
+
+	/* Create video nodes and links */
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		struct mtk_fd_dev_video_device *node = &m2m2->nodes[i];
+		struct video_device *vdev = &node->vdev;
+		struct vb2_queue *vbq = &node->vbq;
+		u32 flags;
+
+		/* Initialize miscellaneous variables */
+		mutex_init(&node->lock);
+		INIT_LIST_HEAD(&node->buffers);
+
+		/* Initialize formats to default values */
+		mtk_fd_node_to_v4l2(dev, i, vdev, &node->vdev_fmt);
+
+		/* Initialize media entities */
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+		r = media_entity_init(&vdev->entity, 1, &node->vdev_pad, 0);
+#else
+		r = media_entity_pads_init(&vdev->entity, 1, &node->vdev_pad);
+#endif
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed initialize media entity (%d)\n", r);
+			goto fail_vdev_media_entity;
+		}
+		node->vdev_pad.flags = node->output ?
+			MEDIA_PAD_FL_SOURCE : MEDIA_PAD_FL_SINK;
+		vdev->entity.ops = NULL;
+
+		/* Initialize vbq */
+		vbq->type = node->vdev_fmt.type;
+		vbq->io_modes = VB2_MMAP | VB2_DMABUF;
+		vbq->ops = &mtk_fd_vb2_ops;
+		vbq->mem_ops = m2m2->vb2_mem_ops;
+		m2m2->buf_struct_size = sizeof(struct mtk_fd_dev_buffer);
+		vbq->buf_struct_size = m2m2->buf_struct_size;
+		vbq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;
+		vbq->min_buffers_needed = 0;	/* Can streamon w/o buffers */
+		/* Put the process hub sub device in the vb2 private data*/
+		vbq->drv_priv = m2m2;
+		vbq->lock = &node->lock;
+		r = vb2_queue_init(vbq);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed to initialize video queue (%d)\n", r);
+			goto fail_vdev;
+		}
+
+		/* Initialize vdev */
+		snprintf(vdev->name, sizeof(vdev->name), "%s %s",
+			 m2m2->name, node->name);
+		vdev->release = video_device_release_empty;
+		vdev->fops = &m2m2->v4l2_file_ops;
+		vdev->lock = &node->lock;
+		vdev->v4l2_dev = m2m2->v4l2_dev;
+		vdev->queue = &node->vbq;
+		vdev->vfl_dir = node->output ? VFL_DIR_TX : VFL_DIR_RX;
+		video_set_drvdata(vdev, m2m2);
+		pr_info("register vdev: %s\n", vdev->name);
+		r = video_register_device(vdev, VFL_TYPE_GRABBER, -1);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed to register video device (%d)\n", r);
+			goto fail_vdev;
+		}
+
+		/* Create link between video node and the subdev pad */
+		flags = 0;
+		if (node->enabled)
+			flags |= MEDIA_LNK_FL_ENABLED;
+		if (node->immutable)
+			flags |= MEDIA_LNK_FL_IMMUTABLE;
+		if (node->output) {
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+			r = media_entity_create_link
+#else
+			r = media_create_pad_link
+#endif
+						(&vdev->entity, 0,
+						 &m2m2->subdev.entity,
+						 i, flags);
+		} else {
+#if KERNEL_VERSION(4, 5, 0) >= MTK_FD_KERNEL_BASE_VERSION
+			r = media_entity_create_link
+#else
+			r = media_create_pad_link
+#endif
+						(&m2m2->subdev.entity,
+						 i, &vdev->entity, 0,
+						 flags);
+		}
+		if (r)
+			goto fail_link;
+	}
+
+	return 0;
+
+	for (; i >= 0; i--) {
+fail_link:
+		video_unregister_device(&m2m2->nodes[i].vdev);
+fail_vdev:
+		media_entity_cleanup(&m2m2->nodes[i].vdev.entity);
+fail_vdev_media_entity:
+		mutex_destroy(&m2m2->nodes[i].lock);
+	}
+fail_subdevs:
+	v4l2_device_unregister_subdev(&m2m2->subdev);
+fail_subdev:
+	media_entity_cleanup(&m2m2->subdev.entity);
+fail_media_entity:
+	kfree(m2m2->subdev_pads);
+fail_subdev_pads:
+	v4l2_device_unregister(m2m2->v4l2_dev);
+fail_v4l2_dev:
+fail_media_dev:
+	pr_err("fail_v4l2_dev: media_device_unregister and clenaup:%llx",
+	       (unsigned long long)m2m2->media_dev);
+	media_device_unregister(m2m2->media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_FD_KERNEL_BASE_VERSION
+	media_device_cleanup(m2m2->media_dev);
+#endif
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_mem2mem2_v4l2_register);
+
+int mtk_fd_v4l2_unregister(struct mtk_fd_dev *dev)
+{
+	struct mtk_fd_mem2mem2_device *m2m2 = &dev->mem2mem2;
+	unsigned int i;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		video_unregister_device(&m2m2->nodes[i].vdev);
+		media_entity_cleanup(&m2m2->nodes[i].vdev.entity);
+		mutex_destroy(&m2m2->nodes[i].lock);
+	}
+
+	v4l2_device_unregister_subdev(&m2m2->subdev);
+	media_entity_cleanup(&m2m2->subdev.entity);
+	kfree(m2m2->subdev_pads);
+	v4l2_device_unregister(m2m2->v4l2_dev);
+	media_device_unregister(m2m2->media_dev);
+#if KERNEL_VERSION(4, 5, 0) <= MTK_FD_KERNEL_BASE_VERSION
+	media_device_cleanup(m2m2->media_dev);
+#endif
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_fd_v4l2_unregister);
+
+void mtk_fd_v4l2_buffer_done(struct vb2_buffer *vb,
+			     enum vb2_buffer_state state)
+{
+	struct mtk_fd_mem2mem2_buffer *b =
+		container_of(vb, struct mtk_fd_mem2mem2_buffer, vbb.vb2_buf);
+
+	list_del(&b->list);
+	vb2_buffer_done(&b->vbb.vb2_buf, state);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_v4l2_buffer_done);
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.c b/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.c
new file mode 100644
index 000000000000..bd447b7b3f4c
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.c
@@ -0,0 +1,114 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include "mtk_fd.h"
+#include "mtk_fd-ctx.h"
+#include "mtk_fd-v4l2.h"
+
+static struct mtk_fd_ctx_format fd_param_fmts[] = {
+	{
+		.fmt.meta = {
+		.dataformat = V4L2_META_FMT_MTISP_PARAMS,
+		.max_buffer_size = 1024 * 30,
+		},
+	},
+};
+
+static struct mtk_fd_ctx_format in_fmts[] = {
+	{
+		.fmt.img = {
+			.pixelformat  = V4L2_PIX_FMT_VYUY,
+			.depth    = { 16 },
+			.row_depth  = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat  = V4L2_PIX_FMT_YUYV,
+			.depth    = { 16 },
+			.row_depth  = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat  = V4L2_PIX_FMT_YVYU,
+			.depth	  = { 16 },
+			.row_depth  = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat  = V4L2_PIX_FMT_UYVY,
+			.depth    = { 16 },
+			.row_depth  = { 16 },
+			.num_planes = 1,
+		},
+	},
+};
+
+static struct mtk_fd_ctx_queue_desc
+output_queues[MTK_FD_CTX_FD_TOTAL_OUTPUT] = {
+	{
+		.id = MTK_FD_CTX_FD_YUV_IN,
+		.name = "FDInput",
+		.capture = 0,
+		.image = 1,
+		.fmts = in_fmts,
+		.num_fmts = ARRAY_SIZE(in_fmts),
+		.default_fmt_idx = 1,
+	},
+	{
+		.id = MTK_FD_CTX_FD_CONFIG_IN,
+		.name = "FDConfig",
+		.capture = 0,
+		.image = 0,
+		.fmts = fd_param_fmts,
+		.num_fmts = 1,
+		.default_fmt_idx = 0,
+	},
+};
+
+static struct mtk_fd_ctx_queue_desc
+capture_queues[MTK_FD_CTX_FD_TOTAL_CAPTURE] = {
+	{
+		.id = MTK_FD_CTX_FD_OUT,
+		.name = "FDOutput",
+		.capture = 1,
+		.image = 0,
+		.fmts = fd_param_fmts,
+		.num_fmts = 1,
+		.default_fmt_idx = 0,
+	},
+};
+
+static struct mtk_fd_ctx_queues_setting queues_setting = {
+	.master = MTK_FD_CTX_FD_OUT,
+	.output_queue_descs = output_queues,
+	.total_output_queues = MTK_FD_CTX_FD_TOTAL_OUTPUT,
+	.capture_queue_descs = capture_queues,
+	.total_capture_queues = MTK_FD_CTX_FD_TOTAL_CAPTURE,
+};
+
+int mtk_fd_ctx_fd_init(struct mtk_fd_ctx *ctx)
+{
+	/* Initialize main data structure */
+	return mtk_fd_ctx_core_queue_setup(ctx, &queues_setting);
+}
+EXPORT_SYMBOL_GPL(mtk_fd_ctx_fd_init);
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.h b/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.h
new file mode 100644
index 000000000000..0702abc0edd0
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd-v4l2.h
@@ -0,0 +1,36 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_FD_V4L2__
+#define __MTK_FD_V4L2__
+
+#include <linux/types.h>
+#include "mtk_fd-ctx.h"
+
+#define MTK_FD_DEV_NAME     "MTK-FD-V4L2"
+
+/* Input: YUV image */
+#define MTK_FD_CTX_FD_YUV_IN		0
+/* Input: FD Configuration */
+#define MTK_FD_CTX_FD_CONFIG_IN		1
+#define MTK_FD_CTX_FD_TOTAL_OUTPUT	2
+
+/* OUT: FD output devices*/
+#define MTK_FD_CTX_FD_OUT		2
+#define MTK_FD_CTX_FD_TOTAL_CAPTURE	1
+
+int mtk_fd_ctx_fd_init(struct mtk_fd_ctx *ctx);
+
+#endif /*__MTK_FD_V4L2__*/
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd.c b/drivers/media/platform/mtk-isp/fd/mtk_fd.c
new file mode 100644
index 000000000000..c8e097a8dc9a
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd.c
@@ -0,0 +1,754 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015 MediaTek Inc.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/device.h>
+#include <linux/kdev_t.h>
+
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/mm_types.h>
+#include <linux/mm.h>
+#include <linux/jiffies.h>
+#include <linux/sched.h>
+#include <linux/uaccess.h>
+#include <asm/page.h>
+#include <linux/vmalloc.h>
+#include <linux/interrupt.h>
+#include <linux/wait.h>
+
+#include <linux/of_platform.h>
+#include <linux/of_irq.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+
+#include "mtk_fd.h"
+#include "mtk_fd-core.h"
+
+#include <linux/remoteproc.h>
+#include <linux/platform_data/mtk_scp.h>
+
+#include <linux/pm_runtime.h>
+#include <linux/clk.h>
+
+#ifdef CONFIG_PM_WAKELOCKS
+#include <linux/pm_wakeup.h>
+#else
+#include <linux/wakelock.h>
+#endif
+
+#define FD_DRVNAME	"mtk-fd"
+
+static const struct of_device_id mtk_fd_of_ids[] = {
+	/* Remider: Add this device node manually in .dtsi */
+	{ .compatible = "mediatek,fd", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, mtk_fd_of_ids);
+
+static void mtk_fd_prepare_enable_ccf_clock(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	int ret;
+
+	pm_runtime_get_sync(fd_hw_dev->larb_dev);
+	ret = clk_prepare_enable(fd_hw_dev->fd_clk);
+	if (ret)
+		dev_err(&fd_hw_dev->pdev->dev,
+			"cannot prepare and enable CG_IMGSYS_FD clock\n");
+}
+
+static void mtk_fd_disable_unprepare_ccf_clock(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	clk_disable_unprepare(fd_hw_dev->fd_clk);
+}
+
+static int mtk_fd_clk_ctrl(struct mtk_fd_drv_dev *fd_hw_dev, int en)
+{
+	if (en)
+		mtk_fd_prepare_enable_ccf_clock(fd_hw_dev);
+	else
+		mtk_fd_disable_unprepare_ccf_clock(fd_hw_dev);
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "clock en: %d\n", en);
+
+	return 0;
+}
+
+static int mtk_fd_wait_irq(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	int timeout;
+
+	timeout = wait_event_interruptible_timeout
+		(fd_hw_dev->wq,
+		 (fd_hw_dev->fd_irq_result & FD_IRQ_MASK),
+		 mtk_fd_us_to_jiffies(1 * 1000000));
+
+	if (timeout == 0) {
+		dev_err(&fd_hw_dev->pdev->dev,
+			"%s timeout, %d\n",
+			__func__, fd_hw_dev->fd_irq_result);
+		return -EAGAIN;
+	}
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "irq_res: 0x%8x\n",
+		fd_hw_dev->fd_irq_result);
+
+	if (timeout != 0 && !(fd_hw_dev->fd_irq_result & FD_IRQ_MASK)) {
+		dev_err(&fd_hw_dev->pdev->dev,
+			"%s interrupted by system signal, return value(%d)\n",
+			__func__, timeout);
+		return -ERESTARTSYS;
+	}
+
+	if (!(fd_hw_dev->fd_irq_result & FD_IRQ_MASK)) {
+		dev_err(&fd_hw_dev->pdev->dev,
+			"%s Not FD, %d\n",
+			__func__, fd_hw_dev->fd_irq_result);
+		return -1;
+	}
+
+	fd_hw_dev->fd_irq_result = 0;
+
+	return 0;
+}
+
+static int mtk_fd_send_ipi_init(struct platform_device *pdev,
+				struct fd_buffer *scp_mem)
+{
+	struct ipi_message fd_init_msg;
+
+	fd_init_msg.cmd_id = FD_CMD_INIT;
+	fd_init_msg.fd_manager = *scp_mem;
+
+	scp_ipi_send(pdev, SCP_IPI_FD_CMD, &fd_init_msg, sizeof(fd_init_msg),
+		     0);
+
+	return 0;
+}
+
+static int mtk_fd_send_ipi_cmd(struct platform_device *pdev,
+			       struct v4l2_fd_param *fd_param)
+{
+	struct ipi_message fd_ipi_msg;
+
+	fd_ipi_msg.cmd_id = FD_CMD_ENQ;
+	fd_ipi_msg.fd_param = *fd_param;
+
+	scp_ipi_send(pdev, SCP_IPI_FD_CMD, &fd_ipi_msg, sizeof(fd_ipi_msg), 0);
+
+	return 0;
+}
+
+static irqreturn_t mtk_fd_irq(int irq, void *dev_addr)
+{
+	struct mtk_fd_drv_dev *fd_hw_dev;
+
+	fd_hw_dev = (struct mtk_fd_drv_dev *)dev_addr;
+	fd_hw_dev->fd_irq_result = FD_RD32(fd_hw_dev->fd_base + FD_INT);
+	wake_up_interruptible(&fd_hw_dev->wq);
+
+	return IRQ_HANDLED;
+}
+
+static int mtk_fd_do_callback(struct mtk_fd_drv_dev *fd_hw_dev,
+			      unsigned int frame_state)
+{
+	int ret = 0;
+	struct device *dev;
+	struct mtk_fd_ctx *fd_ctx;
+	struct mtk_fd_ctx_finish_param fparam;
+	struct mtk_isp_fd_drv_data *drv_data;
+
+	drv_data = mtk_fd_hw_dev_to_drv(fd_hw_dev);
+	dev = &drv_data->fd_hw_dev.pdev->dev;
+	fd_ctx = &drv_data->fd_dev.ctx;
+
+	fparam.state = frame_state;
+	fparam.frame_id = fd_hw_dev->fd_ctx.frame_id;
+	dev_dbg(dev, "frame_id(%d)\n", fparam.frame_id);
+
+	ret = mtk_fd_ctx_core_job_finish(&drv_data->fd_dev.ctx, &fparam);
+
+	if (ret)
+		dev_err(dev, "frame_id(%d), finish op failed: %d\n",
+			fparam.frame_id, ret);
+	else
+		fd_hw_dev->state = FD_CBD;
+
+	return ret;
+}
+
+static int mtk_fd_dequeue(struct mtk_fd_drv_dev *fd_hw_dev,
+			  struct v4l2_fd_param *fd_param)
+{
+	struct mtk_isp_fd_drv_data *drv_data;
+	struct fd_user_output *fd_output;
+	u32 num = 0, i = 0;
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "-E. %s.\n", __func__);
+
+	if ((uint64_t)fd_hw_dev->fd_base < VA_OFFSET) {
+		dev_info(&fd_hw_dev->pdev->dev,
+			 "-X. %s. fd_base_error: %p\n",
+			 __func__, fd_hw_dev->fd_base);
+		return -1;
+	}
+
+	num = FD_RD32(fd_hw_dev->fd_base + FD_RESULT);
+	FD_WR32(0x0, fd_hw_dev->fd_base + FD_INT_EN);
+	fd_output = (struct fd_user_output *)fd_param->fd_user_result.va;
+	fd_output->face_number = num;
+
+	drv_data = mtk_fd_hw_dev_to_drv(fd_hw_dev);
+	if ((uint64_t)drv_data < VA_OFFSET) {
+		dev_dbg(&fd_hw_dev->pdev->dev,
+			"-X. %s. fd_base_error\n", __func__);
+		return -1;
+	}
+	mtk_fd_do_callback(fd_hw_dev, MTK_FD_CTX_FRAME_DATA_DONE);
+
+	for (i = 0; i < num; i++) {
+		dev_dbg(&fd_hw_dev->pdev->dev,
+			"id:%d, typ:%d, x0:%d, y0:%d, x1:%d, y1:%d, fcv:0x%x\n",
+			fd_output->face[i].face_idx,
+			fd_output->face[i].type,
+			fd_output->face[i].x0,
+			fd_output->face[i].y0,
+			fd_output->face[i].x1,
+			fd_output->face[i].y1,
+			fd_output->face[i].fcv);
+	}
+	dev_dbg(&fd_hw_dev->pdev->dev, "-X. %s.\n", __func__);
+	return 0;
+}
+
+static int mtk_fd_manager_buf_init(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	struct fd_manager_ctx *manager_ctx;
+
+	manager_ctx = (struct fd_manager_ctx *)fd_hw_dev->fd_ctx.scp_mem.va;
+	manager_ctx->rs_result = fd_hw_dev->fd_ctx.rs_result;
+
+	return 0;
+}
+
+static int mtk_fd_alloc_rs_buf(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	u64 va = 0;
+	dma_addr_t dma_handle = 0;
+	u32 size = RS_BUF_SIZE_MAX;
+
+	va = (uint64_t)dma_alloc_coherent(&fd_hw_dev->pdev->dev, size,
+	&dma_handle, GFP_KERNEL);
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "rsbuffer size: %u\n", size);
+	dev_dbg(&fd_hw_dev->pdev->dev, "va = 0x%llx, iova = 0x%x\n", va,
+		dma_handle);
+
+	if (va == 0) {
+		dev_err(&fd_hw_dev->pdev->dev, "dma_alloc null va!\n");
+		return -1;
+	}
+
+	memset((uint8_t *)va, 0, size);
+
+	fd_hw_dev->fd_ctx.rs_result.va = va;
+	fd_hw_dev->fd_ctx.rs_result.iova = dma_handle;
+
+	return 0;
+}
+
+static int mtk_fd_get_reserve_mem(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	phys_addr_t scp_mem_pa;
+	u64 scp_mem_va;
+	u32 scp_mem_iova;
+	u32 size = 0, size_align = 0;
+	struct sg_table *sgt;
+	int n_pages = 0, i = 0, ret = 0;
+	struct page **pages = NULL;
+	struct mtk_fd_drv_ctx *fd_ctx;
+	struct platform_device *pdev = fd_hw_dev->pdev;
+
+	fd_ctx = &fd_hw_dev->fd_ctx;
+
+	scp_mem_iova = 0;
+	scp_mem_va = scp_get_reserve_mem_virt(SCP_FD_MEM_ID);
+	scp_mem_pa = scp_get_reserve_mem_phys(SCP_FD_MEM_ID);
+	size = (u32)scp_get_reserve_mem_size(SCP_FD_MEM_ID);
+
+	dev_dbg(&pdev->dev, "fd_scp_mem va: 0x%llx, pa: 0x%llx, sz:0x%x\n",
+		scp_mem_va, (u64)scp_mem_pa, size);
+
+	if (scp_mem_va != 0 && size > 0)
+		memset((void *)scp_mem_va, 0, size);
+
+	/* get iova */
+	sgt = &fd_ctx->sgtable;
+	sg_alloc_table(sgt, 1, GFP_KERNEL);
+
+	size_align = round_up(size, PAGE_SIZE);
+	n_pages = size_align >> PAGE_SHIFT;
+
+	pages = kmalloc_array(n_pages, sizeof(struct page *), GFP_KERNEL);
+
+	for (i = 0; i < n_pages; i++)
+		pages[i] = phys_to_page(scp_mem_pa + i * PAGE_SIZE);
+	ret = sg_alloc_table_from_pages(sgt, pages, n_pages,
+					0, size_align, GFP_KERNEL);
+
+	if (ret) {
+		dev_err(&pdev->dev, "failed to get allocate sg table\n");
+		kfree(pages);
+		return ret;
+	}
+
+	dma_map_sg_attrs(&pdev->dev, sgt->sgl, sgt->nents,
+			 DMA_BIDIRECTIONAL, DMA_ATTR_SKIP_CPU_SYNC);
+	scp_mem_iova = sg_dma_address(sgt->sgl);
+	kfree(pages);
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "scpmem size:%u,0x%X\n", size, size);
+	dev_dbg(&fd_hw_dev->pdev->dev, "pa:0x%08X\n", (u32)scp_mem_pa);
+	dev_dbg(&fd_hw_dev->pdev->dev, "va:0x%16llX\n", (u64)scp_mem_va);
+	dev_dbg(&fd_hw_dev->pdev->dev, "iova:0x%08X\n", (u32)scp_mem_iova);
+
+	fd_ctx->scp_mem.pa = scp_mem_pa;
+	fd_ctx->scp_mem.va = scp_mem_va;
+	fd_ctx->scp_mem.iova = scp_mem_iova;
+
+	return 0;
+}
+
+static int mtk_fd_load_vpu(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	struct mtk_fd_drv_ctx *fd_ctx;
+	int ret = 0;
+	phandle rproc_phandle;
+
+	fd_ctx = &fd_hw_dev->fd_ctx;
+
+	/* init vpu */
+	fd_ctx->vpu_pdev = scp_get_pdev(fd_hw_dev->pdev);
+
+	if (!fd_ctx->vpu_pdev) {
+		dev_err(&fd_hw_dev->pdev->dev,
+			"Failed to get VPU device\n");
+		return -EINVAL;
+	}
+
+	if (of_property_read_u32(fd_hw_dev->pdev->dev.of_node,
+				 "mediatek,scp", &rproc_phandle)) {
+		dev_err(&fd_hw_dev->pdev->dev,
+			"Could not get scp device\n");
+		return -EINVAL;
+	}
+
+	fd_ctx->rproc_handle = rproc_get_by_phandle(rproc_phandle);
+
+	if (!fd_ctx->rproc_handle) {
+		dev_err(&fd_hw_dev->pdev->dev,
+			"Could not get FD's rproc_handle\n");
+		return -EINVAL;
+	}
+
+	dev_info(&fd_hw_dev->pdev->dev, "FD rproc_phandle: %llx",
+		 (unsigned long long)fd_ctx->rproc_handle);
+
+	ret = rproc_boot(fd_ctx->rproc_handle);
+	if (ret < 0) {
+		/**
+		 * Return 0 if downloading firmware successfully,
+		 * otherwise it is failed
+		 */
+		dev_err(&fd_hw_dev->pdev->dev,
+			"rproc_boot failed!");
+		return -EINVAL;
+	}
+	return ret;
+}
+
+static int mtk_fd_open_context(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	struct mtk_fd_drv_ctx *fd_ctx;
+
+	fd_ctx = &fd_hw_dev->fd_ctx;
+
+	mtk_fd_load_vpu(fd_hw_dev);
+
+	mtk_fd_get_reserve_mem(fd_hw_dev);
+	mtk_fd_alloc_rs_buf(fd_hw_dev);
+	mtk_fd_manager_buf_init(fd_hw_dev);
+
+	mtk_fd_send_ipi_init(fd_ctx->vpu_pdev, &fd_ctx->scp_mem);
+	return 0;
+}
+
+static int mtk_fd_release_context(struct mtk_fd_drv_dev *fd_hw_dev)
+{
+	struct mtk_fd_drv_ctx *fd_ctx;
+
+	fd_ctx = &fd_hw_dev->fd_ctx;
+
+	atomic_set(&fd_ctx->fd_user_cnt, 0);
+	atomic_set(&fd_ctx->fd_stream_cnt, 0);
+	atomic_set(&fd_ctx->fd_enque_cnt, 0);
+	sg_free_table(&fd_ctx->sgtable);
+
+	return 0;
+}
+
+int mtk_fd_open(struct platform_device *pdev)
+{
+	int ret = 0;
+	s32 usercount;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+	struct mtk_isp_fd_drv_data *fd_drv;
+	struct mtk_fd_drv_ctx *fd_ctx;
+
+	dev_dbg(&pdev->dev, "- E. %s.\n", __func__);
+
+	if (!pdev) {
+		dev_err(&fd_hw_dev->pdev->dev, "platform device is NULL\n");
+		return -EINVAL;
+	}
+
+	fd_drv = dev_get_drvdata(&pdev->dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+	fd_ctx = &fd_hw_dev->fd_ctx;
+	dev_dbg(&fd_hw_dev->pdev->dev, "open fd_hw_dev = 0x%p\n", fd_hw_dev);
+	dev_dbg(&fd_hw_dev->pdev->dev, "open fd_drv = 0x%p\n", fd_drv);
+
+	usercount = atomic_inc_return(&fd_hw_dev->fd_ctx.fd_user_cnt);
+
+	if (usercount == 1) {
+		/* Enable clock */
+		pm_runtime_get_sync(&fd_hw_dev->pdev->dev);
+
+		mtk_fd_open_context(fd_hw_dev);
+		fd_hw_dev->state = FD_INI;
+		fd_hw_dev->streaming = STREAM_OFF;
+	}
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "usercount = %d",
+		atomic_read(&fd_ctx->fd_user_cnt));
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "X. %s\n", __func__);
+
+	return ret;
+}
+EXPORT_SYMBOL(mtk_fd_open);
+
+int mtk_fd_streamon(struct platform_device *pdev, u16 id)
+{
+	int ret = 0;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+	struct mtk_isp_fd_drv_data *fd_drv;
+
+	fd_drv = dev_get_drvdata(&pdev->dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+
+	dev_dbg(&pdev->dev, "- E. %s\n", __func__);
+	fd_hw_dev->streaming = STREAM_ON;
+	atomic_inc_return(&fd_hw_dev->fd_ctx.fd_stream_cnt);
+
+	dev_dbg(&pdev->dev, "- X. %s\n", __func__);
+	return ret;
+}
+EXPORT_SYMBOL(mtk_fd_streamon);
+
+int mtk_fd_enqueue(struct platform_device *pdev,
+		   struct v4l2_fd_param *fd_param)
+{
+	struct mtk_fd_drv_dev *fd_hw_dev;
+	struct mtk_fd_drv_ctx *fd_ctx;
+	struct mtk_isp_fd_drv_data *fd_drv;
+
+	dev_dbg(&pdev->dev, "- E. %s\n", __func__);
+	fd_drv = dev_get_drvdata(&pdev->dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+	fd_ctx = &fd_hw_dev->fd_ctx;
+
+	fd_ctx->frame_id = fd_param->frame_id;
+
+	if (fd_hw_dev->streaming == STREAM_OFF || fd_hw_dev->state == FD_ENQ) {
+		dev_err(&fd_hw_dev->pdev->dev, "enqueue before stream on!\n");
+		return mtk_fd_do_callback(fd_hw_dev,
+						MTK_FD_CTX_FRAME_DATA_ERROR);
+	}
+
+	fd_hw_dev->state = FD_ENQ;
+	atomic_inc_return(&fd_ctx->fd_enque_cnt);
+
+	if (mtk_fd_send_ipi_cmd(fd_ctx->vpu_pdev, fd_param))
+		return -2;
+
+	if (mtk_fd_wait_irq(fd_hw_dev))
+		return mtk_fd_do_callback(fd_hw_dev,
+						MTK_FD_CTX_FRAME_DATA_ERROR);
+
+	mtk_fd_dequeue(fd_hw_dev, fd_param);
+
+	dev_dbg(&pdev->dev, "- X. %s\n", __func__);
+	return 0;
+}
+EXPORT_SYMBOL(mtk_fd_enqueue);
+
+int mtk_fd_release(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+	struct mtk_isp_fd_drv_data *fd_drv;
+
+	fd_drv = dev_get_drvdata(&pdev->dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+	dev_dbg(&fd_hw_dev->pdev->dev, "- E. %s\n", __func__);
+
+	if (!pdev) {
+		dev_err(&fd_hw_dev->pdev->dev, "platform device is NULL\n");
+		return -EINVAL;
+	}
+
+	dev_info(&fd_hw_dev->pdev->dev, "release fd_hw_dev: 0x%p\n", fd_hw_dev);
+
+	if (atomic_dec_and_test(&fd_hw_dev->fd_ctx.fd_user_cnt)) {
+		if (fd_hw_dev->state == FD_ENQ)
+			mtk_fd_wait_irq(fd_hw_dev);
+
+		mtk_fd_release_context(fd_hw_dev);
+
+		pm_runtime_put_sync(&fd_hw_dev->pdev->dev);
+	}
+	dev_info(&fd_hw_dev->pdev->dev, "usercount = %d\n",
+		 atomic_read(&fd_hw_dev->fd_ctx.fd_user_cnt));
+
+	dev_dbg(&fd_hw_dev->pdev->dev, "- X. %s\n", __func__);
+	return ret;
+}
+EXPORT_SYMBOL(mtk_fd_release);
+
+int mtk_fd_streamoff(struct platform_device *pdev, u16 id)
+{
+	int ret = 0;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+	struct mtk_isp_fd_drv_data *fd_drv;
+
+	fd_drv = dev_get_drvdata(&pdev->dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+
+	dev_dbg(&pdev->dev, "- E. %s\n", __func__);
+
+	if (fd_hw_dev->state == FD_ENQ)
+		mtk_fd_wait_irq(fd_hw_dev);
+
+	fd_hw_dev->streaming = STREAM_OFF;
+	atomic_dec_return(&fd_hw_dev->fd_ctx.fd_stream_cnt);
+
+	dev_dbg(&pdev->dev, "- X. %s\n", __func__);
+	return ret;
+}
+EXPORT_SYMBOL(mtk_fd_streamoff);
+
+static struct mtk_fd_ctx_desc mtk_isp_ctx_desc_fd = {
+	"proc_device_fd", mtk_fd_ctx_fd_init,};
+
+static int mtk_fd_probe(struct platform_device *pdev)
+{
+	struct mtk_isp_fd_drv_data *fd_drv;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+	struct mtk_fd_drv_ctx *fd_ctx;
+	struct device_node *node;
+	struct platform_device *larb_pdev;
+	int irq_num = 0;
+	int ret = 0;
+
+	dev_info(&pdev->dev, "E. %s.\n", __func__);
+
+	fd_drv = devm_kzalloc(&pdev->dev, sizeof(*fd_drv), GFP_KERNEL);
+
+	if (!fd_drv)
+		return -ENOMEM;
+
+	dev_set_drvdata(&pdev->dev, fd_drv);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+
+	if (!fd_hw_dev) {
+		dev_err(&pdev->dev, "Unable to allocate fd_hw_dev\n");
+		return -ENOMEM;
+	}
+
+	dev_info(&pdev->dev, "open fd_hw_dev = 0x%p\n", fd_hw_dev);
+	dev_info(&pdev->dev, "open fd_drv = 0x%p\n", fd_drv);
+
+	fd_hw_dev->pdev = pdev;
+	fd_ctx = &fd_hw_dev->fd_ctx;
+
+	irq_num = irq_of_parse_and_map(pdev->dev.of_node, FD_IRQ_IDX);
+	ret = request_irq(irq_num, (irq_handler_t)mtk_fd_irq,
+			  IRQF_TRIGGER_NONE, FD_DRVNAME, fd_hw_dev);
+	if (ret) {
+		dev_info(&pdev->dev, "%s request_irq fail, irq=%d\n",
+			 __func__, irq_num);
+		return ret;
+	}
+	dev_info(&pdev->dev, "irq_num=%d\n", irq_num);
+
+	node = of_parse_phandle(pdev->dev.of_node, "mediatek,larb", 0);
+	if (!node) {
+		dev_err(&pdev->dev, "no mediatek, larb found");
+		return -EINVAL;
+	}
+	larb_pdev = of_find_device_by_node(node);
+	if (!larb_pdev) {
+		dev_err(&pdev->dev, "no mediatek, larb device found");
+		return -EINVAL;
+	}
+	fd_hw_dev->larb_dev = &larb_pdev->dev;
+
+	node = of_find_compatible_node(NULL, NULL, "mediatek,fd");
+	if (!node) {
+		dev_err(&pdev->dev, "find fd node failed!!!\n");
+		return -ENODEV;
+	}
+	fd_hw_dev->fd_base = of_iomap(node, 0);
+	if (!fd_hw_dev->fd_base) {
+		dev_err(&pdev->dev, "unable to map fd node!!!\n");
+		return -ENODEV;
+	}
+	dev_info(&pdev->dev, "fd_hw_dev->fd_base: %lx\n",
+		 (unsigned long)fd_hw_dev->fd_base);
+
+	/* CCF: Grab clock pointer (struct clk*) */
+	fd_hw_dev->fd_clk = devm_clk_get(&pdev->dev, "FD_CLK_IMG_FD");
+	if (IS_ERR(fd_hw_dev->fd_clk)) {
+		dev_err(&pdev->dev, "cannot get FD_CLK_IMG_FD clock\n");
+		return PTR_ERR(fd_hw_dev->fd_clk);
+	}
+
+	pm_runtime_enable(&pdev->dev);
+
+	atomic_set(&fd_ctx->fd_user_cnt, 0);
+	atomic_set(&fd_ctx->fd_stream_cnt, 0);
+	atomic_set(&fd_ctx->fd_enque_cnt, 0);
+
+	init_waitqueue_head(&fd_hw_dev->wq);
+
+	fd_hw_dev->fd_irq_result = 0;
+	fd_hw_dev->streaming = STREAM_OFF;
+
+	ret = mtk_fd_dev_core_init(pdev, &fd_drv->fd_dev, &mtk_isp_ctx_desc_fd);
+
+	if (ret)
+		dev_err(&pdev->dev, "v4l2 init failed: %d\n", ret);
+
+	dev_info(&pdev->dev, "X. FD driver probe.\n");
+
+	return 0;
+}
+
+static int mtk_fd_remove(struct platform_device *pdev)
+{
+	int i4IRQ = 0;
+	struct mtk_fd_drv_dev *fd_hw_dev = NULL;
+	struct mtk_isp_fd_drv_data *drv_data = dev_get_drvdata(&pdev->dev);
+
+	dev_info(&fd_hw_dev->pdev->dev, "-E. %s\n", __func__);
+	if (drv_data) {
+		mtk_fd_dev_core_release(pdev, &drv_data->fd_dev);
+		fd_hw_dev = &drv_data->fd_hw_dev;
+	} else {
+		dev_err(&pdev->dev, "Can't find fd driver data\n");
+		return -EINVAL;
+	}
+
+	mtk_fd_clk_ctrl(fd_hw_dev, clock_off);
+	pm_runtime_disable(&pdev->dev);
+
+	i4IRQ = platform_get_irq(pdev, 0);
+	free_irq(i4IRQ, NULL);
+	kfree(fd_hw_dev);
+
+	dev_info(&fd_hw_dev->pdev->dev, "-X. %s\n", __func__);
+	return 0;
+}
+
+static int mtk_fd_suspend(struct device *dev)
+{
+	struct mtk_isp_fd_drv_data *fd_drv;
+	struct platform_device *pdev;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+
+	if (pm_runtime_suspended(dev))
+		return 0;
+
+	fd_drv = dev_get_drvdata(dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+	pdev = fd_hw_dev->pdev;
+
+	dev_info(&pdev->dev, "E.%s\n", __func__);
+
+	if (atomic_read(&fd_hw_dev->fd_ctx.fd_user_cnt) > 0) {
+		mtk_fd_clk_ctrl(fd_hw_dev, clock_off);
+		dev_info(&pdev->dev, "Disable clock\n");
+	}
+
+	dev_info(&pdev->dev, "X.%s\n", __func__);
+	return 0;
+}
+
+static int mtk_fd_resume(struct device *dev)
+{
+	struct mtk_isp_fd_drv_data *fd_drv;
+	struct platform_device *pdev;
+	struct mtk_fd_drv_dev *fd_hw_dev;
+
+	if (pm_runtime_suspended(dev))
+		return 0;
+
+	fd_drv = dev_get_drvdata(dev);
+	fd_hw_dev = &fd_drv->fd_hw_dev;
+	pdev = fd_hw_dev->pdev;
+
+	dev_info(&pdev->dev, "E.%s\n", __func__);
+
+	if (atomic_read(&fd_hw_dev->fd_ctx.fd_user_cnt) > 0) {
+		mtk_fd_clk_ctrl(fd_hw_dev, clock_on);
+		dev_info(&pdev->dev, "Enable clock\n");
+	}
+
+	dev_info(&pdev->dev, "X.%s\n", __func__);
+	return 0;
+}
+
+static const struct dev_pm_ops mtk_fd_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(mtk_fd_suspend, mtk_fd_resume)
+	SET_RUNTIME_PM_OPS(mtk_fd_suspend, mtk_fd_resume, NULL)
+};
+
+static struct platform_driver mtk_fd_driver = {
+	.probe   = mtk_fd_probe,
+	.remove  = mtk_fd_remove,
+	.driver  = {
+		.name  = FD_DRVNAME,
+		.of_match_table = mtk_fd_of_ids,
+		.pm = &mtk_fd_pm_ops,
+	}
+};
+module_platform_driver(mtk_fd_driver);
+
+MODULE_DESCRIPTION("Mediatek FD driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/media/platform/mtk-isp/fd/mtk_fd.h b/drivers/media/platform/mtk-isp/fd/mtk_fd.h
new file mode 100644
index 000000000000..6cae44064a32
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/fd/mtk_fd.h
@@ -0,0 +1,127 @@
+/* SPDX-License-Identifier: GPL-2.0
+ * Copyright (C) 2015 MediaTek Inc.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_FD_H__
+#define __MTK_FD_H__
+
+#define MTK_FD_MAX_NO		(1024)
+#define MAX_FACE_SEL_NUM	(MTK_FD_MAX_NO + 2)
+
+/* The max number of face sizes could be detected, for feature scaling */
+#define FACE_SIZE_NUM_MAX	(14)
+
+/* FACE_SIZE_NUM_MAX + 1, first scale for input image W/H */
+#define FD_SCALE_NUM		(15)
+
+/* Number of Learning data sets */
+#define LEARNDATA_NUM		(18)
+
+struct fd_buffer {
+	__u64 va;	/* used by APMCU access */
+	__u32 pa;	/* used by CM4 access */
+	__u32 iova;	/* used by HW access */
+} __packed;
+
+enum fd_img_format {
+	FMT_VYUY = 2,
+	FMT_UYVY,
+	FMT_YVYU,
+	FMT_YUYV,
+};
+
+enum fd_mode {
+	FDMODE,
+	SDMODE,
+	VFB,
+	CFB,
+};
+
+struct fd_face_result {
+	__u64 face_idx:12, type:1, x0:10, y0:10, x1:10, y1:10,
+		fcv:18, rip_dir:4, rop_dir:3, det_size:5;
+};
+
+struct fd_user_output {
+	struct fd_face_result face[MAX_FACE_SEL_NUM];
+	__u16 face_number;
+};
+
+struct v4l2_fd_param {
+	u32 frame_id;
+	u16 src_img_h;
+	u16 src_img_w;
+	struct fd_buffer src_img;
+	struct fd_buffer fd_user_param;
+	struct fd_buffer fd_user_result;
+} __packed;
+
+/**
+ * mtk_fd_enqueue - enqueue to fd driver
+ *
+ * @pdev: FD platform device
+ * @fdvtconfig: frame parameters from V4L2 common Framework
+ *
+ * Enqueue a frame to fd driver.
+ *
+ * Return: Return 0 if successfully, otherwise it is failed.
+ */
+int mtk_fd_enqueue(struct platform_device *pdev,
+		   struct v4l2_fd_param *fd_param);
+
+/**
+ * mtk_fd_open -
+ *
+ * @pdev: FD platform device
+ *
+ * Open the FD device driver
+ *
+ * Return: Return 0 if success, otherwise it is failed.
+ */
+int mtk_fd_open(struct platform_device *pdev);
+
+/**
+ * mtk_fd_release -
+ *
+ * @pdev: FD platform device
+ *
+ * Enqueue a frame to FD driver.
+ *
+ * Return: Return 0 if success, otherwise it is failed.
+ */
+int mtk_fd_release(struct platform_device *pdev);
+
+/**
+ * mtk_fd_streamon -
+ *
+ * @pdev: FD platform device
+ * @id: device context id
+ *
+ * Stream on
+ *
+ * Return: Return 0 if success, otherwise it is failed.
+ */
+int mtk_fd_streamon(struct platform_device *pdev, u16 id);
+
+/**
+ * mtk_fd_streamoff -
+ *
+ * @pdev: FD platform device
+ * @id: device context id
+ *
+ * Stream off
+ *
+ * Return: Return 0 if success, otherwise it is failed.
+ */
+int mtk_fd_streamoff(struct platform_device *pdev, u16 id);
+
+#endif/*__MTK_FD_H__*/
diff --git a/drivers/media/platform/mtk-isp/isp_50/Makefile b/drivers/media/platform/mtk-isp/isp_50/Makefile
new file mode 100644
index 000000000000..3211fb095f35
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/Makefile
@@ -0,0 +1,26 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+
+ifeq ($(CONFIG_VIDEO_MEDIATEK_ISP_PASS1_SUPPORT),y)
+obj-y += cam/
+endif
+ifeq ($(CONFIG_VIDEO_MEDIATEK_ISP_DIP_SUPPORT),y)
+obj-y += dip/
+endif
+ifeq ($(CONFIG_VIDEO_MEDIATEK_ISP_CAMSV_SUPPORT),y)
+obj-y += camSV/
+endif
+ifeq ($(CONFIG_MTK_SENINF),y)
+obj-y += seninf/
+endif
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/Makefile b/drivers/media/platform/mtk-isp/isp_50/cam/Makefile
new file mode 100644
index 000000000000..8ddc34baf386
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/Makefile
@@ -0,0 +1,19 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+
+mtk-cam-isp-objs += \
+	mtk_cam.o mtk_cam-dev.o mtk_cam-dev-ctx-core.o \
+	mtk_cam-ctrl.o mtk_cam-scp.o \
+	mtk_cam-v4l2-util.o mtk_cam-smem-drv.o
+
+obj-$(CONFIG_VIDEO_MEDIATEK_ISP_PASS1_SUPPORT) += mtk-cam-isp.o
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.c
new file mode 100644
index 000000000000..455216ad9cc4
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.c
@@ -0,0 +1,133 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ryan Yu <ryan.yu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include "mtk_cam-dev.h"
+#include "mtk_cam-ctrl.h"
+#include "mtk_cam.h"
+
+static int handle_ctrl_get_bin_info(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_cam_dev *cam_dev = ctrl->priv;
+	const unsigned int idx = MTK_CAM_P1_MAIN_STREAM_OUT;
+	struct v4l2_format *imgo_fmt = &cam_dev->mem2mem2_nodes[idx].vdev_fmt;
+	unsigned int width, height;
+
+	width = imgo_fmt->fmt.pix_mp.width;
+	height = imgo_fmt->fmt.pix_mp.height;
+
+	dev_dbg(&cam_dev->pdev->dev, "Get bin info w*h:(%d*%d)",
+		width, height);
+
+	ctrl->val = (width << 16) | height;
+
+	return 0;
+}
+
+static int handle_ctrl_get_raw_path(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_cam_dev *cam_dev = ctrl->priv;
+	struct isp_p1_device *p1_dev = get_p1_device(&cam_dev->pdev->dev);
+
+	ctrl->val = p1_dev->isp_ctx.isp_raw_path;
+
+	dev_dbg(&cam_dev->pdev->dev, "Get raw path:%d", ctrl->val);
+
+	return 0;
+}
+
+static int handle_ctrl_set_raw_path(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_cam_dev *cam_dev = ctrl->priv;
+	struct isp_p1_device *p1_dev = get_p1_device(&cam_dev->pdev->dev);
+
+	p1_dev->isp_ctx.isp_raw_path = ctrl->val;
+	dev_dbg(&cam_dev->pdev->dev, "Set raw path:%d", ctrl->val);
+	return 0;
+}
+
+static int mtk_cam_dev_g_ctrl(struct v4l2_ctrl *ctrl)
+{
+	switch (ctrl->id) {
+	case V4L2_CID_PRIVATE_GET_BIN_INFO:
+		handle_ctrl_get_bin_info(ctrl);
+		break;
+	case V4L2_CID_PRIVATE_RAW_PATH:
+		handle_ctrl_get_raw_path(ctrl);
+		break;
+	default:
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static int mtk_cam_dev_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	switch (ctrl->id) {
+	case V4L2_CID_PRIVATE_RAW_PATH:
+		return handle_ctrl_set_raw_path(ctrl);
+	default:
+		return -EINVAL;
+	}
+}
+
+static const struct v4l2_ctrl_ops mtk_cam_dev_ctrl_ops = {
+	.g_volatile_ctrl = mtk_cam_dev_g_ctrl,
+	.s_ctrl = mtk_cam_dev_s_ctrl,
+};
+
+struct v4l2_ctrl_config mtk_cam_controls[] = {
+	{
+	.ops = &mtk_cam_dev_ctrl_ops,
+	.id = V4L2_CID_PRIVATE_GET_BIN_INFO,
+	.name = "MTK CAM GET BIN INFO",
+	.type = V4L2_CTRL_TYPE_INTEGER,
+	.min = (IMG_MIN_WIDTH << 16) | IMG_MIN_HEIGHT,
+	.max = (IMG_MAX_WIDTH << 16) | IMG_MAX_HEIGHT,
+	.step = 1,
+	.def = (IMG_MAX_WIDTH << 16) | IMG_MAX_HEIGHT,
+	.flags = V4L2_CTRL_FLAG_READ_ONLY | V4L2_CTRL_FLAG_VOLATILE,
+	},
+	{
+	.ops = &mtk_cam_dev_ctrl_ops,
+	.id = V4L2_CID_PRIVATE_RAW_PATH,
+	.name = "MTK CAM RAW PATH",
+	.type = V4L2_CTRL_TYPE_BOOLEAN,
+	.min = 0,
+	.max = 1,
+	.step = 1,
+	.def = 1,
+	},
+};
+
+int mtk_cam_ctrl_init(struct mtk_cam_dev *cam_dev,
+		      struct v4l2_ctrl_handler *hdl)
+{
+	unsigned int i;
+
+	/* Initialized HW controls, allow V4L2_CID_MTK_CAM_MAX ctrls */
+	v4l2_ctrl_handler_init(hdl, V4L2_CID_MTK_CAM_MAX);
+	if (hdl->error) {
+		v4l2_ctrl_handler_free(hdl);
+		return hdl->error;
+	}
+
+	for (i = 0; i < ARRAY_SIZE(mtk_cam_controls); i++)
+		v4l2_ctrl_new_custom(hdl, &mtk_cam_controls[i], cam_dev);
+
+	dev_info(&cam_dev->pdev->dev, "%s done", __func__);
+	return 0;
+}
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.h
new file mode 100644
index 000000000000..74a6538c81ac
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctrl.h
@@ -0,0 +1,32 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ryan Yu <ryan.yu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_CAM_CTRL_H__
+#define __MTK_CAM_CTRL_H__
+
+#include <media/v4l2-ctrls.h>
+
+#define V4L2_CID_MTK_CAM_PRIVATE_CAM  V4L2_CID_USER_MTK_CAM_BASE
+#define V4L2_CID_PRIVATE_GET_BIN_INFO \
+	(V4L2_CID_MTK_CAM_PRIVATE_CAM + 1)
+#define V4L2_CID_PRIVATE_RAW_PATH \
+	(V4L2_CID_MTK_CAM_PRIVATE_CAM + 2)
+
+#define V4L2_CID_MTK_CAM_MAX	16
+
+int mtk_cam_ctrl_init(struct mtk_cam_dev *cam_dev,
+		      struct v4l2_ctrl_handler *hdl);
+
+#endif /* __MTK_CAM_CTRL_H__ */
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctx.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctx.h
new file mode 100644
index 000000000000..5f3b807c595d
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-ctx.h
@@ -0,0 +1,116 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_CAM_CTX_H__
+#define __MTK_CAM_CTX_H__
+
+#include <linux/device.h>
+#include <linux/types.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ctrls.h>
+#include <media/videobuf2-core.h>
+#include <media/v4l2-subdev.h>
+
+#define MTK_CAM_DEV_NODES			11
+#define MTK_CAM_DEV_FRAME_BUNDLE_BUFFER_MAX	MTK_CAM_DEV_NODES
+
+struct mtk_cam_dev;
+
+/*
+ * struct mtk_cam_dev_node_desc - node attributes
+ *
+ * @id:		 id of the context queue
+ * @name:	 media entity name
+ * @description: descritpion of node
+ * @cap:	 mapped to V4L2 capabilities
+ * @buf_type:	 mapped to V4L2 buffer type
+ * @dma_port:	 the dma port associated to the buffer
+ * @link_flags:	 default media link flags
+ * @smem_alloc:	 using the cam_smem_drv as alloc ctx or not
+ * @capture:	 true for capture queue (device to user)
+ *		 false for output queue (from user to device)
+ * @image:	 true for image node, false for meta node
+ * @num_fmts:	 the number of supported formats
+ * @default_fmt_idx: default format of this node
+ * @max_buf_count: maximum V4L2 buffer count
+ * @ioctl_ops:  mapped to v4l2_ioctl_ops
+ * @fmts:	supported format
+ *
+ */
+struct mtk_cam_dev_node_desc {
+	u8 id;
+	char *name;
+	char *description;
+	u32 cap;
+	u32 buf_type;
+	u32 dma_port;
+	u32 link_flags;
+	u8 smem_alloc:1;
+	u8 capture:1;
+	u8 image:1;
+	u8 num_fmts;
+	u8 default_fmt_idx;
+	u8 max_buf_count;
+	const struct v4l2_ioctl_ops *ioctl_ops;
+	struct v4l2_format *fmts;
+};
+
+/* Attributes setup by device owner */
+struct mtk_cam_dev_queues_setting {
+	struct mtk_cam_dev_node_desc *output_node_descs;
+	unsigned int total_output_nodes;
+	struct mtk_cam_dev_node_desc *capture_node_descs;
+	unsigned int total_capture_nodes;
+};
+
+struct mtk_cam_dev_start_param {
+	int request_fd;
+	struct mtk_cam_dev_buffer*
+		buffers[MTK_CAM_DEV_FRAME_BUNDLE_BUFFER_MAX];
+};
+
+struct mtk_cam_dev_finish_param {
+	int request_fd;
+	unsigned int frame_seq_no;
+	unsigned int state;
+	struct list_head *list_buf;
+};
+
+/* For v4l2 event data, must smaller than 64 bytes */
+struct mtk_cam_dev_stat_event_data {
+	__u32 frame_seq_no;
+	__u32 irq_status_mask;
+	__u32 dma_status_mask;
+};
+
+int mtk_cam_dev_core_queue_setup(struct mtk_cam_dev *cam_dev,
+				 struct mtk_cam_dev_queues_setting *setting);
+int mtk_cam_dev_core_job_finish(struct mtk_cam_dev *cam_dev,
+				struct mtk_cam_dev_finish_param *param);
+int mtk_cam_dev_queue_event_dev_state(struct mtk_cam_dev *cam_dev,
+				      struct mtk_cam_dev_stat_event_data *stat);
+void mtk_cam_dev_fmt_set_img(struct device *dev,
+			     struct v4l2_pix_format_mplane *dest_fmt,
+			     struct v4l2_pix_format_mplane *src_fmt,
+			     unsigned int node_id);
+struct v4l2_format *
+mtk_cam_dev_find_fmt(struct mtk_cam_dev_node_desc *queue_desc, u32 format);
+void mtk_cam_dev_load_default_fmt(struct device *dev,
+				  struct mtk_cam_dev_node_desc *queue,
+				  struct v4l2_format *dest_fmt);
+void mtk_cam_dev_cal_mplane_pix_fmt(struct device *dev,
+				    struct v4l2_pix_format_mplane *dest_fmt,
+				    unsigned int node_id);
+#endif /*__MTK_CAM_CTX_H__*/
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev-ctx-core.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev-ctx-core.c
new file mode 100644
index 000000000000..c17b294c64f9
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev-ctx-core.c
@@ -0,0 +1,302 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include <linux/dma-mapping.h>
+#include <media/v4l2-event.h>
+
+#include "mtk_cam.h"
+#include "mtk_cam-ctx.h"
+#include "mtk_cam-dev.h"
+#include "mtk_cam-v4l2-util.h"
+#include "mtk_cam-smem.h"
+
+static __u32 get_pixel_byte_by_fmt(__u32 pix_fmt)
+{
+	switch (pix_fmt) {
+	case V4L2_PIX_FMT_MTISP_B8:
+	case V4L2_PIX_FMT_MTISP_F8:
+		return 8;
+	case V4L2_PIX_FMT_MTISP_B10:
+	case V4L2_PIX_FMT_MTISP_F10:
+		return 10;
+	case V4L2_PIX_FMT_MTISP_B12:
+	case V4L2_PIX_FMT_MTISP_F12:
+		return 12;
+	case V4L2_PIX_FMT_MTISP_B14:
+	case V4L2_PIX_FMT_MTISP_F14:
+		return 14;
+	case V4L2_PIX_FMT_MTISP_U8:
+	case V4L2_PIX_FMT_MTISP_U10:
+	case V4L2_PIX_FMT_MTISP_U12:
+	case V4L2_PIX_FMT_MTISP_U14:
+		return 16;
+	default:
+		return 0;
+	}
+}
+
+static __u32 align_main_stream_size(__u32 size, unsigned int pix_mode)
+{
+	switch (pix_mode) {
+	case default_pixel_mode:
+	case four_pixel_mode:
+		return ALIGN(size, 8);
+	case two_pixel_mode:
+		return ALIGN(size, 4);
+	case one_pixel_mode:
+		return ALIGN(size, 2);
+	default:
+		break;
+	}
+	return 0;
+}
+
+static unsigned int align_packetd_out_size(__u32 size,
+					   unsigned int pix_mode,
+					   __u32 fmt)
+{
+	switch (pix_mode) {
+	case default_pixel_mode:
+	case four_pixel_mode:
+		return ALIGN(size, 16);
+	case two_pixel_mode:
+		return ALIGN(size, 8);
+	case one_pixel_mode:
+		if (fmt == V4L2_PIX_FMT_MTISP_F10)
+			return ALIGN(size, 4);
+		else
+			return ALIGN(size, 8);
+	default:
+		return ALIGN(size, 16);
+	}
+	return 0;
+}
+
+static __u32 cal_main_stream_stride(struct device *dev,
+				    __u32 width,
+				    __u32 pix_fmt,
+				    __u32 pix_mode)
+{
+	__u32 stride;
+	__u32 pixel_byte = get_pixel_byte_by_fmt(pix_fmt);
+
+	width = ALIGN(width, 4);
+	stride = ALIGN(DIV_ROUND_UP(width * pixel_byte, 8), 2);
+	/* expand stride, instead of shrink width */
+	stride = align_main_stream_size(stride, pix_mode);
+
+	dev_dbg(dev,
+		"main width:%d, pix_mode:%d, stride:%d\n",
+		width, pix_mode, stride);
+	return stride;
+}
+
+static __u32 cal_packed_out_stride(struct device *dev,
+				   __u32 width,
+				   __u32 pix_fmt,
+				   __u32 pix_mode)
+{
+	__u32 stride;
+	__u32 pixel_byte = get_pixel_byte_by_fmt(pix_fmt);
+
+	width = ALIGN(width, 4);
+	stride = DIV_ROUND_UP(width * 3, 2);
+	stride = DIV_ROUND_UP(stride * pixel_byte, 8);
+	/* expand stride, instead of shrink width */
+	stride = align_packetd_out_size(stride, pix_mode, pix_fmt);
+
+	dev_dbg(dev,
+		"packed width:%d, pix_mode:%d, stride:%d\n",
+		width, pix_mode, stride);
+
+	return stride;
+}
+
+static __u32 cal_img_stride(struct device *dev,
+			    int node_id,
+			    __u32 width,
+			    __u32 pix_fmt)
+{
+	/* Currently, only support one_pixel_mode */
+	if (node_id == MTK_CAM_P1_MAIN_STREAM_OUT)
+		return cal_main_stream_stride(dev, width, pix_fmt,
+					      one_pixel_mode);
+	else if (node_id == MTK_CAM_P1_PACKED_BIN_OUT)
+		return cal_packed_out_stride(dev, width, pix_fmt,
+					      one_pixel_mode);
+
+	return 0;
+}
+
+struct v4l2_format *
+mtk_cam_dev_find_fmt(struct mtk_cam_dev_node_desc *desc, u32 format)
+{
+	unsigned int i;
+	struct v4l2_format *dev_fmt;
+
+	for (i = 0; i < desc->num_fmts; i++) {
+		dev_fmt = &desc->fmts[i];
+		if (dev_fmt->fmt.pix_mp.pixelformat == format)
+			return dev_fmt;
+	}
+
+	return NULL;
+}
+
+/* The helper to configure the device context */
+int mtk_cam_dev_core_queue_setup(struct mtk_cam_dev *cam_dev,
+				 struct mtk_cam_dev_queues_setting *setting)
+{
+	unsigned int i, node_idx;
+
+	node_idx = 0;
+
+	/* Setup the output queue */
+	for (i = 0; i < setting->total_output_nodes; i++)
+		cam_dev->mem2mem2_nodes[node_idx++].desc =
+			setting->output_node_descs[i];
+
+	/* Setup the capture queue */
+	for (i = 0; i < setting->total_capture_nodes; i++)
+		cam_dev->mem2mem2_nodes[node_idx++].desc =
+			setting->capture_node_descs[i];
+
+	cam_dev->dev_node_num = node_idx;
+
+	return 0;
+}
+
+int mtk_cam_dev_core_job_finish(struct mtk_cam_dev *cam_dev,
+				struct mtk_cam_dev_finish_param *fram_param)
+{
+	struct mtk_cam_dev_buffer *buf, *b0;
+
+	if (!cam_dev->streaming)
+		return 0;
+
+	dev_dbg(&cam_dev->pdev->dev,
+		"job recvied request fd(%d), frame_seq(%d) state(%d)\n",
+		fram_param->request_fd,
+		fram_param->frame_seq_no,
+		fram_param->state);
+
+	/*
+	 * Set the buffer's VB2 status so that the user can dequeue
+	 * the buffer.
+	 */
+	list_for_each_entry_safe(buf, b0, fram_param->list_buf, list) {
+		list_del(&buf->list);
+		buf->vbb.vb2_buf.timestamp = ktime_get_ns();
+		buf->vbb.sequence = fram_param->frame_seq_no;
+		vb2_buffer_done(&buf->vbb.vb2_buf, fram_param->state);
+	}
+
+	return 0;
+}
+
+int mtk_cam_dev_queue_event_dev_state(struct mtk_cam_dev *cam_dev,
+				      struct mtk_cam_dev_stat_event_data *stat)
+{
+	struct v4l2_event event;
+
+	memset(&event, 0, sizeof(event));
+	event.type = V4L2_EVENT_FRAME_SYNC;
+	event.u.frame_sync.frame_sequence = stat->frame_seq_no;
+	v4l2_event_queue(cam_dev->subdev.devnode, &event);
+
+	return 0;
+}
+
+/* Calcuate mplane pix format */
+void mtk_cam_dev_cal_mplane_pix_fmt(struct device *dev,
+				    struct v4l2_pix_format_mplane *dest_fmt,
+				    unsigned int node_id)
+{
+	unsigned int i;
+	__u32 bpl, sizeimage, imagsize;
+
+	imagsize = 0;
+	for (i = 0 ; i < dest_fmt->num_planes; ++i) {
+		bpl = cal_img_stride(dev,
+				     node_id,
+				     dest_fmt->width,
+				     dest_fmt->pixelformat);
+		sizeimage = bpl * dest_fmt->height;
+		imagsize += sizeimage;
+		dest_fmt->plane_fmt[i].bytesperline = bpl;
+		dest_fmt->plane_fmt[i].sizeimage = sizeimage;
+		memset(dest_fmt->plane_fmt[i].reserved,
+		       0, sizeof(dest_fmt->plane_fmt[i].reserved));
+		dev_dbg(dev, "plane:%d,bpl:%d,sizeimage:%u\n",
+			i,  bpl, dest_fmt->plane_fmt[i].sizeimage);
+	}
+	if (dest_fmt->num_planes == 1)
+		dest_fmt->plane_fmt[0].sizeimage = imagsize;
+}
+
+void mtk_cam_dev_fmt_set_img(struct device *dev,
+			     struct v4l2_pix_format_mplane *dest_fmt,
+			     struct v4l2_pix_format_mplane *src_fmt,
+			     unsigned int node_id)
+{
+	dest_fmt->width = src_fmt->width;
+	dest_fmt->height = src_fmt->height;
+	dest_fmt->pixelformat = src_fmt->pixelformat;
+	dest_fmt->field = src_fmt->field;
+	dest_fmt->colorspace = src_fmt->colorspace;
+	dest_fmt->num_planes = src_fmt->num_planes;
+	/* Use default */
+	dest_fmt->ycbcr_enc = V4L2_YCBCR_ENC_DEFAULT;
+	dest_fmt->quantization = V4L2_QUANTIZATION_DEFAULT;
+	dest_fmt->xfer_func =
+		V4L2_MAP_XFER_FUNC_DEFAULT(dest_fmt->colorspace);
+	memset(dest_fmt->reserved, 0, sizeof(dest_fmt->reserved));
+
+	dev_dbg(dev, "%s: Dest Fmt:%c%c%c%c, w*h:%d*%d\n",
+		__func__,
+		(dest_fmt->pixelformat & 0xFF),
+		(dest_fmt->pixelformat >> 8) & 0xFF,
+		(dest_fmt->pixelformat >> 16) & 0xFF,
+		(dest_fmt->pixelformat >> 24) & 0xFF,
+		dest_fmt->width,
+		dest_fmt->height);
+
+	mtk_cam_dev_cal_mplane_pix_fmt(dev, dest_fmt, node_id);
+}
+
+/* Get the default format setting */
+void mtk_cam_dev_load_default_fmt(struct device *dev,
+				  struct mtk_cam_dev_node_desc *queue_desc,
+				  struct v4l2_format *dest)
+{
+	struct v4l2_format *default_fmt =
+		&queue_desc->fmts[queue_desc->default_fmt_idx];
+
+	dest->type = queue_desc->buf_type;
+
+	/* Configure default format based on node type */
+	if (queue_desc->image) {
+		mtk_cam_dev_fmt_set_img(dev,
+					&dest->fmt.pix_mp,
+					&default_fmt->fmt.pix_mp,
+					queue_desc->id);
+	} else {
+		dest->fmt.meta.dataformat = default_fmt->fmt.meta.dataformat;
+		dest->fmt.meta.buffersize = default_fmt->fmt.meta.buffersize;
+	}
+}
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.c
new file mode 100644
index 000000000000..35e77ee4ec47
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.c
@@ -0,0 +1,525 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ * Copyright (C) 2017 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * MTK_CAM-dev is highly based on Intel IPU3 ImgU driver.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ioctl.h>
+#include <media/v4l2-event.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk_cam.h"
+#include "mtk_cam-dev.h"
+#include "mtk_cam-smem.h"
+#include "mtk_cam-v4l2-util.h"
+
+static const struct v4l2_ioctl_ops mtk_cam_v4l2_vcap_ioctl_ops = {
+	.vidioc_querycap = mtk_cam_videoc_querycap,
+	.vidioc_enum_framesizes = mtk_cam_enum_framesizes,
+	.vidioc_enum_fmt_vid_cap_mplane = mtk_cam_videoc_enum_fmt,
+	.vidioc_g_fmt_vid_cap_mplane = mtk_cam_videoc_g_fmt,
+	.vidioc_s_fmt_vid_cap_mplane = mtk_cam_videoc_s_fmt,
+	.vidioc_try_fmt_vid_cap_mplane = mtk_cam_videoc_try_fmt,
+	.vidioc_enum_input = mtk_cam_vidioc_enum_input,
+	.vidioc_g_input = mtk_cam_vidioc_g_input,
+	.vidioc_s_input = mtk_cam_vidioc_s_input,
+	/* buffer queue management */
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+	.vidioc_subscribe_event = mtk_cam_vidioc_subscribe_event,
+	.vidioc_unsubscribe_event = v4l2_event_unsubscribe,
+};
+
+static const struct v4l2_ioctl_ops mtk_cam_v4l2_vout_ioctl_ops = {
+	.vidioc_querycap = mtk_cam_videoc_querycap,
+	.vidioc_enum_framesizes = mtk_cam_enum_framesizes,
+	.vidioc_enum_fmt_vid_out_mplane = mtk_cam_videoc_enum_fmt,
+	.vidioc_g_fmt_vid_out_mplane = mtk_cam_videoc_g_fmt,
+	.vidioc_s_fmt_vid_out_mplane = mtk_cam_videoc_s_fmt,
+	.vidioc_try_fmt_vid_out_mplane = mtk_cam_videoc_try_fmt,
+	.vidioc_enum_input = mtk_cam_vidioc_enum_input,
+	.vidioc_g_input = mtk_cam_vidioc_g_input,
+	.vidioc_s_input = mtk_cam_vidioc_s_input,
+	/* buffer queue management */
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static  const struct v4l2_ioctl_ops mtk_cam_v4l2_meta_cap_ioctl_ops = {
+	.vidioc_querycap = mtk_cam_videoc_querycap,
+	.vidioc_enum_fmt_meta_cap = mtk_cam_meta_enum_format,
+	.vidioc_g_fmt_meta_cap = mtk_cam_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_cap = mtk_cam_videoc_g_meta_fmt,
+	.vidioc_try_fmt_meta_cap = mtk_cam_videoc_g_meta_fmt,
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static  const struct v4l2_ioctl_ops mtk_cam_v4l2_meta_out_ioctl_ops = {
+	.vidioc_querycap = mtk_cam_videoc_querycap,
+	.vidioc_enum_fmt_meta_out = mtk_cam_meta_enum_format,
+	.vidioc_g_fmt_meta_out = mtk_cam_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_out = mtk_cam_videoc_g_meta_fmt,
+	.vidioc_try_fmt_meta_out = mtk_cam_videoc_g_meta_fmt,
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static struct v4l2_format meta_fmts[] = {
+	{
+		.fmt.meta = {
+			.dataformat = V4L2_META_FMT_MTISP_PARAMS,
+			.buffersize = 128 * PAGE_SIZE,
+		},
+	},
+	{
+		.fmt.meta = {
+			.dataformat = V4L2_META_FMT_MTISP_3A,
+			.buffersize = 300 * PAGE_SIZE,
+		},
+	},
+	{
+		.fmt.meta = {
+			.dataformat = V4L2_META_FMT_MTISP_AF,
+			.buffersize = 160 * PAGE_SIZE,
+		},
+	},
+	{
+		.fmt.meta = {
+			.dataformat = V4L2_META_FMT_MTISP_LCS,
+			.buffersize = 80 * PAGE_SIZE,
+		},
+	},
+	{
+		.fmt.meta = {
+			.dataformat = V4L2_META_FMT_MTISP_LMV,
+			.buffersize = 128 * PAGE_SIZE,
+		},
+	},
+};
+
+/* Need to update mtk_cam_dev_fmt_set_img for default format configuration */
+static struct v4l2_format stream_out_fmts[] = {
+	{
+		.fmt.pix_mp = {
+			.width = IMG_MAX_WIDTH,
+			.height = IMG_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_B8,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_SRGB,
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.pix_mp = {
+			.width = IMG_MAX_WIDTH,
+			.height = IMG_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_B10,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_SRGB,
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.pix_mp = {
+			.width = IMG_MAX_WIDTH,
+			.height = IMG_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_B12,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_SRGB,
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.pix_mp = {
+			.width = IMG_MAX_WIDTH,
+			.height = IMG_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_B14,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_SRGB,
+			.num_planes = 1,
+		},
+	},
+};
+
+static struct v4l2_format bin_out_fmts[] = {
+	{
+		.fmt.pix_mp = {
+			.width = RRZ_MAX_WIDTH,
+			.height = RRZ_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_F8,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_RAW,
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.pix_mp = {
+			.width = RRZ_MAX_WIDTH,
+			.height = RRZ_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_F10,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_RAW,
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.pix_mp = {
+			.width = RRZ_MAX_WIDTH,
+			.height = RRZ_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_F12,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_RAW,
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.pix_mp = {
+			.width = RRZ_MAX_WIDTH,
+			.height = RRZ_MAX_HEIGHT,
+			.pixelformat = V4L2_PIX_FMT_MTISP_F14,
+			.field = V4L2_FIELD_NONE,
+			.colorspace = V4L2_COLORSPACE_RAW,
+			.num_planes = 1,
+		},
+	},
+};
+
+static struct mtk_cam_dev_node_desc
+	output_queues[MTK_CAM_P1_TOTAL_OUTPUT] = {
+	{
+		.id = MTK_CAM_P1_META_IN_0,
+		.name = "meta input",
+		.description = "ISP tuning parameters",
+		.cap = V4L2_CAP_META_OUTPUT,
+		.buf_type = V4L2_BUF_TYPE_META_OUTPUT,
+		.link_flags = 0,
+		.capture = false,
+		.image = false,
+		.smem_alloc = true,
+		.fmts = meta_fmts,
+		.num_fmts = ARRAY_SIZE(meta_fmts),
+		.default_fmt_idx = 0,
+		.max_buf_count = 10,
+		.ioctl_ops = &mtk_cam_v4l2_meta_out_ioctl_ops,
+	},
+};
+
+static struct mtk_cam_dev_node_desc
+	capture_queues[MTK_CAM_P1_TOTAL_CAPTURE] = {
+	{
+		.id = MTK_CAM_P1_MAIN_STREAM_OUT,
+		.name = "main stream",
+		.cap = V4L2_CAP_VIDEO_CAPTURE_MPLANE,
+		.buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
+		.link_flags = 0,
+		.capture = true,
+		.image = true,
+		.smem_alloc = false,
+		.dma_port = R_IMGO,
+		.fmts = stream_out_fmts,
+		.num_fmts = ARRAY_SIZE(stream_out_fmts),
+		.default_fmt_idx = 0,
+		.ioctl_ops = &mtk_cam_v4l2_vcap_ioctl_ops,
+	},
+	{
+		.id = MTK_CAM_P1_PACKED_BIN_OUT,
+		.name = "packed out",
+		.cap = V4L2_CAP_VIDEO_CAPTURE_MPLANE,
+		.buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
+		.link_flags = 0,
+		.capture = true,
+		.image = true,
+		.smem_alloc = false,
+		.dma_port = R_RRZO,
+		.fmts = bin_out_fmts,
+		.num_fmts = ARRAY_SIZE(bin_out_fmts),
+		.default_fmt_idx = 1,
+		.ioctl_ops = &mtk_cam_v4l2_vcap_ioctl_ops,
+	},
+	{
+		.id = MTK_CAM_P1_META_OUT_0,
+		.name = "partial meta 0",
+		.description = "AE/AWB histogram",
+		.cap = V4L2_CAP_META_CAPTURE,
+		.buf_type = V4L2_BUF_TYPE_META_CAPTURE,
+		.link_flags = 0,
+		.capture = true,
+		.image = false,
+		.smem_alloc = false,
+		.dma_port = R_AAO | R_FLKO | R_PSO,
+		.fmts = meta_fmts,
+		.num_fmts = ARRAY_SIZE(meta_fmts),
+		.default_fmt_idx = 1,
+		.max_buf_count = 5,
+		.ioctl_ops = &mtk_cam_v4l2_meta_cap_ioctl_ops,
+	},
+	{
+		.id = MTK_CAM_P1_META_OUT_1,
+		.name = "partial meta 1",
+		.description = "AF histogram",
+		.cap = V4L2_CAP_META_CAPTURE,
+		.buf_type = V4L2_BUF_TYPE_META_CAPTURE,
+		.link_flags = 0,
+		.capture = true,
+		.image = false,
+		.smem_alloc = false,
+		.dma_port = R_AFO,
+		.fmts = meta_fmts,
+		.num_fmts = ARRAY_SIZE(meta_fmts),
+		.default_fmt_idx = 2,
+		.max_buf_count = 5,
+		.ioctl_ops = &mtk_cam_v4l2_meta_cap_ioctl_ops,
+	},
+	{
+		.id = MTK_CAM_P1_META_OUT_2,
+		.name = "partial meta 2",
+		.description = "Local contrast enhanced statistics",
+		.cap = V4L2_CAP_META_CAPTURE,
+		.buf_type = V4L2_BUF_TYPE_META_CAPTURE,
+		.link_flags = MEDIA_LNK_FL_DYNAMIC,
+		.capture = true,
+		.image = false,
+		.smem_alloc = false,
+		.dma_port = R_LCSO,
+		.fmts = meta_fmts,
+		.num_fmts = ARRAY_SIZE(meta_fmts),
+		.default_fmt_idx = 3,
+		.max_buf_count = 10,
+		.ioctl_ops = &mtk_cam_v4l2_meta_cap_ioctl_ops,
+	},
+	{
+		.id = MTK_CAM_P1_META_OUT_3,
+		.name = "partial meta 3",
+		.description = "Local motion vector histogram",
+		.cap = V4L2_CAP_META_CAPTURE,
+		.buf_type = V4L2_BUF_TYPE_META_CAPTURE,
+		.link_flags = MEDIA_LNK_FL_DYNAMIC,
+		.capture = true,
+		.image = false,
+		.smem_alloc = false,
+		.dma_port = R_LMVO,
+		.fmts = meta_fmts,
+		.num_fmts = ARRAY_SIZE(meta_fmts),
+		.default_fmt_idx = 4,
+		.max_buf_count = 10,
+		.ioctl_ops = &mtk_cam_v4l2_meta_cap_ioctl_ops,
+	},
+};
+
+static struct mtk_cam_dev_queues_setting queues_setting = {
+	.output_node_descs = output_queues,
+	.total_output_nodes = MTK_CAM_P1_TOTAL_OUTPUT,
+	.capture_node_descs = capture_queues,
+	.total_capture_nodes = MTK_CAM_P1_TOTAL_CAPTURE,
+};
+
+static struct platform_device *
+mtk_cam_dev_of_find_smem_dev(struct platform_device *pdev)
+{
+	struct device_node *smem_dev_node;
+
+	smem_dev_node = of_parse_phandle(pdev->dev.of_node,
+					 "smem_device", 0);
+	if (!smem_dev_node) {
+		dev_err(&pdev->dev,
+			"failed to find isp smem device for (%s)\n",
+			pdev->name);
+		return NULL;
+	}
+
+	dev_dbg(&pdev->dev, "smem of node found, try to discovery device\n");
+	return of_find_device_by_node(smem_dev_node);
+}
+
+/* Initliaze a mtk_cam_dev representing a completed HW ISP device. */
+static int mtk_cam_dev_init(struct mtk_cam_dev *cam_dev,
+			    struct platform_device *pdev)
+{
+	int ret;
+
+	/* v4l2 sub-device registration */
+	dev_info(&cam_dev->pdev->dev, "mem2mem2.name: %s\n",
+		 MTK_CAM_DEV_P1_NAME);
+	ret = mtk_cam_mem2mem2_v4l2_register(cam_dev);
+	if (ret) {
+		dev_err(&cam_dev->pdev->dev,
+			"failed to create V4L2 devices (%d)\n", ret);
+		goto failed_mem2mem2;
+	}
+
+	ret = mtk_cam_v4l2_async_register(cam_dev);
+	if (ret) {
+		dev_err(&cam_dev->pdev->dev, "v4l2 async init failed\n");
+		goto failed_async;
+	}
+
+	return 0;
+
+failed_mem2mem2:
+failed_async:
+	return ret;
+}
+
+/* Get a free buffer from a video node */
+static struct mtk_cam_dev_buffer *
+mtk_cam_dev_get_pending_buf(struct mtk_cam_dev *cam_dev, int node)
+{
+	struct mtk_cam_dev_buffer *buf;
+	struct mtk_cam_video_device *vdev;
+
+	if (node > cam_dev->dev_node_num || node < 0) {
+		dev_err(&cam_dev->pdev->dev, "Invalid mtk_cam_dev node.\n");
+		return NULL;
+	}
+	vdev = &cam_dev->mem2mem2_nodes[node];
+
+	spin_lock(&cam_dev->mem2mem2_nodes[node].slock);
+	buf = list_first_entry_or_null(&vdev->pending_list,
+				       struct mtk_cam_dev_buffer,
+				       list);
+	if (!buf) {
+		spin_unlock(&cam_dev->mem2mem2_nodes[node].slock);
+		return NULL;
+	}
+	list_del(&buf->list);
+	spin_unlock(&cam_dev->mem2mem2_nodes[node].slock);
+
+	return buf;
+}
+
+int mtk_cam_dev_queue_buffers(struct mtk_cam_dev *cam_dev)
+{
+	unsigned int node;
+	const int mtk_cam_dev_node_num = cam_dev->dev_node_num;
+	struct device *dev = &cam_dev->pdev->dev;
+	struct mtk_cam_dev_start_param s_param;
+	struct mtk_cam_dev_buffer *buf;
+
+	memset(&s_param, 0, sizeof(struct mtk_cam_dev_start_param));
+
+	dev_dbg(dev, "%s\n", __func__);
+
+	if (!cam_dev->streaming) {
+		dev_dbg(dev, "%s: stream off, no enqueue\n", __func__);
+		return 0;
+	}
+
+	/* Check all enabled nodes to collect its buffer  */
+	for (node = 0; node < mtk_cam_dev_node_num; node++) {
+		if (!cam_dev->mem2mem2_nodes[node].enabled)
+			continue;
+
+		dev_dbg(dev, "Check node:%d, queue:%d\n",
+			node, cam_dev->mem2mem2_nodes[node].enabled);
+
+		buf = mtk_cam_dev_get_pending_buf(cam_dev, node);
+		if (!buf) {
+			dev_warn(dev, "No available buffer of enabled node %d\n",
+				 node);
+			continue;
+		}
+
+		buf->daddr =
+			vb2_dma_contig_plane_dma_addr(&buf->vbb.vb2_buf, 0);
+		if (cam_dev->mem2mem2_nodes[node].desc.smem_alloc) {
+			buf->scp_addr = mtk_cam_smem_iova_to_scp_addr
+				(&cam_dev->smem_pdev->dev,
+				buf->daddr);
+		} else {
+			buf->scp_addr = 0;
+		}
+
+		dev_dbg(dev,
+			"Buf: fd:%d idx:%d state:%d daddr:0x%pK scp_addr:0x%pK",
+			buf->vbb.request_fd,
+			buf->vbb.vb2_buf.index,
+			buf->vbb.vb2_buf.state,
+			buf->daddr,
+			buf->scp_addr);
+
+		s_param.buffers[node] = buf;
+		s_param.request_fd = buf->vbb.request_fd;
+	}
+
+	/* Trigger en-queued job to driver */
+	mtk_isp_enqueue(dev, &s_param);
+
+	return 0;
+}
+
+int mtk_cam_dev_core_init(struct platform_device *pdev,
+			  struct mtk_cam_dev *cam_dev)
+{
+	struct platform_device *smem_dev;
+
+	smem_dev = mtk_cam_dev_of_find_smem_dev(pdev);
+	if (!smem_dev) {
+		dev_err(&pdev->dev, "failed to find smem_dev\n");
+		return -EINVAL;
+	}
+
+	cam_dev->pdev = pdev;
+	cam_dev->smem_pdev = smem_dev;
+
+	mtk_cam_dev_core_queue_setup(cam_dev, &queues_setting);
+	mtk_cam_dev_init(cam_dev, pdev);
+
+	return 0;
+}
+
+int mtk_cam_dev_core_release(struct platform_device *pdev,
+			     struct mtk_cam_dev *cam_dev)
+{
+	mtk_cam_v4l2_async_unregister(cam_dev);
+	mtk_cam_v4l2_unregister(cam_dev);
+
+	return 0;
+}
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.h
new file mode 100644
index 000000000000..57c02616c9c0
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-dev.h
@@ -0,0 +1,166 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * MTK_CAM-dev is highly based on Intel IPU3 ImgU driver.
+ *
+ */
+
+#ifndef __MTK_CAM_DEV_H__
+#define __MTK_CAM_DEV_H__
+
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/version.h>
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+
+#include "mtk_cam-ctx.h"
+
+#define MTK_CAM_DEV_NODE_MAX			MTK_CAM_DEV_NODES
+#define MTK_CAM_DEV_P1_NAME			"MTK-ISP-P1-V4L2"
+
+#define MTK_CAM_MAX_SENSORS_NUM		2
+
+/* Sensor index */
+#define MTK_CAM_MAIN_SENSOR		0
+#define MTK_CAM_SUB_SENSOR		1
+
+/* Input video nodes */
+#define MTK_CAM_P1_META_IN_0		0
+#define MTK_CAM_P1_TOTAL_OUTPUT		1
+
+/* Output video nodes */
+#define MTK_CAM_P1_MAIN_STREAM_OUT	1
+#define MTK_CAM_P1_PACKED_BIN_OUT	2
+#define MTK_CAM_P1_META_OUT_0		3
+#define MTK_CAM_P1_META_OUT_1		4
+#define MTK_CAM_P1_META_OUT_2		5
+#define MTK_CAM_P1_META_OUT_3		6
+#define MTK_CAM_P1_TOTAL_CAPTURE	6
+
+struct mtk_cam_dev_buffer {
+	struct vb2_v4l2_buffer	vbb;
+	struct list_head	list;
+	/* Intenal part */
+	dma_addr_t		daddr;
+	dma_addr_t		scp_addr;
+};
+
+/*
+ * struct mtk_cam_video_device - Mediatek video device structure.
+ *
+ * @enabled: indicate stream on or off
+ * @id: id for mtk_cam_dev_node_desc or mem2mem2_nodes array
+ * @vdev_fmt: the V4L2 format of video device
+ * @vdev_apd: the media pad graph object of video device
+ * @vbq: a videobuf queue of video device
+ * @ctrl_handler: the control handler of video device
+ * @desc: the node attributes of video device
+ * @pending_list: list for pending buffers before enqueuing into driver
+ * @lock: serializes vb2 queue and video device operations.
+ * @slock: protect for pending_list.
+ *
+ */
+struct mtk_cam_video_device {
+	unsigned int enabled;
+	unsigned int id;
+	struct v4l2_format vdev_fmt;
+	struct video_device vdev;
+	struct media_pad vdev_pad;
+	struct vb2_queue vbq;
+	struct v4l2_ctrl_handler ctrl_handler;
+	struct mtk_cam_dev_node_desc desc;
+	struct list_head pending_list;
+	/* Used for vbq & vdev */
+	struct mutex lock;
+	/* protect for pending_list */
+	spinlock_t slock;
+};
+
+/*
+ * struct mtk_cam_dev - Mediatek camera device structure.
+ *
+ * @cio_enabled: indicate stream on or off
+ * @sensor: sensor sub-device
+ * @seninf: sensor_if sub-device
+ *
+ * Below is the graph topology for Camera IO connection.
+ * sensor 1 (main) --> sensor IF --> P1 sub-device
+ * sensor 2 (sub)  -->
+ *
+ */
+struct mtk_cam_dev {
+	struct platform_device *pdev;
+	struct platform_device *smem_pdev;
+	struct media_pipeline pipeline;
+	struct media_device media_dev;
+	struct media_pad *subdev_pads;
+	struct v4l2_subdev subdev;
+	struct v4l2_device v4l2_dev;
+	struct v4l2_ctrl_handler ctrl_handler;
+	struct v4l2_async_notifier notifier;
+	struct mtk_cam_video_device mem2mem2_nodes[MTK_CAM_DEV_NODE_MAX];
+	struct v4l2_subdev *sensor;
+	struct v4l2_subdev *sensor_if;
+	unsigned int cio_enabled;
+	unsigned int cio_pad_sink;
+	unsigned int dev_node_num;
+	unsigned int streaming;
+	int request_fd;
+	unsigned int request_count;
+};
+
+int mtk_cam_dev_core_init(struct platform_device *pdev,
+			  struct mtk_cam_dev *cam_dev);
+int mtk_cam_v4l2_register(struct device *dev,
+			  struct media_device *media_dev,
+			  struct v4l2_device *v4l2_dev,
+			  struct v4l2_ctrl_handler *ctrl_handler);
+int mtk_cam_v4l2_unregister(struct mtk_cam_dev *cam_dev);
+int mtk_cam_mem2mem2_v4l2_register(struct mtk_cam_dev *cam_dev);
+int mtk_cam_v4l2_async_register(struct mtk_cam_dev *cam_dev);
+void mtk_cam_v4l2_async_unregister(struct mtk_cam_dev *cam_dev);
+int mtk_cam_dev_queue_buffers(struct mtk_cam_dev *cam_dev);
+int mtk_cam_dev_core_release(struct platform_device *pdev,
+			     struct mtk_cam_dev *cam_dev);
+
+static inline struct mtk_cam_video_device *
+file_to_mtk_cam_node(struct file *__file)
+{
+	return container_of(video_devdata(__file),
+		struct mtk_cam_video_device, vdev);
+}
+
+static inline struct mtk_cam_dev *
+mtk_cam_subdev_to_dev(struct v4l2_subdev *__sd)
+{
+	return container_of(__sd,
+		struct mtk_cam_dev, subdev);
+}
+
+static inline struct mtk_cam_video_device *
+mtk_cam_vbq_to_vdev(struct vb2_queue *__vq)
+{
+	return container_of(__vq,
+		struct mtk_cam_video_device, vbq);
+}
+
+static inline struct mtk_cam_dev_buffer *
+mtk_cam_vb2_buf_to_dev_buf(struct vb2_buffer *__vb)
+{
+	return container_of(__vb,
+		struct mtk_cam_dev_buffer, vbb.vb2_buf);
+}
+
+#endif /* __MTK_CAM_DEV_H__ */
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-regs.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-regs.h
new file mode 100644
index 000000000000..90736a14d996
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-regs.h
@@ -0,0 +1,147 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ryan Yu <ryan.yu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _CAM_REGS_H
+#define _CAM_REGS_H
+
+/* TG Bit Mask */
+#define VFDATA_EN_BIT	BIT(0)
+#define CMOS_EN_BIT	BIT(0)
+
+/* normal signal bit */
+#define VS_INT_ST	BIT(0)
+#define HW_PASS1_DON_ST	BIT(11)
+#define SOF_INT_ST	BIT(12)
+#define SW_PASS1_DON_ST	BIT(30)
+
+/* err status bit */
+#define TG_ERR_ST	BIT(4)
+#define TG_GBERR_ST	BIT(5)
+#define CQ_CODE_ERR_ST	BIT(6)
+#define CQ_APB_ERR_ST	BIT(7)
+#define CQ_VS_ERR_ST	BIT(8)
+#define AMX_ERR_ST	BIT(15)
+#define RMX_ERR_ST	BIT(16)
+#define BMX_ERR_ST	BIT(17)
+#define RRZO_ERR_ST	BIT(18)
+#define AFO_ERR_ST	BIT(19)
+#define IMGO_ERR_ST	BIT(20)
+#define AAO_ERR_ST	BIT(21)
+#define PSO_ERR_ST	BIT(22)
+#define LCSO_ERR_ST	BIT(23)
+#define BNR_ERR_ST	BIT(24)
+#define LSCI_ERR_ST	BIT(25)
+#define DMA_ERR_ST	BIT(29)
+
+/* CAM DMA done status */
+#define FLKO_DONE_ST	BIT(4)
+#define AFO_DONE_ST	BIT(5)
+#define AAO_DONE_ST	BIT(7)
+#define PSO_DONE_ST	BIT(14)
+
+/* IRQ signal mask */
+#define INT_ST_MASK_CAM	( \
+			VS_INT_ST |\
+			HW_PASS1_DON_ST |\
+			SOF_INT_ST |\
+			SW_PASS1_DON_ST)
+
+/* IRQ Warning Mask */
+#define INT_ST_MASK_CAM_WARN	(\
+				RRZO_ERR_ST |\
+				AFO_ERR_ST |\
+				IMGO_ERR_ST |\
+				AAO_ERR_ST |\
+				PSO_ERR_ST | \
+				LCSO_ERR_ST |\
+				BNR_ERR_ST |\
+				LSCI_ERR_ST)
+
+/* IRQ Error Mask */
+#define INT_ST_MASK_CAM_ERR	(\
+				TG_ERR_ST |\
+				TG_GBERR_ST |\
+				CQ_CODE_ERR_ST |\
+				CQ_APB_ERR_ST |\
+				CQ_VS_ERR_ST |\
+				BNR_ERR_ST |\
+				RMX_ERR_ST |\
+				BMX_ERR_ST |\
+				BNR_ERR_ST |\
+				LSCI_ERR_ST |\
+				DMA_ERR_ST)
+
+/* IRQ Signal Log Mask */
+#define INT_ST_LOG_MASK_CAM	(\
+				SOF_INT_ST |\
+				SW_PASS1_DON_ST |\
+				VS_INT_ST |\
+				TG_ERR_ST |\
+				TG_GBERR_ST |\
+				RRZO_ERR_ST |\
+				AFO_ERR_ST |\
+				IMGO_ERR_ST |\
+				AAO_ERR_ST |\
+				DMA_ERR_ST)
+
+/* DMA Event Notification Mask */
+#define DMA_ST_MASK_CAM	(\
+			AFO_DONE_ST |\
+			AAO_DONE_ST |\
+			PSO_DONE_ST |\
+			FLKO_DONE_ST)
+
+/* Status check */
+#define REG_CTL_EN		0x0004
+#define REG_CTL_DMA_EN		0x0008
+#define REG_CTL_FMT_SEL		0x0010
+#define REG_CTL_EN2		0x0018
+#define REG_CTL_RAW_INT_EN	0x0020
+#define REG_CTL_RAW_INT_STAT	0x0024
+#define REG_CTL_RAW_INT2_STAT	0x0034
+#define REG_CTL_RAW_INT3_STAT	0x00c4
+#define REG_CTL_TWIN_STAT	0x0050
+
+#define REG_TG_SEN_MODE		0x0230
+#define REG_TG_SEN_GRAB_PIX	0x0238
+#define REG_TG_SEN_GRAB_LIN	0x023c
+#define REG_TG_VF_CON		0x0234
+#define REG_TG_INTER_ST		0x026c
+#define REG_TG_SUB_PERIOD	0x02a4
+
+#define REG_IMGO_BASE_ADDR	0x1020
+#define REG_RRZO_BASE_ADDR	0x1050
+
+/* Error status log */
+#define REG_IMGO_ERR_STAT	0x1360
+#define REG_RRZO_ERR_STAT	0x1364
+#define REG_AAO_ERR_STAT	0x1368
+#define REG_AFO_ERR_STAT	0x136c
+#define REG_LCSO_ERR_STAT	0x1370
+#define REG_UFEO_ERR_STAT	0x1374
+#define REG_PDO_ERR_STAT	0x1378
+#define REG_BPCI_ERR_STAT	0x137c
+#define REG_LSCI_ERR_STAT	0x1384
+#define REG_PDI_ERR_STAT	0x138c
+#define REG_LMVO_ERR_STAT	0x1390
+#define REG_FLKO_ERR_STAT	0x1394
+#define REG_PSO_ERR_STAT	0x13a0
+
+/* ISP command */
+#define REG_CQ_THR0_BASEADDR	0x0198
+#define REG_CTL_SPARE2		0x0058
+#define REG_HW_FRAME_NUM	0x13b8
+
+#endif	/* _CAM_REGS_H */
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.c
new file mode 100644
index 000000000000..be5fd365f16f
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.c
@@ -0,0 +1,488 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Seraph Huang <seraph.huang@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/atomic.h>
+#include <linux/kthread.h>
+#include <linux/platform_data/mtk_scp.h>
+#include <linux/remoteproc.h>
+#include <linux/sched.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
+#include <linux/vmalloc.h>
+
+#include "mtk_cam.h"
+
+static int isp_composer_dma_sg_init(struct mtk_isp_p1_ctx *isp_ctx)
+{
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(isp_ctx);
+	struct device *dev = &p1_dev->pdev->dev;
+	phys_addr_t scp_mem_va;
+	u32 size, size_align;
+	struct sg_table *sgt;
+	struct page **pages;
+	unsigned int n_pages, i;
+	int ret;
+
+	scp_mem_va = scp_get_reserve_mem_virt(SCP_ISP_MEM_ID);
+	isp_ctx->scp_mem_pa = scp_get_reserve_mem_phys(SCP_ISP_MEM_ID);
+	size = scp_get_reserve_mem_size(SCP_ISP_MEM_ID);
+
+	dev_dbg(dev, "isp scp mem: va:0x%llx, pa:0x%llx sz:0x%x\n",
+		scp_mem_va, isp_ctx->scp_mem_pa, size);
+
+	if (scp_mem_va != 0 && size > 0)
+		memset((void *)scp_mem_va, 0, size);
+
+	/* get iova address */
+	sgt = &isp_ctx->sgtable;
+	sg_alloc_table(sgt, 1, GFP_KERNEL);
+
+	size_align = round_up(size, PAGE_SIZE);
+	n_pages = size_align >> PAGE_SHIFT;
+
+	pages = kmalloc_array(n_pages, sizeof(struct page *),
+			      GFP_KERNEL);
+	if (!pages)
+		goto fail_pages_alloc;
+
+	for (i = 0; i < n_pages; i++)
+		pages[i] = phys_to_page(isp_ctx->scp_mem_pa + i * PAGE_SIZE);
+
+	ret = sg_alloc_table_from_pages(sgt, pages, n_pages,
+					0, size_align, GFP_KERNEL);
+	if (ret) {
+		dev_err(dev, "failed to allocate sg table:%d\n", ret);
+		goto fail_table_alloc;
+	}
+	sgt->nents = dma_map_sg_attrs(dev, sgt->sgl, sgt->orig_nents,
+				      DMA_BIDIRECTIONAL,
+				      DMA_ATTR_SKIP_CPU_SYNC);
+	if (!sgt->nents) {
+		dev_err(dev, "failed to dma sg map\n");
+		goto fail_map;
+	}
+
+	isp_ctx->scp_mem_iova = sg_dma_address(sgt->sgl);
+
+	return 0;
+
+fail_map:
+	sg_free_table(sgt);
+fail_table_alloc:
+	while (n_pages--)
+		__free_page(pages[n_pages]);
+fail_pages_alloc:
+	kfree(pages);
+	return -ENOMEM;
+}
+
+static void isp_composer_deinit(struct mtk_isp_p1_ctx *isp_ctx)
+{
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(isp_ctx);
+	struct mtk_isp_queue_work *ipi_job, *tmp_ipi_job;
+
+	list_for_each_entry_safe(ipi_job, tmp_ipi_job,
+				 &isp_ctx->composer_txlist.queue,
+				 list_entry) {
+		list_del(&ipi_job->list_entry);
+		kfree(ipi_job);
+		atomic_dec(&isp_ctx->composer_txlist.queue_cnt);
+	}
+
+	atomic_set(&isp_ctx->ipi_occupied, 0);
+	atomic_set(&isp_ctx->composing_frame, 0);
+	atomic_set(&isp_ctx->scp_state, SCP_STATE_INVALID);
+	mutex_destroy(&isp_ctx->composer_tx_lock);
+
+	dma_unmap_sg_attrs(&p1_dev->pdev->dev, isp_ctx->sgtable.sgl,
+			   isp_ctx->sgtable.orig_nents,
+			   DMA_BIDIRECTIONAL, DMA_ATTR_SKIP_CPU_SYNC);
+	sg_free_table(&isp_ctx->sgtable);
+
+	if (!IS_ERR(isp_ctx->composer_tx_thread.thread)) {
+		kthread_stop(isp_ctx->composer_tx_thread.thread);
+		wake_up_interruptible(&isp_ctx->composer_tx_thread.wq);
+		isp_ctx->composer_tx_thread.thread = NULL;
+	}
+
+	isp_ctx->composer_deinit_donecb(isp_ctx);
+}
+
+/*
+ * Two kinds of flow control in isp_composer_tx_work.
+ *
+ * Case 1: IPI commands flow control. The maximum number of command queues is 3.
+ * There are two types of IPI commands (SCP_ISP_CMD/SCP_ISP_FRAME) in P1 driver.
+ * It is controlled by ipi_occupied.
+ * The priority of SCP_ISP_CMD is higher than SCP_ISP_FRAME.
+ *
+ * Case 2: Frame buffers flow control. The maximum number of frame buffers is 3.
+ * It is controlled by composing_frame.
+ * Frame buffer is sent by SCP_ISP_FRAME command.
+ */
+static int isp_composer_tx_work(void *data)
+{
+	struct mtk_isp_p1_ctx *isp_ctx = (struct mtk_isp_p1_ctx *)data;
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(isp_ctx);
+	struct device *dev = &p1_dev->pdev->dev;
+	struct mtk_isp_queue_work *isp_composer_work, *tmp_ipi_job;
+	struct isp_queue *composer_txlist = &isp_ctx->composer_txlist;
+	int ret;
+
+	while (1) {
+		ret = wait_event_interruptible
+			(isp_ctx->composer_tx_thread.wq,
+			 (atomic_read(&composer_txlist->queue_cnt) > 0 &&
+			 atomic_read(&isp_ctx->ipi_occupied) < 4 &&
+			 atomic_read(&isp_ctx->composing_frame) < 3) ||
+			 atomic_read(&isp_ctx->cmd_queued) > 0 ||
+			 kthread_should_stop());
+
+		if (kthread_should_stop())
+			break;
+
+		if (ret == ERESTARTSYS) {
+			dev_err(dev, "interrupted by a signal!\n");
+			continue;
+		}
+
+		spin_lock(&composer_txlist->lock);
+		if (atomic_read(&isp_ctx->cmd_queued) > 0) {
+			list_for_each_entry_safe(isp_composer_work, tmp_ipi_job,
+						 &composer_txlist->queue,
+						 list_entry) {
+				if (isp_composer_work->type == SCP_ISP_CMD) {
+					dev_dbg(dev, "Found a cmd\n");
+					break;
+				}
+			}
+		} else {
+			if (atomic_read(&isp_ctx->composing_frame) >=
+				ISP_FRAME_COMPOSING_MAX_NUM) {
+				spin_unlock(&composer_txlist->lock);
+				continue;
+			}
+			isp_composer_work =
+			    list_first_entry_or_null
+				(&composer_txlist->queue,
+				 struct mtk_isp_queue_work,
+				 list_entry);
+		}
+
+		list_del(&isp_composer_work->list_entry);
+		atomic_dec(&composer_txlist->queue_cnt);
+		spin_unlock(&composer_txlist->lock);
+
+		if (atomic_read(&isp_ctx->scp_state) == SCP_STATE_INVALID) {
+			dev_err(dev,
+				"ignore IPI type: %d, SCP state %d!\n",
+				isp_composer_work->type,
+				atomic_read(&isp_ctx->scp_state));
+			kfree(isp_composer_work);
+			continue;
+		}
+		if (isp_composer_work->type == SCP_ISP_CMD) {
+			mutex_lock(&isp_ctx->composer_tx_lock);
+			scp_ipi_send
+				(p1_dev->scp_pdev,
+				 SCP_IPI_ISP_CMD,
+				 &isp_composer_work->cmd,
+				 sizeof(isp_composer_work->cmd),
+				 0);
+			mutex_unlock(&isp_ctx->composer_tx_lock);
+			atomic_dec(&isp_ctx->cmd_queued);
+			atomic_inc(&isp_ctx->ipi_occupied);
+			dev_dbg(dev,
+				"%s cmd id %d sent, %d ipi buf occupied",
+				__func__,
+				isp_composer_work->cmd.cmd_id,
+				atomic_read(&isp_ctx->ipi_occupied));
+		} else if (isp_composer_work->type == SCP_ISP_FRAME) {
+			mutex_lock(&isp_ctx->composer_tx_lock);
+			scp_ipi_send
+				(p1_dev->scp_pdev,
+				 SCP_IPI_ISP_FRAME,
+				 &isp_composer_work->frameparams,
+				 sizeof(isp_composer_work->frameparams),
+				 0);
+			mutex_unlock(&isp_ctx->composer_tx_lock);
+			atomic_inc(&isp_ctx->ipi_occupied);
+			atomic_inc(&isp_ctx->composing_frame);
+			dev_dbg(dev,
+				"%s frame %d sent, %d ipi, %d CQ bufs occupied",
+				__func__,
+				isp_composer_work->frameparams.frame_seq_no,
+				atomic_read(&isp_ctx->ipi_occupied),
+				atomic_read(&isp_ctx->composing_frame));
+		} else {
+			dev_err(dev,
+				"ignore IPI type: %d!\n",
+				isp_composer_work->type);
+			kfree(isp_composer_work);
+			continue;
+		}
+		kfree(isp_composer_work);
+	}
+	return ret;
+}
+
+static int isp_composer_rx_work(void *data)
+{
+	struct mtk_isp_p1_ctx *isp_ctx = (struct mtk_isp_p1_ctx *)data;
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(data);
+	struct device *dev = &p1_dev->pdev->dev;
+	struct mtk_isp_scp_p1_cmd ipi_msg;
+	int ret;
+	unsigned int ipi_queue_occupied, i;
+	unsigned long flags;
+	atomic_t *evts_end = &isp_ctx->composer_evts_end;
+	atomic_t *evts_start = &isp_ctx->composer_evts_start;
+	u8 ack_cmd_id;
+
+	while (1) {
+		ret = wait_event_interruptible(isp_ctx->composer_rx_thread.wq,
+					       (atomic_read(evts_end) !=
+					       atomic_read(evts_start)) ||
+					       kthread_should_stop());
+
+		if (kthread_should_stop())
+			break;
+
+		if (ret == ERESTARTSYS) {
+			dev_err(dev, "interrupted by a signal!\n");
+			continue;
+		}
+
+		spin_lock_irqsave(&isp_ctx->composer_evts_lock, flags);
+		i = atomic_read(evts_start);
+		memcpy(&ipi_msg,
+		       &isp_ctx->composer_evts[i],
+		       sizeof(struct mtk_isp_scp_p1_cmd));
+		atomic_set(evts_start, ++i & 0x3);
+		spin_unlock_irqrestore(&isp_ctx->composer_evts_lock, flags);
+
+		switch (ipi_msg.cmd_id) {
+		case ISP_CMD_SCP_STATE:
+			atomic_set(&isp_ctx->scp_state,
+				   ipi_msg.cmd_data[0]);
+			break;
+		case ISP_CMD_ACK:
+			ipi_queue_occupied =
+				atomic_dec_return(&isp_ctx->ipi_occupied);
+			if (ipi_queue_occupied >= ISP_COMPOSING_MAX_NUM)
+				wake_up_interruptible
+					(&isp_ctx->composer_tx_thread.wq);
+
+			ack_cmd_id = ipi_msg.ack_info.cmd_id;
+			if (ack_cmd_id == ISP_CMD_FRAME_ACK) {
+				dev_dbg(dev,
+					"%s frame %d ack\n",
+					__func__,
+					ipi_msg.ack_info.frame_seq_no);
+				atomic_set(&isp_ctx->composed_frame_id,
+					   ipi_msg.ack_info.frame_seq_no);
+			} else {
+				dev_dbg(dev, "%s cmd id: %d",
+					__func__,
+					ack_cmd_id);
+				if (ack_cmd_id == ISP_CMD_DEINIT) {
+					isp_composer_deinit(isp_ctx);
+					isp_ctx->composer_rx_thread.thread =
+						NULL;
+					return -1;
+				}
+			}
+			break;
+		default:
+			break;
+		};
+	}
+	return ret;
+}
+
+static void isp_composer_handler(void *data, unsigned int len, void *priv)
+{
+	struct mtk_isp_p1_ctx *isp_ctx;
+	struct mtk_isp_scp_p1_cmd *ipi_msg_ptr;
+	unsigned long flags;
+	unsigned int i;
+
+	ipi_msg_ptr = (struct mtk_isp_scp_p1_cmd *)data;
+	isp_ctx = (struct mtk_isp_p1_ctx *)priv;
+
+	spin_lock_irqsave(&isp_ctx->composer_evts_lock, flags);
+	i = atomic_read(&isp_ctx->composer_evts_end);
+	memcpy(&isp_ctx->composer_evts[i], data,
+	       sizeof(struct mtk_isp_scp_p1_cmd));
+	atomic_set(&isp_ctx->composer_evts_end, ++i & 0x3);
+	spin_unlock_irqrestore(&isp_ctx->composer_evts_lock, flags);
+
+	wake_up_interruptible(&isp_ctx->composer_rx_thread.wq);
+}
+
+int isp_composer_init(struct mtk_isp_p1_ctx *isp_ctx)
+{
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(isp_ctx);
+	struct device *dev = &p1_dev->pdev->dev;
+	int ret;
+
+	atomic_set(&isp_ctx->scp_state, SCP_STATE_INVALID);
+
+	ret = scp_ipi_register(p1_dev->scp_pdev,
+			       SCP_IPI_ISP_CMD,
+			       isp_composer_handler,
+			       isp_ctx);
+	if (ret)
+		return ret;
+
+	if (!isp_ctx->composer_tx_thread.thread) {
+		mutex_init(&isp_ctx->composer_tx_lock);
+		init_waitqueue_head(&isp_ctx->composer_tx_thread.wq);
+		INIT_LIST_HEAD(&isp_ctx->composer_txlist.queue);
+		spin_lock_init(&isp_ctx->composer_txlist.lock);
+		isp_ctx->composer_tx_thread.thread =
+			kthread_run(isp_composer_tx_work, (void *)isp_ctx,
+				    "isp_composer_tx");
+		if (IS_ERR(isp_ctx->composer_tx_thread.thread)) {
+			dev_err(dev, "unable to start kthread\n");
+			isp_ctx->composer_tx_thread.thread = NULL;
+			return -ENOMEM;
+		}
+	}
+	atomic_set(&isp_ctx->composer_txlist.queue_cnt, 0);
+
+	if (!isp_ctx->composer_rx_thread.thread) {
+		init_waitqueue_head(&isp_ctx->composer_rx_thread.wq);
+		isp_ctx->composer_rx_thread.thread =
+			kthread_run(isp_composer_rx_work, (void *)isp_ctx,
+				    "isp_composer_rx");
+		if (IS_ERR(isp_ctx->composer_rx_thread.thread)) {
+			dev_err(dev, "unable to start kthread\n");
+			isp_ctx->composer_rx_thread.thread = NULL;
+			return -ENOMEM;
+		}
+	}
+
+	atomic_set(&isp_ctx->composer_evts_start, 0);
+	atomic_set(&isp_ctx->composer_evts_end, 0);
+	spin_lock_init(&isp_ctx->composer_evts_lock);
+
+	atomic_set(&isp_ctx->ipi_occupied, 0);
+	atomic_set(&isp_ctx->composing_frame, 0);
+	atomic_set(&isp_ctx->scp_state, SCP_STATE_BOOTING);
+	atomic_set(&isp_ctx->cmd_queued, 0);
+
+	return 0;
+}
+
+void isp_composer_enqueue(struct mtk_isp_p1_ctx *isp_ctx,
+			  void *data,
+			  enum mtk_isp_scp_ipi_type type)
+{
+	struct mtk_isp_queue_work *isp_composer_work;
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(isp_ctx);
+	struct device *dev = &p1_dev->pdev->dev;
+
+	isp_composer_work = kzalloc(sizeof(*isp_composer_work), GFP_KERNEL);
+	isp_composer_work->type = type;
+	switch (type) {
+	case SCP_ISP_CMD:
+		memcpy(&isp_composer_work->cmd, data,
+		       sizeof(isp_composer_work->cmd));
+
+		spin_lock(&isp_ctx->composer_txlist.lock);
+		list_add_tail(&isp_composer_work->list_entry,
+			      &isp_ctx->composer_txlist.queue);
+		atomic_inc(&isp_ctx->composer_txlist.queue_cnt);
+		spin_unlock(&isp_ctx->composer_txlist.lock);
+
+		dev_dbg(dev, "Enq ipi cmd id:%d\n",
+			isp_composer_work->cmd.cmd_id);
+		atomic_inc(&isp_ctx->cmd_queued);
+		wake_up_interruptible(&isp_ctx->composer_tx_thread.wq);
+		break;
+	case SCP_ISP_FRAME:
+		memcpy(&isp_composer_work->frameparams, data,
+		       sizeof(isp_composer_work->frameparams));
+
+		spin_lock(&isp_ctx->composer_txlist.lock);
+		list_add_tail(&isp_composer_work->list_entry,
+			      &isp_ctx->composer_txlist.queue);
+		atomic_inc(&isp_ctx->composer_txlist.queue_cnt);
+		spin_unlock(&isp_ctx->composer_txlist.lock);
+
+		dev_dbg(dev, "Enq ipi frame_num:%d\n",
+			isp_composer_work->frameparams.frame_seq_no);
+		wake_up_interruptible(&isp_ctx->composer_tx_thread.wq);
+		break;
+	default:
+		break;
+	}
+}
+
+int isp_composer_hw_init(struct mtk_isp_p1_ctx *isp_ctx)
+{
+	struct img_buffer frameparam;
+	struct mtk_isp_scp_p1_cmd composer_tx_cmd;
+	int ret;
+
+	ret = isp_composer_dma_sg_init(isp_ctx);
+	if (ret)
+		return ret;
+
+	frameparam.scp_addr = isp_ctx->scp_mem_pa;
+	frameparam.iova = isp_ctx->scp_mem_iova;
+
+	composer_tx_cmd.cmd_id = ISP_CMD_INIT;
+	composer_tx_cmd.frameparam.hw_module = isp_ctx->isp_hw_module;
+	memcpy(&composer_tx_cmd.frameparam.cq_addr, &frameparam,
+	       sizeof(struct img_buffer));
+	isp_composer_enqueue(isp_ctx, &composer_tx_cmd, SCP_ISP_CMD);
+
+	return 0;
+}
+
+void isp_composer_hw_config(struct mtk_isp_p1_ctx *isp_ctx,
+			    struct p1_config_param *config_param)
+{
+	struct mtk_isp_scp_p1_cmd composer_tx_cmd;
+
+	memset(&composer_tx_cmd, 0, sizeof(composer_tx_cmd));
+	composer_tx_cmd.cmd_id = ISP_CMD_CONFIG;
+	memcpy(&composer_tx_cmd.cmd_data[0], config_param,
+	       sizeof(struct p1_config_param));
+	isp_composer_enqueue(isp_ctx, &composer_tx_cmd, SCP_ISP_CMD);
+}
+
+void isp_composer_stream(struct mtk_isp_p1_ctx *isp_ctx, int on)
+{
+	struct mtk_isp_scp_p1_cmd composer_tx_cmd;
+
+	memset(&composer_tx_cmd, 0, sizeof(composer_tx_cmd));
+	composer_tx_cmd.cmd_id = ISP_CMD_STREAM;
+	memcpy(&composer_tx_cmd.cmd_data[0], &on, sizeof(on));
+	isp_composer_enqueue(isp_ctx, &composer_tx_cmd, SCP_ISP_CMD);
+}
+
+void isp_composer_hw_deinit(struct mtk_isp_p1_ctx *isp_ctx,
+			    void (*donecb)(void *data))
+{
+	struct mtk_isp_scp_p1_cmd composer_tx_cmd;
+
+	memset(&composer_tx_cmd, 0, sizeof(composer_tx_cmd));
+	composer_tx_cmd.cmd_id = ISP_CMD_DEINIT;
+	isp_ctx->composer_deinit_donecb = donecb;
+	isp_composer_enqueue(isp_ctx, &composer_tx_cmd, SCP_ISP_CMD);
+}
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.h
new file mode 100644
index 000000000000..abc34e785cd3
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-scp.h
@@ -0,0 +1,215 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Seraph Huang <seraph.huang@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _MTK_ISP_SCP_H
+#define _MTK_ISP_SCP_H
+
+#include <linux/platform_data/mtk_scp.h>
+#include <linux/remoteproc.h>
+#include <linux/types.h>
+
+#define MAX_IMG_DMA_PORT	2
+#define MAX_META_DMA_PORT	8
+#define MAX_META_DMA_NODES	4
+
+/* describes the maximum size of a payload */
+#define MTK_IPI_CMD_SIZE	272
+
+/*
+ * struct img_size - image size information.
+ *
+ * @w: image width, the unit is pixel
+ * @h: image height, the unit is pixel
+ * @xsize: bytes per line based on width.
+ * @stride: bytes per line when changing line.
+ *          Normally, calculate new STRIDE based on
+ *          xsize + HW constrain(page or align).
+ *
+ */
+struct img_size {
+	__u32 w;
+	__u32 h;
+	__u32 xsize;
+	__u32 stride;
+} __packed;
+
+/*
+ * struct img_buffer - buffer address information.
+ *
+ * @iova: DMA address for external devices.
+ * @scp_addr: SCP address for external co-process unit.
+ *
+ */
+struct img_buffer {
+	__u32 iova;
+	__u32 scp_addr;
+} __packed;
+
+struct p1_img_crop {
+	__u32 left;
+	__u32 top;
+	__u32 width;
+	__u32 height;
+} __packed;
+
+struct p1_img_output {
+	struct img_buffer buffer;
+	struct img_size size;
+	struct p1_img_crop crop;
+	__u8 pixel_byte;
+	__u32 img_fmt;
+} __packed;
+
+/*
+ * struct cfg_in_param - image input parameters structure.
+ *                       Normally, it comes from sensor information.
+ *
+ * @continuous: indicate the sensor mode.
+ *              1: continuous
+ *              0: single
+ * @subsample: indicate to enables SOF subsample or not.
+ * @pixel_mode: describe 1/2/4 pixels per clock cycle.
+ * @data_pattern: describe input data pattern.
+ * @raw_pixel_id: bayer sequence.
+ * @tg_fps: the fps rate of TG (time generator).
+ * @img_fmt: the image format of input source.
+ * @p1_img_crop: the crop configuration of input source.
+ *
+ */
+struct cfg_in_param {
+	__u8 continuous;
+	__u8 subsample;
+	__u8 pixel_mode;
+	__u8 data_pattern;
+	__u8 raw_pixel_id;
+	__u16 tg_fps;
+	__u32 img_fmt;
+	struct p1_img_crop crop;
+} __packed;
+
+/*
+ * struct cfg_main_out_param - the image output parameters of main stream.
+ *
+ * @bypass: indicate this device is enabled or disabled or not .
+ * @pure_raw: indicate the image path control.
+ *            1: pure raw
+ *            0: processing raw
+ * @pure_raw_pack: indicate the image is packed or not.
+ *                 1: packed mode
+ *                 0: unpacked mode
+ * @p1_img_output: the output image information.
+ *
+ */
+struct cfg_main_out_param {
+	/* Bypass main out parameters */
+	__u8 bypass;
+	/* Control HW image raw path */
+	__u8 pure_raw;
+	/* Control HW image pack function */
+	__u8 pure_raw_pack;
+	struct p1_img_output output;
+} __packed;
+
+/*
+ * struct cfg_resize_out_param - the image output parameters of
+ *                               packed out stream.
+ *
+ * @bypass: indicate this device is enabled or disabled or not .
+ * @p1_img_output: the output image information.
+ *
+ */
+struct cfg_resize_out_param {
+	/* Bypass resize parameters */
+	__u8 bypass;
+	struct p1_img_output output;
+} __packed;
+
+/*
+ * struct cfg_meta_out_param - output meta information.
+ *
+ * @enabled_meta_dmas: indicate which meta DMAs are enabled.
+ *
+ */
+struct cfg_meta_out_param {
+	__u32 enabled_meta_dmas;
+} __packed;
+
+struct p1_config_param {
+	/* Sensor/TG info */
+	struct cfg_in_param cfg_in_param;
+	/* IMGO DMA */
+	struct cfg_main_out_param cfg_main_param;
+	/* RRZO DMA */
+	struct cfg_resize_out_param cfg_resize_param;
+	/* 3A DMAs and other. */
+	struct cfg_meta_out_param cfg_meta_param;
+} __packed;
+
+struct p1_frame_param {
+	/* frame sequence number */
+	__u32 frame_seq_no;
+	/* SOF index */
+	__u32 sof_idx;
+	/* The memory address of tuning buffer from user space */
+	struct img_buffer tuning_addr;
+	struct p1_img_output img_dma_buffers[MAX_IMG_DMA_PORT];
+	struct img_buffer meta_addrs[MAX_META_DMA_NODES];
+} __packed;
+
+struct isp_init_info {
+	__u8 hw_module;
+	struct img_buffer cq_addr;
+} __packed;
+
+struct isp_ack_info {
+	__u8 cmd_id;
+	__u32 frame_seq_no;
+} __packed;
+
+enum mtk_isp_scp_CMD {
+	ISP_CMD_INIT,
+	ISP_CMD_CONFIG,
+	ISP_CMD_STREAM,
+	ISP_CMD_DEINIT,
+	ISP_CMD_ACK,
+	ISP_CMD_SCP_STATE,
+	ISP_CMD_FRAME_ACK,
+	ISP_CMD_RESERVED,
+};
+
+struct mtk_isp_scp_p1_cmd {
+	__u8 cmd_id;
+	__u64 drv_data;
+	union {
+		struct isp_init_info frameparam;
+		struct p1_config_param config_param;
+		__u8 cmd_data[MTK_IPI_CMD_SIZE - sizeof(__u8) - sizeof(__u64)];
+		__u8 is_stream_on;
+		struct isp_ack_info ack_info;
+	};
+} __packed;
+
+enum mtk_isp_scp_p1_state {
+	SCP_STATE_INVALID = 0,
+	SCP_STATE_BOOTING,
+	SCP_STATE_RBREADY,
+};
+
+struct isp_scp_p1_param {
+	struct list_head list_entry;
+	struct mtk_isp_scp_p1_cmd cmd;
+};
+
+#endif /* _MTK_ISP_SCP_H */
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem-drv.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem-drv.c
new file mode 100644
index 000000000000..9a92080a1451
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem-drv.c
@@ -0,0 +1,398 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_fdt.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/dma-contiguous.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/iommu.h>
+#include <asm/cacheflush.h>
+
+#define MTK_CAM_SMEM_DEV_NAME "MTK-CAM-SMEM"
+
+struct mtk_cam_smem_drv {
+	struct platform_device *pdev;
+	struct sg_table sgt;
+	struct page **smem_pages;
+	int num_smem_pages;
+	dma_addr_t smem_base;
+	dma_addr_t smem_dma_base;
+	unsigned int smem_size;
+};
+
+/*
+ * MTK CAM SMEM DMA ops
+ */
+struct dma_coherent_mem {
+	void		*virt_base;
+	dma_addr_t	device_base;
+	unsigned long	pfn_base;
+	int		size;
+	int		flags;
+	unsigned long	*bitmap;
+	spinlock_t	spinlock; /* dma_coherent_mem attributes protection */
+	bool		use_dev_dma_pfn_offset;
+};
+
+static struct reserved_mem *isp_reserved_smem;
+
+dma_addr_t mtk_cam_smem_iova_to_scp_addr(struct device *dev,
+					 dma_addr_t iova)
+{
+		struct iommu_domain *smem_dom;
+		dma_addr_t addr;
+		dma_addr_t limit;
+		struct mtk_cam_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+
+		smem_dom = iommu_get_domain_for_dev(dev);
+		if (!smem_dom) {
+			dev_warn(dev, "No iommu group domain");
+			return 0;
+		}
+
+		addr = iommu_iova_to_phys(smem_dom, iova);
+
+		limit = smem_dev->smem_base + smem_dev->smem_size;
+		if (addr < smem_dev->smem_base || addr >= limit) {
+			dev_err(dev,
+				"Unexpected scp_addr %pa (must >= %pa and <%pa)\n",
+				&addr, &smem_dev->smem_base, &limit);
+			return 0;
+		}
+		dev_dbg(dev, "Pa verifcation pass: %pa(>=%pa, <%pa)\n",
+			&addr, &smem_dev->smem_base, &limit);
+		return addr;
+}
+
+static int mtk_cam_smem_get_sgtable(struct device *dev,
+				    struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, unsigned long attrs)
+{
+	struct mtk_cam_smem_drv *smem_dev = dev_get_drvdata(dev);
+	int n_pages_align = 0;
+	int size_align = 0;
+	int page_start = 0;
+	unsigned long long offset_p = 0;
+
+	dma_addr_t scp_addr = mtk_cam_smem_iova_to_scp_addr(dev, dma_addr);
+
+	offset_p = (unsigned long long)scp_addr -
+		(unsigned long long)smem_dev->smem_base;
+
+	size_align = round_up(size, PAGE_SIZE);
+	n_pages_align = size_align >> PAGE_SHIFT;
+	page_start = offset_p >> PAGE_SHIFT;
+	dev_dbg(dev,
+		"%s:page idx:%d,page pa:0x%llx,pa:0x%llx, aligned size:%d pages:%d\n",
+		__func__,
+		page_start,
+		(unsigned long long)page_to_phys(*(smem_dev->smem_pages
+			+ page_start)),
+		(unsigned long long)scp_addr,
+		size_align,
+		n_pages_align
+		);
+
+	return sg_alloc_table_from_pages(sgt,
+		smem_dev->smem_pages + page_start,
+		n_pages_align,
+		0, size_align, GFP_KERNEL);
+}
+
+static void *mtk_cam_smem_get_cpu_addr(struct mtk_cam_smem_drv *smem_dev,
+				       struct scatterlist *sg)
+{
+	struct device *dev = &smem_dev->pdev->dev;
+	struct dma_coherent_mem *dma_mem = dev->dma_mem;
+
+	dma_addr_t addr = (phys_addr_t)sg_phys(sg);
+
+	if (addr < smem_dev->smem_base ||
+	    addr > smem_dev->smem_base + smem_dev->smem_size) {
+		dev_err(dev, "Invalid scp_addr 0x%llx from sg\n", addr);
+		return NULL;
+	}
+
+	return dma_mem->virt_base + (addr - smem_dev->smem_base);
+}
+
+static void mtk_cam_smem_sync_sg_for_cpu(struct device *dev,
+					 struct scatterlist *sgl, int nelems,
+					 enum dma_data_direction dir)
+{
+	struct mtk_cam_smem_drv *smem_dev =
+		dev_get_drvdata(dev);
+	void *cpu_addr;
+
+	cpu_addr = mtk_cam_smem_get_cpu_addr(smem_dev, sgl);
+	dev_dbg(dev,
+		"__dma_unmap_area:scp_addr(0x%llx),vaddr(0x%llx),size(%d),dir(%d)\n",
+		(unsigned long long)sg_phys(sgl),
+		(unsigned long long)cpu_addr,
+		sgl->length,
+		dir);
+	__dma_unmap_area(cpu_addr, sgl->length, dir);
+}
+
+static void mtk_cam_smem_sync_sg_for_device(struct device *dev,
+					    struct scatterlist *sgl,
+					    int nelems,
+					    enum dma_data_direction dir)
+{
+	struct mtk_cam_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+	void *cpu_addr;
+
+	cpu_addr = mtk_cam_smem_get_cpu_addr(smem_dev, sgl);
+	flush_cache_vmap((unsigned long long)cpu_addr,
+			 (unsigned long long)cpu_addr + sgl->length);
+	__dma_flush_area(cpu_addr, sgl->length);
+	dev_dbg(dev,
+		"__dma_map_area:scp_addr(0x%llx),vaddr(0x%llx),size(%d),dir(%d)\n",
+		(unsigned long long)sg_phys(sgl),
+		(unsigned long long)cpu_addr,
+		sgl->length,
+		dir);
+	__dma_map_area(cpu_addr, sgl->length, dir);
+}
+
+static int mtk_cam_smem_setup_dma_ops(struct device *dev,
+				      const struct dma_map_ops *smem_ops)
+{
+	if (!dev->dma_ops)
+		return -EINVAL;
+
+	memcpy((void *)smem_ops, dev->dma_ops, sizeof(*smem_ops));
+	((struct dma_map_ops *)smem_ops)->get_sgtable =
+		mtk_cam_smem_get_sgtable;
+	((struct dma_map_ops *)smem_ops)->sync_sg_for_device =
+		mtk_cam_smem_sync_sg_for_device;
+	((struct dma_map_ops *)smem_ops)->sync_sg_for_cpu =
+		mtk_cam_smem_sync_sg_for_cpu;
+	dev->dma_ops = smem_ops;
+
+	return 0;
+}
+
+static const struct dma_map_ops smem_dma_ops = {
+	.get_sgtable = mtk_cam_smem_get_sgtable,
+};
+
+static int mtk_cam_smem_init(struct mtk_cam_smem_drv **mtk_cam_smem_drv_out,
+			     struct platform_device *pdev)
+{
+	struct mtk_cam_smem_drv *isp_sys;
+	struct device *dev = &pdev->dev;
+
+	isp_sys = devm_kzalloc(dev,
+			       sizeof(*isp_sys), GFP_KERNEL);
+	isp_sys->pdev = pdev;
+	*mtk_cam_smem_drv_out = isp_sys;
+
+	return 0;
+}
+
+static int mtk_cam_smem_drv_probe(struct platform_device *pdev)
+{
+	struct mtk_cam_smem_drv *smem_drv;
+	int r = 0;
+	struct device *dev = &pdev->dev;
+
+	dev_dbg(dev, "probe mtk_cam_smem_drv\n");
+
+	r = mtk_cam_smem_init(&smem_drv, pdev);
+
+	if (!smem_drv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, smem_drv);
+
+	if (isp_reserved_smem) {
+		dma_addr_t dma_addr;
+		dma_addr_t addr;
+		struct iommu_domain *smem_dom;
+		unsigned int i;
+		int size_align;
+		struct page **pages;
+		int n_pages;
+		struct sg_table *sgt = &smem_drv->sgt;
+
+		size_align = round_down(isp_reserved_smem->size,
+					PAGE_SIZE);
+		n_pages = size_align >> PAGE_SHIFT;
+
+		pages = kmalloc_array(n_pages, sizeof(struct page *),
+				      GFP_KERNEL);
+
+		if (!pages)
+			return -ENOMEM;
+
+		for (i = 0; i < n_pages; i++)
+			pages[i] = phys_to_page(isp_reserved_smem->base
+						+ i * PAGE_SIZE);
+
+		r = sg_alloc_table_from_pages(sgt, pages, n_pages, 0,
+					      size_align, GFP_KERNEL);
+
+		if (r) {
+			dev_err(dev, "failed to get alloca sg table\n");
+			return -ENOMEM;
+		}
+
+		dma_map_sg_attrs(dev, sgt->sgl, sgt->nents,
+				 DMA_BIDIRECTIONAL,
+				 DMA_ATTR_SKIP_CPU_SYNC);
+
+		dma_addr = sg_dma_address(sgt->sgl);
+		smem_dom = iommu_get_domain_for_dev(dev);
+		addr = iommu_iova_to_phys(smem_dom, dma_addr);
+
+		if (addr != isp_reserved_smem->base)
+			dev_err(dev,
+				"incorrect pa(0x%llx) should be 0x%llx\n",
+			(unsigned long long)addr,
+			(unsigned long long)isp_reserved_smem->base);
+
+		r = dma_declare_coherent_memory(dev,
+						isp_reserved_smem->base,
+			dma_addr, size_align, DMA_MEMORY_EXCLUSIVE);
+
+		dev_dbg(dev,
+			"Coherent mem base(0x%llx,%llx),size(%lx),ret(%d)\n",
+			isp_reserved_smem->base,
+			dma_addr, size_align, r);
+
+		smem_drv->smem_base = isp_reserved_smem->base;
+		smem_drv->smem_size = size_align;
+		smem_drv->smem_pages = pages;
+		smem_drv->num_smem_pages = n_pages;
+		smem_drv->smem_dma_base = dma_addr;
+
+		dev_dbg(dev, "smem_drv setting (0x%llx,%lx,0x%llx,%d)\n",
+			smem_drv->smem_base, smem_drv->smem_size,
+			(unsigned long long)smem_drv->smem_pages,
+			smem_drv->num_smem_pages);
+	}
+
+	r = mtk_cam_smem_setup_dma_ops(dev, &smem_dma_ops);
+
+	return r;
+}
+
+static int mtk_cam_smem_drv_remove(struct platform_device *pdev)
+{
+	struct mtk_cam_smem_drv *smem_drv =
+		dev_get_drvdata(&pdev->dev);
+
+	kfree(smem_drv->smem_pages);
+	return 0;
+}
+
+static int mtk_cam_smem_drv_suspend(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_cam_smem_drv_resume(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_cam_smem_drv_dummy_cb(struct device *dev)
+{
+	return 0;
+}
+
+static const struct dev_pm_ops mtk_cam_smem_drv_pm_ops = {
+	SET_RUNTIME_PM_OPS(&mtk_cam_smem_drv_dummy_cb,
+			   &mtk_cam_smem_drv_dummy_cb, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS
+		(&mtk_cam_smem_drv_suspend, &mtk_cam_smem_drv_resume)
+};
+
+static const struct of_device_id mtk_cam_smem_drv_of_match[] = {
+	{
+		.compatible = "mediatek,mt8183-cam_smem",
+	},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, mtk_cam_smem_drv_of_match);
+
+static struct platform_driver mtk_cam_smem_driver = {
+	.probe = mtk_cam_smem_drv_probe,
+	.remove = mtk_cam_smem_drv_remove,
+	.driver = {
+		.name = MTK_CAM_SMEM_DEV_NAME,
+		.of_match_table =
+			of_match_ptr(mtk_cam_smem_drv_of_match),
+		.pm = &mtk_cam_smem_drv_pm_ops,
+	},
+};
+
+static int __init mtk_cam_smem_dma_setup(struct reserved_mem
+					 *rmem)
+{
+	unsigned long node = rmem->fdt_node;
+
+	if (of_get_flat_dt_prop(node, "reusable", NULL))
+		return -EINVAL;
+
+	if (!of_get_flat_dt_prop(node, "no-map", NULL)) {
+		pr_err("Reserved memory: regions without no-map are not yet supported\n");
+		return -EINVAL;
+	}
+
+	isp_reserved_smem = rmem;
+
+	pr_err("Reserved memory: created DMA memory pool at %pa, size %ld MiB\n",
+	       &rmem->base, (unsigned long)rmem->size / SZ_1M);
+	return 0;
+}
+
+RESERVEDMEM_OF_DECLARE(mtk_cam_smem,
+		       "mediatek,reserve-memory-cam_smem",
+		       mtk_cam_smem_dma_setup);
+
+int __init mtk_cam_smem_drv_init(void)
+{
+	int ret;
+
+	pr_debug("platform_driver_register: mtk_cam_smem_driver\n");
+	ret = platform_driver_register(&mtk_cam_smem_driver);
+	if (ret)
+		pr_warn("isp smem drv init failed, driver didn't probe\n");
+
+	return ret;
+}
+subsys_initcall(mtk_cam_smem_drv_init);
+
+void __exit mtk_cam_smem_drv_ext(void)
+{
+	platform_driver_unregister(&mtk_cam_smem_driver);
+}
+module_exit(mtk_cam_smem_drv_ext);
+MODULE_AUTHOR("Frederic Chen <frederic.chen@mediatek.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Mediatek CAM shared memory driver");
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem.h
new file mode 100644
index 000000000000..719ec0255679
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-smem.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_CAM_SMEM_H__
+#define __MTK_CAM_SMEM_H__
+
+#include <linux/dma-mapping.h>
+
+dma_addr_t mtk_cam_smem_iova_to_scp_addr(struct device *smem_dev,
+					 dma_addr_t iova);
+
+#endif /*__MTK_CAM_SMEM_H__*/
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.c
new file mode 100644
index 000000000000..97e88219a112
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.c
@@ -0,0 +1,1184 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * MTK_CAM-v4l2 is highly based on Intel IPU3 ImgU driver.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/pm_runtime.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf2-dma-contig.h>
+#include <media/v4l2-subdev.h>
+#include <media/v4l2-event.h>
+#include <media/v4l2-fwnode.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_graph.h>
+#include <media/v4l2-common.h>
+#include <media/media-entity.h>
+#include <media/v4l2-async.h>
+
+#include "mtk_cam.h"
+#include "mtk_cam-ctrl.h"
+#include "mtk_cam-dev.h"
+#include "mtk_cam-v4l2-util.h"
+
+#define MTK_CAM_SENSOR_MAIN_PAD_SRC		0
+#define MTK_CAM_SENSOR_SUB_PAD_SRC		0
+#define MTK_CAM_SENSOR_IF_PAD_MAIN_SINK		0
+#define MTK_CAM_SENSOR_IF_PAD_SUB_SINK		1
+#define MTK_CAM_SENSOR_IF_PAD_SRC		4
+
+#define SUBDEV_CIO_NAME				"cam-io"
+#define SUBDEV_SENINF_NAME			"seninf"
+#define SUBDEV_SENSOR_NAME			"sensor"
+#define SUBDEV_SENSOR_MAIN_NAME			"sensor_main"
+#define SUBDEV_SENSOR_SUB_NAME			"sensor_sub"
+
+static int mtk_cam_subdev_open(struct v4l2_subdev *sd,
+			       struct v4l2_subdev_fh *fh)
+{
+	struct mtk_cam_dev *cam_dev = mtk_cam_subdev_to_dev(sd);
+
+	cam_dev->request_fd = -1;
+	cam_dev->request_count = 0;
+
+	return mtk_isp_open(&cam_dev->pdev->dev);
+}
+
+static int mtk_cam_subdev_close(struct v4l2_subdev *sd,
+				struct v4l2_subdev_fh *fh)
+{
+	struct mtk_cam_dev *cam_dev = mtk_cam_subdev_to_dev(sd);
+
+	return mtk_isp_release(&cam_dev->pdev->dev);
+}
+
+static int mtk_cam_v4l2_discover_sensor(struct mtk_cam_dev *cam_dev)
+{
+	struct media_graph graph;
+	struct media_entity *entity = &cam_dev->subdev.entity;
+	struct media_device *mdev = entity->graph_obj.mdev;
+	struct device *dev = &cam_dev->pdev->dev;
+	struct v4l2_subdev *sensor;
+	struct v4l2_subdev *sensor_if;
+	int ret;
+
+	mutex_lock(&mdev->graph_mutex);
+	ret = media_graph_walk_init(&graph, mdev);
+	if (ret) {
+		mutex_unlock(&mdev->graph_mutex);
+		return ret;
+	}
+
+	sensor = NULL;
+	sensor_if = NULL;
+
+	media_graph_walk_start(&graph, entity);
+	while ((entity = media_graph_walk_next(&graph))) {
+		dev_dbg(dev, "Graph traversal: entity: %s\n", entity->name);
+
+		if (!strcmp(entity->name, SUBDEV_SENINF_NAME)) {
+			sensor_if = media_entity_to_v4l2_subdev(entity);
+			dev_dbg(dev, "Sensor if entity found: %s\n",
+				entity->name);
+		}
+
+		if (!strncmp(entity->name, SUBDEV_SENSOR_NAME, 6)) {
+			sensor = media_entity_to_v4l2_subdev(entity);
+			dev_dbg(dev, "Sensor if entity found: %s\n",
+				entity->name);
+		}
+	}
+	mutex_unlock(&mdev->graph_mutex);
+	media_graph_walk_cleanup(&graph);
+
+	if (!sensor_if) {
+		dev_err(dev, "Sensor IF has not been connected\n");
+		return -EINVAL;
+	}
+	if (!sensor) {
+		dev_err(dev, "Sensor has not been not connected\n");
+		return -EINVAL;
+	}
+	cam_dev->sensor_if = sensor_if;
+	cam_dev->sensor = sensor;
+
+	return 0;
+}
+
+static int mtk_cam_cio_stream_on(struct mtk_cam_dev *cam_dev)
+{
+	struct device *dev = &cam_dev->pdev->dev;
+	int ret;
+
+	/* Align vb2_core_streamon design */
+	if (cam_dev->streaming) {
+		dev_warn(dev, "already streaming\n", dev);
+		return 0;
+	}
+
+	/*
+	 * Get sensor interace and sensor sub device.
+	 * If the call succeeds, sensor if and sensor are filled
+	 * in isp_dev->cio->sensor_if and isp_dev->cio->sensor.
+	 */
+	ret = mtk_cam_v4l2_discover_sensor(cam_dev);
+	if (ret) {
+		dev_err(dev, "no sensor/sensor if connected:%d\n", ret);
+		return -EPERM;
+	}
+
+	/* seninf must stream on first */
+	dev_dbg(dev, "streamed on sensor-if:%s\n",
+		cam_dev->sensor_if->entity.name);
+	ret = v4l2_subdev_call(cam_dev->sensor_if, video, s_stream, 1);
+	if (ret) {
+		dev_err(dev, "sensor-if:%s stream on failed:%d\n",
+			cam_dev->sensor_if->entity.name, ret);
+		return -EPERM;
+	}
+
+	dev_dbg(dev, "streamed on sensor:%s\n",
+		cam_dev->sensor->entity.name);
+	ret = v4l2_subdev_call(cam_dev->sensor, video, s_stream, 1);
+	if (ret) {
+		dev_err(dev, "sensor:%s stream on failed:%d\n",
+			cam_dev->sensor->entity.name, ret);
+		goto fail_sensor_on;
+	}
+
+	ret = mtk_isp_streamon(dev);
+	if (ret) {
+		dev_err(dev, "Pass 1 stream on failed:%d\n", ret);
+		goto fail_cam_on;
+	}
+	cam_dev->streaming = true;
+
+	dev_dbg(dev, "streamed on Pass 1\n");
+	mtk_cam_dev_queue_buffers(cam_dev);
+
+	return 0;
+
+fail_cam_on:
+	v4l2_subdev_call(cam_dev->sensor, video, s_stream, 0);
+fail_sensor_on:
+	v4l2_subdev_call(cam_dev->sensor_if, video, s_stream, 0);
+	return -EPERM;
+}
+
+static int mtk_cam_cio_stream_off(struct mtk_cam_dev *cam_dev)
+{
+	struct device *dev = &cam_dev->pdev->dev;
+	int ret;
+
+	if (!cam_dev->streaming) {
+		dev_warn(dev, "already stream off");
+		return 0;
+	}
+
+	dev_dbg(dev, "streamed off sensor:%s\n",
+		cam_dev->sensor->entity.name);
+	ret = v4l2_subdev_call(cam_dev->sensor, video, s_stream, 0);
+	if (ret) {
+		dev_err(dev, "sensor:%s stream off failed:%d\n",
+			cam_dev->sensor->entity.name, ret);
+		return -EPERM;
+	}
+
+	dev_dbg(dev, "streamed off sensor-if:%s\n",
+		cam_dev->sensor_if->entity.name);
+	ret = v4l2_subdev_call(cam_dev->sensor_if, video, s_stream, 0);
+	if (ret) {
+		dev_err(dev, "sensor_if:%s stream off failed:%d\n",
+			cam_dev->sensor_if->entity.name, ret);
+		goto fail_sensor_off;
+	}
+
+	mtk_isp_streamoff(dev);
+	cam_dev->streaming = false;
+	dev_dbg(dev, "streamed off Pass 1\n");
+
+	return 0;
+
+fail_sensor_off:
+	v4l2_subdev_call(cam_dev->sensor_if, video, s_stream, 1);
+	return -EPERM;
+}
+
+static int mtk_cam_subdev_s_stream(struct v4l2_subdev *sd,
+				   int enable)
+{
+	struct mtk_cam_dev *cam_dev = mtk_cam_subdev_to_dev(sd);
+
+	if (enable)
+		return mtk_cam_cio_stream_on(cam_dev);
+	else
+		return mtk_cam_cio_stream_off(cam_dev);
+}
+
+static int mtk_cam_subdev_subscribe_event(struct v4l2_subdev *subdev,
+					  struct v4l2_fh *fh,
+					  struct v4l2_event_subscription *sub)
+{
+	switch (sub->type) {
+	case V4L2_EVENT_FRAME_SYNC:
+		return v4l2_event_subscribe(fh, sub, 0, NULL);
+	default:
+		return -EINVAL;
+	}
+}
+
+static int mtk_cam_link_setup(struct media_entity *entity,
+			      const struct media_pad *local,
+	const struct media_pad *remote, u32 flags)
+{
+	struct mtk_cam_dev *cam_dev =
+		container_of(entity, struct mtk_cam_dev, subdev.entity);
+	u32 pad = local->index;
+
+	dev_dbg(&cam_dev->pdev->dev, "link setup: %d --> %d\n",
+		pad, remote->index);
+
+	if (pad == cam_dev->cio_pad_sink)
+		cam_dev->cio_enabled = !!(flags & MEDIA_LNK_FL_ENABLED);
+	else
+		cam_dev->mem2mem2_nodes[pad].enabled =
+			!!(flags & MEDIA_LNK_FL_ENABLED);
+
+	return 0;
+}
+
+static void mtk_cam_vb2_buf_queue(struct vb2_buffer *vb)
+{
+	struct mtk_cam_dev *mtk_cam_dev = vb2_get_drv_priv(vb->vb2_queue);
+	struct mtk_cam_video_device *node = mtk_cam_vbq_to_vdev(vb->vb2_queue);
+	struct device *dev = &mtk_cam_dev->pdev->dev;
+	struct mtk_cam_dev_buffer *buf;
+	struct vb2_v4l2_buffer *v4l2_buf;
+
+	dev_dbg(dev, "queue vb2_buf: Node(%s) queue id(%d)\n",
+		node->vdev.name,
+		node->id);
+
+	buf = mtk_cam_vb2_buf_to_dev_buf(vb);
+	v4l2_buf = to_vb2_v4l2_buffer(vb);
+
+	if (mtk_cam_dev->request_fd != v4l2_buf->request_fd) {
+		mtk_cam_dev->request_fd = v4l2_buf->request_fd;
+		mtk_cam_dev->request_count =
+			vb->req_obj.req->num_incomplete_objects;
+		dev_dbg(dev, "init  mtk_cam_dev_buf, fd(%d) count(%d)\n",
+			v4l2_buf->request_fd,
+			vb->req_obj.req->num_incomplete_objects);
+	}
+
+	/* Added the buffer into the tracking list */
+	spin_lock(&node->slock);
+	list_add_tail(&buf->list, &node->pending_list);
+	spin_unlock(&node->slock);
+
+	mtk_cam_dev->request_count--;
+
+	if (!mtk_cam_dev->request_count) {
+		mtk_cam_dev->request_fd = -1;
+		dev_dbg(dev, "%s: mtk_cam_dev_queue_buffers\n",
+			node->vdev.name);
+		mtk_cam_dev_queue_buffers(mtk_cam_dev);
+	}
+}
+
+static int mtk_cam_vb2_queue_setup(struct vb2_queue *vq,
+				   unsigned int *num_buffers,
+				   unsigned int *num_planes,
+				   unsigned int sizes[],
+				   struct device *alloc_devs[])
+{
+	struct mtk_cam_dev *cam_dev = vb2_get_drv_priv(vq);
+	struct mtk_cam_video_device *node = mtk_cam_vbq_to_vdev(vq);
+	struct device *dev = &cam_dev->pdev->dev;
+	unsigned int max_buffer_count = node->desc.max_buf_count;
+	const struct v4l2_format *fmt = &node->vdev_fmt;
+	unsigned int size;
+
+	/* Check the limitation of buffer size */
+	if (max_buffer_count > 0)
+		*num_buffers = clamp_val(*num_buffers, 1, max_buffer_count);
+	else
+		*num_buffers = clamp_val(*num_buffers, 1, VB2_MAX_FRAME);
+
+	if (node->desc.smem_alloc) {
+		alloc_devs[0] = &cam_dev->smem_pdev->dev;
+		dev_dbg(dev, "Select smem alloc_devs(0x%pK)\n", alloc_devs[0]);
+	} else {
+		alloc_devs[0] = &cam_dev->pdev->dev;
+		dev_dbg(dev, "Select default alloc_devs(0x%pK)\n",
+			alloc_devs[0]);
+	}
+
+	vq->dma_attrs |= DMA_ATTR_NON_CONSISTENT;
+
+	if (vq->type == V4L2_BUF_TYPE_META_OUTPUT ||
+	    vq->type == V4L2_BUF_TYPE_META_CAPTURE)
+		size = fmt->fmt.meta.buffersize;
+	else
+		size = fmt->fmt.pix_mp.plane_fmt[0].sizeimage;
+
+	/* Validate initialized num_planes & size[0] */
+	if (*num_planes) {
+		if (sizes[0] < size)
+			return -EINVAL;
+	} else {
+		*num_planes = 1;
+		sizes[0] = size;
+	}
+
+	/* Initialize buffer queue & locks */
+	INIT_LIST_HEAD(&node->pending_list);
+	mutex_init(&node->lock);
+	spin_lock_init(&node->slock);
+
+	return 0;
+}
+
+static bool
+mtk_cam_all_nodes_streaming(struct mtk_cam_dev *cam_dev,
+			    struct mtk_cam_video_device *except)
+{
+	unsigned int i;
+
+	for (i = 0; i < cam_dev->dev_node_num; i++) {
+		struct mtk_cam_video_device *node = &cam_dev->mem2mem2_nodes[i];
+
+		if (node == except)
+			continue;
+		if (node->enabled && !vb2_start_streaming_called(&node->vbq))
+			return false;
+	}
+
+	return true;
+}
+
+static void mtk_cam_return_all_buffers(struct mtk_cam_dev *cam_dev,
+				       struct mtk_cam_video_device *node,
+				       enum vb2_buffer_state state)
+{
+	struct mtk_cam_dev_buffer *b, *b0;
+	unsigned int i;
+
+	dev_dbg(&cam_dev->pdev->dev, "%s: node:%s", __func__, node->vdev.name);
+
+	/* Return all buffers */
+	spin_lock(&node->slock);
+	list_for_each_entry_safe(b, b0, &node->pending_list, list) {
+		list_del(&b->list);
+	}
+	spin_unlock(&node->slock);
+
+	for (i = 0; i < node->vbq.num_buffers; ++i)
+		if (node->vbq.bufs[i]->state == VB2_BUF_STATE_ACTIVE)
+			vb2_buffer_done(node->vbq.bufs[i], state);
+}
+
+static int mtk_cam_vb2_start_streaming(struct vb2_queue *vq,
+				       unsigned int count)
+{
+	struct mtk_cam_dev *cam_dev = vb2_get_drv_priv(vq);
+	struct mtk_cam_video_device *node = mtk_cam_vbq_to_vdev(vq);
+	int ret;
+
+	if (!node->enabled) {
+		dev_err(&cam_dev->pdev->dev, "Node:%d is not enable\n",
+			node->id);
+		ret = -EINVAL;
+		goto fail_return_bufs;
+	}
+
+	ret = media_pipeline_start(&node->vdev.entity, &cam_dev->pipeline);
+	if (ret < 0) {
+		dev_err(&cam_dev->pdev->dev, "Node:%d %s failed\n",
+			node->id, __func__);
+		goto fail_return_bufs;
+	}
+
+	if (!mtk_cam_all_nodes_streaming(cam_dev, node))
+		return 0;
+
+	/* Start streaming of the whole pipeline now */
+	ret = v4l2_subdev_call(&cam_dev->subdev, video, s_stream, 1);
+	if (ret < 0) {
+		dev_err(&cam_dev->pdev->dev, "Node:%d s_stream failed\n",
+			node->id);
+		goto fail_stop_pipeline;
+	}
+	return 0;
+
+fail_stop_pipeline:
+	media_pipeline_stop(&node->vdev.entity);
+fail_return_bufs:
+	mtk_cam_return_all_buffers(cam_dev, node, VB2_BUF_STATE_QUEUED);
+	return ret;
+}
+
+static void mtk_cam_vb2_stop_streaming(struct vb2_queue *vq)
+{
+	struct mtk_cam_dev *cam_dev = vb2_get_drv_priv(vq);
+	struct mtk_cam_video_device *node = mtk_cam_vbq_to_vdev(vq);
+
+	/* Was this the first node with streaming disabled? */
+	if (mtk_cam_all_nodes_streaming(cam_dev, node)) {
+		/* Yes, really stop streaming now */
+		if (v4l2_subdev_call(&cam_dev->subdev, video, s_stream, 0))
+			dev_err(&cam_dev->pdev->dev,
+				"failed to stop streaming\n");
+	}
+	mtk_cam_return_all_buffers(cam_dev, node, VB2_BUF_STATE_ERROR);
+	media_pipeline_stop(&node->vdev.entity);
+}
+
+int mtk_cam_videoc_querycap(struct file *file, void *fh,
+			    struct v4l2_capability *cap)
+{
+	struct mtk_cam_dev *cam_dev = video_drvdata(file);
+
+	strscpy(cap->driver, MTK_CAM_DEV_P1_NAME, sizeof(cap->driver));
+	strscpy(cap->card, MTK_CAM_DEV_P1_NAME, sizeof(cap->card));
+	snprintf(cap->bus_info, sizeof(cap->bus_info), "platform:%s",
+		 dev_name(cam_dev->media_dev.dev));
+
+	return 0;
+}
+
+int mtk_cam_videoc_enum_fmt(struct file *file, void *fh,
+			    struct v4l2_fmtdesc *f)
+{
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(file);
+
+	if (f->index > node->desc.num_fmts || f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->pixelformat = node->desc.fmts[f->index].fmt.pix_mp.pixelformat;
+	f->flags = 0;
+
+	return 0;
+}
+
+int mtk_cam_videoc_g_fmt(struct file *file, void *fh, struct v4l2_format *f)
+{
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(file);
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+int mtk_cam_videoc_try_fmt(struct file *file, void *fh,
+			   struct v4l2_format *in_fmt)
+{
+	struct mtk_cam_dev *cam_dev = video_drvdata(file);
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(file);
+	struct v4l2_format *dev_fmt;
+	__u32  width, height;
+
+	if (in_fmt->type != node->vbq.type)
+		return -EINVAL;
+
+	dev_dbg(&cam_dev->pdev->dev, "%s: fmt:%c%c%c%c, w*h:%u*%u\n",
+		__func__,
+		(in_fmt->fmt.pix_mp.pixelformat & 0xFF),
+		(in_fmt->fmt.pix_mp.pixelformat >> 8) & 0xFF,
+		(in_fmt->fmt.pix_mp.pixelformat >> 16) & 0xFF,
+		(in_fmt->fmt.pix_mp.pixelformat >> 24) & 0xFF,
+		in_fmt->fmt.pix_mp.width, in_fmt->fmt.pix_mp.height);
+
+	width = in_fmt->fmt.pix_mp.width;
+	height = in_fmt->fmt.pix_mp.height;
+
+	dev_fmt = mtk_cam_dev_find_fmt(&node->desc,
+				       in_fmt->fmt.pix_mp.pixelformat);
+	if (dev_fmt) {
+		mtk_cam_dev_fmt_set_img(&cam_dev->pdev->dev,
+					&in_fmt->fmt.pix_mp,
+					&dev_fmt->fmt.pix_mp,
+					node->id);
+	} else {
+		mtk_cam_dev_load_default_fmt(&cam_dev->pdev->dev,
+					     &node->desc,
+					     in_fmt);
+	}
+	in_fmt->fmt.pix_mp.width = clamp_t(u32,
+					   width,
+					   CAM_MIN_WIDTH,
+					   in_fmt->fmt.pix_mp.width);
+	in_fmt->fmt.pix_mp.height = clamp_t(u32,
+					    height,
+					    CAM_MIN_HEIGHT,
+					    in_fmt->fmt.pix_mp.height);
+	mtk_cam_dev_cal_mplane_pix_fmt(&cam_dev->pdev->dev,
+				       &in_fmt->fmt.pix_mp,
+				       node->id);
+
+	return 0;
+}
+
+int mtk_cam_videoc_s_fmt(struct file *file, void *fh, struct v4l2_format *f)
+{
+	struct mtk_cam_dev *cam_dev = video_drvdata(file);
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(file);
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	if (cam_dev->streaming)
+		return -EBUSY;
+
+	/* Get the valid format */
+	mtk_cam_videoc_try_fmt(file, fh, f);
+
+	/* Configure to video device */
+	mtk_cam_dev_fmt_set_img(&cam_dev->pdev->dev,
+				&node->vdev_fmt.fmt.pix_mp,
+				&f->fmt.pix_mp,
+				node->id);
+
+	return 0;
+}
+
+int mtk_cam_vidioc_enum_input(struct file *file, void *fh,
+			      struct v4l2_input *input)
+{
+	if (input->index > 0)
+		return -EINVAL;
+
+	strscpy(input->name, "camera", sizeof(input->name));
+	input->type = V4L2_INPUT_TYPE_CAMERA;
+
+	return 0;
+}
+
+int mtk_cam_vidioc_g_input(struct file *file, void *fh, unsigned int *input)
+{
+	*input = 0;
+
+	return 0;
+}
+
+int mtk_cam_vidioc_s_input(struct file *file, void *fh, unsigned int input)
+{
+	return input == 0 ? 0 : -EINVAL;
+}
+
+int mtk_cam_vidioc_subscribe_event(struct v4l2_fh *fh,
+				   const struct v4l2_event_subscription *sub)
+{
+	switch (sub->type) {
+	case V4L2_EVENT_CTRL:
+		return v4l2_ctrl_subscribe_event(fh, sub);
+	default:
+		return -EINVAL;
+	}
+}
+
+int mtk_cam_enum_framesizes(struct file *filp, void *priv,
+			    struct v4l2_frmsizeenum *sizes)
+{
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(filp);
+	struct v4l2_format *dev_fmt;
+
+	dev_fmt = mtk_cam_dev_find_fmt(&node->desc, sizes->pixel_format);
+	if (!dev_fmt || sizes->index)
+		return -EINVAL;
+
+	if (node->id == MTK_CAM_P1_MAIN_STREAM_OUT) {
+		sizes->type = V4L2_FRMSIZE_TYPE_CONTINUOUS;
+		sizes->stepwise.max_width = IMG_MAX_WIDTH;
+		sizes->stepwise.min_width = IMG_MIN_WIDTH;
+		sizes->stepwise.max_height = IMG_MAX_HEIGHT;
+		sizes->stepwise.min_height = IMG_MIN_HEIGHT;
+		sizes->stepwise.step_height = 1;
+		sizes->stepwise.step_width = 1;
+	} else if (node->id == MTK_CAM_P1_PACKED_BIN_OUT) {
+		sizes->type = V4L2_FRMSIZE_TYPE_CONTINUOUS;
+		sizes->stepwise.max_width = RRZ_MAX_WIDTH;
+		sizes->stepwise.min_width = RRZ_MIN_WIDTH;
+		sizes->stepwise.max_height = RRZ_MAX_HEIGHT;
+		sizes->stepwise.min_height = RRZ_MIN_HEIGHT;
+		sizes->stepwise.step_height = 1;
+		sizes->stepwise.step_width = 1;
+	}
+
+	return 0;
+}
+
+int mtk_cam_meta_enum_format(struct file *file, void *fh,
+			     struct v4l2_fmtdesc *f)
+{
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(file);
+
+	/* Each node is dedicated to only one meta format */
+	if (f->index > 0 || f->type != node->vbq.type)
+		return -EINVAL;
+
+	strscpy(f->description, node->desc.description,
+		sizeof(node->desc.description));
+	f->pixelformat = node->vdev_fmt.fmt.meta.dataformat;
+
+	return 0;
+}
+
+int mtk_cam_videoc_g_meta_fmt(struct file *file, void *fh,
+			      struct v4l2_format *f)
+{
+	struct mtk_cam_video_device *node = file_to_mtk_cam_node(file);
+
+	/* Each node is dedicated to only one meta format */
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+/* subdev internal operations */
+static const struct v4l2_subdev_internal_ops mtk_cam_subdev_internal_ops = {
+	.open = mtk_cam_subdev_open,
+	.close = mtk_cam_subdev_close,
+};
+
+static const struct v4l2_subdev_core_ops mtk_cam_subdev_core_ops = {
+	.subscribe_event = mtk_cam_subdev_subscribe_event,
+	.unsubscribe_event = v4l2_event_subdev_unsubscribe,
+};
+
+static const struct v4l2_subdev_video_ops mtk_cam_subdev_video_ops = {
+	.s_stream = mtk_cam_subdev_s_stream,
+};
+
+static const struct v4l2_subdev_ops mtk_cam_subdev_ops = {
+	.core = &mtk_cam_subdev_core_ops,
+	.video = &mtk_cam_subdev_video_ops,
+};
+
+static const struct media_entity_operations mtk_cam_media_ops = {
+	.link_setup = mtk_cam_link_setup,
+	.link_validate = v4l2_subdev_link_validate,
+};
+
+static void mtk_cam_vb2_buf_request_complete(struct vb2_buffer *vb)
+{
+	struct mtk_cam_dev *dev = vb2_get_drv_priv(vb->vb2_queue);
+
+	v4l2_ctrl_request_complete(vb->req_obj.req,
+				   dev->v4l2_dev.ctrl_handler);
+}
+
+static const struct vb2_ops mtk_cam_vb2_ops = {
+	.buf_queue = mtk_cam_vb2_buf_queue,
+	.queue_setup = mtk_cam_vb2_queue_setup,
+	.start_streaming = mtk_cam_vb2_start_streaming,
+	.stop_streaming = mtk_cam_vb2_stop_streaming,
+	.wait_prepare = vb2_ops_wait_prepare,
+	.wait_finish = vb2_ops_wait_finish,
+	.buf_request_complete = mtk_cam_vb2_buf_request_complete,
+};
+
+static const struct v4l2_file_operations mtk_cam_v4l2_fops = {
+	.unlocked_ioctl = video_ioctl2,
+	.open = v4l2_fh_open,
+	.release = vb2_fop_release,
+	.poll = vb2_fop_poll,
+	.mmap = vb2_fop_mmap,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl32 = v4l2_compat_ioctl32,
+#endif
+};
+
+/*
+ * Config node's video properties
+ * according to the device context requirement
+ */
+static void mtk_cam_node_to_v4l2(struct mtk_cam_dev *cam_dev,
+				 unsigned int node,
+				 struct video_device *vdev,
+				 struct v4l2_format *f)
+{
+	struct mtk_cam_dev_node_desc *node_desc =
+		&cam_dev->mem2mem2_nodes[node].desc;
+
+	/* set cap/type/ioctl_ops of the video device */
+	vdev->device_caps = V4L2_CAP_STREAMING | node_desc->cap;
+	f->type = node_desc->buf_type;
+	vdev->ioctl_ops = node_desc->ioctl_ops;
+
+	mtk_cam_dev_load_default_fmt(&cam_dev->pdev->dev,
+				     node_desc,
+				     f);
+}
+
+static const struct media_device_ops mtk_cam_media_req_ops = {
+	.req_validate = vb2_request_validate,
+	.req_queue = vb2_request_queue,
+};
+
+static int mtk_cam_media_register(struct device *dev,
+				  struct media_device *media_dev)
+{
+	int ret;
+
+	media_dev->dev = dev;
+	strscpy(media_dev->model, MTK_CAM_DEV_P1_NAME,
+		sizeof(media_dev->model));
+	snprintf(media_dev->bus_info, sizeof(media_dev->bus_info),
+		 "platform:%s", dev_name(dev));
+	media_dev->hw_revision = 0;
+	media_device_init(media_dev);
+	media_dev->ops = &mtk_cam_media_req_ops;
+	dev_info(dev, "Register media device: %s, 0x%pK",
+		 MTK_CAM_DEV_P1_NAME, media_dev);
+
+	ret = media_device_register(media_dev);
+	if (ret) {
+		dev_err(dev, "failed to register media device (%d)\n", ret);
+		goto fail_v4l2_dev;
+	}
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+	media_device_cleanup(media_dev);
+
+	return ret;
+}
+
+int mtk_cam_v4l2_register(struct device *dev,
+			  struct media_device *media_dev,
+			  struct v4l2_device *v4l2_dev,
+			  struct v4l2_ctrl_handler *ctrl_handler)
+{
+	int ret;
+
+	/* Set up v4l2 device */
+	v4l2_dev->ctrl_handler = ctrl_handler;
+	v4l2_dev->mdev = media_dev;
+	dev_info(dev, "Register v4l2 device: 0x%pK", v4l2_dev);
+	ret = v4l2_device_register(dev, v4l2_dev);
+	if (ret) {
+		dev_err(dev, "failed to register V4L2 device (%d)\n", ret);
+		goto fail_v4l2_dev;
+	}
+
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+	media_device_cleanup(media_dev);
+
+	return ret;
+}
+
+int mtk_cam_mem2mem2_v4l2_register(struct mtk_cam_dev *cam_dev)
+{
+	struct device *dev = &cam_dev->pdev->dev;
+	unsigned int num_nodes = cam_dev->dev_node_num;
+	/* Total pad numbers is video devices + one seninf pad */
+	unsigned int num_subdev_pads = MTK_CAM_DEV_NODE_MAX + 1;
+	unsigned int i;
+	int ret;
+
+	ret = mtk_cam_media_register(dev,
+				     &cam_dev->media_dev);
+	if (ret) {
+		dev_err(dev, "failed to register media device:%d\n", ret);
+		goto fail_media_dev;
+	}
+
+	ret = mtk_cam_v4l2_register(dev,
+				    &cam_dev->media_dev,
+				    &cam_dev->v4l2_dev,
+				    NULL);
+	if (ret) {
+		dev_err(dev, "failed to register V4L2 device:%d\n", ret);
+		goto fail_v4l2_dev;
+	}
+
+	/* Initialize subdev media entity */
+	cam_dev->subdev_pads = kcalloc(num_subdev_pads,
+				       sizeof(*cam_dev->subdev_pads),
+				       GFP_KERNEL);
+	if (!cam_dev->subdev_pads) {
+		ret = -ENOMEM;
+		goto fail_subdev_pads;
+	}
+
+	ret = media_entity_pads_init(&cam_dev->subdev.entity,
+				     num_subdev_pads,
+				     cam_dev->subdev_pads);
+	if (ret) {
+		dev_err(dev, "failed initialize media pads:%d:\n", ret);
+		goto fail_media_entity;
+	}
+
+	/* Initialize all pads with MEDIA_PAD_FL_SOURCE */
+	for (i = 0; i < num_subdev_pads; i++)
+		cam_dev->subdev_pads[i].flags = MEDIA_PAD_FL_SOURCE;
+
+	/* Customize connection IO media info. */
+	cam_dev->cio_pad_sink = num_subdev_pads - 1;
+	cam_dev->subdev_pads[cam_dev->cio_pad_sink].flags =
+		MEDIA_PAD_FL_SINK;
+
+	/* Initialize subdev */
+	v4l2_subdev_init(&cam_dev->subdev, &mtk_cam_subdev_ops);
+	cam_dev->subdev.entity.function = MEDIA_ENT_F_PROC_VIDEO_STATISTICS;
+	cam_dev->subdev.entity.ops = &mtk_cam_media_ops;
+	cam_dev->subdev.flags = V4L2_SUBDEV_FL_HAS_DEVNODE |
+				V4L2_SUBDEV_FL_HAS_EVENTS;
+	snprintf(cam_dev->subdev.name, sizeof(cam_dev->subdev.name),
+		 "%s", MTK_CAM_DEV_P1_NAME);
+	v4l2_set_subdevdata(&cam_dev->subdev, cam_dev);
+	cam_dev->subdev.internal_ops = &mtk_cam_subdev_internal_ops;
+
+	dev_info(dev, "register subdev: %s\n", cam_dev->subdev.name);
+	ret = v4l2_device_register_subdev(&cam_dev->v4l2_dev, &cam_dev->subdev);
+	if (ret) {
+		dev_err(dev, "failed initialize subdev:%d\n", ret);
+		goto fail_subdev;
+	}
+
+	/* Create video nodes and links */
+	for (i = 0; i < num_nodes; i++) {
+		struct mtk_cam_video_device *node = &cam_dev->mem2mem2_nodes[i];
+		struct video_device *vdev = &node->vdev;
+		struct vb2_queue *vbq = &node->vbq;
+		u32 output = !cam_dev->mem2mem2_nodes[i].desc.capture;
+		u32 link_flags = cam_dev->mem2mem2_nodes[i].desc.link_flags;
+
+		cam_dev->subdev_pads[i].flags = output ?
+			MEDIA_PAD_FL_SINK : MEDIA_PAD_FL_SOURCE;
+
+		/* Initialize miscellaneous variables */
+		mutex_init(&node->lock);
+		spin_lock_init(&node->slock);
+		INIT_LIST_HEAD(&node->pending_list);
+
+		/* Initialize formats to default values */
+		mtk_cam_node_to_v4l2(cam_dev, i, vdev, &node->vdev_fmt);
+
+		/* Initialize media entities */
+		ret = media_entity_pads_init(&vdev->entity, 1, &node->vdev_pad);
+		if (ret) {
+			dev_err(dev, "failed initialize media pad:%d\n", ret);
+			goto fail_vdev_media_entity;
+		}
+		node->enabled = false;
+		node->id = i;
+		node->vdev_pad.flags = cam_dev->subdev_pads[i].flags;
+		vdev->entity.ops = NULL;
+		/* Initialize vbq */
+		vbq->type = node->vdev_fmt.type;
+		if (vbq->type == V4L2_BUF_TYPE_META_OUTPUT)
+			vbq->io_modes = VB2_MMAP;
+		else
+			vbq->io_modes = VB2_MMAP | VB2_DMABUF;
+		if (vbq->type == V4L2_BUF_TYPE_META_CAPTURE)
+			vdev->entity.function =
+				MEDIA_ENT_F_PROC_VIDEO_STATISTICS;
+		vbq->ops = &mtk_cam_vb2_ops;
+		vbq->mem_ops = &vb2_dma_contig_memops;
+		vbq->buf_struct_size = sizeof(struct mtk_cam_dev_buffer);
+		vbq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;
+		vbq->min_buffers_needed = 0;	/* Can streamon w/o buffers */
+		/* Put the process hub sub device in the vb2 private data */
+		vbq->drv_priv = cam_dev;
+		vbq->lock = &node->lock;
+		vbq->supports_requests = true;
+
+		ret = vb2_queue_init(vbq);
+		if (ret) {
+			dev_err(dev, "failed to init. vb2 queue:%d\n", ret);
+			goto fail_vdev;
+		}
+
+		/* Initialize vdev */
+		snprintf(vdev->name, sizeof(vdev->name), "%s %s",
+			 MTK_CAM_DEV_P1_NAME, node->desc.name);
+		vdev->release = video_device_release_empty;
+		vdev->fops = &mtk_cam_v4l2_fops;
+		vdev->lock = &node->lock;
+		vdev->v4l2_dev = &cam_dev->v4l2_dev;
+		vdev->queue = &node->vbq;
+		vdev->vfl_dir = output ? VFL_DIR_TX : VFL_DIR_RX;
+		/* Enable private control for image video devices */
+		if (node->desc.image) {
+			mtk_cam_ctrl_init(cam_dev, &node->ctrl_handler);
+			vdev->ctrl_handler = &node->ctrl_handler;
+		}
+		video_set_drvdata(vdev, cam_dev);
+		dev_info(dev, "register vdev:%d:%s\n", i, vdev->name);
+		ret = video_register_device(vdev, VFL_TYPE_GRABBER, -1);
+		if (ret) {
+			dev_err(dev, "failed to register vde:%d\n", ret);
+			goto fail_vdev;
+		}
+
+		/* Create link between video node and the subdev pad */
+		if (output) {
+			ret = media_create_pad_link(&vdev->entity, 0,
+						    &cam_dev->subdev.entity,
+						    i, link_flags);
+		} else {
+			ret = media_create_pad_link(&cam_dev->subdev.entity,
+						    i, &vdev->entity, 0,
+						    link_flags);
+		}
+		if (ret)
+			goto fail_link;
+	}
+
+	return 0;
+
+	for (; i >= 0; i--) {
+fail_link:
+		video_unregister_device(&cam_dev->mem2mem2_nodes[i].vdev);
+fail_vdev:
+		media_entity_cleanup(&cam_dev->mem2mem2_nodes[i].vdev.entity);
+fail_vdev_media_entity:
+		mutex_destroy(&cam_dev->mem2mem2_nodes[i].lock);
+	}
+fail_subdev:
+	media_entity_cleanup(&cam_dev->subdev.entity);
+fail_media_entity:
+	kfree(cam_dev->subdev_pads);
+fail_subdev_pads:
+	v4l2_device_unregister(&cam_dev->v4l2_dev);
+fail_v4l2_dev:
+fail_media_dev:
+	dev_err(dev, "fail_v4l2_dev mdev: 0x%pK", &cam_dev->media_dev);
+	media_device_unregister(&cam_dev->media_dev);
+	media_device_cleanup(&cam_dev->media_dev);
+
+	return ret;
+}
+
+int mtk_cam_v4l2_unregister(struct mtk_cam_dev *cam_dev)
+{
+	unsigned int i;
+	struct mtk_cam_video_device *dev;
+
+	for (i = 0; i < cam_dev->dev_node_num; i++) {
+		dev = &cam_dev->mem2mem2_nodes[i];
+		video_unregister_device(&dev->vdev);
+		media_entity_cleanup(&dev->vdev.entity);
+		mutex_destroy(&dev->lock);
+		if (dev->desc.image)
+			v4l2_ctrl_handler_free(&dev->ctrl_handler);
+	}
+
+	v4l2_device_unregister_subdev(&cam_dev->subdev);
+	media_entity_cleanup(&cam_dev->subdev.entity);
+	kfree(cam_dev->subdev_pads);
+	v4l2_device_unregister(&cam_dev->v4l2_dev);
+	media_device_unregister(&cam_dev->media_dev);
+	media_device_cleanup(&cam_dev->media_dev);
+
+	return 0;
+}
+
+struct sensor_async_subdev {
+	struct v4l2_async_subdev asd;
+};
+
+static struct v4l2_subdev *get_subdev_by_name(struct mtk_cam_dev *cam_dev,
+					      char *name)
+{
+	struct device_node *node;
+	struct v4l2_subdev *sd;
+
+	list_for_each_entry(sd, &cam_dev->v4l2_dev.subdevs, list) {
+		if (!(sd->flags & V4L2_SUBDEV_FL_HAS_DEVNODE))
+			continue;
+		node = to_of_node(sd->fwnode);
+		if (node) {
+			if (!strcmp(node->name, name))
+				return sd;
+		}
+	}
+	return NULL;
+}
+
+static int mtk_cam_dev_complete(struct v4l2_async_notifier *notifier)
+{
+	struct mtk_cam_dev *cam_dev =
+		container_of(notifier, struct mtk_cam_dev, notifier);
+	struct device *dev = &cam_dev->pdev->dev;
+	struct v4l2_subdev *sd;
+	struct v4l2_subdev *src_sd, *sink_sd;
+	struct device_node *node;
+	int ret;
+
+	dev_info(dev, "Complete the v4l2 registration\n");
+
+	ret = v4l2_device_register_subdev_nodes(&cam_dev->v4l2_dev);
+	if (ret) {
+		dev_err(dev, "failed initialize subdev nodes:%d\n", ret);
+		return ret;
+	}
+
+	/* Links among sensors, sensor interface and cio */
+	list_for_each_entry(sd, &cam_dev->v4l2_dev.subdevs, list) {
+		if (!(sd->flags & V4L2_SUBDEV_FL_HAS_DEVNODE))
+			continue;
+		node = to_of_node(sd->fwnode);
+		if (node)
+			sd->entity.name = node->name;
+	}
+
+	src_sd = get_subdev_by_name(cam_dev, SUBDEV_SENSOR_MAIN_NAME);
+	sink_sd = get_subdev_by_name(cam_dev, SUBDEV_SENINF_NAME);
+	if (src_sd && sink_sd) {
+		dev_dbg(dev, "Link create:%s-->%s\n",
+			src_sd->entity.name, sink_sd->entity.name);
+		ret = media_create_pad_link(&src_sd->entity,
+					    MTK_CAM_SENSOR_MAIN_PAD_SRC,
+					    &sink_sd->entity,
+					    MTK_CAM_SENSOR_IF_PAD_MAIN_SINK,
+					    0);
+		if (ret)
+			dev_err(dev,
+				"fail to create pad link %s %s, ret:%d\n",
+				src_sd->entity.name, sink_sd->entity.name,
+				ret);
+	} else {
+		dev_err(dev, "not found: sensor_main(0x%pK), seninf(%pK)\n",
+			src_sd, sink_sd);
+	}
+
+	src_sd = get_subdev_by_name(cam_dev, SUBDEV_SENSOR_SUB_NAME);
+	if (src_sd && sink_sd) {
+		dev_dbg(dev, "Link create: %s --> %s\n",
+			src_sd->entity.name, sink_sd->entity.name);
+		ret = media_create_pad_link(&src_sd->entity,
+					    MTK_CAM_SENSOR_SUB_PAD_SRC,
+					    &sink_sd->entity,
+					    MTK_CAM_SENSOR_IF_PAD_SUB_SINK,
+					    0);
+		if (ret)
+			dev_err(dev,
+				"fail to create pad link %s %s, ret:%d:\n",
+				src_sd->entity.name, sink_sd->entity.name,
+				ret);
+	} else {
+		dev_warn(dev, "not found: sensor_sub(0x%pK), seninf(0x%pK)\n",
+			 src_sd, sink_sd);
+	}
+
+	ret = media_create_pad_link(&sink_sd->entity,
+				    MTK_CAM_SENSOR_IF_PAD_SRC,
+				    &cam_dev->subdev.entity,
+				    cam_dev->cio_pad_sink,
+				    0);
+	if (ret)
+		dev_err(dev, "fail to create pad link %s %s err:%d\n",
+			sink_sd->entity.name, cam_dev->subdev.entity.name, ret);
+
+	return ret;
+}
+
+static int mtk_cam_dev_notifier_bound(struct v4l2_async_notifier *notifier,
+				      struct v4l2_subdev *sd,
+				      struct v4l2_async_subdev *asd)
+{
+	struct mtk_cam_dev *cam_dev =
+		container_of(notifier, struct mtk_cam_dev, notifier);
+	struct device *dev = &cam_dev->pdev->dev;
+
+	dev_info(dev, "%s bound\n", sd->entity.name);
+	if (!strncmp(&sd->entity.name[9],
+		     SUBDEV_SENINF_NAME,
+		     strlen(SUBDEV_SENINF_NAME)))
+		mtk_cam_dev_complete(notifier);
+
+	return 0;
+}
+
+static void mtk_cam_dev_notifier_unbind(struct v4l2_async_notifier *notifier,
+					struct v4l2_subdev *sd,
+					struct v4l2_async_subdev *asd)
+{
+	struct mtk_cam_dev *cam_dev =
+		container_of(notifier, struct mtk_cam_dev, notifier);
+	struct device *dev = &cam_dev->pdev->dev;
+
+	dev_dbg(dev, "%s unbound\n", sd->entity.name);
+}
+
+static int mtk_cam_dev_notifier_complete(struct v4l2_async_notifier *notifier)
+{
+	return 0;
+}
+
+static const struct v4l2_async_notifier_operations mtk_cam_async_ops = {
+	.bound = mtk_cam_dev_notifier_bound,
+	.unbind = mtk_cam_dev_notifier_unbind,
+	.complete = mtk_cam_dev_notifier_complete,
+};
+
+static int mtk_cam_dev_fwnode_parse(struct device *dev,
+				    struct v4l2_fwnode_endpoint *vep,
+				    struct v4l2_async_subdev *asd)
+{
+	dev_dbg(dev, "%s: To be implemented\n", __func__);
+
+	return 0;
+}
+
+int mtk_cam_v4l2_async_register(struct mtk_cam_dev *cam_dev)
+{
+	int ret;
+
+	ret = v4l2_async_notifier_parse_fwnode_endpoints
+		(&cam_dev->pdev->dev, &cam_dev->notifier,
+		 sizeof(struct sensor_async_subdev),
+		 mtk_cam_dev_fwnode_parse);
+	if (ret < 0)
+		return ret;
+
+	if (!cam_dev->notifier.num_subdevs)
+		return -ENODEV;
+
+	cam_dev->notifier.ops = &mtk_cam_async_ops;
+	dev_info(&cam_dev->pdev->dev, "mtk_cam v4l2_async_notifier_register\n");
+	ret = v4l2_async_notifier_register(&cam_dev->v4l2_dev,
+					   &cam_dev->notifier);
+	if (ret) {
+		dev_err(&cam_dev->pdev->dev,
+			"failed to register async notifier : %d\n", ret);
+		v4l2_async_notifier_cleanup(&cam_dev->notifier);
+	}
+
+	return ret;
+}
+
+void mtk_cam_v4l2_async_unregister(struct mtk_cam_dev *cam_dev)
+{
+	v4l2_async_notifier_unregister(&cam_dev->notifier);
+	v4l2_async_notifier_cleanup(&cam_dev->notifier);
+}
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.h
new file mode 100644
index 000000000000..73b36916da08
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam-v4l2-util.h
@@ -0,0 +1,43 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_CAM_DEV_V4L2_H__
+#define __MTK_CAM_DEV_V4L2_H__
+
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+
+int mtk_cam_videoc_querycap(struct file *file, void *fh,
+			    struct v4l2_capability *cap);
+int mtk_cam_enum_framesizes(struct file *filp, void *priv,
+			    struct v4l2_frmsizeenum *sizes);
+int mtk_cam_videoc_enum_fmt(struct file *file, void *fh,
+			    struct v4l2_fmtdesc *f);
+int mtk_cam_videoc_g_fmt(struct file *file, void *fh, struct v4l2_format *f);
+int mtk_cam_videoc_s_fmt(struct file *file, void *fh, struct v4l2_format *f);
+int mtk_cam_videoc_try_fmt(struct file *file,
+			   void *fh, struct v4l2_format *in_fmt);
+int mtk_cam_vidioc_enum_input(struct file *file, void *fh,
+			      struct v4l2_input *input);
+int mtk_cam_vidioc_g_input(struct file *file, void *fh, unsigned int *input);
+int mtk_cam_vidioc_s_input(struct file *file, void *fh, unsigned int input);
+int mtk_cam_meta_enum_format(struct file *file, void *fh,
+			     struct v4l2_fmtdesc *f);
+int mtk_cam_videoc_g_meta_fmt(struct file *file, void *fh,
+			      struct v4l2_format *f);
+int mtk_cam_vidioc_subscribe_event(struct v4l2_fh *fh,
+				   const struct v4l2_event_subscription *sub);
+
+#endif /* __MTK_CAM_DEV_V4L2_H__ */
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.c b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.c
new file mode 100644
index 000000000000..935cf7e1ec15
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.c
@@ -0,0 +1,1098 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ryan Yu <ryan.yu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/atomic.h>
+#include <linux/cdev.h>
+#include <linux/compat.h>
+#include <linux/fs.h>
+#include <linux/interrupt.h>
+#include <linux/jiffies.h>
+#include <linux/kernel.h>
+#include <linux/ktime.h>
+#include <linux/module.h>
+#include <linux/of_platform.h>
+#include <linux/of_irq.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/platform_data/mtk_scp.h>
+#include <linux/pm_runtime.h>
+#include <linux/remoteproc.h>
+#include <linux/sched/clock.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
+#include <linux/videodev2.h>
+#include <linux/vmalloc.h>
+
+#include "mtk_cam.h"
+#include "mtk_cam-regs.h"
+#include "mtk_cam-ctx.h"
+
+static const struct of_device_id mtk_isp_of_ids[] = {
+	{.compatible = "mediatek,mt8183-camisp",},
+	{}
+};
+MODULE_DEVICE_TABLE(of, mtk_isp_of_ids);
+
+/* list of clocks required by isp cam */
+static const char * const mtk_isp_clks[] = {
+	"CAMSYS_CAM_CGPDN", "CAMSYS_CAMTG_CGPDN"
+};
+
+static void isp_dumpdmastat(struct isp_device *isp_dev)
+{
+	dev_err(isp_dev->dev,
+		"IMGO:0x%x, RRZO:0x%x, AAO=0x%x, AFO=0x%x, LMVO=0x%x\n",
+		readl(isp_dev->regs + REG_IMGO_ERR_STAT),
+		readl(isp_dev->regs + REG_RRZO_ERR_STAT),
+		readl(isp_dev->regs + REG_AAO_ERR_STAT),
+		readl(isp_dev->regs + REG_AFO_ERR_STAT),
+		readl(isp_dev->regs + REG_LMVO_ERR_STAT));
+	dev_err(isp_dev->dev,
+		"LCSO=0x%x, PSO=0x%x, FLKO=0x%x, BPCI:0x%x, LSCI=0x%x\n",
+		readl(isp_dev->regs + REG_LCSO_ERR_STAT),
+		readl(isp_dev->regs + REG_PSO_ERR_STAT),
+		readl(isp_dev->regs + REG_FLKO_ERR_STAT),
+		readl(isp_dev->regs + REG_BPCI_ERR_STAT),
+		readl(isp_dev->regs + REG_LSCI_ERR_STAT));
+}
+
+static void mtk_isp_notify(struct mtk_isp_p1_ctx *isp_ctx,
+			   unsigned int request_fd,
+			   unsigned int frame_seq_no,
+			   struct list_head *list_buf,
+			   enum vb2_buffer_state state)
+{
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(isp_ctx);
+	struct device *dev = &p1_dev->pdev->dev;
+	struct mtk_cam_dev_finish_param fram_param;
+
+	fram_param.list_buf = list_buf;
+	fram_param.request_fd = request_fd;
+	fram_param.frame_seq_no = frame_seq_no;
+	fram_param.state = state;
+	dev_dbg(dev, "request fd(%d) frame_seq_no(%d)\n",
+		fram_param.request_fd,
+		fram_param.frame_seq_no);
+	mtk_cam_dev_core_job_finish(p1_dev->cam_dev, &fram_param);
+}
+
+static void isp_deque_frame(struct isp_p1_device *p1_dev, int frame_seq_no)
+{
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct platform_device *pdev = p1_dev->pdev;
+	struct mtk_isp_queue_job *framejob, *tmp;
+	struct isp_queue *p1_enqueue_list = &isp_ctx->p1_enqueue_list;
+
+	/* Match dequeue work and enqueue frame */
+	spin_lock(&p1_enqueue_list->lock);
+	list_for_each_entry_safe(framejob, tmp, &p1_enqueue_list->queue,
+				 list_entry) {
+		dev_dbg(&pdev->dev,
+			"%s frame_seq_no=%d, isp_composer_work->req_num=%d\n",
+			__func__,
+			framejob->frame_seq_no, frame_seq_no);
+		/* Match by the en-queued request number */
+		if (framejob->frame_seq_no == frame_seq_no) {
+			/* Pass to user space */
+			mtk_isp_notify(isp_ctx,
+				       framejob->request_fd,
+				       framejob->frame_seq_no,
+				       &framejob->list_buf,
+				       VB2_BUF_STATE_DONE);
+			atomic_dec(&p1_enqueue_list->queue_cnt);
+			dev_dbg(&pdev->dev,
+				"frame(frame_seq_no=%d) is done, queue_cnt(%d)\n",
+				framejob->frame_seq_no,
+				atomic_read(&p1_enqueue_list->queue_cnt));
+
+			/* remove only when frame ready */
+			list_del(&framejob->list_entry);
+			kfree(framejob);
+			break;
+		} else if (framejob->frame_seq_no < frame_seq_no) {
+			/* Pass to user space for frame drop */
+			mtk_isp_notify(isp_ctx,
+				       framejob->request_fd,
+				       framejob->frame_seq_no,
+				       &framejob->list_buf,
+				       VB2_BUF_STATE_ERROR);
+			atomic_dec(&p1_enqueue_list->queue_cnt);
+			dev_dbg(&pdev->dev,
+				"frame(frame_seq_no=%d) drop, queue_cnt(%d)\n",
+				framejob->frame_seq_no,
+				atomic_read(&p1_enqueue_list->queue_cnt));
+
+			/* remove only drop frame */
+			list_del(&framejob->list_entry);
+			kfree(framejob);
+		}
+	}
+	spin_unlock(&p1_enqueue_list->lock);
+}
+
+static int isp_deque_work(void *data)
+{
+	struct isp_p1_device *p1_dev = (struct isp_p1_device *)data;
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct device *dev = &p1_dev->pdev->dev;
+	struct mtk_cam_dev *cam_dev = p1_dev->cam_dev;
+	struct mtk_cam_dev_stat_event_data event_data;
+	atomic_t *irq_data_end = &isp_ctx->irq_data_end;
+	atomic_t *irq_data_start = &isp_ctx->irq_data_start;
+	unsigned long flags;
+	int ret, i;
+
+	while (1) {
+		ret = wait_event_interruptible(isp_ctx->isp_deque_thread.wq,
+					       (atomic_read(irq_data_end) !=
+					       atomic_read(irq_data_start)) ||
+					       kthread_should_stop());
+
+		if (kthread_should_stop())
+			break;
+
+		if (ret == ERESTARTSYS) {
+			dev_err(dev, "interrupted by a signal!\n");
+			continue;
+		}
+
+		spin_lock_irqsave(&isp_ctx->irq_dequeue_lock, flags);
+		i = atomic_read(&isp_ctx->irq_data_start);
+		memcpy(&event_data, &isp_ctx->irq_event_datas[i],
+		       sizeof(event_data));
+		memset(&isp_ctx->irq_event_datas[i], 0x00, sizeof(event_data));
+		atomic_set(&isp_ctx->irq_data_start, ++i & 0x3);
+		spin_unlock_irqrestore(&isp_ctx->irq_dequeue_lock, flags);
+
+		if (event_data.irq_status_mask & VS_INT_ST) {
+			/* Notify specific HW events to user space */
+			mtk_cam_dev_queue_event_dev_state(cam_dev,
+							  &event_data);
+			dev_dbg(dev,
+				"event IRQ(0x%x) DMA(0x%x) is sent\n",
+				event_data.irq_status_mask,
+				event_data.dma_status_mask);
+			mtk_cam_dev_queue_event_dev_state(cam_dev,
+							  &event_data);
+		} else if (event_data.irq_status_mask & SW_PASS1_DON_ST) {
+			isp_deque_frame(p1_dev,
+					event_data.frame_seq_no);
+		}
+	}
+	return 0;
+}
+
+static int irq_handle_sof(struct isp_device *isp_dev,
+			  dma_addr_t base_addr,
+			  unsigned int frame_num)
+{
+	unsigned int cq_addr_index;
+	struct isp_p1_device *p1_dev = get_p1_device(isp_dev->dev);
+	int cq_num = atomic_read(&p1_dev->isp_ctx.composed_frame_id);
+
+	if (cq_num > frame_num) {
+		cq_addr_index = frame_num % CQ_BUFFER_COUNT;
+
+		writel(base_addr +
+			(dma_addr_t)(CQ_ADDRESS_OFFSET * cq_addr_index),
+			isp_dev->regs + REG_CQ_THR0_BASEADDR);
+		dev_dbg(isp_dev->dev,
+			"SOF_INT_ST cq_num:%d, frame_num:%d cq_addr:%d",
+			cq_num, frame_num, cq_addr_index);
+	} else {
+		dev_dbg(isp_dev->dev,
+			"SOF_INT_ST cq_num:%d, frame_num:%d",
+			cq_num, frame_num);
+	}
+
+	isp_dev->sof_count += 1;
+
+	return cq_num;
+}
+
+static int irq_handle_notify_event(struct isp_device *isp_dev,
+				   unsigned int irqstatus,
+				   unsigned int dmastatus)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(isp_dev->dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	unsigned long flags;
+	int i;
+
+	spin_lock_irqsave(&isp_ctx->irq_dequeue_lock, flags);
+	i = atomic_read(&isp_ctx->irq_data_end);
+	isp_ctx->irq_event_datas[i].frame_seq_no = isp_dev->current_frame;
+	isp_ctx->irq_event_datas[i].irq_status_mask |=
+		(irqstatus & INT_ST_MASK_CAM);
+	isp_ctx->irq_event_datas[i].dma_status_mask |=
+		(dmastatus & DMA_ST_MASK_CAM);
+	atomic_set(&isp_ctx->irq_data_end, ++i & 0x3);
+	spin_unlock_irqrestore(&isp_ctx->irq_dequeue_lock, flags);
+
+	wake_up_interruptible(&isp_ctx->isp_deque_thread.wq);
+
+	dev_dbg(isp_dev->dev,
+		"%s notify IRQ (0x%x) DMA status (0x%x) for frame_seq_no: %d\n",
+		__func__,
+		(irqstatus & INT_ST_MASK_CAM),
+		(dmastatus & DMA_ST_MASK_CAM),
+		isp_dev->current_frame);
+
+	return 0;
+}
+
+irqreturn_t isp_irq_cam(int irq, void *data)
+{
+	struct isp_device *isp_dev = (struct isp_device *)data;
+	struct isp_p1_device *p1_dev = get_p1_device(isp_dev->dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct device *dev = isp_dev->dev;
+	unsigned int cardinalnum, cq_num, hw_frame_num;
+	unsigned int irqstatus, errstatus, warnstatus, dmastatus;
+	unsigned long flags;
+
+	/* Check the streaming is off or not */
+	if (!p1_dev->cam_dev->streaming)
+		return IRQ_HANDLED;
+
+	cardinalnum = isp_dev->isp_hw_module - ISP_CAM_A_IDX;
+	cq_num = 0;
+
+	spin_lock_irqsave(&isp_dev->spinlock_irq, flags);
+	irqstatus = readl(isp_dev->regs + REG_CTL_RAW_INT_STAT);
+	dmastatus = readl(isp_dev->regs + REG_CTL_RAW_INT2_STAT);
+	hw_frame_num = readl(isp_dev->regs + REG_HW_FRAME_NUM);
+	spin_unlock_irqrestore(&isp_dev->spinlock_irq, flags);
+
+	/* Ignore unnecessary IRQ */
+	if (irqstatus == 0)
+		return IRQ_HANDLED;
+
+	errstatus = irqstatus & INT_ST_MASK_CAM_ERR;
+	warnstatus = irqstatus & INT_ST_MASK_CAM_WARN;
+	irqstatus = irqstatus & INT_ST_MASK_CAM;
+
+	/* sof , done order check . */
+	spin_lock_irqsave(&isp_dev->spinlock_irq, flags);
+	if ((irqstatus & HW_PASS1_DON_ST) && (irqstatus & SOF_INT_ST)) {
+		dev_warn(dev,
+			 "isp sof_don block, %d\n",
+			 isp_dev->sof_count);
+
+		/* Notify IRQ event and enqueue ready frame */
+		irq_handle_notify_event(isp_dev, irqstatus, dmastatus);
+		isp_dev->current_frame = hw_frame_num;
+	} else {
+		if (irqstatus & SOF_INT_ST)
+			isp_dev->current_frame = hw_frame_num;
+
+		if ((irqstatus & INT_ST_MASK_CAM) ||
+		    (dmastatus & DMA_ST_MASK_CAM))
+			irq_handle_notify_event(isp_dev, irqstatus, dmastatus);
+	}
+	spin_unlock_irqrestore(&isp_dev->spinlock_irq, flags);
+
+	if (irqstatus & SOF_INT_ST)
+		cq_num = irq_handle_sof(isp_dev, isp_ctx->scp_mem_iova,
+					hw_frame_num);
+
+	if (irqstatus & SW_PASS1_DON_ST) {
+		int num = atomic_dec_return(&isp_ctx->composing_frame);
+
+		dev_dbg(dev, "SW_PASS1_DON_ST queued frame:%d\n", num);
+		/* Notify TX thread to send if TX frame is blocked */
+		wake_up_interruptible
+				(&isp_ctx->composer_tx_thread.wq);
+	}
+
+	/* check ISP error status */
+	if (errstatus) {
+		dev_err(dev,
+			"raw_int_err:0x%x/0x%x, raw_int3_err:0x%x\n",
+			irqstatus, warnstatus, errstatus);
+
+		/* show DMA errors in detail */
+		if (errstatus & DMA_ERR_ST)
+			isp_dumpdmastat(isp_dev);
+	}
+
+	if (irqstatus & INT_ST_LOG_MASK_CAM)
+		dev_dbg(dev, IRQ_STAT_STR,
+			'A' + cardinalnum,
+			isp_dev->sof_count,
+			irqstatus,
+			dmastatus,
+			hw_frame_num,
+			cq_num);
+	return IRQ_HANDLED;
+}
+
+static int enable_sys_clock(struct isp_p1_device *p1_dev)
+{
+	struct device *dev = &p1_dev->pdev->dev;
+	int ret;
+
+	dev_info(dev, "- %s dev id:%d\n", __func__, dev->id);
+
+	ret = clk_bulk_prepare_enable(p1_dev->isp_clk.num_clks,
+				      p1_dev->isp_clk.clk_list);
+	if (ret < 0)
+		goto clk_err;
+	return 0;
+clk_err:
+	dev_err(dev, "cannot pre-en isp_cam clock:%d\n", ret);
+	clk_bulk_disable_unprepare(p1_dev->isp_clk.num_clks,
+				   p1_dev->isp_clk.clk_list);
+	return ret;
+}
+
+static void disable_sys_clock(struct isp_p1_device *p1_dev)
+{
+	struct device *dev = &p1_dev->pdev->dev;
+
+	dev_info(dev, "- %s dev id:%d\n", __func__, dev->id);
+	clk_bulk_disable_unprepare(p1_dev->isp_clk.num_clks,
+				   p1_dev->isp_clk.clk_list);
+}
+
+static int mtk_isp_probe(struct platform_device *pdev)
+{
+	struct isp_p1_device *p1_dev;
+	struct mtk_isp_p1_ctx *isp_ctx;
+	struct isp_device *isp_dev;
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	int ret;
+	unsigned int i;
+
+	/* Allocate context */
+	p1_dev = devm_kzalloc(dev, sizeof(*p1_dev), GFP_KERNEL);
+	if (!p1_dev)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, p1_dev);
+	isp_ctx = &p1_dev->isp_ctx;
+	p1_dev->pdev = pdev;
+
+	p1_dev->isp_devs =
+		devm_kzalloc(dev,
+			     sizeof(struct isp_device) * ISP_DEV_NODE_NUM,
+			     GFP_KERNEL);
+	if (!p1_dev->isp_devs)
+		return -ENOMEM;
+
+	p1_dev->cam_dev =
+		devm_kzalloc(dev, sizeof(struct mtk_cam_dev), GFP_KERNEL);
+	if (!p1_dev->isp_devs)
+		return -ENOMEM;
+
+	/* iomap registers */
+	for (i = ISP_CAMSYS_CONFIG_IDX; i < ISP_DEV_NODE_NUM; i++) {
+		isp_dev = &p1_dev->isp_devs[i];
+		isp_dev->isp_hw_module = i;
+		isp_dev->dev = dev;
+		res = platform_get_resource(pdev, IORESOURCE_MEM, i);
+		isp_dev->regs = devm_ioremap_resource(dev, res);
+
+		dev_info(dev, "cam%u, map_addr=0x%lx\n",
+			 i, (unsigned long)isp_dev->regs);
+
+		if (!isp_dev->regs)
+			return PTR_ERR(isp_dev->regs);
+
+		/* support IRQ from ISP_CAM_A_IDX */
+		if (i >= ISP_CAM_A_IDX) {
+			/* reg & interrupts index is shifted with 1  */
+			isp_dev->irq = platform_get_irq(pdev, i - 1);
+			if (isp_dev->irq > 0) {
+				ret = devm_request_irq(dev, isp_dev->irq,
+						       isp_irq_cam,
+						       IRQF_SHARED,
+						       dev_driver_string(dev),
+						       (void *)isp_dev);
+				if (ret) {
+					dev_err(dev,
+						"req_irq fail, dev(%s) irq=%d\n",
+						dev->of_node->name,
+						isp_dev->irq);
+					return ret;
+				}
+				dev_info(dev, "Registered irq=%d, ISR: %s\n",
+					 isp_dev->irq, dev_driver_string(dev));
+			}
+		}
+		spin_lock_init(&isp_dev->spinlock_irq);
+	}
+
+	p1_dev->isp_clk.num_clks = ARRAY_SIZE(mtk_isp_clks);
+	p1_dev->isp_clk.clk_list =
+		devm_kcalloc(dev,
+			     p1_dev->isp_clk.num_clks,
+			     sizeof(*p1_dev->isp_clk.clk_list),
+			     GFP_KERNEL);
+	if (!p1_dev->isp_clk.clk_list)
+		return -ENOMEM;
+
+	for (i = 0; i < p1_dev->isp_clk.num_clks; ++i)
+		p1_dev->isp_clk.clk_list->id = mtk_isp_clks[i];
+
+	ret = devm_clk_bulk_get(dev,
+				p1_dev->isp_clk.num_clks,
+				p1_dev->isp_clk.clk_list);
+	if (ret) {
+		dev_err(dev, "cannot get isp cam clock:%d\n", ret);
+		return ret;
+	}
+
+	/* initialize the v4l2 common part */
+	ret = mtk_cam_dev_core_init(pdev, p1_dev->cam_dev);
+	if (ret)
+		return ret;
+
+	spin_lock_init(&isp_ctx->p1_enqueue_list.lock);
+	atomic_set(&p1_dev->isp_ctx.isp_user_cnt, 0);
+	pm_runtime_enable(dev);
+
+	return 0;
+}
+
+static int mtk_isp_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct isp_p1_device *p1_dev = dev_get_drvdata(dev);
+
+	pm_runtime_disable(dev);
+	mtk_cam_dev_core_release(pdev, p1_dev->cam_dev);
+
+	return 0;
+}
+
+static int mtk_isp_suspend(struct device *dev)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct isp_device *isp_dev;
+	unsigned int reg_val;
+	int usercount, module;
+
+	module = p1_dev->isp_ctx.isp_hw_module;
+	usercount = atomic_read(&p1_dev->isp_ctx.isp_user_cnt);
+
+	dev_dbg(dev, "- %s:%d\n", __func__, usercount);
+
+	/* If no user count, no further action */
+	if (!usercount)
+		return 0;
+
+	isp_dev = &p1_dev->isp_devs[module];
+	reg_val = readl(isp_dev->regs + REG_TG_VF_CON);
+	if (reg_val & VFDATA_EN_BIT) {
+		dev_dbg(dev, "Cam:%d suspend, disable VF\n", module);
+		/* disable VF */
+		writel((reg_val & (~VFDATA_EN_BIT)),
+		       isp_dev->regs + REG_TG_VF_CON);
+		/*
+		 * After VF enable, The TG frame count will be reset to 0;
+		 */
+		reg_val = readl(isp_dev->regs + REG_TG_SEN_MODE);
+		writel((reg_val & (~CMOS_EN_BIT)),
+		       isp_dev->regs +  + REG_TG_SEN_MODE);
+	}
+
+	disable_sys_clock(p1_dev);
+
+	return 0;
+}
+
+static int mtk_isp_resume(struct device *dev)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct isp_device *isp_dev;
+	unsigned int reg_val;
+	int module, usercount;
+
+	module = p1_dev->isp_ctx.isp_hw_module;
+	usercount = atomic_read(&p1_dev->isp_ctx.isp_user_cnt);
+
+	dev_dbg(dev, "- %s:%d\n", __func__, usercount);
+
+	/* If no user count, no further action */
+	if (!usercount)
+		return 0;
+
+	enable_sys_clock(p1_dev);
+
+	/* V4L2 stream-on phase & restore HW stream-on status */
+	if (p1_dev->cam_dev->streaming) {
+		isp_dev = &p1_dev->isp_devs[module];
+		dev_dbg(dev, "Cam:%d resume,enable VF\n", module);
+		/* Enable CMOS */
+		reg_val = readl(isp_dev->regs + REG_TG_SEN_MODE);
+		writel((reg_val | CMOS_EN_BIT),
+		       isp_dev->regs + REG_TG_SEN_MODE);
+		/* Enable VF */
+		reg_val = readl(isp_dev->regs + REG_TG_VF_CON);
+		writel((reg_val | VFDATA_EN_BIT),
+		       isp_dev->regs + REG_TG_VF_CON);
+	}
+	return 0;
+}
+
+static int isp_init_context(struct isp_p1_device *p1_dev)
+{
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct device *dev = &p1_dev->pdev->dev;
+	unsigned int i;
+
+	dev_dbg(dev, "init irq work thread\n");
+	if (!isp_ctx->isp_deque_thread.thread) {
+		mutex_init(&isp_ctx->composer_tx_lock);
+		init_waitqueue_head(&isp_ctx->isp_deque_thread.wq);
+		isp_ctx->isp_deque_thread.thread =
+			kthread_run(isp_deque_work, (void *)p1_dev,
+				    "isp_deque_work");
+		if (IS_ERR(isp_ctx->isp_deque_thread.thread)) {
+			dev_err(dev, "unable to alloc kthread\n");
+			isp_ctx->isp_deque_thread.thread = NULL;
+			return -ENOMEM;
+		}
+	}
+	spin_lock_init(&isp_ctx->irq_dequeue_lock);
+
+	INIT_LIST_HEAD(&isp_ctx->p1_enqueue_list.queue);
+	atomic_set(&isp_ctx->p1_enqueue_list.queue_cnt, 0);
+
+	for (i = 0; i < ISP_DEV_NODE_NUM; i++)
+		spin_lock_init(&p1_dev->isp_devs[i].spinlock_irq);
+
+	spin_lock_init(&isp_ctx->p1_enqueue_list.lock);
+	spin_lock_init(&isp_ctx->composer_txlist.lock);
+
+	atomic_set(&isp_ctx->irq_data_end, 0);
+	atomic_set(&isp_ctx->irq_data_start, 0);
+	return 0;
+}
+
+static int isp_uninit_context(struct isp_p1_device *p1_dev)
+{
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct mtk_isp_queue_job *framejob, *tmp_framejob;
+
+	spin_lock_irq(&isp_ctx->p1_enqueue_list.lock);
+	list_for_each_entry_safe(framejob, tmp_framejob,
+				 &isp_ctx->p1_enqueue_list.queue, list_entry) {
+		list_del(&framejob->list_entry);
+		kfree(framejob);
+	}
+	spin_unlock_irq(&isp_ctx->p1_enqueue_list.lock);
+
+	atomic_set(&isp_ctx->isp_user_cnt, 0);
+
+	if (!IS_ERR(isp_ctx->isp_deque_thread.thread)) {
+		kthread_stop(isp_ctx->isp_deque_thread.thread);
+		wake_up_interruptible(&isp_ctx->isp_deque_thread.wq);
+		isp_ctx->isp_deque_thread.thread = NULL;
+	}
+
+	return 0;
+}
+
+/* Utility functions */
+static unsigned int get_sensor_pixel_id(unsigned int fmt)
+{
+	switch (fmt) {
+	case MEDIA_BUS_FMT_SBGGR8_1X8:
+	case MEDIA_BUS_FMT_SBGGR10_1X10:
+	case MEDIA_BUS_FMT_SBGGR12_1X12:
+	case MEDIA_BUS_FMT_SBGGR14_1X14:
+		return raw_pxl_id_b;
+	case MEDIA_BUS_FMT_SGBRG8_1X8:
+	case MEDIA_BUS_FMT_SGBRG10_1X10:
+	case MEDIA_BUS_FMT_SGBRG12_1X12:
+	case MEDIA_BUS_FMT_SGBRG14_1X14:
+		return raw_pxl_id_gb;
+	case MEDIA_BUS_FMT_SGRBG8_1X8:
+	case MEDIA_BUS_FMT_SGRBG10_1X10:
+	case MEDIA_BUS_FMT_SGRBG12_1X12:
+	case MEDIA_BUS_FMT_SGRBG14_1X14:
+		return raw_pxl_id_gr;
+	case MEDIA_BUS_FMT_SRGGB8_1X8:
+	case MEDIA_BUS_FMT_SRGGB10_1X10:
+	case MEDIA_BUS_FMT_SRGGB12_1X12:
+	case MEDIA_BUS_FMT_SRGGB14_1X14:
+		return raw_pxl_id_r;
+	default:
+		return raw_pxl_id_b;
+	}
+}
+
+static unsigned int get_sensor_fmt(unsigned int fmt)
+{
+	switch (fmt) {
+	case MEDIA_BUS_FMT_SBGGR8_1X8:
+	case MEDIA_BUS_FMT_SGBRG8_1X8:
+	case MEDIA_BUS_FMT_SGRBG8_1X8:
+	case MEDIA_BUS_FMT_SRGGB8_1X8:
+		return img_fmt_bayer8;
+	case MEDIA_BUS_FMT_SBGGR10_1X10:
+	case MEDIA_BUS_FMT_SGBRG10_1X10:
+	case MEDIA_BUS_FMT_SGRBG10_1X10:
+	case MEDIA_BUS_FMT_SRGGB10_1X10:
+		return img_fmt_bayer10;
+	case MEDIA_BUS_FMT_SBGGR12_1X12:
+	case MEDIA_BUS_FMT_SGBRG12_1X12:
+	case MEDIA_BUS_FMT_SGRBG12_1X12:
+	case MEDIA_BUS_FMT_SRGGB12_1X12:
+		return img_fmt_bayer12;
+	case MEDIA_BUS_FMT_SBGGR14_1X14:
+	case MEDIA_BUS_FMT_SGBRG14_1X14:
+	case MEDIA_BUS_FMT_SGRBG14_1X14:
+	case MEDIA_BUS_FMT_SRGGB14_1X14:
+		return img_fmt_bayer14;
+	default:
+		return img_fmt_unknown;
+	}
+}
+
+static unsigned int get_img_fmt(unsigned int fourcc)
+{
+	switch (fourcc) {
+	case V4L2_PIX_FMT_MTISP_B8:
+		return img_fmt_bayer8;
+	case V4L2_PIX_FMT_MTISP_F8:
+		return img_fmt_fg_bayer8;
+	case V4L2_PIX_FMT_MTISP_B10:
+		return img_fmt_bayer10;
+	case V4L2_PIX_FMT_MTISP_F10:
+		return img_fmt_fg_bayer10;
+	case V4L2_PIX_FMT_MTISP_B12:
+		return img_fmt_bayer12;
+	case V4L2_PIX_FMT_MTISP_F12:
+		return img_fmt_fg_bayer12;
+	case V4L2_PIX_FMT_MTISP_B14:
+		return img_fmt_bayer14;
+	case V4L2_PIX_FMT_MTISP_F14:
+		return img_fmt_fg_bayer14;
+	default:
+		return img_fmt_unknown;
+	}
+}
+
+static unsigned int get_pixel_byte(unsigned int fourcc)
+{
+	switch (fourcc) {
+	case V4L2_PIX_FMT_MTISP_B8:
+	case V4L2_PIX_FMT_MTISP_F8:
+		return 8;
+	case V4L2_PIX_FMT_MTISP_B10:
+	case V4L2_PIX_FMT_MTISP_F10:
+		return 10;
+	case V4L2_PIX_FMT_MTISP_B12:
+	case V4L2_PIX_FMT_MTISP_F12:
+		return 12;
+	case V4L2_PIX_FMT_MTISP_B14:
+	case V4L2_PIX_FMT_MTISP_F14:
+		return 14;
+	case V4L2_PIX_FMT_MTISP_U8:
+	case V4L2_PIX_FMT_MTISP_U10:
+	case V4L2_PIX_FMT_MTISP_U12:
+	case V4L2_PIX_FMT_MTISP_U14:
+		return 16;
+	default:
+		return 10;
+	}
+}
+
+static void composer_deinit_done_cb(void *data)
+{
+	struct isp_p1_device *p1_dev = p1_ctx_to_dev(data);
+
+	disable_sys_clock(p1_dev);
+	/* Notify PM */
+	pm_runtime_put_sync(&p1_dev->pdev->dev);
+}
+
+/* ISP P1 interface functions */
+int mtk_isp_open(struct device *dev)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	s32 usercount = atomic_inc_return(&isp_ctx->isp_user_cnt);
+	phandle rproc_phandle;
+	int ret;
+
+	dev_dbg(dev, "%s usercount=%d\n", __func__, usercount);
+
+	if (usercount == 1) {
+		p1_dev->scp_pdev = scp_get_pdev(p1_dev->pdev);
+		if (!p1_dev->scp_pdev) {
+			dev_err(dev, "Failed to get scp device\n");
+			return -EINVAL;
+		}
+		ret = of_property_read_u32(dev->of_node, "mediatek,scp",
+					   &rproc_phandle);
+		if (ret) {
+			dev_err(dev, "fail to get rproc_phandle:%d\n", ret);
+			return ret;
+		}
+
+		p1_dev->rproc_handle = rproc_get_by_phandle(rproc_phandle);
+		dev_dbg(dev, "p1 rproc_phandle: 0x%pK\n\n",
+			p1_dev->rproc_handle);
+		if (!p1_dev->rproc_handle) {
+			dev_err(dev, "fail to get rproc_handle\n");
+			return -EINVAL;
+		}
+
+		ret = rproc_boot(p1_dev->rproc_handle);
+		if (ret < 0) {
+			/*
+			 * Return 0 if downloading firmware successfully,
+			 * otherwise it is failed
+			 */
+			dev_err(dev, "rproc_boot failed:%d\n", ret);
+			return -EINVAL;
+		}
+
+		pm_runtime_get_sync(dev);
+
+		/* ISP HW INIT */
+		isp_ctx->isp_hw_module = ISP_CAM_B_IDX;
+		/* Use pure RAW as default HW path */
+		isp_ctx->isp_raw_path = ISP_PURE_RAW_PATH;
+
+		ret = isp_init_context(p1_dev);
+		if (ret)
+			return ret;
+		ret = isp_composer_init(isp_ctx);
+		if (ret)
+			return ret;
+		ret = isp_composer_hw_init(isp_ctx);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+int mtk_isp_release(struct device *dev)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+
+	if (atomic_dec_and_test(&p1_dev->isp_ctx.isp_user_cnt)) {
+		isp_composer_hw_deinit(isp_ctx, composer_deinit_done_cb);
+		isp_uninit_context(p1_dev);
+	}
+
+	dev_dbg(dev, "%s usercount = %d\n", __func__,
+		atomic_read(&p1_dev->isp_ctx.isp_user_cnt));
+
+	return 0;
+}
+
+int mtk_isp_streamon(struct device *dev)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct p1_config_param config_param;
+	struct mtk_cam_dev *cam_dev = p1_dev->cam_dev;
+	struct v4l2_subdev_format sd_format;
+	unsigned int sd_width, sd_height;
+	unsigned int enable_dma, idx, i;
+	int ret;
+
+	p1_dev->isp_devs[isp_ctx->isp_hw_module].current_frame = 0;
+	p1_dev->isp_devs[isp_ctx->isp_hw_module].sof_count = 0;
+
+	isp_ctx->frame_seq_no = 1;
+	atomic_set(&isp_ctx->composed_frame_id, 0);
+
+	/* Get the enabled DMA ports */
+	enable_dma = 0;
+	for (i = 0; i < cam_dev->dev_node_num; i++) {
+		if (cam_dev->mem2mem2_nodes[i].enabled)
+			enable_dma |=
+				cam_dev->mem2mem2_nodes[i].desc.dma_port;
+	}
+	dev_dbg(dev, "%s enable_dma:0x%x", __func__, enable_dma);
+
+	/* sensor config */
+	sd_format.which = V4L2_SUBDEV_FORMAT_ACTIVE;
+	ret = v4l2_subdev_call(cam_dev->sensor,
+			       pad, get_fmt, NULL, &sd_format);
+
+	if (ret) {
+		dev_dbg(dev, "sensor(%s) g_fmt on failed(%d)\n",
+			cam_dev->sensor->entity.name, ret);
+		return -EPERM;
+	}
+
+	dev_dbg(dev,
+		"sensor get_fmt ret=%d, w=%d, h=%d, code=0x%x, field=%d, color=%d\n",
+		ret, sd_format.format.width, sd_format.format.height,
+		sd_format.format.code, sd_format.format.field,
+		sd_format.format.colorspace);
+
+	config_param.cfg_in_param.continuous = 0x1;
+	config_param.cfg_in_param.subsample = 0x0;
+	/* fix to one pixel mode in default */
+	config_param.cfg_in_param.pixel_mode = one_pixel_mode;
+	/* support normal pattern in default */
+	config_param.cfg_in_param.data_pattern = 0x0;
+
+	config_param.cfg_in_param.crop.left = 0x0;
+	config_param.cfg_in_param.crop.top = 0x0;
+
+	config_param.cfg_in_param.raw_pixel_id =
+		get_sensor_pixel_id(sd_format.format.code);
+	config_param.cfg_in_param.img_fmt =
+		get_sensor_fmt(sd_format.format.code);
+	config_param.cfg_in_param.crop.width = sd_format.format.width;
+	config_param.cfg_in_param.crop.height = sd_format.format.height;
+	sd_width = sd_format.format.width;
+	sd_height = sd_format.format.height;
+
+	idx = MTK_CAM_P1_MAIN_STREAM_OUT;
+	if ((enable_dma & R_IMGO) == R_IMGO) {
+		struct v4l2_format *imgo_fmt =
+			&p1_dev->cam_dev->mem2mem2_nodes[idx].vdev_fmt;
+
+		config_param.cfg_main_param.pure_raw = isp_ctx->isp_raw_path;
+		config_param.cfg_main_param.pure_raw_pack = 1;
+		config_param.cfg_main_param.bypass = 0;
+
+		config_param.cfg_main_param.output.img_fmt =
+			get_img_fmt(imgo_fmt->fmt.pix_mp.pixelformat);
+		config_param.cfg_main_param.output.pixel_byte =
+			get_pixel_byte(imgo_fmt->fmt.pix_mp.pixelformat);
+		config_param.cfg_main_param.output.size.w =
+			imgo_fmt->fmt.pix_mp.width;
+		config_param.cfg_main_param.output.size.h =
+			imgo_fmt->fmt.pix_mp.height;
+
+		config_param.cfg_main_param.output.size.stride =
+			imgo_fmt->fmt.pix_mp.plane_fmt[0].bytesperline;
+		config_param.cfg_main_param.output.size.xsize =
+			imgo_fmt->fmt.pix_mp.plane_fmt[0].bytesperline;
+
+		config_param.cfg_main_param.output.crop.left = 0x0;
+		config_param.cfg_main_param.output.crop.top = 0x0;
+
+		config_param.cfg_main_param.output.crop.width = sd_width;
+		config_param.cfg_main_param.output.crop.height = sd_height;
+
+		WARN_ONCE(imgo_fmt->fmt.pix_mp.width > sd_width ||
+			  imgo_fmt->fmt.pix_mp.height > sd_height,
+			  "img out:%d:%d in:%d:%d",
+			  imgo_fmt->fmt.pix_mp.width,
+			  imgo_fmt->fmt.pix_mp.height,
+			  sd_width,
+			  sd_height);
+
+		dev_dbg(dev,
+			"imgo pixel_byte:%d img_fmt:0x%x raw:%d\n",
+			config_param.cfg_main_param.output.pixel_byte,
+			config_param.cfg_main_param.output.img_fmt,
+			config_param.cfg_main_param.pure_raw);
+		dev_dbg(dev,
+			"imgo param:size=(%0dx%0d),stride:%d,xsize:%d,crop=(%0dx%0d)\n",
+			config_param.cfg_main_param.output.size.w,
+			config_param.cfg_main_param.output.size.h,
+			config_param.cfg_main_param.output.size.stride,
+			config_param.cfg_main_param.output.size.xsize,
+			config_param.cfg_main_param.output.crop.width,
+			config_param.cfg_main_param.output.crop.height);
+	} else {
+		config_param.cfg_main_param.bypass = 1;
+	}
+
+	idx = MTK_CAM_P1_PACKED_BIN_OUT;
+	if ((enable_dma & R_RRZO) == R_RRZO) {
+		struct v4l2_format *rrzo_fmt =
+			&p1_dev->cam_dev->mem2mem2_nodes[idx].vdev_fmt;
+
+		config_param.cfg_resize_param.bypass = 0;
+		config_param.cfg_resize_param.output.img_fmt =
+			get_img_fmt(rrzo_fmt->fmt.pix_mp.pixelformat);
+		config_param.cfg_resize_param.output.pixel_byte =
+			get_pixel_byte(rrzo_fmt->fmt.pix_mp.pixelformat);
+		config_param.cfg_resize_param.output.size.w =
+			rrzo_fmt->fmt.pix_mp.width;
+		config_param.cfg_resize_param.output.size.h =
+			rrzo_fmt->fmt.pix_mp.height;
+		config_param.cfg_resize_param.output.size.stride =
+			rrzo_fmt->fmt.pix_mp.plane_fmt[0].bytesperline;
+		config_param.cfg_resize_param.output.size.xsize =
+			rrzo_fmt->fmt.pix_mp.plane_fmt[0].bytesperline;
+
+		config_param.cfg_resize_param.output.crop.left = 0x0;
+		config_param.cfg_resize_param.output.crop.top = 0x0;
+		config_param.cfg_resize_param.output.crop.width = sd_width;
+		config_param.cfg_resize_param.output.crop.height = sd_height;
+
+		WARN_ONCE(rrzo_fmt->fmt.pix_mp.width > sd_width ||
+			  rrzo_fmt->fmt.pix_mp.height > sd_height,
+			  "rrz out:%d:%d in:%d:%d",
+			  rrzo_fmt->fmt.pix_mp.width,
+			  rrzo_fmt->fmt.pix_mp.height,
+			  sd_width,
+			  sd_height);
+
+		dev_dbg(dev, "rrzo pixel_byte:%d img_fmt:0x%x\n",
+			config_param.cfg_resize_param.output.pixel_byte,
+			config_param.cfg_resize_param.output.img_fmt);
+		dev_dbg(dev,
+			"rrzo param:size=(%0dx%0d),stride:%d,xsize:%d,crop=(%0dx%0d)\n",
+			config_param.cfg_resize_param.output.size.w,
+			config_param.cfg_resize_param.output.size.h,
+			config_param.cfg_resize_param.output.size.stride,
+			config_param.cfg_resize_param.output.size.xsize,
+			config_param.cfg_resize_param.output.crop.width,
+			config_param.cfg_resize_param.output.crop.height);
+	} else {
+		config_param.cfg_resize_param.bypass = 1;
+	}
+
+	/* Configure meta DMAs info. */
+	config_param.cfg_meta_param.enabled_meta_dmas = enable_dma;
+
+	isp_composer_hw_config(isp_ctx, &config_param);
+
+	/* Stream on */
+	isp_composer_stream(isp_ctx, 1);
+	dev_dbg(dev, "%s done\n", __func__);
+	return 0;
+}
+
+int mtk_isp_streamoff(struct device *dev)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+
+	isp_composer_stream(isp_ctx, 0);
+	dev_dbg(dev, "%s done\n", __func__);
+
+	return 0;
+}
+
+int mtk_isp_enqueue(struct device *dev,
+		    struct mtk_cam_dev_start_param *frameparamsbase)
+{
+	struct isp_p1_device *p1_dev = get_p1_device(dev);
+	struct mtk_isp_p1_ctx *isp_ctx = &p1_dev->isp_ctx;
+	struct p1_frame_param frameparams;
+	struct mtk_isp_queue_job *framejob;
+	struct mtk_cam_dev_buffer **bundle_buffers;
+	unsigned int i, idx;
+
+	framejob = kzalloc(sizeof(*framejob), GFP_ATOMIC);
+	memset(framejob, 0, sizeof(*framejob));
+	memset(&frameparams, 0, sizeof(frameparams));
+	INIT_LIST_HEAD(&framejob->list_buf);
+
+	bundle_buffers = &frameparamsbase->buffers[0];
+	frameparams.frame_seq_no = isp_ctx->frame_seq_no++;
+	frameparams.sof_idx =
+		p1_dev->isp_devs[isp_ctx->isp_hw_module].sof_count;
+	framejob->request_fd = frameparamsbase->request_fd;
+	framejob->frame_seq_no = frameparams.frame_seq_no;
+
+	idx = MTK_CAM_P1_META_IN_0;
+	if (bundle_buffers[idx]) {
+		frameparams.tuning_addr.iova =
+			bundle_buffers[idx]->daddr;
+		frameparams.tuning_addr.scp_addr =
+			bundle_buffers[idx]->scp_addr;
+		list_add_tail(&bundle_buffers[idx]->list,
+			      &framejob->list_buf);
+	}
+
+	/* Image output */
+	idx = MTK_CAM_P1_MAIN_STREAM_OUT;
+	if (bundle_buffers[idx]) {
+		frameparams.img_dma_buffers[0].buffer.iova =
+			bundle_buffers[idx]->daddr;
+		frameparams.img_dma_buffers[0].buffer.scp_addr =
+			bundle_buffers[idx]->scp_addr;
+		dev_dbg(dev, "main stream address pa:0x%x iova:0x%x\n",
+			frameparams.img_dma_buffers[0].buffer.scp_addr,
+			frameparams.img_dma_buffers[0].buffer.iova);
+		list_add_tail(&bundle_buffers[idx]->list,
+			      &framejob->list_buf);
+	}
+
+	/* Resize output */
+	idx = MTK_CAM_P1_PACKED_BIN_OUT;
+	if (bundle_buffers[idx]) {
+		frameparams.img_dma_buffers[1].buffer.iova =
+			bundle_buffers[idx]->daddr;
+		frameparams.img_dma_buffers[1].buffer.scp_addr =
+			bundle_buffers[idx]->scp_addr;
+		dev_dbg(dev, "packed out address:0x%x iova:0x%x\n",
+			frameparams.img_dma_buffers[1].buffer.scp_addr,
+			frameparams.img_dma_buffers[1].buffer.iova);
+		list_add_tail(&bundle_buffers[idx]->list,
+			      &framejob->list_buf);
+	}
+
+	/* Meta output DMAs */
+	for (i = 0; i < MAX_META_DMA_NODES; i++) {
+		idx = MTK_CAM_P1_META_OUT_0 + i;
+		if (bundle_buffers[idx]) {
+			frameparams.meta_addrs[i].iova =
+			  bundle_buffers[idx]->daddr;
+			frameparams.meta_addrs[i].scp_addr =
+			  bundle_buffers[idx]->scp_addr;
+			list_add_tail(&bundle_buffers[idx]->list,
+				      &framejob->list_buf);
+		} else {
+			frameparams.meta_addrs[i].iova = 0;
+			frameparams.meta_addrs[i].scp_addr = 0;
+		}
+	}
+
+	spin_lock(&isp_ctx->p1_enqueue_list.lock);
+	list_add_tail(&framejob->list_entry, &isp_ctx->p1_enqueue_list.queue);
+	atomic_inc(&isp_ctx->p1_enqueue_list.queue_cnt);
+	spin_unlock(&isp_ctx->p1_enqueue_list.lock);
+
+	isp_composer_enqueue(isp_ctx, &frameparams, SCP_ISP_FRAME);
+	dev_dbg(dev, "request fd(0x%x) frame_seq_no(%d) is queued cnt:(%d)\n",
+		frameparamsbase->request_fd,
+		frameparams.frame_seq_no,
+		atomic_read(&isp_ctx->p1_enqueue_list.queue_cnt));
+
+	return 0;
+}
+
+static const struct dev_pm_ops mtk_isp_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(mtk_isp_suspend, mtk_isp_resume)
+	SET_RUNTIME_PM_OPS(mtk_isp_suspend, mtk_isp_resume, NULL)
+};
+
+static struct platform_driver mtk_isp_driver = {
+	.probe   = mtk_isp_probe,
+	.remove  = mtk_isp_remove,
+	.driver  = {
+		.name  = ISP_DEV_NAME,
+		.of_match_table = mtk_isp_of_ids,
+		.pm     = &mtk_isp_pm_ops,
+	}
+};
+
+module_platform_driver(mtk_isp_driver);
+
+MODULE_DESCRIPTION("Camera ISP driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.h b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.h
new file mode 100644
index 000000000000..6d1305826a5a
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/cam/mtk_cam.h
@@ -0,0 +1,288 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ryan Yu <ryan.yu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __CAMERA_ISP_H
+#define __CAMERA_ISP_H
+
+#include <linux/cdev.h>
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include <linux/ioctl.h>
+#include <linux/irqreturn.h>
+#include <linux/miscdevice.h>
+#include <linux/pm_qos.h>
+#include <linux/scatterlist.h>
+
+#include "mtk_cam-dev.h"
+#include "mtk_cam-ctx.h"
+#include "mtk_cam-scp.h"
+
+#define ISP_DEV_NAME		"mtk-cam"
+
+#define CAM_A_MAX_WIDTH		3328U
+#define CAM_A_MAX_HEIGHT	2496U
+#define CAM_B_MAX_WIDTH		5376U
+#define CAM_B_MAX_HEIGHT	4032U
+
+#define CAM_MIN_WIDTH		80U
+#define CAM_MIN_HEIGHT		60U
+
+#define IMG_MAX_WIDTH		CAM_B_MAX_WIDTH
+#define IMG_MAX_HEIGHT		CAM_B_MAX_HEIGHT
+#define IMG_MIN_WIDTH		CAM_MIN_WIDTH
+#define IMG_MIN_HEIGHT		CAM_MIN_HEIGHT
+
+#define RRZ_MAX_WIDTH		CAM_B_MAX_WIDTH
+#define RRZ_MAX_HEIGHT		CAM_B_MAX_HEIGHT
+#define RRZ_MIN_WIDTH		CAM_MIN_WIDTH
+#define RRZ_MIN_HEIGHT		CAM_MIN_HEIGHT
+
+#define R_IMGO		BIT(0)
+#define R_RRZO		BIT(1)
+#define R_AAO		BIT(3)
+#define R_AFO		BIT(4)
+#define R_LCSO		BIT(5)
+#define R_PDO		BIT(6)
+#define R_LMVO		BIT(7)
+#define R_FLKO		BIT(8)
+#define R_RSSO		BIT(9)
+#define R_PSO		BIT(10)
+
+#define ISP_COMPOSING_MAX_NUM		4
+#define ISP_FRAME_COMPOSING_MAX_NUM	3
+
+#define IRQ_DATA_BUF_SIZE		4
+#define COMPOSRE_EVENT_BUF_SIZE		4
+
+#define CQ_ADDRESS_OFFSET		0x640
+#define CQ_BUFFER_COUNT			3
+
+#define IRQ_STAT_STR "cam%c, SOF_%d irq(0x%x), " \
+			"dma(0x%x), frame_num(%d)/cq_num(%d)\n"
+
+/*
+ * In order with the sequence of device nodes defined in dtsi rule,
+ * one hardware module should be mapping to one node.
+ */
+enum isp_dev_node_enum {
+	ISP_CAMSYS_CONFIG_IDX = 0,
+	ISP_CAM_UNI_IDX,
+	ISP_CAM_A_IDX,
+	ISP_CAM_B_IDX,
+	ISP_DEV_NODE_NUM
+};
+
+/* Image RAW path for ISP P1 module. */
+enum isp_raw_path_enum {
+	ISP_PROCESS_RAW_PATH = 0,
+	ISP_PURE_RAW_PATH
+};
+
+enum {
+	img_fmt_unknown		= 0x0000,
+	img_fmt_raw_start	= 0x2200,
+	img_fmt_bayer8		= img_fmt_raw_start,
+	img_fmt_bayer10,
+	img_fmt_bayer12,
+	img_fmt_bayer14,
+	img_fmt_fg_bayer8,
+	img_fmt_fg_bayer10,
+	img_fmt_fg_bayer12,
+	img_fmt_fg_bayer14,
+};
+
+enum {
+	raw_pxl_id_b   = 0,
+	raw_pxl_id_gb,
+	raw_pxl_id_gr,
+	raw_pxl_id_r
+};
+
+enum {
+	default_pixel_mode = 0,
+	one_pixel_mode,
+	two_pixel_mode,
+	four_pixel_mode,
+	pixel_mode_num,
+};
+
+struct isp_queue {
+	struct list_head queue;
+	atomic_t queue_cnt;
+	spinlock_t lock; /* queue attributes protection */
+};
+
+struct isp_thread {
+	struct task_struct *thread;
+	wait_queue_head_t wq;
+};
+
+enum mtk_isp_scp_ipi_type {
+	SCP_ISP_CMD = 0,
+	SCP_ISP_FRAME,
+};
+
+struct mtk_isp_queue_work {
+	union {
+		struct mtk_isp_scp_p1_cmd cmd;
+		struct p1_frame_param frameparams;
+	};
+	struct list_head list_entry;
+	enum mtk_isp_scp_ipi_type type;
+};
+
+struct mtk_isp_queue_job {
+	struct list_head list_entry;
+	struct list_head list_buf;
+	unsigned int request_fd;
+	unsigned int frame_seq_no;
+};
+
+struct isp_clk_struct {
+	int num_clks;
+	struct clk_bulk_data *clk_list;
+};
+
+struct isp_device {
+	struct device *dev;
+	void __iomem *regs;
+	int irq;
+	spinlock_t spinlock_irq; /* ISP reg setting integrity */
+	unsigned int current_frame;
+	u8 sof_count;
+	u8 isp_hw_module;
+};
+
+struct mtk_isp_p1_ctx {
+	atomic_t scp_state;
+	struct isp_queue composer_txlist;
+	struct isp_thread composer_tx_thread;
+	atomic_t cmd_queued;
+	struct mutex composer_tx_lock; /* isp composer work protection */
+
+	struct isp_thread composer_rx_thread;
+	struct mtk_isp_scp_p1_cmd composer_evts[COMPOSRE_EVENT_BUF_SIZE];
+	atomic_t composer_evts_start;
+	atomic_t composer_evts_end;
+	spinlock_t composer_evts_lock; /* SCP events protection */
+	/* increase after ipi */
+	atomic_t ipi_occupied;
+	/* increase after frame enqueue */
+	atomic_t composing_frame;
+	/* current composed frame id */
+	atomic_t composed_frame_id;
+
+	struct isp_queue p1_enqueue_list;
+
+	struct isp_thread isp_deque_thread;
+	struct mtk_cam_dev_stat_event_data irq_event_datas[IRQ_DATA_BUF_SIZE];
+	atomic_t irq_data_start;
+	atomic_t irq_data_end;
+	spinlock_t irq_dequeue_lock; /* ISP frame dequeuq protection */
+
+	dma_addr_t scp_mem_pa;
+	dma_addr_t scp_mem_iova;
+	struct sg_table sgtable;
+
+	/* increase after open, decrease when close */
+	atomic_t isp_user_cnt;
+	/* frame sequence number, increase per en-queue*/
+	int frame_seq_no;
+	unsigned int isp_hw_module;
+	unsigned int isp_raw_path;
+
+	void (*composer_deinit_donecb)(void *isp_ctx);
+
+	struct list_head list;
+};
+
+struct isp_p1_device {
+	struct platform_device *pdev;
+
+	/* for SCP driver  */
+	struct platform_device *scp_pdev;
+	struct rproc *rproc_handle;
+
+	struct mtk_isp_p1_ctx isp_ctx;
+	struct isp_clk_struct isp_clk;
+	struct mtk_cam_dev *cam_dev;
+	struct isp_device *isp_devs;
+};
+
+static inline struct isp_p1_device *
+p1_ctx_to_dev(const struct mtk_isp_p1_ctx *__p1_ctx)
+{
+	return container_of(__p1_ctx, struct isp_p1_device, isp_ctx);
+}
+
+static inline struct isp_p1_device *get_p1_device(struct device *dev)
+{
+	return ((struct isp_p1_device *)dev_get_drvdata(dev));
+}
+
+int isp_composer_init(struct mtk_isp_p1_ctx *isp_ctx);
+int isp_composer_hw_init(struct mtk_isp_p1_ctx *isp_ctx);
+void isp_composer_hw_config(struct mtk_isp_p1_ctx *isp_ctx,
+			    struct p1_config_param *config_param);
+void isp_composer_stream(struct mtk_isp_p1_ctx *isp_ctx, int on);
+void isp_composer_hw_deinit(struct mtk_isp_p1_ctx *isp_ctx,
+			    void (*donecb)(void *data));
+void isp_composer_enqueue(struct mtk_isp_p1_ctx *isp_ctx,
+			  void *data,
+			  enum mtk_isp_scp_ipi_type type);
+
+/**
+ * mtk_isp_open - open isp driver and initialize related resources.
+ *
+ * @dev:	isp device.
+ *
+ */
+int mtk_isp_open(struct device *dev);
+
+/**
+ * mtk_isp_release - release isp driver and related resources.
+ *
+ * @dev:	isp device.
+ *
+ */
+int mtk_isp_release(struct device *dev);
+
+/**
+ * mtk_isp_streamon - start to output image & meta data.
+ *
+ * @dev:	isp device.
+ *
+ */
+int mtk_isp_streamon(struct device *dev);
+
+/**
+ * mtk_isp_streamoff -  stop to output image & meta data.
+ *
+ * @dev:	isp device.
+ *
+ */
+int mtk_isp_streamoff(struct device *dev);
+
+/**
+ * mtk_isp_enqueue - enqueue a frame bundle to ISP driver.
+ *
+ * @dev:	isp device.
+ * @frameparamsbase: pointer to &struct mtk_cam_dev_start_param.
+ *
+ */
+int mtk_isp_enqueue(struct device *dev,
+		    struct mtk_cam_dev_start_param *frameparamsbase);
+
+#endif /*__CAMERA_ISP_H*/
diff --git a/drivers/media/platform/mtk-isp/isp_50/camSV/Makefile b/drivers/media/platform/mtk-isp/isp_50/camSV/Makefile
new file mode 100644
index 000000000000..59b8a89496dd
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/camSV/Makefile
@@ -0,0 +1,15 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+
+obj-y += camerasv_isp.o
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/camSV/camerasv_isp.c b/drivers/media/platform/mtk-isp/isp_50/camSV/camerasv_isp.c
new file mode 100644
index 000000000000..9020f725d3be
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/camSV/camerasv_isp.c
@@ -0,0 +1,6613 @@
+/*
+ * Copyright (C) 2016 MediaTek Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See http://www.gnu.org/licenses/gpl-2.0.html for more details.
+ */
+
+/******************************************************************************
+ * camerasv_isp.c - Mediatek Linux ISP Device Driver
+ *
+ * DESCRIPTION:
+ *     This file provid the other drivers ISP relative functions
+ *
+ ******************************************************************************/
+#include <linux/types.h>
+#include <linux/device.h>
+#include <linux/cdev.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/proc_fs.h>  /* proc file use */
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/uaccess.h>
+#include <linux/atomic.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/of_platform.h>
+#include <linux/of_irq.h>
+#include <linux/of_address.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/printk.h> /*for kernel log reduction*/
+#include <linux/pm_runtime.h>
+#include <media/v4l2-ctrls.h>
+#include <media/v4l2-device.h>
+#include <media/v4l2-event.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf2-dma-sg.h>
+#include <media/videobuf2-vmalloc.h>
+#include <linux/sched/clock.h> //cpu_clock()
+#include <linux/ktime.h>
+
+int camsv_debug;
+EXPORT_SYMBOL_GPL(camsv_debug);
+module_param_named(debug, camsv_debug, int, 0644);
+
+#define dprintk(level, fmt, arg...)					      \
+	do {								      \
+		if (camsv_debug >= level)					      \
+			pr_info("camsv: %s: " fmt, __func__, ## arg); \
+	} while (0)
+
+//for compatible cam modules
+#define CAMSV_V4L2
+
+#ifdef CONFIG_COMPAT
+/* 64 bit */
+#include <linux/fs.h>
+#include <linux/compat.h>
+#endif
+
+#ifdef CONFIG_PM_WAKELOCKS
+#include <linux/pm_wakeup.h>
+#else
+#include <linux/wakelock.h>
+#endif
+
+#ifdef CONFIG_OF
+#include <linux/of_platform.h>  /* for device tree */
+#include <linux/of_irq.h>       /* for device tree */
+#include <linux/of_address.h>   /* for device tree */
+#endif
+
+#include "inc/camerasv_isp.h"
+#include "inc/cam_regs.h"
+
+/*  */
+#ifndef MTRUE
+#define MTRUE               1
+#endif
+#ifndef MFALSE
+#define MFALSE              0
+#endif
+
+#define ISP_DEV_NAME                "camerasv-isp"
+#define SMI_LARB_MMU_CTL            (1)
+/*#define ENABLE_WAITIRQ_LOG*/ /* wait irq debug logs */
+/*#define ENABLE_STT_IRQ_LOG*/  /*show STT irq debug logs */
+
+/* Queue timestamp for deque. Update when non-drop frame @SOF */
+#define TIMESTAMP_QUEUE_EN          (0)
+#if (TIMESTAMP_QUEUE_EN == 1)
+#define TSTMP_SUBSAMPLE_INTPL		(1)
+#else
+#define TSTMP_SUBSAMPLE_INTPL		(0)
+#endif
+#define ISP_BOTTOMHALF_WORKQ		(0)
+
+#if (ISP_BOTTOMHALF_WORKQ == 1)
+#include <linux/workqueue.h>
+#endif
+
+static int ISP_WaitIrq(struct ISP_WAIT_IRQ_STRUCT *WaitIrq);
+
+/* ---------------------------------------------------------------------------- */
+
+#define MyTag "[ISP]"
+#define IRQTag "KEEPER"
+
+#define LOG_VRB(format, args...)    pr_debug(MyTag "[%s] " format, __func__, ##args)
+
+#define ISP_DEBUG
+#ifdef ISP_DEBUG
+#define LOG_DBG(format, args...)    pr_info(MyTag "[%s] " format, __func__, ##args)
+#else
+#define LOG_DBG(format, args...)
+#endif
+
+#define LOG_INF(format, args...)       pr_info(MyTag "[%s] " format, __func__, ##args)
+#define LOG_NOTICE(format, args...)    pr_notice(MyTag "[%s] " format, __func__, ##args)
+#define LOG_WRN(format, args...)    pr_warn(MyTag "[%s] " format, __func__, ##args)
+#define LOG_ERR(format, args...)    pr_err(MyTag "[%s] " format, __func__, ##args)
+
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+#define mt_reg_sync_writel(v, a) \
+		do {	\
+			__raw_writel((v), (void __force __iomem *)((a)));	\
+			/* add memory barrier */ \
+			mb();  \
+		} while (0)
+
+#define ISP_WR32(addr, data)    mt_reg_sync_writel(data, addr)  /* For 89     Only.*/   /* NEED_TUNING_BY_PROJECT */
+#define ISP_RD32(addr)                  ioread32((void *)addr)
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+/* dynamic log level */
+#define ISP_DBG_INT                 (0x00000001)
+#define ISP_DBG_READ_REG            (0x00000004)
+#define ISP_DBG_WRITE_REG           (0x00000008)
+#define ISP_DBG_CLK                 (0x00000010)
+#define ISP_DBG_TASKLET             (0x00000020)
+#define ISP_DBG_SCHEDULE_WORK       (0x00000040)
+#define ISP_DBG_BUF_WRITE           (0x00000080)
+#define ISP_DBG_BUF_CTRL            (0x00000100)
+#define ISP_DBG_REF_CNT_CTRL        (0x00000200)
+#define ISP_DBG_INT_2               (0x00000400)
+#define ISP_DBG_INT_3               (0x00000800)
+#define ISP_DBG_HW_DON              (0x00001000)
+#define ISP_DBG_ION_CTRL            (0x00002000)
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static irqreturn_t ISP_CAMSV_Irq_CAMSV(enum ISP_CAMSV_IRQ_TYPE_ENUM irq_module,
+	enum ISP_CAMSV_DEV_NODE_ENUM cam_idx, const char *str, void *DeviceId);
+static irqreturn_t ISP_CAMSV_Irq_CAMSV_0(int  Irq, void *DeviceId);
+static irqreturn_t ISP_CAMSV_Irq_CAMSV_1(int  Irq, void *DeviceId);
+static irqreturn_t ISP_CAMSV_Irq_CAMSV_2(int  Irq, void *DeviceId);
+static irqreturn_t ISP_CAMSV_Irq_CAMSV_3(int  Irq, void *DeviceId);
+static irqreturn_t ISP_CAMSV_Irq_CAMSV_4(int  Irq, void *DeviceId);
+static irqreturn_t ISP_CAMSV_Irq_CAMSV_5(int  Irq, void *DeviceId);
+
+
+typedef irqreturn_t (*IRQ_CB)(int, void *);
+
+struct ISR_TABLE {
+	IRQ_CB          isr_fp;
+	unsigned int    int_number;
+	char            device_name[16];
+};
+
+#ifndef CONFIG_OF
+static const struct ISR_TABLE IRQ_CAMSV_CB_TBL[ISP_IRQ_TYPE_AMOUNT] = {
+	{ISP_Irq_CAM_A,     CAM0_IRQ_BIT_ID,    "CAM_A"},
+	{NULL,                            0,    "CAM_B"},
+	{ISP_Irq_CAMSV_0,   CAM_SV0_IRQ_BIT_ID, "CAMSV_0"},
+	{ISP_Irq_CAMSV_1,   CAM_SV1_IRQ_BIT_ID, "CAMSV_1"},
+	{NULL,                               0,     "UNI"}
+};
+
+#else
+/* int number is got from kernel api */
+
+static const struct ISR_TABLE IRQ_CAMSV_CB_TBL[ISP_IRQ_TYPE_AMOUNT] = {
+	{ISP_CAMSV_Irq_CAMSV_0,   0,  "camsv1"},
+	{ISP_CAMSV_Irq_CAMSV_1,   0,  "camsv2"},
+	{ISP_CAMSV_Irq_CAMSV_2,   0,  "camsv3"},
+	{ISP_CAMSV_Irq_CAMSV_3,   0,  "camsv4"},
+	{ISP_CAMSV_Irq_CAMSV_4,   0,  "camsv5"},
+	{ISP_CAMSV_Irq_CAMSV_5,   0,  "camsv6"},
+};
+
+/*
+ * Note!!! The order and member of .compatible must be the same with that in
+ *  "ISP_DEV_NODE_ENUM" in camera_isp.h
+ */
+static const struct of_device_id isp_camsv_of_ids[] = {
+	{ .compatible = "mediatek,mt8183-camsv", },
+	{ .compatible = "mediatek,camsv1", },
+	{ .compatible = "mediatek,camsv2", },
+	{ .compatible = "mediatek,camsv3", },
+	{ .compatible = "mediatek,camsv4", },
+	{ .compatible = "mediatek,camsv5", },
+	{ .compatible = "mediatek,camsv6", },
+	{}
+};
+
+#endif
+/* //////////////////////////////////////////////////////////////////////////////////////////// */
+/*  */
+typedef void (*tasklet_cb)(unsigned long);
+struct Tasklet_table {
+	tasklet_cb tkt_cb;
+	struct tasklet_struct  *pIsp_tkt;
+};
+
+static struct tasklet_struct tkt[ISP_IRQ_TYPE_AMOUNT];
+
+static void ISP_TaskletFunc_SV_0(unsigned long data);
+static void ISP_TaskletFunc_SV_1(unsigned long data);
+static void ISP_TaskletFunc_SV_2(unsigned long data);
+static void ISP_TaskletFunc_SV_3(unsigned long data);
+static void ISP_TaskletFunc_SV_4(unsigned long data);
+static void ISP_TaskletFunc_SV_5(unsigned long data);
+static long ISP_Buf_CTRL_FUNC_V4L2(unsigned long Param);
+static MUINT32 DMAO_CAMSV_BusSizeCal(struct IspDMACfg dma_cfg);
+static bool CAMSV_PIPE_CHECK_DMAO_STATUS(struct CAMSV_BUF_CTRL camsv_buf_ctl);
+static bool CAMSV_PIPE_CHECK_TG_CHECK(struct CAMSV_BUF_CTRL camsv_buf_ctl, MUINT32 intErrStatus);
+static bool CAMSV_PIPE_CHECK_ENQUE_CHECK(struct CAMSV_BUF_CTRL camsv_buf_ctl);
+static bool CAMSV_BUF_CTRL_C_FSM_SetFSM(enum E_STATE state, bool lock, struct CAMSV_BUF_CTRL *camsv_buf_ctl);
+static void BUF_CTRL_CAMSV_IMGO_FBC_STATUS(struct CAMSV_BUF_CTRL camsv_buf_ctl);
+static enum E_STATE CAMSV_BUF_CTRL_C_FSM_GetFSM(struct CAMSV_BUF_CTRL camsv_buf_ctl);
+static MUINT32 CAMSV_BUF_CTRL_estimateTimeout(struct CAMSV_BUF_CTRL camsv_buf_ctl, MUINT32 subSample);
+static void camsv_vb2_return_all_buffers(struct camsv_Module *camsv_m,
+					enum vb2_buffer_state state);
+
+static struct Tasklet_table isp_tasklet[ISP_IRQ_TYPE_AMOUNT] = {
+	{ISP_TaskletFunc_SV_0,  &tkt[ISP_IRQ_TYPE_INT_CAMSV_0_ST]},
+	{ISP_TaskletFunc_SV_1,  &tkt[ISP_IRQ_TYPE_INT_CAMSV_1_ST]},
+	{ISP_TaskletFunc_SV_2,  &tkt[ISP_IRQ_TYPE_INT_CAMSV_2_ST]},
+	{ISP_TaskletFunc_SV_3,  &tkt[ISP_IRQ_TYPE_INT_CAMSV_3_ST]},
+	{ISP_TaskletFunc_SV_4,  &tkt[ISP_IRQ_TYPE_INT_CAMSV_4_ST]},
+	{ISP_TaskletFunc_SV_5,  &tkt[ISP_IRQ_TYPE_INT_CAMSV_5_ST]},
+};
+
+#if (ISP_BOTTOMHALF_WORKQ == 1)
+struct IspWorkqueTable {
+	enum ISP_CAMSV_IRQ_TYPE_ENUM	module;
+	struct work_struct  isp_bh_work;
+};
+
+static void ISP_BH_Workqueue(struct work_struct *pWork);
+
+static struct IspWorkqueTable isp_workque[ISP_IRQ_TYPE_AMOUNT] = {
+	{ISP_IRQ_TYPE_INT_CAM_A_ST},
+	{ISP_IRQ_TYPE_INT_CAM_B_ST},
+	{ISP_IRQ_TYPE_INT_CAM_C_ST},
+	{ISP_IRQ_TYPE_INT_CAMSV_0_ST},
+	{ISP_IRQ_TYPE_INT_CAMSV_1_ST},
+	{ISP_IRQ_TYPE_INT_CAMSV_2_ST},
+	{ISP_IRQ_TYPE_INT_CAMSV_3_ST},
+	{ISP_IRQ_TYPE_INT_CAMSV_4_ST},
+	{ISP_IRQ_TYPE_INT_CAMSV_5_ST},
+	{ISP_IRQ_TYPE_INT_UNI_A_ST}
+};
+#endif
+
+#ifdef CONFIG_OF
+
+#include <linux/clk.h>
+struct ISP_CLK_STRUCT {
+	struct clk *ISP_CAM_CAMSYS;
+	struct clk *ISP_CAM_CAMTG;
+	struct clk *ISP_CAM_CAMSV0;
+	struct clk *ISP_CAM_CAMSV1;
+	struct clk *ISP_CAM_CAMSV2;
+
+	struct device	*larbipu;
+	struct device	*larbcam;
+	struct device	*dev;
+};
+
+static struct ISP_CLK_STRUCT isp_clk;
+static struct isp_device *isp_devs;
+static int nr_isp_devs;
+static unsigned int m_CurrentPPB;
+
+#ifdef CONFIG_PM_WAKELOCKS
+static struct wakeup_source isp_wake_lock;
+#else
+static struct wake_lock isp_wake_lock;
+#endif
+static int g_WaitLockCt;
+static int g_CamSVUserCt;
+
+/* Get HW modules' base address from device nodes */
+#define ISP_CAMSYS_CONFIG_BASE          (isp_devs[ISP_CAMSYS_CONFIG_IDX].regs)
+#define ISP_CAM_A_BASE                  (isp_devs[ISP_CAM_A_IDX].regs)
+#define ISP_CAM_B_BASE                  (isp_devs[ISP_CAM_B_IDX].regs)
+#define ISP_CAM_C_BASE                  (isp_devs[ISP_CAM_C_IDX].regs)
+#define ISP_CAMSV0_BASE                 (isp_devs[ISP_CAMSV0_IDX].regs)
+#define ISP_CAMSV1_BASE                 (isp_devs[ISP_CAMSV1_IDX].regs)
+#define ISP_CAMSV2_BASE                 (isp_devs[ISP_CAMSV2_IDX].regs)
+#define ISP_CAMSV3_BASE                 (isp_devs[ISP_CAMSV3_IDX].regs)
+#define ISP_CAMSV4_BASE                 (isp_devs[ISP_CAMSV4_IDX].regs)
+#define ISP_CAMSV5_BASE                 (isp_devs[ISP_CAMSV5_IDX].regs)
+#define ISP_CAM_UNI_BASE                (isp_devs[ISP_UNI_A_IDX].regs)
+
+#if (SMI_LARB_MMU_CTL == 1)
+static void __iomem *SMI_LARB_BASE[8];
+#endif
+
+#endif
+
+/* maximum number for supporting user to do interrupt operation */
+/* index 0 is for all the user that do not do register irq first */
+#define IRQ_USER_NUM_MAX 32
+static  spinlock_t      SpinLock_UserKey;
+
+
+#if (TIMESTAMP_QUEUE_EN == 1)
+static int32_t ISP_PopBufTimestamp(unsigned int module, unsigned int dma_id, struct S_START_T *pTstp);
+static int32_t ISP_WaitTimestampReady(unsigned int module, unsigned int dma_id);
+#endif
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+/* internal data */
+/* pointer to the kmalloc'd area, rounded up to a page boundary */
+static int *pTbl_RTBuf[ISP_IRQ_TYPE_AMOUNT];
+static int Tbl_RTBuf_MMPSize[ISP_IRQ_TYPE_AMOUNT];
+
+/* original pointer for kmalloc'd area as returned by kmalloc */
+static void *pBuf_kmalloc[ISP_IRQ_TYPE_AMOUNT];
+/*  */
+static struct ISP_RT_BUF_STRUCT *pstRTBuf[ISP_IRQ_TYPE_AMOUNT] = {NULL};
+
+static unsigned int G_u4EnableClockCount;
+static atomic_t G_u4DevNodeCt;
+
+static int pr_detect_count;
+
+
+/* isr dbg log , sw isr response counter , +1 when sw receive 1 sof isr. */
+static unsigned int sof_count[ISP_IRQ_TYPE_AMOUNT] = {0};
+
+/* current invoked time is at 1st sof or not during each streaming, reset when streaming off */
+static bool g1stSof[ISP_IRQ_TYPE_AMOUNT] = {0};
+#if (TSTMP_SUBSAMPLE_INTPL == 1)
+static bool g1stSwP1Done[ISP_IRQ_TYPE_AMOUNT] = {0};
+static unsigned long long gPrevSofTimestp[ISP_IRQ_TYPE_AMOUNT];
+#endif
+
+static struct S_START_T gSTime[ISP_IRQ_TYPE_AMOUNT] = {{0} };
+
+#ifdef _MAGIC_NUM_ERR_HANDLING_
+#define _INVALID_FRM_CNT_ 0xFFFF
+#endif
+
+/*save ion fd*/
+//#define ENABLE_KEEP_ION_HANDLE
+
+#ifdef ENABLE_KEEP_ION_HANDLE
+#define _ion_keep_max_   (64)/*32*/
+#include "inc/ion_drv.h" /*g_ion_device*/
+static struct ion_client *pIon_client;
+static struct mutex ion_client_mutex;
+static int G_WRDMA_IonCt[ISP_CAMSV0_IDX - ISP_CAM_A_IDX][_dma_max_wr_*_ion_keep_max_];
+static int G_WRDMA_IonFd[ISP_CAMSV0_IDX - ISP_CAM_A_IDX][_dma_max_wr_*_ion_keep_max_];
+static struct ion_handle *G_WRDMA_IonHnd[ISP_CAMSV0_IDX - ISP_CAM_A_IDX][_dma_max_wr_*_ion_keep_max_];
+/* protect G_WRDMA_IonHnd & G_WRDMA_IonFd */
+static spinlock_t SpinLock_IonHnd[ISP_CAMSV0_IDX - ISP_CAM_A_IDX][_dma_max_wr_];
+
+struct T_ION_TBL {
+	enum ISP_CAMSV_DEV_NODE_ENUM node;
+	int *pIonCt;
+	int *pIonFd;
+	struct ion_handle **pIonHnd;
+	spinlock_t *pLock;
+};
+
+static struct T_ION_TBL gION_TBL[ISP_DEV_NODE_NUM] = {
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_CAM_A_IDX, (int *)G_WRDMA_IonCt[ISP_CAM_A_IDX - ISP_CAM_A_IDX],
+		(int *)G_WRDMA_IonFd[ISP_CAM_A_IDX - ISP_CAM_A_IDX],
+		(struct ion_handle **)G_WRDMA_IonHnd[ISP_CAM_A_IDX - ISP_CAM_A_IDX],
+		(spinlock_t *)SpinLock_IonHnd[ISP_CAM_A_IDX - ISP_CAM_A_IDX]},
+	{ISP_CAM_B_IDX, (int *)G_WRDMA_IonCt[ISP_CAM_B_IDX - ISP_CAM_A_IDX],
+		(int *)G_WRDMA_IonFd[ISP_CAM_B_IDX - ISP_CAM_A_IDX],
+		(struct ion_handle **)G_WRDMA_IonHnd[ISP_CAM_B_IDX - ISP_CAM_A_IDX],
+		(spinlock_t *)SpinLock_IonHnd[ISP_CAM_B_IDX - ISP_CAM_A_IDX]},
+	{ISP_CAM_C_IDX, (int *)G_WRDMA_IonCt[ISP_CAM_C_IDX - ISP_CAM_A_IDX],
+		(int *)G_WRDMA_IonFd[ISP_CAM_C_IDX - ISP_CAM_A_IDX],
+		(struct ion_handle **)G_WRDMA_IonHnd[ISP_CAM_C_IDX - ISP_CAM_A_IDX],
+		(spinlock_t *)SpinLock_IonHnd[ISP_CAM_C_IDX - ISP_CAM_A_IDX]},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL},
+	{ISP_DEV_NODE_NUM, NULL, NULL, NULL, NULL}
+};
+#endif
+/*******************************************************************************
+ *
+ ********************************************************************************/
+#define ISP_BUF_SIZE            (4096)
+#define ISP_BUF_WRITE_AMOUNT    6
+
+enum ISP_BUF_STATUS_ENUM {
+	ISP_BUF_STATUS_EMPTY,
+	ISP_BUF_STATUS_HOLD,
+	ISP_BUF_STATUS_READY
+};
+
+struct ISP_BUF_STRUCT {
+	enum ISP_BUF_STATUS_ENUM Status;
+	unsigned int                Size;
+	unsigned char *pData;
+};
+
+struct ISP_BUF_INFO_STRUCT {
+	struct ISP_BUF_STRUCT      Read;
+	struct ISP_BUF_STRUCT      Write[ISP_BUF_WRITE_AMOUNT];
+};
+
+enum ISP_HW_MODULE {
+	CAM_A   = 0,
+	CAM_B,
+	/* CAM_C,        //not supported in everest */
+	/* CAM_D,        //not supported in everest */
+	CAM_MAX,
+	CAMSV_START = CAM_MAX,
+	CAMSV_0 = CAMSV_START,
+	CAMSV_1,
+	CAMSV_2,
+	CAMSV_3,
+	CAMSV_4,
+	CAMSV_5,
+	CAMSV_MAX,
+	DIP_START = CAMSV_MAX,
+	DIP_A = DIP_START,
+	/* DIP_B,            //not supported in everest */
+	DIP_MAX,
+	MAX_ISP_HW_MODULE = DIP_MAX
+};
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+#define ISP_ISR_MAX_NUM 32
+#define INT_ERR_WARN_TIMER_THREAS 1000
+#define INT_ERR_WARN_MAX_TIME 1
+
+struct ISP_IRQ_ERR_WAN_CNT_STRUCT {
+	unsigned int m_err_int_cnt[ISP_IRQ_TYPE_AMOUNT][ISP_ISR_MAX_NUM]; /* cnt for each err int # */
+	unsigned int m_warn_int_cnt[ISP_IRQ_TYPE_AMOUNT][ISP_ISR_MAX_NUM]; /* cnt for each warning int # */
+	unsigned int m_err_int_mark[ISP_IRQ_TYPE_AMOUNT]; /* mark for err int, where its cnt > threshold */
+	unsigned int m_warn_int_mark[ISP_IRQ_TYPE_AMOUNT]; /* mark for warn int, where its cnt > threshold */
+	unsigned long m_int_usec[ISP_IRQ_TYPE_AMOUNT];
+};
+
+static int FirstUnusedIrqUserKey = 1;
+#define USERKEY_STR_LEN 128
+
+struct UserKeyInfo {
+	char userName[USERKEY_STR_LEN]; /* name for the user that register a userKey */
+	int userKey;    /* the user key for that user */
+};
+/* array for recording the user name for a specific user key */
+static struct UserKeyInfo IrqUserKey_UserInfo[IRQ_USER_NUM_MAX];
+
+struct ISP_IRQ_INFO_STRUCT {
+	/* Add an extra index for status type in Everest -> signal or dma */
+	unsigned int    Status[ISP_IRQ_TYPE_AMOUNT][ISP_IRQ_ST_AMOUNT][IRQ_USER_NUM_MAX];
+	unsigned int    Mask[ISP_IRQ_TYPE_AMOUNT][ISP_IRQ_ST_AMOUNT];
+	unsigned int    ErrMask[ISP_IRQ_TYPE_AMOUNT][ISP_IRQ_ST_AMOUNT];
+	unsigned int    WarnMask[ISP_IRQ_TYPE_AMOUNT][ISP_IRQ_ST_AMOUNT];
+	unsigned int    Warn2Mask[ISP_IRQ_TYPE_AMOUNT][ISP_IRQ_ST_AMOUNT];
+	/* flag for indicating that user do mark for a interrupt or not */
+	unsigned int    MarkedFlag[ISP_IRQ_TYPE_AMOUNT][ISP_IRQ_ST_AMOUNT][IRQ_USER_NUM_MAX];
+	/* time for marking a specific interrupt */
+	unsigned int    MarkedTime_sec[ISP_IRQ_TYPE_AMOUNT][32][IRQ_USER_NUM_MAX];
+	/* time for marking a specific interrupt */
+	unsigned int    MarkedTime_usec[ISP_IRQ_TYPE_AMOUNT][32][IRQ_USER_NUM_MAX];
+	/* number of a specific signal that passed by */
+	int             PassedBySigCnt[ISP_IRQ_TYPE_AMOUNT][32][IRQ_USER_NUM_MAX];
+	/* */
+	unsigned int    LastestSigTime_sec[ISP_IRQ_TYPE_AMOUNT][32];
+	/* latest time for each interrupt */
+	unsigned int    LastestSigTime_usec[ISP_IRQ_TYPE_AMOUNT][32];
+	/* latest time for each interrupt */
+};
+
+struct ISP_TIME_LOG_STRUCT {
+	unsigned int     Vd;
+	unsigned int     Expdone;
+	unsigned int     WorkQueueVd;
+	unsigned int     WorkQueueExpdone;
+	unsigned int     TaskletVd;
+	unsigned int     TaskletExpdone;
+};
+
+#if (TIMESTAMP_QUEUE_EN == 1)
+#define ISP_TIMESTPQ_DEPTH      (256)
+struct ISP_TIMESTPQ_INFO_STRUCT {
+	struct {
+		struct S_START_T   TimeQue[ISP_TIMESTPQ_DEPTH];
+		unsigned int     WrIndex; /* increase when p1done or dmao done */
+		unsigned int     RdIndex; /* increase when user deque */
+		unsigned long long  TotalWrCnt;
+		unsigned long long  TotalRdCnt;
+		/* TSTP_V3 unsigned int	    PrevFbcDropCnt; */
+		unsigned int     PrevFbcWCnt;
+	} Dmao[_camsv_max_];
+	unsigned int  DmaEnStatus[_camsv_max_];
+};
+#endif
+
+/**********************************************************************/
+#define my_get_pow_idx(value)      \
+	({                                                          \
+		int i = 0, cnt = 0;                                  \
+		for (i = 0; i < 32; i++) {                            \
+			if ((value>>i) & (0x00000001)) {   \
+				break;                                      \
+			} else {                                            \
+				cnt++;  \
+			}                                      \
+		}                                                    \
+		cnt;                                                \
+	})
+
+static struct ISP_RAW_INT_STATUS g_ISPIntStatus[ISP_IRQ_TYPE_AMOUNT];
+static struct ISP_RAW_INT_STATUS g_ISPIntStatus_SMI[ISP_IRQ_TYPE_AMOUNT];
+
+static unsigned int g_DmaErr_CAM[ISP_IRQ_TYPE_AMOUNT][_camsv_max_] = {{0} };
+
+#define SUPPORT_MAX_IRQ 32
+struct ISP_INFO_STRUCT {
+	spinlock_t                      SpinLockIspRef;
+	spinlock_t                      SpinLockIsp;
+	spinlock_t                      SpinLockIrq[ISP_IRQ_TYPE_AMOUNT];
+	spinlock_t                      SpinLockIrqCnt[ISP_IRQ_TYPE_AMOUNT];
+	spinlock_t                      SpinLockRTBC;
+	spinlock_t                      SpinLockClock;
+	wait_queue_head_t               WaitQueueHead[ISP_IRQ_TYPE_AMOUNT];
+	/* wait_queue_head_t*              WaitQHeadList; */
+	wait_queue_head_t      WaitQHeadList[SUPPORT_MAX_IRQ];
+	unsigned int                         UserCount;
+	unsigned int                         DebugMask;
+	int							IrqNum;
+	struct ISP_IRQ_INFO_STRUCT			IrqInfo;
+	struct ISP_IRQ_ERR_WAN_CNT_STRUCT		IrqCntInfo;
+	struct ISP_BUF_INFO_STRUCT			BufInfo;
+	struct ISP_TIME_LOG_STRUCT             TimeLog;
+	#if (TIMESTAMP_QUEUE_EN == 1)
+	struct ISP_TIMESTPQ_INFO_STRUCT        TstpQInfo[ISP_IRQ_TYPE_AMOUNT];
+	#endif
+};
+
+static struct ISP_INFO_STRUCT IspInfo;
+static bool    SuspnedRecord[ISP_DEV_NODE_NUM] = {0};
+
+enum eLOG_TYPE {
+	_LOG_DBG = 0,   /* currently, only used at ipl_buf_ctrl. to protect critical section */
+	_LOG_INF = 1,
+	_LOG_ERR = 2,
+	_LOG_MAX = 3,
+};
+
+#define NORMAL_STR_LEN (512)
+#define ERR_PAGE 2
+#define DBG_PAGE 2
+#define INF_PAGE 4
+/* #define SV_LOG_STR_LEN NORMAL_STR_LEN */
+
+#define LOG_PPNUM 2
+struct SV_LOG_STR {
+	unsigned int _cnt[LOG_PPNUM][_LOG_MAX];
+	/* char   _str[_LOG_MAX][SV_LOG_STR_LEN]; */
+	char *_str[LOG_PPNUM][_LOG_MAX];
+	struct S_START_T   _lastIrqTime;
+};
+
+static void *pLog_kmalloc;
+static struct SV_LOG_STR gSvLog[ISP_IRQ_TYPE_AMOUNT];
+
+/**
+ *   for irq used,keep log until IRQ_LOG_PRINTER being involked,
+ *   limited:
+ *   each log must shorter than 512 bytes
+ *   total log length in each irq/logtype can't over 1024 bytes
+ */
+#define IRQ_LOG_KEEPER_T(sec, usec) {\
+		ktime_t time;           \
+		time = ktime_get();     \
+		sec = time;        \
+		do_div(sec, 1000);    \
+		usec = do_div(sec, 1000000);\
+	}
+
+#define IRQ_LOG_KEEPER(irq, ppb, logT, fmt, ...) do {\
+	char *ptr; \
+	char *pDes;\
+	int avaLen;\
+	unsigned int *ptr2 = &gSvLog[irq]._cnt[ppb][logT];\
+	unsigned int str_leng;\
+	unsigned int i;\
+	struct SV_LOG_STR *pSrc = &gSvLog[irq];\
+	if (logT == _LOG_ERR) {\
+		str_leng = NORMAL_STR_LEN*ERR_PAGE; \
+	} else if (logT == _LOG_DBG) {\
+		str_leng = NORMAL_STR_LEN*DBG_PAGE; \
+	} else if (logT == _LOG_INF) {\
+		str_leng = NORMAL_STR_LEN*INF_PAGE;\
+	} else {\
+		str_leng = 0;\
+	} \
+	ptr = pDes = (char *)&(gSvLog[irq]._str[ppb][logT][gSvLog[irq]._cnt[ppb][logT]]);    \
+	avaLen = str_leng - 1 - gSvLog[irq]._cnt[ppb][logT];\
+	if (avaLen > 1) {\
+		snprintf((char *)(pDes), avaLen, "[%d.%06d]" fmt,\
+			gSvLog[irq]._lastIrqTime.sec, gSvLog[irq]._lastIrqTime.usec,\
+			##__VA_ARGS__);   \
+		if ('\0' != gSvLog[irq]._str[ppb][logT][str_leng - 1]) {\
+			LOG_NOTICE("log str over flow(%d)", irq);\
+		} \
+		while (*ptr++ != '\0') {        \
+			(*ptr2)++;\
+		}     \
+	} else { \
+		LOG_INF("(%d)(%d)log str avalible=0, print log\n", irq, logT);\
+		ptr = pSrc->_str[ppb][logT];\
+		if (pSrc->_cnt[ppb][logT] != 0) {\
+			if (logT == _LOG_DBG) {\
+				for (i = 0; i < DBG_PAGE; i++) {\
+					if (ptr[NORMAL_STR_LEN*(i+1) - 1] != '\0') {\
+						ptr[NORMAL_STR_LEN*(i+1) - 1] = '\0';\
+						LOG_DBG("%s", &ptr[NORMAL_STR_LEN*i]);\
+					} else{\
+						LOG_DBG("%s", &ptr[NORMAL_STR_LEN*i]);\
+						break;\
+					} \
+				} \
+			} \
+			else if (logT == _LOG_INF) {\
+				for (i = 0; i < INF_PAGE; i++) {\
+					if (ptr[NORMAL_STR_LEN*(i+1) - 1] != '\0') {\
+						ptr[NORMAL_STR_LEN*(i+1) - 1] = '\0';\
+						LOG_INF("%s", &ptr[NORMAL_STR_LEN*i]);\
+					} else{\
+						LOG_INF("%s", &ptr[NORMAL_STR_LEN*i]);\
+						break;\
+					} \
+				} \
+			} \
+			else if (logT == _LOG_ERR) {\
+				for (i = 0; i < ERR_PAGE; i++) {\
+					if (ptr[NORMAL_STR_LEN*(i+1) - 1] != '\0') {\
+						ptr[NORMAL_STR_LEN*(i+1) - 1] = '\0';\
+						LOG_NOTICE("%s", &ptr[NORMAL_STR_LEN*i]);\
+					} else{\
+						LOG_NOTICE("%s", &ptr[NORMAL_STR_LEN*i]);\
+						break;\
+					} \
+				} \
+			} \
+			else {\
+				LOG_NOTICE("N.S.%d", logT);\
+			} \
+			ptr[0] = '\0';\
+			pSrc->_cnt[ppb][logT] = 0;\
+			avaLen = str_leng - 1;\
+			ptr = pDes = (char *)&(pSrc->_str[ppb][logT][pSrc->_cnt[ppb][logT]]);\
+			ptr2 = &(pSrc->_cnt[ppb][logT]);\
+			snprintf((char *)(pDes), avaLen, fmt, ##__VA_ARGS__);   \
+			while (*ptr++ != '\0') {\
+				(*ptr2)++;\
+			} \
+		} \
+	} \
+} while (0)
+
+#define IRQ_LOG_PRINTER(irq, ppb_in, logT_in) do {\
+		struct SV_LOG_STR *pSrc = &gSvLog[irq];\
+		char *ptr;\
+		unsigned int i;\
+		int ppb = 0;\
+		int logT = 0;\
+		if (ppb_in > 1) {\
+			ppb = 1;\
+		} else{\
+			ppb = ppb_in;\
+		} \
+		if (logT_in > _LOG_ERR) {\
+			logT = _LOG_ERR;\
+		} else{\
+			logT = logT_in;\
+		} \
+		ptr = pSrc->_str[ppb][logT];\
+		if (pSrc->_cnt[ppb][logT] != 0) {\
+			if (logT == _LOG_DBG) {\
+				for (i = 0; i < DBG_PAGE; i++) {\
+					if (ptr[NORMAL_STR_LEN*(i+1) - 1] != '\0') {\
+						ptr[NORMAL_STR_LEN*(i+1) - 1] = '\0';\
+						LOG_DBG("%s", &ptr[NORMAL_STR_LEN*i]);\
+					} else{\
+						LOG_DBG("%s", &ptr[NORMAL_STR_LEN*i]);\
+						break;\
+					} \
+				} \
+			} \
+			else if (logT == _LOG_INF) {\
+				for (i = 0; i < INF_PAGE; i++) {\
+					if (ptr[NORMAL_STR_LEN*(i+1) - 1] != '\0') {\
+						ptr[NORMAL_STR_LEN*(i+1) - 1] = '\0';\
+						LOG_INF("%s", &ptr[NORMAL_STR_LEN*i]);\
+					} else{\
+						LOG_INF("%s", &ptr[NORMAL_STR_LEN*i]);\
+						break;\
+					} \
+				} \
+			} \
+			else if (logT == _LOG_ERR) {\
+				for (i = 0; i < ERR_PAGE; i++) {\
+					if (ptr[NORMAL_STR_LEN*(i+1) - 1] != '\0') {\
+						ptr[NORMAL_STR_LEN*(i+1) - 1] = '\0';\
+						LOG_NOTICE("%s", &ptr[NORMAL_STR_LEN*i]);\
+					} else{\
+						LOG_NOTICE("%s", &ptr[NORMAL_STR_LEN*i]);\
+						break;\
+					} \
+				} \
+			} \
+			else {\
+				LOG_NOTICE("N.S.%d", logT);\
+			} \
+			ptr[0] = '\0';\
+			pSrc->_cnt[ppb][logT] = 0;\
+		} \
+	} while (0)
+
+/* //////////////////////////////////////////////////// */
+
+struct _isp_bk_reg_t {
+	unsigned int  CAM_TG_INTER_ST;                                 /* 453C*/
+};
+
+static struct _isp_bk_reg_t g_BkReg[ISP_IRQ_TYPE_AMOUNT];
+
+/* if isp has been suspend, frame cnt needs to add previous value*/
+#define ISP_RD32_TG_CAM_FRM_CNT(IrqType, reg_module) ({\
+	unsigned int _regVal;\
+	_regVal = ISP_RD32(CAMSV_REG_TG_INTER_ST(reg_module));\
+	_regVal = ((_regVal & 0x00FF0000) >> 16) + g_BkReg[IrqType].CAM_TG_INTER_ST;\
+	if (_regVal > 255) { \
+		_regVal -= 256;\
+	} \
+	_regVal;\
+})
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline unsigned int ISP_MsToJiffies(unsigned int Ms)
+{
+	return ((Ms * HZ + 512) >> 10);
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline unsigned int ISP_UsToJiffies(unsigned int Us)
+{
+	return (((Us / 1000) * HZ + 512) >> 10);
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline unsigned int
+ISP_GetIRQState(unsigned int type, unsigned int stType, unsigned int userNumber, unsigned int stus)
+{
+	unsigned int ret;
+	unsigned long flags; /* old: unsigned int flags;*//* FIX to avoid build warning */
+
+	/*  */
+	spin_lock_irqsave(&(IspInfo.SpinLockIrq[type]), flags);
+	dprintk(3, "type %d, stType %d, userNumber %d, stus %x, wait stus %x\n",
+		type, stType, userNumber, IspInfo.IrqInfo.Status[type][stType][userNumber],
+		stus);
+	ret = (IspInfo.IrqInfo.Status[type][stType][userNumber] & stus);
+	spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[type]), flags);
+	/*  */
+	return ret;
+}
+
+
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline unsigned int ISP_JiffiesToMs(unsigned int Jiffies)
+{
+	return ((Jiffies * 1000) / HZ);
+}
+
+static inline int CamSv_Pwn_On(void)
+{
+	int ret;
+
+	ret = pm_runtime_get_sync(isp_clk.dev);
+	if (ret)
+		LOG_ERR("pm_runtime_get_sync fail %d", ret);
+	return ret;
+}
+
+static inline int CamSv_Pwn_Off(void)
+{
+	int ret;
+
+	ret = pm_runtime_put_sync(isp_clk.dev);
+	if (ret)
+		LOG_ERR("pm_runtime_put_sync fail %d", ret);
+	return ret;
+}
+
+static inline void Prepare_Enable_ccf_clock(void)
+{
+	int ret;
+	/* must keep this clk open order: CG_SCP_SYS_DIS-> CG_DISP0_SMI_COMMON -> CG_SCP_SYS_ISP/CAM -> ISP clk */
+
+	LOG_INF("enable CG/MTCMOS through SMI CLK API\n");
+
+	ret = pm_runtime_get_sync(isp_clk.larbipu);
+	if (ret < 0)
+		LOG_ERR("pm_runtime_get_sync larb3 fail %d", ret);
+
+	ret = pm_runtime_get_sync(isp_clk.larbcam);
+	if (ret < 0)
+		LOG_ERR("pm_runtime_get_sync larb6 fail %d", ret);
+
+	ret = clk_prepare_enable(isp_clk.ISP_CAM_CAMSYS);
+	if (ret)
+		LOG_NOTICE("cannot pre-en ISP_CAM_CAMSYS clock\n");
+
+	ret = clk_prepare_enable(isp_clk.ISP_CAM_CAMTG);
+	if (ret)
+		LOG_NOTICE("cannot pre-en ISP_CAM_CAMTG clock\n");
+
+	ret = clk_prepare_enable(isp_clk.ISP_CAM_CAMSV0);
+	if (ret)
+		LOG_NOTICE("cannot pre-en ISP_CAM_CAMSV0 clock\n");
+
+	ret = clk_prepare_enable(isp_clk.ISP_CAM_CAMSV1);
+	if (ret)
+		LOG_NOTICE("cannot pre-en ISP_CAM_CAMSV1 clock\n");
+
+	ret = clk_prepare_enable(isp_clk.ISP_CAM_CAMSV2);
+	if (ret)
+		LOG_NOTICE("cannot pre-en ISP_CAM_CAMSV2 clock\n");
+
+}
+
+static inline void Disable_Unprepare_ccf_clock(void)
+{
+	/* must keep this clk close order: ISP clk -> CG_SCP_SYS_ISP/CAM -> CG_DISP0_SMI_COMMON -> CG_SCP_SYS_DIS */
+	clk_disable_unprepare(isp_clk.ISP_CAM_CAMSV0);
+	clk_disable_unprepare(isp_clk.ISP_CAM_CAMSV1);
+	clk_disable_unprepare(isp_clk.ISP_CAM_CAMSV2);
+	clk_disable_unprepare(isp_clk.ISP_CAM_CAMTG);
+	clk_disable_unprepare(isp_clk.ISP_CAM_CAMSYS);
+
+	pm_runtime_put_sync(isp_clk.larbcam);
+	pm_runtime_put_sync(isp_clk.larbipu);
+
+	LOG_INF("disable CG/MTCMOS through SMI CLK API\n");
+}
+
+/*******************************************************************************
+ *	V4L2 CamSV ioctrl
+ ********************************************************************************/
+
+int camsv_VF_GET_IRQ_MODULE(enum ISP_CAMSV_DEV_NODE_ENUM cam_idx)
+{
+	enum ISP_CAMSV_IRQ_TYPE_ENUM m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_0_ST;
+
+	switch (cam_idx) {
+		/* CAMSV */
+		case ISP_CAMSV0_IDX: {
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_0_ST;
+			break;
+		}
+		case ISP_CAMSV1_IDX: {
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_1_ST;
+			break;
+		}
+		case ISP_CAMSV2_IDX: {
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_2_ST;
+			break;
+		}
+		case ISP_CAMSV3_IDX: {
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_3_ST;
+			break;
+		}
+		case ISP_CAMSV4_IDX: {
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_4_ST;
+			break;
+		}
+		case ISP_CAMSV5_IDX: {
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_5_ST;
+			break;
+		}
+		default: {
+			dprintk(1, "cam_idx %d unsupport(camsv only)\n", cam_idx);
+			m_isp_irq_module = ISP_IRQ_TYPE_INT_CAMSV_0_ST;
+			break;
+		}
+	}
+
+	return m_isp_irq_module;
+}
+
+int camsv_VF_WAIT_IRQ(struct camsv_Module *camsv_m, struct ISP_WAIT_IRQ_ST *IrqInfo)
+{
+	struct ISP_WAIT_IRQ_STRUCT irqstruct;
+	struct timeval time_frmb;
+	struct timeval Snd_time_frmb;
+	unsigned long long  sec = 0;
+	unsigned long       usec = 0;
+	unsigned long long  Sndsec = 0;
+	unsigned long       Sndusec = 0;
+	int Ret = 0;
+	MUINT32 OrgTimeOut;
+	enum ISP_IRQ_CLEAR_ENUM OrgClr;
+
+	dprintk(3, "camsv_m->camsv_port_input.u4HwModule %d\n",
+		camsv_m->camsv_port_input.u4HwModule);
+
+	OrgTimeOut = IrqInfo->Timeout;
+	OrgClr = IrqInfo->Clear;
+	irqstruct.Type = camsv_VF_GET_IRQ_MODULE(camsv_m->camsv_port_input.u4HwModule);
+	memcpy(&irqstruct.EventInfo, IrqInfo, sizeof(struct ISP_WAIT_IRQ_ST));
+
+	do {
+
+		/*  */
+		sec = cpu_clock(0);     /* ns */
+		do_div(sec, 1000);    /* usec */
+		usec = do_div(sec, 1000000);    /* sec and usec */
+		time_frmb.tv_usec = usec;
+		time_frmb.tv_sec = sec;
+
+
+		dprintk(4, "1 IRQ type(%d), timeout(%d), userkey(%d), st_status(%d), status(%x), t(%ld.%ld)\n",
+			irqstruct.Type, irqstruct.EventInfo.Timeout,
+			irqstruct.EventInfo.UserKey, irqstruct.EventInfo.St_type, irqstruct.EventInfo.Status,
+			time_frmb.tv_sec, time_frmb.tv_usec);
+
+		Ret = ISP_WaitIrq(&irqstruct);
+
+		/*  */
+		Sndsec = cpu_clock(0);     /* ns */
+		do_div(Sndsec, 1000);    /* usec */
+		Sndusec = do_div(Sndsec, 1000000);    /* sec and usec */
+		Snd_time_frmb.tv_usec = Sndusec;
+		Snd_time_frmb.tv_sec = Sndsec;
+
+		dprintk(4, "2 IRQ type(%d), timeout(%d), userkey(%d), st_status(%d), status(%x), t(%ld.%ld), Ret %d\n",
+			irqstruct.Type, irqstruct.EventInfo.Timeout,
+			irqstruct.EventInfo.UserKey, irqstruct.EventInfo.St_type, irqstruct.EventInfo.Status,
+			Snd_time_frmb.tv_sec, Snd_time_frmb.tv_usec, Ret);
+
+		//receive restart system call signal, errno == SIG_ERESTARTSYS
+		if ((Ret < 0) && (irqstruct.EventInfo.Timeout > 0)) {
+			if ((Sndsec-sec) > 1000 && (((Sndsec-sec)/1000) < irqstruct.EventInfo.Timeout)) { //at least 1ms
+				irqstruct.EventInfo.Timeout = irqstruct.EventInfo.Timeout - ((Sndsec-sec)/1000);
+				irqstruct.EventInfo.Clear = ISP_IRQ_CLEAR_NONE;
+				dprintk(1, "Interrupted by other wait again. Type(%d),Status(0x%08x),Timeout(%dms)\n",
+					irqstruct.Type, IrqInfo->Status, irqstruct.EventInfo.Timeout);
+			} else {
+				break;
+			}
+		} else
+			break;
+
+	} while (1);
+
+	if (Ret < 0) {
+		dprintk(1, "ISP(0x%x)_WAIT_IRQ fail(%d). Wait Status(0x%08x), Timeout(%d).\n",
+		irqstruct.Type, Ret, IrqInfo->Status, IrqInfo->Timeout);
+		return MFALSE;
+	}
+	return MTRUE;
+}
+
+int camsv_VF_LOG(int module, int irq_type, int mode_value)
+{
+	unsigned int vf, cam_dmao = 0;
+
+	vf = ISP_RD32(CAMSV_REG_TG_VF_CON(module));
+
+	switch (mode_value) {
+		/* CAMSV */
+		case 11: {
+			dprintk(3, "CAMSV_%d viewFinder is ON\n", (irq_type-3));
+			cam_dmao = (ISP_RD32(CAMSV_REG_MODULE_EN(module)) & 0x10);
+			dprintk(3, "CAMSV_%d:[DMA_EN]:0x%x\n", (irq_type-3), cam_dmao);
+			vf = ISP_RD32(CAMSV_REG_TG_VF_CON(module));
+			dprintk(3, "is ON %x\n", ISP_RD32(CAMSV_REG_TG_VF_CON(module)));
+			if (vf & 0x1)
+				LOG_NOTICE("CAMSV_%d: vf already enabled\n", (irq_type-3));
+			else
+				ISP_WR32(CAMSV_REG_TG_VF_CON(module), (vf+0x1));
+
+			pstRTBuf[irq_type]->ring_buf[_camsv_imgo_].active =
+				((cam_dmao & 0x10) ? (MTRUE) : (MFALSE));
+			/*reset 1st sof flag when vf is enabled*/
+			g1stSof[irq_type] = MTRUE;
+			break;
+		}
+		case 10: {
+			dprintk(3, "CAMSV_%d viewFinder is OFF\n", (irq_type-3));
+			vf = ISP_RD32(CAMSV_REG_TG_VF_CON(module));
+			dprintk(3, "is OFF %x\n", ISP_RD32(CAMSV_REG_TG_VF_CON(module)));
+			if (vf & 0x1)
+				ISP_WR32(CAMSV_REG_TG_VF_CON(module), (vf-0x1));
+			else
+				LOG_NOTICE("CAMSV_%d: vf already disalbed\n", (irq_type-3));
+			break;
+		}
+		default: {
+			dprintk(1, "mode_value %d unsupport\n", mode_value);
+		}
+	}
+	return 0;
+}
+
+/*******************************************************************************
+ *	V4L2 CamSV configs
+ ********************************************************************************/
+int CAMSV_TG_CTRL_config(struct CAMSV_TG_CTRL camsv_tg_cfg)
+{
+	unsigned int reg_module = camsv_tg_cfg.m_hwModule;
+	unsigned int m_SubSample = camsv_tg_cfg.m_SubSample;
+	unsigned int m_continuous = camsv_tg_cfg.m_continuous;
+	enum E_CamPixelMode m_PixMode = camsv_tg_cfg.m_PixMode;
+	struct IspRect *m_Crop = &(camsv_tg_cfg.m_Crop);
+	unsigned int regVal;
+
+	dprintk(3, " + reg_module %d\n", reg_module);
+	//subsample
+	//for vsync subsample function, need to make sure cmos_en is off.
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+	ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), 0xFFFFFFFE&regVal); /*[0], CMOS_EN=0*/
+	dprintk(3, " m_SubSample(%d)\n", m_SubSample);
+	if (m_SubSample) {
+		regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+		//sof
+		regVal |= 0x00040000;/*[18], SOF_SUB_EN=1*/
+		//vsync
+		regVal |= 0x00020000;/*[17], VS_SUB_EN=1*/
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), regVal);
+		ISP_WR32(CAMSV_REG_TG_SUB_PERIOD(reg_module), ((m_SubSample<<8)|m_SubSample));
+	} else{
+		regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+		//sof
+		regVal &= 0xFFFBFFFF;/*[18], SOF_SUB_EN=0*/
+		//vsync
+		regVal &= 0xFFFDFFFF;/*[17], VS_SUB_EN=0*/
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), regVal);
+		ISP_WR32(CAMSV_REG_TG_SUB_PERIOD(reg_module), ((m_SubSample<<8)|m_SubSample));
+	}
+
+	//timestamp
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+	ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), (0x00010000|regVal)); /*[16], TIME_STP_EN=1*/
+
+	//trig mode
+	dprintk(3, "m_continuous(%d)\n", m_continuous);
+	if (m_continuous) {
+		regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(reg_module));
+		ISP_WR32(CAMSV_REG_TG_VF_CON(reg_module), (0xFFFFFFFD&regVal)); /*[1], SINGLE_MODE=0*/
+	} else{
+		regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(reg_module));
+		ISP_WR32(CAMSV_REG_TG_VF_CON(reg_module), (0x00000002|regVal)); /*[1], SINGLE_MODE=1*/
+	}
+
+	//pix mode
+	dprintk(3, "m_PixMode(%x)\n", m_PixMode);
+	switch (m_PixMode) {
+	case ePixMode_1:
+		regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+		/*[1], DBL_DATA_BUS=0, [13], DBL_DATA_BUS1=0*/
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), (0xFFFFDFFD&regVal));
+		break;
+	case ePixMode_2:
+		regVal = (0x00000002 | ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module)));/*[1], DBL_DATA_BUS=1*/
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), (0xFFFFDFFF&regVal)); /*[13], DBL_DATA_BUS1=0*/
+		break;
+	case ePixMode_4:
+		regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+		/*[1], DBL_DATA_BUS=1, [13], DBL_DATA_BUS1=1*/
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), (0x00002002|regVal));
+		break;
+	default:
+		LOG_INF("- unsupported pix mode:0x%x\n", m_PixMode);
+		break;
+	}
+
+	//cropping window
+	dprintk(3, "m_Crop.w(%ld 0x%08lx)\n", m_Crop->w, m_Crop->w);
+	if ((m_Crop->w % 4) != 0) {
+		LOG_INF("TG cropping size need 4-alignment\n");
+		return 1;
+	}
+
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_GRAB_PXL(reg_module));
+	ISP_WR32(CAMSV_REG_TG_SEN_GRAB_PXL(reg_module), (((m_Crop->w+m_Crop->x)<<16)|m_Crop->x));
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_GRAB_LIN(reg_module));
+	ISP_WR32(CAMSV_REG_TG_SEN_GRAB_LIN(reg_module), (((m_Crop->h+m_Crop->y)<<16)|m_Crop->y));
+
+	//
+	dprintk(3, "CAMSV_TG_CTRL::_config-\n");
+
+	return 0;
+}
+
+void CAMSV_TG_CTRL_enable(struct CAMSV_TG_CTRL camsv_tg_cfg)
+{
+	unsigned int reg_module = camsv_tg_cfg.m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "CAMSV_TG_CTRL::_enable+\n");
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+	ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), (0x00000001|regVal)); /*[0], CMOS_EN=1*/
+}
+
+void CAMSV_TG_CTRL_disable(struct CAMSV_TG_CTRL camsv_tg_cfg)
+{
+	unsigned int reg_module = camsv_tg_cfg.m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "CAMSV_TG_CTRL::_disable+\n");
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(reg_module));
+	ISP_WR32(CAMSV_REG_TG_SEN_MODE(reg_module), 0xFFFFFFFE&regVal); /*[0], CMOS_EN=0*/
+}
+
+int CAMSV_TOP_CTRL_config(struct CAMSV_TOP_CTRL camsv_top_cfg)
+{
+	unsigned int m_hwModule = camsv_top_cfg.m_hwModule;
+	unsigned int m_SubSample = camsv_top_cfg.SubSample;
+	enum E_CamPixelMode m_PixMode = camsv_top_cfg.m_PixMode;
+	struct ISP_BUFFER_CTRL_STRUCT buf_ctrl;
+		unsigned int _clrPort = 1;
+		unsigned int _dma[1] = {_camsv_imgo_};
+		unsigned int regVal;
+		unsigned int i = 0;/*_loglevel = 0,*/
+		unsigned int int_en = (SV_VS1_ST |
+		SV_TG_ERR_ST |
+		SV_TG_GBERR_ST |
+		SV_SOF_INT_ST |
+		SV_HW_PASS1_DON_ST |
+		SV_HW_IMGO_ERR_ST |
+		SV_HW_IMGO_OVERR_ST |
+		SV_SW_PASS1_DON_ST);
+
+	dprintk(3, " +\n");
+
+	buf_ctrl.module = (m_hwModule-2); /* transfer ISP_DEV_NODE_ENUM to ISP_IRQ_TYPE_ENUM */
+	while (_clrPort--) {
+		buf_ctrl.ctrl = ISP_RT_BUF_CTRL_CLEAR;
+		buf_ctrl.buf_id = (enum _isp_dma_enum_)_dma[_clrPort];
+		buf_ctrl.data_ptr = NULL;
+		buf_ctrl.pExtend = 0;
+
+			if (ISP_Buf_CTRL_FUNC_V4L2((unsigned long)&buf_ctrl))
+				LOG_INF("ERROR:clear buf ctrl fail\n");
+		}
+
+	//reset
+	dprintk(3, "CAMSV TOP reset\n");
+	ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x4); /*SW_RST: 1*/
+	ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x0); /*SW_RST: 0*/
+	ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x1); /*IMGO_RST_TRIG: 1*/
+
+	while ((ISP_RD32(CAMSV_REG_SW_CTL(m_hwModule)) != 0x3) && i++ < 1000) { // Polling IMGO_RST_ST to 1
+		dprintk(3, "CAMSV resetting.. %d ..CAMSV_SW_CTL:0x%x\n", i, ISP_RD32(CAMSV_REG_SW_CTL(m_hwModule)));
+	}
+	ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x0); // IMGO_RST_TRIG: 0
+
+	//func en
+	regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+	ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0x40000001|regVal); /*[0], TG_EN=1, [30], DB_EN=1*/
+
+	//fmt sel
+	dprintk(3, "FMT_SEL.Raw %x\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Raw);
+	regVal = camsv_top_cfg.camsv_top_ctl.FMT_SEL.Raw;
+	ISP_WR32(CAMSV_REG_FMT_SEL(m_hwModule), regVal);
+
+	//interrupt en
+	ISP_WR32(CAMSV_REG_INT_EN(m_hwModule), int_en);
+
+	//subsample p1 done
+	if (m_SubSample) {
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0x00000020|regVal); /*[5], DOWN_SAMPLE_EN=1*/
+	} else {
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0xFFFFFFDF&regVal); /*[5], DOWN_SAMPLE_EN=0*/
+	}
+	regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+	/*[8-13], DOWN_SAMPLE_PERIOD*/
+	ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), ((0xFFFFC0FF)&regVal)|(m_SubSample<<8));
+
+	// PAK setting
+	switch (camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT) {
+	case SV_TG_FMT_RAW8:
+		dprintk(3, "TG1_FMT(%d) SV_TG_FMT_RAW8\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		regVal |= 0x00000004;
+		regVal &= 0xFFFFFFF7;
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), regVal); /*[2], PAK_EN=1, [3], PAK_SEL=0*/
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), 0xFFFFFFF8&regVal); /*[0-2], PAK_MODE=0*/
+		break;
+	case SV_TG_FMT_RAW10:
+		dprintk(3, "TG1_FMT(%d) SV_TG_FMT_RAW10\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		regVal |= 0x00000004;
+		regVal &= 0xFFFFFFF7;
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), regVal); /*[2], PAK_EN=1, [3], PAK_SEL=0*/
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), ((0xFFFFFFF8)&regVal)|(0x00000001)); /*[0-2], PAK_MODE=1*/
+		break;
+	case SV_TG_FMT_RAW12:
+		dprintk(3, "TG1_FMT(%d) SV_TG_FMT_RAW12\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		regVal |= 0x00000004;
+		regVal &= 0xFFFFFFF7;
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), regVal); /*[2], PAK_EN=1, [3], PAK_SEL=0*/
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), ((0xFFFFFFF8)&regVal)|(0x00000002)); /*[0-2], PAK_MODE=2*/
+		break;
+	case SV_TG_FMT_RAW14:
+		dprintk(3, "TG1_FMT(%d)\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+		/* Fall through */
+	case SV_TG_FMT_YUV422:
+		dprintk(3, "TG1_FMT(%d)\n",  camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+		/* Fall through */
+	case SV_TG_FMT_JPG:
+		dprintk(3, "TG1_FMT(%d)\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		regVal &= 0xFFFFFFFB;
+		regVal |= 0x00000008;
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), regVal); /*[2], PAK_EN=0, [3], PAK_SEL=1*/
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), 0xFFFFFFF8&regVal); /*[0-2], PAK_MODE=0*/
+		break;
+	default:
+		LOG_INF("Unsupported TG fmt:%d\n", camsv_top_cfg.camsv_top_ctl.FMT_SEL.Bits.TG1_FMT);
+	}
+
+	//pix mode
+	switch (m_PixMode) {
+	case ePixMode_1:
+		dprintk(3, "pixmode(%d) _1_pix_\n", m_PixMode);
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), 0xFFFFFFCF&regVal); /*[4-5], PAK_DBL_MODE=0*/
+		break;
+	case ePixMode_2:
+		dprintk(3, "pixmode(%d) _2_pix_\n", m_PixMode);
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), (0xFFFFFFCF&regVal)|(0x1<<4)); /*[4-5], PAK_DBL_MODE=1*/
+		break;
+	case ePixMode_4:
+		dprintk(3, "pixmode(%d) _4_pix_\n", m_PixMode);
+		regVal = ISP_RD32(CAMSV_REG_PAK(m_hwModule));
+		ISP_WR32(CAMSV_REG_PAK(m_hwModule), (0xFFFFFFCF&regVal)|(0x2<<4)); /*[4-5], PAK_DBL_MODE=2*/
+		break;
+	default:
+		LOG_INF("- unsupported pix mode:0x%x\n", m_PixMode);
+		break;
+	}
+
+	//reset FH
+	ISP_WR32(CAMSV_REG_DMA_FRAME_HEADER_EN(m_hwModule), 0x0);
+
+	//special
+	regVal = ISP_RD32(CAMSV_REG_DMA_RSV1(m_hwModule))&0x7fffffff;
+	ISP_WR32(CAMSV_REG_DMA_RSV1(m_hwModule), regVal);
+	ISP_WR32(CAMSV_REG_DMA_RSV6(m_hwModule), 0xffffffff);
+
+	//dma performance
+	regVal = ISP_RD32(CAMSV_REG_SPECIAL_FUN_EN(m_hwModule))|0x61000000;
+	ISP_WR32(CAMSV_REG_SPECIAL_FUN_EN(m_hwModule), regVal);
+
+	dprintk(3, "en(0x%08x),fmtSel(0x%08x),intEn(0x%08x),SubSample(0x%x)\n",
+		ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule)),
+		camsv_top_cfg.camsv_top_ctl.FMT_SEL.Raw,
+		int_en, m_SubSample);
+
+	dprintk(3, "CAMSV_TOP_CTRL::_config-\n");
+
+	return 0;
+}
+
+int CAMSV_TOP_CTRL_enable(struct CAMSV_TOP_CTRL camsv_top_cfg)
+{
+	unsigned int m_hwModule = camsv_top_cfg.m_hwModule;
+	unsigned int regVal;
+	struct ISP_CLEAR_IRQ_ST clr_irq;
+	struct ISP_CLEAR_IRQ_STRUCT    ClearIrq;
+	bool m_bBusy = MFALSE;
+	int i = 0;
+	unsigned long flags = 0;
+	unsigned int dbg[3] = {m_hwModule, ISP_IRQ_TYPE_INT_CAMSV_0_ST, 11};
+	int ret = 0;
+
+	dprintk(3, "CAMSV_TOP_CTRL::_enable+, m_hwModule %d\n", m_hwModule);
+
+	clr_irq.Status = ClearIrq.EventInfo.Status = SW_PASS1_DON_ST;
+	clr_irq.UserKey = ClearIrq.EventInfo.UserKey = 0x0;
+	clr_irq.St_type = ClearIrq.EventInfo.St_type = SIGNAL_INT;
+	ClearIrq.Type = ISP_IRQ_TYPE_INT_CAMSV_0_ST;
+
+	// CAMSV clock enable
+	regVal = ISP_RD32(CAMSV_REG_CLK_EN(m_hwModule));
+	/*[0]TG_DP_CK_EN=1, [2]PAK_DP_CK_EN=1, [15]DMA_DP_CK_EN=1*/
+	ISP_WR32(CAMSV_REG_CLK_EN(m_hwModule), regVal|0x00008005);
+
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(m_hwModule));/*[0] CMOS_EN, check */
+
+	if (regVal&0x1) {
+		//ISP_CLEAR_IRQ
+		i = ClearIrq.EventInfo.UserKey;/*avoid line over 120 char per line */
+		dprintk(3, "ISP_CLEAR_IRQ:Type(%d),Status(0x%x), st_status(%d), IrqStatus(0x%x)\n",
+			ClearIrq.Type, ClearIrq.EventInfo.Status, ClearIrq.EventInfo.St_type,
+			IspInfo.IrqInfo.Status[ClearIrq.Type][ClearIrq.EventInfo.St_type][i]);
+		spin_lock_irqsave(&(IspInfo.SpinLockIrq[ClearIrq.Type]), flags);
+		IspInfo.IrqInfo.Status[ClearIrq.Type][ClearIrq.EventInfo.St_type][ClearIrq.EventInfo.UserKey] &=
+			(~ClearIrq.EventInfo.Status);
+		spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[ClearIrq.Type]), flags);
+
+		dprintk(3, "IspInfo.IrqInfo.Status(%x),Type(%d),St_type(%d),UserKey(%d)\n",
+			IspInfo.IrqInfo.Status[ClearIrq.Type][ClearIrq.EventInfo.St_type][ClearIrq.EventInfo.UserKey],
+			ClearIrq.Type, ClearIrq.EventInfo.St_type,
+			ClearIrq.EventInfo.UserKey);
+
+		//ISP_VF_LOG
+		ret = camsv_VF_LOG(dbg[0], dbg[1], dbg[2]);
+		dprintk(3, "LOCK WAKE LOCK, ret %d, regVal %x\n", ret, regVal);
+	} else {
+		LOG_INF("cmos_en is still off,start fail, regVal %x\n", regVal);
+		return -1;
+	}
+
+	m_bBusy = MTRUE;
+
+	dprintk(3, "CAMSV_TOP_CTRL::_enable-\n");
+
+	return 0;
+}
+
+int CAMSV_TOP_CTRL_disable(struct camsv_device *camsv, struct CAMSV_TOP_CTRL camsv_top_cfg)
+{
+	unsigned int m_hwModule = camsv_top_cfg.m_hwModule;
+	unsigned int regVal;
+	struct ISP_WAIT_IRQ_ST irq;
+	bool ret;
+	MUINT32 regstatus;
+	unsigned int waitTgIdleCount = 10;
+	MUINT32 _cnt = 0, i = 0;
+	bool bForce = camsv_top_cfg.bForce;
+	bool m_bBusy = MFALSE;
+	struct ISP_BUFFER_CTRL_STRUCT buf_ctrl;
+	MUINT32 _clrPort = 1;
+	MUINT32 _dma[1] = {_camsv_imgo_};
+	unsigned int dbg[3] = {m_hwModule, ISP_IRQ_TYPE_INT_CAMSV_0_ST, 10};
+	int retv = 0;
+
+	dprintk(3, "CAMSV_TOP_CTRL::_disable, u4HwModule %d, bForce %d +",
+		camsv->camsv_module[camsv_top_cfg.m_hwModule-ISP_CAMSV0_IDX].camsv_port_input.u4HwModule, bForce);
+
+	irq.Clear  = ISP_IRQ_CLEAR_WAIT;
+	irq.Status = VS_INT_ST;
+	irq.St_type = SIGNAL_INT;
+	irq.Timeout = MIN_GRPFRM_TIME_MS * 2;
+	irq.UserKey = 0x0;
+	dbg[1] = camsv_VF_GET_IRQ_MODULE(
+		camsv->camsv_module[camsv_top_cfg.m_hwModule-ISP_CAMSV0_IDX].camsv_port_input.u4HwModule);
+
+	if (bForce == MFALSE) {
+		regVal = 0x1&(ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule)));/*[0], VFDATA_EN*/
+		if (regVal == 1) {
+			//ISP_VF_LOG
+			retv = camsv_VF_LOG(dbg[0], dbg[1], dbg[2]);
+			do {
+				++_cnt;
+				ret = camsv_VF_WAIT_IRQ(&camsv->camsv_module[camsv_top_cfg.m_hwModule-ISP_CAMSV0_IDX],
+					&irq);
+				if (ret == MFALSE) {
+					LOG_INF("wait Irq faile(%d)\n", _cnt);
+					break;
+				}
+				dprintk(3, "wait vsync %d time for TG idle\n", _cnt);
+				/*[8-13], TG_CAM_CS*/
+				regVal = (0x00003F00&(ISP_RD32(CAMSV_REG_TG_INTER_ST(m_hwModule))))>>8;
+				dprintk(3, "regstatus = 0x%08x", regstatus);
+			} while (((0x00003F00&(ISP_RD32(CAMSV_REG_TG_INTER_ST(m_hwModule))))>>8) != 1 &&
+			_cnt < waitTgIdleCount);
+		} else {
+			regVal = (0x00003F00&(ISP_RD32(CAMSV_REG_TG_INTER_ST(m_hwModule))))>>8;/*[8-13], TG_CAM_CS*/
+			if (regVal == 1)
+				LOG_INF("vf_en off + tg idle, no wait vsync\n");
+		}
+	} else {
+		regVal = 0x1&(ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule)));/*[0], VFDATA_EN*/
+		if (regVal) {
+			//ISP_VF_LOG
+			retv = camsv_VF_LOG(dbg[0], dbg[1], dbg[2]);
+		}
+		//reset first for forced stop
+		dprintk(3, "CAMSV TOP reset\n");
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x4); /*SW_RST: 1*/
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x0); /*SW_RST: 0*/
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x1); /*IMGO_RST_TRIG: 1*/
+
+		while ((ISP_RD32(CAMSV_REG_SW_CTL(m_hwModule)) != 0x3) && i++ < 1000) { // Polling IMGO_RST_ST to 1
+			dprintk(3, "CAMSV resetting.. %d ..CAMSV_SW_CTL:0x%x\n", i,
+				ISP_RD32(CAMSV_REG_SW_CTL(m_hwModule)));
+		}
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x0); // IMGO_RST_TRIG: 0
+	}
+
+	regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+	ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0xBFFFFFFF&regVal); /*[30], DB_EN=0 disable double buffer */
+	ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0x0); //disable double buffer, TG_EN, DOWN_SAMPLE, PAK_EN, IMGO_EN
+	ISP_WR32(CAMSV_REG_FMT_SEL(m_hwModule), 0x0);
+	ISP_WR32(CAMSV_REG_INT_EN(m_hwModule), 0x0);
+
+	//close  fbc
+	//FBC on uni will be closed at the _disable() of uni_top
+	//FBC of STT pipe will be closed at STT pipe
+	ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), 0x0);
+
+	regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+	ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0x40000000|regVal);/*[30], DB_EN=1, enable double buffer*/
+
+	buf_ctrl.module = (m_hwModule-2); /* transfer ISP_DEV_NODE_ENUM to ISP_IRQ_TYPE_ENUM */
+	while (_clrPort--) {
+		buf_ctrl.ctrl = ISP_RT_BUF_CTRL_CLEAR;
+		buf_ctrl.buf_id = (enum _isp_dma_enum_)_dma[_clrPort];
+		buf_ctrl.data_ptr = NULL;
+		buf_ctrl.pExtend = 0;
+
+		if (ISP_Buf_CTRL_FUNC_V4L2((unsigned long)&buf_ctrl))
+			LOG_INF("ERROR:clear buf ctrl fail");
+	}
+
+	//reset later for non-forced stop
+	if (bForce == MFALSE) {
+		dprintk(3, "CAMSV TOP reset\n");
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x4); /*SW_RST: 1*/
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x0); /*SW_RST: 0*/
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x1); /*IMGO_RST_TRIG: 1*/
+
+		while ((ISP_RD32(CAMSV_REG_SW_CTL(m_hwModule)) != 0x3) && i++ < 10000) { // Polling IMGO_RST_ST to 1
+			dprintk(3, "CAMSV resetting...CAMSV_SW_CTL:0x%x\n", ISP_RD32(CAMSV_REG_SW_CTL(m_hwModule)));
+		}
+		ISP_WR32(CAMSV_REG_SW_CTL(m_hwModule), 0x0); // IMGO_RST_TRIG: 0
+	}
+
+	// CAMSV clock disable
+	regVal = ISP_RD32(CAMSV_REG_CLK_EN(m_hwModule));
+	/*[0]TG_DP_CK_EN=0, [2]PAK_DP_CK_EN=0, [15]DMA_DP_CK_EN=0*/
+	ISP_WR32(CAMSV_REG_CLK_EN(m_hwModule), regVal&0xFFFF7FFA);
+
+	m_bBusy = MFALSE;
+
+	//register dump after stop()
+	if (_cnt == waitTgIdleCount)
+		LOG_INF("DUMP CAMSV REGISTER When cannot wait TG idle\n");
+
+	dprintk(3, "CAMSV_TOP_CTRL::_disable-");
+
+	return 0;
+}
+
+MUINT32 DMAO_CAMSV_GetCropXUnitBussize(MUINT32 input, MUINT32 pixelBit, MUINT32 bussize)
+{
+	switch (pixelBit) {
+	case 10:
+	case 12:
+		return ((input * pixelBit) / ((bussize+1)<<3));
+	default:
+		return input;
+	}
+}
+
+MUINT32 DMAO_CAMSV_GetCropXUnitPixel(MUINT32 input, MUINT32 pixelBit, MUINT32 bussize)
+{
+	switch (pixelBit) {
+	case 10:
+	case 12:
+		return ((input * ((bussize+1)<<3)) / pixelBit);
+	default:
+		return input;
+	}
+}
+
+int DMAO_CAMSV_config(struct IspDMACfg dma_cfg)
+{
+	unsigned int m_hwModule = dma_cfg.m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "DMAO_CAMSV_B::_config+\n");
+
+	dprintk(3, "memBuf pa(%x),memBuf ofst(%08X), Header addr(%08X)\n",
+		dma_cfg.memBuf.base_pAddr,
+		dma_cfg.memBuf.ofst_addr,
+		dma_cfg.Header_Addr);
+
+	{
+		MUINT32 new_crop_x = 0;
+		//Header_CAMSV_IMGO fh_imgo; // camsv no need to handle header
+		ISP_WR32(CAMSV_REG_IMGO_XSIZE(m_hwModule), dma_cfg.size.xsize - 1);
+		ISP_WR32(CAMSV_REG_IMGO_YSIZE(m_hwModule), dma_cfg.size.h - 1);
+		ISP_WR32(CAMSV_REG_IMGO_STRIDE(m_hwModule), dma_cfg.size.stride);
+
+		//
+		dma_cfg.bus_size = DMAO_CAMSV_BusSizeCal(dma_cfg);
+
+		//if (this->fmt_sel.Bits.TG1_FMT != SV_TG_FMT_RAW8) {
+		switch (dma_cfg.bus_size) {
+		case 0: //  8-bit bus size
+			if (dma_cfg.size.stride % 1 != 0) {
+				dprintk(3, "IMGO stride(%lu) need 1-alignment\n", dma_cfg.size.stride);
+				return -1;
+			}
+			regVal = (ISP_RD32(CAMSV_REG_IMGO_STRIDE(m_hwModule))|(1<<24)|(0<<16));
+			ISP_WR32(CAMSV_REG_IMGO_STRIDE(m_hwModule), regVal);
+			break;
+		case 1: // 16-bit bus size
+			if (dma_cfg.size.stride % 2 != 0) {
+				dprintk(3, "IMGO stride(%lu) need 2-alignment\n", dma_cfg.size.stride);
+				return -1;
+			}
+			regVal = (ISP_RD32(CAMSV_REG_IMGO_STRIDE(m_hwModule))|(1<<24)|(1<<16));
+			ISP_WR32(CAMSV_REG_IMGO_STRIDE(m_hwModule), regVal);
+			break;
+		case 3:// 32-bit bus size
+			if (dma_cfg.size.stride % 4 != 0) {
+				dprintk(3, "IMGO stride(%lu) need 4-alignment\n", dma_cfg.size.stride);
+				return -1;
+			}
+			regVal = (ISP_RD32(CAMSV_REG_IMGO_STRIDE(m_hwModule))|(1<<24)|(3<<16));
+			ISP_WR32(CAMSV_REG_IMGO_STRIDE(m_hwModule), regVal);
+			break;
+		case 7:// 64-bit bus size
+			if (dma_cfg.size.stride % 8 != 0) {
+				dprintk(3, "IMGO stride(%lu) need 8-alignment\n", dma_cfg.size.stride);
+				return -1;
+			}
+			regVal = (ISP_RD32(CAMSV_REG_IMGO_STRIDE(m_hwModule))|(1<<24)|(7<<16));
+			ISP_WR32(CAMSV_REG_IMGO_STRIDE(m_hwModule), regVal);
+			break;
+		}
+		//}
+
+		new_crop_x = DMAO_CAMSV_GetCropXUnitBussize(dma_cfg.crop.x, dma_cfg.pixel_byte, dma_cfg.bus_size);
+		dprintk(3, "****** new_crop_x(%d), GetCropXUnitBussize(x %d, pixel_byte %d, bus_size %d)\n",
+			new_crop_x, dma_cfg.crop.x, dma_cfg.pixel_byte, dma_cfg.bus_size);
+
+		ISP_WR32(CAMSV_REG_IMGO_CROP(m_hwModule), ((dma_cfg.crop.y << 16) | new_crop_x));
+		//reverse for FH below
+		new_crop_x = DMAO_CAMSV_GetCropXUnitPixel(new_crop_x, dma_cfg.pixel_byte, dma_cfg.bus_size);
+		dprintk(3, "****** new_crop_x(%d)\n", new_crop_x);
+
+		ISP_WR32(CAMSV_REG_IMGO_CON(m_hwModule), 0x80000080);
+		ISP_WR32(CAMSV_REG_IMGO_CON2(m_hwModule), 0x00020002);
+		ISP_WR32(CAMSV_REG_IMGO_CON3(m_hwModule), 0x00020002);
+	}
+
+	ISP_RD32(CAMSV_REG_CLK_EN(m_hwModule));
+
+	dprintk(3, "****** Reg(CAMSV_MODULE_EN)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_FMT_SEL)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_FMT_SEL(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_PAK)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_PAK(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_IMGO_XSIZE)=0x%08x(%d)\n",
+		ISP_RD32(CAMSV_REG_IMGO_XSIZE(m_hwModule)), ISP_RD32(CAMSV_REG_IMGO_XSIZE(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_IMGO_YSIZE)=0x%08x(%d)\n",
+		ISP_RD32(CAMSV_REG_IMGO_YSIZE(m_hwModule)), ISP_RD32(CAMSV_REG_IMGO_YSIZE(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_IMGO_STRIDE)=0x%08x([15:0]:%d)\n",
+		ISP_RD32(CAMSV_REG_IMGO_STRIDE(m_hwModule)), (ISP_RD32(CAMSV_REG_IMGO_STRIDE(m_hwModule)))&0xFFFF);
+	dprintk(3, "****** Reg(CAMSV_IMGO_CON)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_IMGO_CON(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_IMGO_CON2)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_IMGO_CON2(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_IMGO_CON3)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_IMGO_CON3(m_hwModule)));
+	dprintk(3, "****** Reg(CAMSV_IMGO_CROP)=0x%08x\n",
+		ISP_RD32(CAMSV_REG_IMGO_CROP(m_hwModule)));
+
+	dprintk(3, "size(w %lu,h %lu,stride %lu,xsize %lu), pixel_byte(%d)\n",
+		dma_cfg.size.w,
+		dma_cfg.size.h,
+		dma_cfg.size.stride,
+		dma_cfg.size.xsize,
+		dma_cfg.pixel_byte);
+
+	dprintk(3, "crop(x %d,y %d,w %lu,h %lu),format(%d),fps(0x%x),cropX_inbussize(%d)\n",
+		dma_cfg.crop.x,
+		dma_cfg.crop.y,
+		dma_cfg.crop.w,
+		dma_cfg.crop.h,
+		dma_cfg.format,
+		dma_cfg.m_fps,
+		DMAO_CAMSV_GetCropXUnitBussize(dma_cfg.crop.x,
+		dma_cfg.pixel_byte, dma_cfg.bus_size));
+
+	dprintk(3, "DMAO_CAMSV_B::_config-\n");
+
+	return 0;
+}
+
+int DMAO_CAMSV_enable(struct IspDMACfg dma_cfg)
+{
+	unsigned int m_hwModule = dma_cfg.m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "DMAO_CAMSV_B::_enable+\n");
+
+	regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+	ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0x00000010|regVal);/*[4], IMGO_EN=1*/
+	regVal = ISP_RD32(CAMSV_REG_DMA_FRAME_HEADER_EN(m_hwModule));
+	ISP_WR32(CAMSV_REG_DMA_FRAME_HEADER_EN(m_hwModule), 0x00000001|regVal);/*[0], FRAME_HEADER_EN_IMGO=1*/
+
+	dprintk(3, "DMAO_CAMSV_B::_enable-\n");
+	return 0;
+}
+
+int DMAO_CAMSV_disable(struct IspDMACfg dma_cfg)
+{
+	unsigned int m_hwModule = dma_cfg.m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "DMAO_CAMSV_B::_disable+\n");
+
+	{
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		ISP_WR32(CAMSV_REG_MODULE_EN(m_hwModule), 0xFFFFFFEF|regVal);/*[4], IMGO_EN=0*/
+		regVal = ISP_RD32(CAMSV_REG_DMA_FRAME_HEADER_EN(m_hwModule));
+		ISP_WR32(CAMSV_REG_DMA_FRAME_HEADER_EN(m_hwModule), 0xFFFFFFFE|regVal);/*[0], FRAME_HEADER_EN_IMGO=0*/
+	}
+
+	dprintk(3, "DMAO_CAMSV_B::_disable-\n");
+
+	return 0;
+}
+
+int DMAO_CAMSV_setBaseAddr(struct IspDMACfg dma_cfg)
+{
+	unsigned int m_hwModule = dma_cfg.m_hwModule;
+
+	dprintk(3, "DMAO_B::setBaseAddr+[]:pa(0x%x_0x%08X),ofst(0x%X)\n",
+	dma_cfg.memBuf.base_pAddr,
+	dma_cfg.Header_Addr,
+	dma_cfg.memBuf.ofst_addr);
+	if (dma_cfg.memBuf.ofst_addr != 0)
+		dprintk(3, "support no damo offsetaddress,bypass offset setting\n");
+
+	ISP_WR32(CAMSV_REG_IMGO_OFST_ADDR(m_hwModule), 0x0);
+	ISP_WR32(CAMSV_REG_IMGO_BASE_ADDR(m_hwModule), (unsigned int)dma_cfg.memBuf.base_pAddr);
+
+	return 0;
+}
+
+static MUINT32 DMAO_CAMSV_BusSizeCal(struct IspDMACfg dma_cfg)
+{
+	switch (dma_cfg.fmt_sel.Bits.TG1_FMT) {
+	case SV_TG_FMT_YUV422:
+		switch (dma_cfg.m_PixMode) {
+		case ePixMode_1:
+			return 1; // 16-bit
+		case ePixMode_2:
+			return 1; // 16-bit
+		case ePixMode_4:
+			return 3; // 32-bit
+		default:
+			LOG_INF("Unsopported pix mode: %d\n", dma_cfg.m_PixMode);
+		}
+		break;
+	case SV_TG_FMT_JPG:
+	//case SV_TG_FMT_RAW8: // jinn - remove
+		switch (dma_cfg.m_PixMode) {
+		case ePixMode_1:
+				return 0; // 8-bit
+		case ePixMode_2:
+			return 1; // 16-bit
+		case ePixMode_4:
+			return 3; // 32-bit
+		default:
+			LOG_INF("Unsopported pix mode: %d\n", dma_cfg.m_PixMode);
+		}
+		break;
+	case SV_TG_FMT_RAW8: // jinn - added
+	case SV_TG_FMT_RAW10:
+	case SV_TG_FMT_RAW12:
+	case SV_TG_FMT_RAW14:
+	default://bayer
+		switch (dma_cfg.m_PixMode) {
+		case ePixMode_1:
+			return 1; // 16-bit
+		case ePixMode_2:
+			return 3; // 32-bit
+		case ePixMode_4:
+			return 7; // 64-bit
+		default:
+			LOG_INF("Unsopported pix mode: %d\n", dma_cfg.m_PixMode);
+		}
+	break;
+	}
+	LOG_INF("BusSizeCal fail\n");
+	return 0;
+}
+
+bool CAMSV_BUF_CTRL_PipeCheck(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	struct ISP_RAW_INT_STATUS err_status = {0};
+	bool chkrst = MTRUE;
+
+	dprintk(3, "start PipeCheck when deque fail at wait signal\n");
+
+	if (err_status.ispIntErr & SV_HW_IMGO_ERR_ST) { //SV_HW_IMGO_ERR_ST
+		LOG_INF("all dmao err status:\n");
+		CAMSV_PIPE_CHECK_DMAO_STATUS(camsv_buf_ctl);
+		chkrst = MFALSE;
+	} else
+		LOG_INF("find no dma err\n");
+
+	if (CAMSV_PIPE_CHECK_TG_CHECK(camsv_buf_ctl, err_status.ispIntErr) == MTRUE)
+		dprintk(3, "TG check pass!\n");
+	else
+		chkrst = MFALSE;
+
+	if ((chkrst == MTRUE) && (err_status.ispIntErr == 0)) {
+		if (CAMSV_PIPE_CHECK_ENQUE_CHECK(camsv_buf_ctl) == MFALSE)
+			goto EXIT;
+		else
+			dprintk(3, "find no err, plz look for previous err ,like enque flow err\n");
+	}
+	dprintk(3, "start dump CAMSV_%d register\n", m_hwModule);
+
+EXIT:
+
+	return MTRUE;
+}
+
+enum E_BC_STATUS CAMSV_BUF_CTRL_waitBufReady(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	#define _LOOP_  (5)
+	enum E_BC_STATUS ret = eCmd_Pass;
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	unsigned int regVal;
+	struct ISP_WAIT_IRQ_ST irq;
+	MUINT32 loopCnt = _LOOP_;
+	char str[128] = {'\0'};
+	MUINT32 FbcCnt;
+
+	//fbc reg dbg log
+	BUF_CTRL_CAMSV_IMGO_FBC_STATUS(camsv_buf_ctl);
+
+	irq.Clear = ISP_IRQ_CLEAR_WAIT;
+	irq.UserKey = 0;
+	irq.Timeout = CAMSV_BUF_CTRL_estimateTimeout(camsv_buf_ctl, 1);
+	dprintk(3, "irq.Timeout: %d\n", irq.Timeout);
+	irq.St_type = SIGNAL_INT;
+	irq.Status = SV_SW_PASS1_DON_ST;
+
+	do {
+		if (camsv_buf_ctl.m_buf_cnt != 0) {
+			regVal = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL2(m_hwModule));
+			FbcCnt = regVal&0x7F;/*[0-6], FBC_CNT*/
+
+			if (FbcCnt < camsv_buf_ctl.m_buf_cnt) {
+				if (loopCnt == _LOOP_) {
+					dprintk(3,
+						"dma:CAMSV_BUF_CTRL already have avail_buf on dram, bWaitBufReady = 0");
+					return eCmd_Pass;
+				}
+				goto EXIT;
+			} else {
+				if (loopCnt == _LOOP_)
+					snprintf(str, sizeof(str),
+						"dma:CAMSV_BUF_CTRL start wait:[enque record:%d_%d],",
+					camsv_buf_ctl.m_buf_cnt, FbcCnt);
+				else {
+					char _tmp[16];
+
+					snprintf(_tmp, sizeof(_tmp), "[%d]time,", ((_LOOP_-loopCnt)+1));
+					strncat(str, _tmp, strlen(_tmp));
+				}
+			}
+		} else {
+			if (loopCnt == _LOOP_) {
+#define FALSE_PASS1_DONE
+#ifdef FALSE_PASS1_DONE
+				ret =  eCmd_Fail;
+				goto EXIT;
+#endif
+			} else {//save how many times of wait_irq before sw enque
+				char _tmp[16];
+
+				snprintf(_tmp, sizeof(_tmp), "[%d],", ((_LOOP_-loopCnt)+1)+1);
+				strncat(str, _tmp, strlen(_tmp));
+			}
+		}
+
+	//if suspend
+	if (CAMSV_BUF_CTRL_C_FSM_GetFSM(camsv_buf_ctl) == E_SUSPEND) {
+		ret = eCmd_Suspending_Pass;
+		goto EXIT;
+	}
+
+	irq.Clear = ISP_IRQ_CLEAR_NONE;
+
+	} while (--loopCnt > 0);
+
+EXIT:
+	switch (ret) {
+	case eCmd_Fail:
+		if (camsv_buf_ctl.m_buf_cnt != 0) {
+			LOG_INF("%s, m_buf_cnt(%d) waitbufready fail. start fail check",
+				str, camsv_buf_ctl.m_buf_cnt);
+			CAMSV_BUF_CTRL_PipeCheck(camsv_buf_ctl);
+		} else {
+			LOG_INF("%s, m_buf_cnt(%d), waitbufready fail is caused by no enque",
+				str, camsv_buf_ctl.m_buf_cnt);
+		}
+		break;
+	case eCmd_Pass:
+		dprintk(3, "%s, waitbufready pass", str);
+		break;
+	case eCmd_Suspending_Pass:
+		dprintk(3, "%s, suspend pass", str);
+		break;
+	default:
+		LOG_INF("unsupported status:%d\n", ret);
+		ret = eCmd_Fail;
+	break;
+	}
+	return ret;
+}
+
+MINT32 CAMSV_BUF_CTRL_config(struct CAMSV_BUF_CTRL *camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl->m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "BUF_CTRL_CAMSV_IMGO:CAMSV_BUF_CTRL::config+\n");
+
+	ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), 0x0);
+	regVal = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule));
+	ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), regVal|0x00010000);/*[16], FBC_MODE=1*/
+
+	camsv_buf_ctl->m_buf_cnt = 0;
+
+	dprintk(3, "BUF_CTRL_CAMSV_IMGO:CAMSV_BUF_CTRL::config-\n");
+
+	return 0;
+}
+
+MINT32 CAMSV_BUF_CTRL_enable(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	unsigned int regVal;
+	unsigned int m_sub_ratio = camsv_buf_ctl.m_sub_ratio;
+
+	dprintk(3, "BUF_CTRL_CAMSV_IMGO:CAMSV_BUF_CTRL::_enable+\n");
+	if (m_sub_ratio)
+		dprintk(3, "subsample:0x%x\n", m_sub_ratio);
+	else
+		dprintk(3, "subsample:0x%x\n", 0);
+
+	regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule));/*[0], VFDATA_EN*/
+
+	if ((regVal&0x1) == 1) { /* 0x1A050504 */
+		LOG_INF("can't enable FBC at streaming\n");
+		return 1;
+	}
+
+	regVal = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule));
+	if (m_sub_ratio) {
+		/*[24-31], SUB_RATIO=m_sub_ratio*/
+		ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), (regVal&0x00FFFFFF)|(m_sub_ratio<<24));
+	} else {
+		/*[24-31], SUB_RATIO=0*/
+		ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), regVal&0x00FFFFFF);
+	}
+	regVal = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule));
+	/*[15], FBC_EN=1, [22], DMA_RING_EN=1*/
+	ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), regVal|0x00408000);
+
+	dprintk(3, "BUF_CTRL_CAMSV_IMGO:CAMSV_BUF_CTRL::_enable-\n");
+	return 0;
+}
+
+MINT32 CAMSV_BUF_CTRL_disable(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	unsigned int regVal;
+
+	dprintk(3, "CAMSV_BUF_CTRL::_disable+\n");
+
+	regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule));/*[0], VFDATA_EN*/
+	if ((regVal&0x1) == 1)
+		dprintk(3, "FBC at streaming\n");
+
+	ISP_WR32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule), 0x0);
+
+
+	dprintk(3, "CAMSV_BUF_CTRL::_disable-\n");
+
+	return 0;
+}
+
+bool CAMSV_BUF_CTRL_suspend(struct camsv_Module *camsv_m,
+				unsigned int *arg)
+{
+	struct CAMSV_BUF_CTRL *camsv_buf_ctl;
+	unsigned int m_hwModule;
+	unsigned int regVal;
+	bool ret = MTRUE;
+
+	camsv_buf_ctl = &camsv_m->camsv_FbcImgo;
+	m_hwModule = camsv_buf_ctl->m_hwModule;
+
+	//lock state
+	CAMSV_BUF_CTRL_C_FSM_SetFSM(E_NORMAL, MTRUE, camsv_buf_ctl);
+
+	dprintk(3, "CAMSV_BUF_CTRL::suspend+, m_hwModule %d\n", m_hwModule);
+
+	regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule));/*[0], VFDATA_EN*/
+	if ((regVal&0x1) == 0) {
+		ret = MFALSE;
+		//unlock
+		CAMSV_BUF_CTRL_C_FSM_SetFSM(E_NORMAL, MFALSE, camsv_buf_ctl);
+	} else {
+		//ISP_VF_LOG
+		camsv_VF_LOG(m_hwModule, ISP_IRQ_TYPE_INT_CAMSV_0_ST, 10);
+		//no need to wait vsync.   pipe with cam's suspend
+		camsv_buf_ctl->m_buf_cnt = 0;
+		//unlock && change state
+		CAMSV_BUF_CTRL_C_FSM_SetFSM(E_SUSPEND, MFALSE, camsv_buf_ctl);
+	}
+
+	return ret;
+}
+
+bool CAMSV_BUF_CTRL_resume(struct camsv_Module *camsv_m,
+				unsigned int *arg)
+{
+	struct CAMSV_BUF_CTRL *camsv_buf_ctl;
+	unsigned int m_hwModule;
+	unsigned int regVal;
+	bool ret = MTRUE;
+
+	camsv_buf_ctl = &camsv_m->camsv_FbcImgo;
+	m_hwModule = camsv_buf_ctl->m_hwModule;
+
+	//lock state
+	CAMSV_BUF_CTRL_C_FSM_SetFSM(E_NORMAL, MTRUE, camsv_buf_ctl);
+
+	dprintk(3, "CAMSV_BUF_CTRL::resume+ m_hwModule %d\n", m_hwModule);
+	regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule));/*[0], VFDATA_EN*/
+	if ((regVal&0x1) == 1) {
+		ret = MFALSE;
+		//unlock
+		CAMSV_BUF_CTRL_C_FSM_SetFSM(E_NORMAL, MFALSE, camsv_buf_ctl);
+	} else {
+		//ISP_VF_LOG
+		camsv_VF_LOG(m_hwModule, ISP_IRQ_TYPE_INT_CAMSV_0_ST, 11);
+		//unlock
+		CAMSV_BUF_CTRL_C_FSM_SetFSM(E_RESUME, MFALSE, camsv_buf_ctl);
+	}
+
+	return ret;
+}
+
+static bool CAMSV_BUF_CTRL_C_FSM_SetFSM(enum E_STATE state, bool lock, struct CAMSV_BUF_CTRL *camsv_buf_ctl)
+{
+	bool ret = MTRUE;
+
+	if (lock)
+		return ret;
+
+	dprintk(3, "target op:%d, current op:%d\n", state, camsv_buf_ctl->m_FSM.m_State);
+	switch (state) {
+	case E_NORMAL:
+		if (camsv_buf_ctl->m_FSM.m_State != E_NORMAL)
+			ret = MFALSE;
+		break;
+	case E_SUSPEND:
+		if (camsv_buf_ctl->m_FSM.m_State == E_NORMAL)
+			camsv_buf_ctl->m_FSM.m_State = E_SUSPEND;
+		else
+			ret = MFALSE;
+		break;
+	case E_RESUME:
+		if (camsv_buf_ctl->m_FSM.m_State == E_SUSPEND)
+			camsv_buf_ctl->m_FSM.m_State = E_NORMAL;
+		break;
+	default:
+		ret = MFALSE;
+		break;
+	}
+
+	if (ret != MTRUE)
+		LOG_INF("error: target op:%d, current op:%d\n", state, camsv_buf_ctl->m_FSM.m_State);
+	return ret;
+}
+
+static enum E_STATE CAMSV_BUF_CTRL_C_FSM_GetFSM(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	return camsv_buf_ctl.m_FSM.m_State;
+}
+
+
+static MUINT32 CAMSV_BUF_CTRL_estimateTimeout(struct CAMSV_BUF_CTRL camsv_buf_ctl, MUINT32 subSample)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	MUINT32 _t_ms = (camsv_buf_ctl.m_recentFrmTimeMs[m_hwModule][0] >=
+		camsv_buf_ctl.m_recentFrmTimeMs[m_hwModule][1]) ?
+		camsv_buf_ctl.m_recentFrmTimeMs[m_hwModule][0] :
+		camsv_buf_ctl.m_recentFrmTimeMs[m_hwModule][1];
+
+	_t_ms *= subSample;
+	_t_ms = (_t_ms < MIN_GRPFRM_TIME_MS) ? MIN_GRPFRM_TIME_MS : _t_ms;
+	_t_ms *= 2;
+
+	return _t_ms;
+}
+
+/**
+ *    check whether this fail is caused by some dmao waiting for enque or not
+ *    no rsso check
+ */
+static bool CAMSV_PIPE_CHECK_ENQUE_CHECK(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	unsigned int regVal;
+	bool rst = MTRUE;
+	MUINT32 imgo_en;
+	MUINT32 imgo_fbc;
+
+	regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));/*[4], IMGO_EN*/
+	imgo_en = (regVal & 0x10);
+
+	if (imgo_en) {
+		imgo_fbc = (0x7F & ISP_RD32(CAMSV_REG_FBC_IMGO_CTL2(m_hwModule)));/*[0-6], FBC_CNT*/
+		if (imgo_fbc == 0) {
+			LOG_INF("IMGO have no enque record\n");
+			rst = MFALSE;
+		}
+	}
+
+	return rst;
+}
+
+static bool CAMSV_PIPE_CHECK_DMAO_STATUS(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	unsigned int regVal;
+	MUINT32 dma_err[_camsv_max_];
+
+	memcpy((void *)dma_err, &g_DmaErr_CAM[m_hwModule], sizeof(unsigned int)*_camsv_max_);
+
+	if (dma_err[0] & 0xffff) {
+		regVal = ISP_RD32(CAMSV_REG_MODULE_EN(m_hwModule));
+		LOG_INF("[cam dmao:0x%x]IMGO ERR:0x%x\n",
+		regVal,
+		dma_err[0]);
+	} else
+		LOG_INF("read no cur dma_err err status\n");
+
+	return MTRUE;
+}
+
+static bool CAMSV_PIPE_CHECK_TG_CHECK(struct CAMSV_BUF_CTRL camsv_buf_ctl, MUINT32 intErrStatus)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+	unsigned int regVal;
+	bool rst = MTRUE;
+	union CAMSV_REG_TG_SEN_GRAB_PXL TG_W;
+	union CAMSV_REG_TG_SEN_GRAB_LIN TG_H;
+	MUINT32 TG_IN_W, TG_IN_V;
+	MUINT32 TG_IN_W_R, TG_IN_V_R;
+	MUINT32 DATA_CNT_R;
+	MUINT32 tmp;
+	union CAMSV_REG_INT_STATUS_U irqStatCheck;
+
+	regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(m_hwModule));/*[0], VFDATA_EN*/
+	if ((regVal & 0x1) == 0) {
+		LOG_INF("viewfinder is not opened yet,flase alarm\n");
+		rst = MTRUE;
+		goto EXIT;
+	}
+
+	irqStatCheck.Raw = intErrStatus;
+
+	if (irqStatCheck.Bits.TG_GBERR_ST_T)
+		rst = MFALSE;
+
+	TG_W.Raw = ISP_RD32(CAMSV_REG_TG_SEN_GRAB_PXL(m_hwModule));
+	TG_H.Raw = ISP_RD32(CAMSV_REG_TG_SEN_GRAB_LIN(m_hwModule));
+	/*[16-30], PXL_CNT*/
+	TG_IN_W = (0x7FFF0000 & ISP_RD32(CAMSV_REG_TG_FRMSIZE_ST(m_hwModule))) >> 16;
+	/*[0-13], LINE_CNT*/
+	TG_IN_V = (0x00003FFF & ISP_RD32(CAMSV_REG_TG_FRMSIZE_ST(m_hwModule)));
+	/*[16-30], PXL_CNT*/
+	TG_IN_W_R = (0x7FFF0000 & ISP_RD32(CAMSV_REG_TG_FRMSIZE_ST_R(m_hwModule))) >> 16;
+	/*[0-13], LINE_CNT*/
+	TG_IN_V_R = (0x00003FFF & ISP_RD32(CAMSV_REG_TG_FRMSIZE_ST_R(m_hwModule)));
+	DATA_CNT_R = ISP_RD32(CAMSV_REG_TG_DAT_NO_R(m_hwModule));/*[0-31], DAT_NO*/
+
+	if (TG_IN_W < (TG_W.Bits.PXL_E - TG_W.Bits.PXL_S)) {
+		LOG_INF("seninf horizontal data is small than grab window_w:%d_%d\n",
+			TG_IN_W, (TG_W.Bits.PXL_E - TG_W.Bits.PXL_S));
+		rst = MFALSE;
+	}
+	if (TG_IN_V < (TG_H.Bits.LIN_E - TG_H.Bits.LIN_S)) {
+		LOG_INF("seninf vertical data is small than grab window_v:%d_%d\n",
+			TG_IN_V, (TG_H.Bits.LIN_E - TG_H.Bits.LIN_S));
+		rst = MFALSE;
+	}
+
+	/*[8-13], TG_CAM_CS*/
+	tmp = (0x00003F00 & ISP_RD32(CAMSV_REG_TG_INTER_ST(m_hwModule))) >> 8;
+	switch (tmp) {
+	case 2: //
+	case 16:
+		if (TG_IN_W_R != TG_IN_W) {
+			regVal = ISP_RD32(CAMSV_REG_TG_DAT_NO_R(m_hwModule));/*[0-31], DAT_NO*/
+			if (regVal == DATA_CNT_R) {
+				LOG_INF(
+					"seninf have no input data for over 1ms when TG is under exposure,cur data:0x%x\n",
+					DATA_CNT_R);
+				rst = MFALSE;
+			}
+		}
+		break;
+	default:
+		LOG_INF("TG is in idle status:0x%x\n", tmp);
+		rst = MTRUE;
+		break;
+	}
+
+	if (rst == MFALSE)
+		LOG_INF("TG checkl fail\n");
+
+EXIT:
+
+	return rst;
+
+}
+
+static void BUF_CTRL_CAMSV_IMGO_FBC_STATUS(struct CAMSV_BUF_CTRL camsv_buf_ctl)
+{
+	unsigned int m_hwModule = camsv_buf_ctl.m_hwModule;
+
+	dprintk(3, "BUF_CTRL_CAMSV_IMGO::FBC_STATUS: 0x%08x_0x%08x, m_buf_cnt(%d)\n",
+		ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(m_hwModule)),
+		ISP_RD32(CAMSV_REG_FBC_IMGO_CTL2(m_hwModule)),
+		camsv_buf_ctl.m_buf_cnt
+	);
+}
+
+void CAM_TIMESTAMP_CAMSV_Enable(struct CAMSV_TIMESTAMP camsv_timestamp)
+{
+	unsigned int m_hwModule = camsv_timestamp.m_hwModule;
+	unsigned int regVal;
+
+	regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(m_hwModule));
+	ISP_WR32(CAMSV_REG_TG_SEN_MODE(m_hwModule), (0x00010000|regVal)); /*[16], TIME_STP_EN=1*/
+}
+
+bool CAM_TIMESTAMP_CAMSV_TimeStamp_SrcClk(struct CAMSV_TIMESTAMP camsv_timestamp)
+{
+	enum TSTMP_MODE m_stmpMode = camsv_timestamp.m_stmpMode;
+	MUINT32 m_TimeClk = camsv_timestamp.m_TimeClk;
+	unsigned int m_hwModule = camsv_timestamp.m_hwModule;
+	unsigned int regVal;
+
+	//clk : 10 -> 1Mhz, 20 -> 2Mhz
+	LOG_INF("ClkSrc : %d Hz, m_hwModule %d\n", m_TimeClk*100000, m_hwModule);
+
+	if (m_stmpMode == LOCAL_MODE) {
+		regVal = ISP_RD32(CAMSV_REG_TIME_STAMP_CTL(m_hwModule));
+		ISP_WR32(CAMSV_REG_TIME_STAMP_CTL(m_hwModule), (0xFFFFFFFE&regVal)); /*[0], TG_TIME_STAMP_SEL=0*/
+	} else {
+		regVal = ISP_RD32(CAMSV_REG_TIME_STAMP_CTL(m_hwModule));
+		ISP_WR32(CAMSV_REG_TIME_STAMP_CTL(m_hwModule), (0x00000001|regVal)); /*[0], TG_TIME_STAMP_SEL=1*/
+	}
+
+	return MTRUE;
+}
+
+/*******************************************************************************
+ *	V4L2 CamSV configs end
+ ********************************************************************************/
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void ISP_EnableClock(bool En)
+{
+	if (En) {
+		int cg_con1 = 0, cg_con2 = 0;
+		/*LOG_INF("CCF:prepare_enable clk");*/
+		spin_lock(&(IspInfo.SpinLockClock));
+		G_u4EnableClockCount++;
+		spin_unlock(&(IspInfo.SpinLockClock));
+		cg_con1 = ISP_RD32(CAMSYS_REG_CG_CON);
+		CamSv_Pwn_On();
+		Prepare_Enable_ccf_clock(); /* !!cannot be used in spinlock!! */
+		cg_con2 = ISP_RD32(CAMSYS_REG_CG_CON);
+
+		LOG_INF("camsys cg org:0x%x new:0x%x enableCount:%d\n",
+			cg_con1, cg_con2, G_u4EnableClockCount);
+
+		/* Disable CAMSYS_HALT1_EN: LSCI & BPCI, To avoid ISP halt keep arise */
+		LOG_INF("###### NEED UPDATE CAMSYS_HALT1_EN: LSCI & BPCI SETTING #######\n");
+	} else {                /* Disable clock. */
+		/*LOG_INF("CCF:disable_unprepare clk\n");*/
+		spin_lock(&(IspInfo.SpinLockClock));
+		if (G_u4EnableClockCount == 0) {
+			spin_unlock(&(IspInfo.SpinLockClock));
+			LOG_INF("G_u4EnableClockCount aleady be 0, do nothing\n");
+			return;
+		}
+
+		G_u4EnableClockCount--;
+		spin_unlock(&(IspInfo.SpinLockClock));
+		Disable_Unprepare_ccf_clock(); /* !!cannot be used in spinlock!! */
+		CamSv_Pwn_Off();
+	}
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline void ISP_Reset(int module)
+{
+	LOG_DBG(" Reset module(%d), CAMSYS clk gate(0x%x)\n",
+		module, ISP_RD32(CAMSYS_REG_CG_CON));
+
+	switch (module) {
+	case ISP_CAMSV0_IDX:
+	case ISP_CAMSV1_IDX:
+	case ISP_CAMSV2_IDX:
+	case ISP_CAMSV3_IDX:
+	case ISP_CAMSV4_IDX:
+	case ISP_CAMSV5_IDX: {
+		/* Reset CAMSV flow */
+		ISP_WR32(CAMSV_REG_SW_CTL(module), 0x4); /* SW_RST: 1 */
+		ISP_WR32(CAMSV_REG_SW_CTL(module), 0x0); /* SW_RST: 0 */
+		ISP_WR32(CAMSV_REG_SW_CTL(module), 0x1); /* IMGO_RST_TRIG: 1 */
+		while (ISP_RD32(CAMSV_REG_SW_CTL(module)) != 0x3) { /* Polling IMGO_RST_ST to 1 */
+			LOG_DBG("CAMSV resetting... module:%d\n", module);
+		}
+		ISP_WR32(CAMSV_REG_SW_CTL(module), 0x0); /* IMGO_RST_TRIG: 0 */
+
+		break;
+	}
+	default:
+		LOG_NOTICE("Not support reset module:%d\n", module);
+		break;
+	}
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static long ISP_Buf_CTRL_FUNC_V4L2(unsigned long Param)
+{
+	int Ret = 0;
+	enum _isp_dma_enum_ rt_dma;
+	unsigned int i = 0;
+	struct ISP_BUFFER_CTRL_STRUCT         rt_buf_ctrl;
+
+	/*  */
+	if ((void __user *)Param == NULL)  {
+		LOG_NOTICE("[rtbc]NULL Param");
+		return -EFAULT;
+	}
+	/*  */
+	memcpy(&rt_buf_ctrl, (void *)Param, sizeof(struct ISP_BUFFER_CTRL_STRUCT));
+	{
+		if (rt_buf_ctrl.module >= ISP_IRQ_TYPE_AMOUNT) {
+			LOG_NOTICE("[rtbc]not supported module:0x%x\n", rt_buf_ctrl.module);
+			return -EFAULT;
+		}
+
+		if (pstRTBuf[rt_buf_ctrl.module] == NULL)  {
+			LOG_NOTICE("[rtbc]NULL pstRTBuf, module:0x%x\n", rt_buf_ctrl.module);
+			return -EFAULT;
+		}
+
+		rt_dma = rt_buf_ctrl.buf_id;
+		if (rt_dma >= _camsv_max_) {
+			LOG_NOTICE("[rtbc]buf_id error:0x%x\n", rt_dma);
+			return -EFAULT;
+		}
+
+		/*  */
+		switch (rt_buf_ctrl.ctrl) {
+		case ISP_RT_BUF_CTRL_CLEAR:
+			/*  */
+			if (IspInfo.DebugMask & ISP_DBG_BUF_CTRL)
+				LOG_INF("[rtbc][%d][CLEAR]:rt_dma(%d)\n", rt_buf_ctrl.module, rt_dma);
+			/*  */
+
+			memset((void *)IspInfo.IrqInfo.LastestSigTime_usec[rt_buf_ctrl.module],
+				0, sizeof(unsigned int) * 32);
+			memset((void *)IspInfo.IrqInfo.LastestSigTime_sec[rt_buf_ctrl.module],
+				0, sizeof(unsigned int) * 32);
+			/* remove, cause clear will be involked only when current module r totally stopped */
+			/* spin_lock_irqsave(&(IspInfo.SpinLockIrq[irqT_Lock]), flags); */
+
+			/* reset active record*/
+			pstRTBuf[rt_buf_ctrl.module]->ring_buf[rt_dma].active = MFALSE;
+			memset((char *)&pstRTBuf[rt_buf_ctrl.module]->ring_buf[rt_dma],
+				0x00, sizeof(struct ISP_RT_RING_BUF_INFO_STRUCT));
+			/* init. frmcnt before vf_en */
+			for (i = 0; i < ISP_RT_BUF_SIZE; i++)
+				pstRTBuf[rt_buf_ctrl.module]->ring_buf[rt_dma].data[i].image.frm_cnt =
+					_INVALID_FRM_CNT_;
+
+			switch (rt_buf_ctrl.module) {
+			case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+			case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+			case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+			case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+			case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+			case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+				if (pstRTBuf[rt_buf_ctrl.module]->ring_buf[_camsv_imgo_].active == MFALSE) {
+					sof_count[rt_buf_ctrl.module] = 0;
+					g1stSof[rt_buf_ctrl.module] = MTRUE;
+					g_ISPIntStatus[rt_buf_ctrl.module].ispIntErr = 0;
+					g_ISPIntStatus[rt_buf_ctrl.module].ispInt3Err = 0;
+					g_ISPIntStatus_SMI[rt_buf_ctrl.module].ispIntErr = 0;
+					g_ISPIntStatus_SMI[rt_buf_ctrl.module].ispInt3Err = 0;
+					pstRTBuf[rt_buf_ctrl.module]->dropCnt = 0;
+					pstRTBuf[rt_buf_ctrl.module]->state = 0;
+				}
+
+				break;
+			default:
+				LOG_NOTICE("unsupported module:0x%x\n", rt_buf_ctrl.module);
+				break;
+			}
+
+			/* spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[irqT_Lock]), flags); */
+
+			break;
+		case ISP_RT_BUF_CTRL_DMA_EN: {
+			unsigned char array[_camsv_max_];
+			unsigned int z;
+			unsigned char *pExt;
+
+			if (rt_buf_ctrl.pExtend == NULL) {
+				LOG_NOTICE("NULL pExtend");
+				Ret = -EFAULT;
+				break;
+			}
+
+			pExt = (unsigned char *)(rt_buf_ctrl.pExtend);
+			for (z = 0; z < _camsv_max_; z++) {
+				if (get_user(array[z], (unsigned char *)pExt) == 0) {
+					pstRTBuf[rt_buf_ctrl.module]->ring_buf[z].active = array[z];
+					if (IspInfo.DebugMask & ISP_DBG_BUF_CTRL)
+						LOG_INF("[rtbc][DMA_EN]:dma_%d:%d", z, array[z]);
+				} else {
+					LOG_NOTICE("[rtbc][DMA_EN]:get_user failed(%d)", z);
+					Ret = -EFAULT;
+				}
+				pExt++;
+			}
+		}
+		break;
+		case ISP_RT_BUF_CTRL_MAX:   /* Add this to remove build warning. */
+			/* Do nothing. */
+			break;
+
+		}
+	}
+
+	return Ret;
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static int ISP_WaitIrq(struct ISP_WAIT_IRQ_STRUCT *WaitIrq)
+{
+	int Ret = 0, Timeout = WaitIrq->EventInfo.Timeout;
+	unsigned long flags; /* old: unsigned int flags;*//* FIX to avoid build warning */
+	unsigned int irqStatus;
+
+	int idx = my_get_pow_idx(WaitIrq->EventInfo.Status);
+	struct timeval time_getrequest;
+	struct timeval time_ready2return;
+	bool freeze_passbysigcnt = false;
+	unsigned long long  sec = 0;
+	unsigned long       usec = 0;
+
+	/* do_gettimeofday(&time_getrequest); */
+	sec = cpu_clock(0);     /* ns */
+	do_div(sec, 1000);    /* usec */
+	usec = do_div(sec, 1000000);    /* sec and usec */
+	time_getrequest.tv_usec = usec;
+	time_getrequest.tv_sec = sec;
+
+	if (WaitIrq->Type >= ISP_IRQ_TYPE_AMOUNT) {
+		LOG_NOTICE("WaitIrq: type error(%d)", WaitIrq->Type);
+		return -EFAULT;
+	}
+
+	if (WaitIrq->EventInfo.St_type >= ISP_IRQ_ST_AMOUNT) {
+		LOG_NOTICE("WaitIrq: st_type error(%d)", WaitIrq->EventInfo.St_type);
+		return -EFAULT;
+	}
+
+	if (WaitIrq->EventInfo.UserKey >= IRQ_USER_NUM_MAX || WaitIrq->EventInfo.UserKey < 0) {
+		LOG_NOTICE("WaitIrq: userkey error(%d)", WaitIrq->EventInfo.UserKey);
+		return -EFAULT;
+	}
+
+#ifdef ENABLE_WAITIRQ_LOG
+	/* Debug interrupt */
+	if (IspInfo.DebugMask & ISP_DBG_INT) {
+		if (WaitIrq->EventInfo.Status & IspInfo.IrqInfo.Mask[WaitIrq->Type][WaitIrq->EventInfo.St_type]) {
+			if (WaitIrq->EventInfo.UserKey > 0) {
+				LOG_INF("+WaitIrq Clear(%d), Type(%d), Status(0x%08x), Timeout(%d/%d),user(%d)\n",
+					WaitIrq->EventInfo.Clear,
+					WaitIrq->Type,
+					WaitIrq->EventInfo.Status,
+					Timeout, WaitIrq->EventInfo.Timeout,
+					WaitIrq->EventInfo.UserKey);
+			}
+		}
+	}
+#endif
+
+	/* 1. wait type update */
+	if (WaitIrq->EventInfo.Clear == ISP_IRQ_CLEAR_STATUS) {
+		spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+/* LOG_DBG("WARNING: Clear(%d), Type(%d): IrqStatus(0x%08X) has been cleared",
+ * WaitIrq->EventInfo.Clear,WaitIrq->Type,IspInfo.IrqInfo.Status[WaitIrq->Type]);
+ */
+		IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey] &=
+		(~WaitIrq->EventInfo.Status);
+		spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+		return Ret;
+	}
+	{
+		spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+		if (WaitIrq->EventInfo.Status &
+		IspInfo.IrqInfo.MarkedFlag[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey]) {
+			spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+			/* force to be non_clear wait if marked before, and check the request wait timing */
+			/* if the entry time of wait request after mark is before signal, */
+			/* we freese the counting for passby signal */
+			/*  */
+			/* v : kernel receive mark request */
+			/* o : kernel receive wait request */
+			/* : return to user */
+			/*  */
+			/* case: freeze is true, and passby signal count = 0 */
+			/*  */
+			/* |                                              | */
+			/* |                                  (wait)    | */
+			/* |       v-------------o++++++ | */
+			/* |                                              | */
+			/* Sig                                            Sig */
+			/*  */
+			/* case: freeze is false, and passby signal count = 1 */
+			/*  */
+			/* |                                              | */
+			/* |                                              | */
+			/* |       v---------------------- |-o  (return) */
+			/* |                                              | */
+			/* Sig                                            Sig */
+			/*  */
+
+			freeze_passbysigcnt = !(ISP_GetIRQState(WaitIrq->Type, WaitIrq->EventInfo.St_type,
+				WaitIrq->EventInfo.UserKey, WaitIrq->EventInfo.Status));
+		} else {
+			spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+			if (WaitIrq->EventInfo.Clear == ISP_IRQ_CLEAR_WAIT) {
+				spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+				if (IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type]
+					[WaitIrq->EventInfo.UserKey] & WaitIrq->EventInfo.Status)
+					IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type]
+					[WaitIrq->EventInfo.UserKey] &= (~WaitIrq->EventInfo.Status);
+
+				spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+			} else if (WaitIrq->EventInfo.Clear == ISP_IRQ_CLEAR_ALL) {
+				spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+				IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type]
+					[WaitIrq->EventInfo.UserKey] = 0;
+				spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+			}
+		}
+	}
+
+	/* Store irqinfo status in here to redeuce time of spin_lock_irqsave */
+	spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+	irqStatus = IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey];
+	spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+	if (WaitIrq->EventInfo.Clear == ISP_IRQ_CLEAR_NONE) {
+		if (IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey]
+			& WaitIrq->EventInfo.Status) {
+#ifdef ENABLE_WAITIRQ_LOG
+			LOG_INF("Already have irq!!!: WaitIrq Timeout(%d) Clear(%d), Type(%d), StType(%d)",
+			", IrqStatus(0x%08x), WaitStatus(0x%08x), Timeout(%d), userKey(%d)\n",
+				WaitIrq->EventInfo.Timeout,
+				WaitIrq->EventInfo.Clear,
+				WaitIrq->Type,
+				WaitIrq->EventInfo.St_type,
+				irqStatus,
+				WaitIrq->EventInfo.Status,
+				WaitIrq->EventInfo.Timeout,
+				WaitIrq->EventInfo.UserKey);
+#endif
+			goto NON_CLEAR_WAIT;
+		}
+	}
+
+#ifdef ENABLE_WAITIRQ_LOG
+	LOG_INF("before wait: Clear(%d) Type(%d) StType(%d) Sts(0x%08x) WaitSts(0x%08x) Timeout(%d) userKey(%d)\n",
+		WaitIrq->EventInfo.Clear,
+		WaitIrq->Type,
+		WaitIrq->EventInfo.St_type,
+		irqStatus,
+		WaitIrq->EventInfo.Status,
+		WaitIrq->EventInfo.Timeout,
+		WaitIrq->EventInfo.UserKey);
+#endif
+	//LOG_INF("1 Timeout %d\n", Timeout);
+	/* 2. start to wait signal */
+	Timeout = wait_event_interruptible_timeout(
+			  IspInfo.WaitQueueHead[WaitIrq->Type],
+			  ISP_GetIRQState(WaitIrq->Type, WaitIrq->EventInfo.St_type, WaitIrq->EventInfo.UserKey,
+			  WaitIrq->EventInfo.Status),
+			  ISP_MsToJiffies(WaitIrq->EventInfo.Timeout));
+
+	//LOG_INF("2 Timeout %d\n", Timeout);
+
+	/* check if user is interrupted by system signal */
+	if ((Timeout != 0) && (!ISP_GetIRQState(WaitIrq->Type, WaitIrq->EventInfo.St_type, WaitIrq->EventInfo.UserKey,
+		WaitIrq->EventInfo.Status))) {
+		LOG_INF("interrupted by system signal,return value(%d),irq Type/User/Sts(0x%x/%d/0x%x)\n",
+			Timeout, WaitIrq->Type, WaitIrq->EventInfo.UserKey, WaitIrq->EventInfo.Status);
+		Ret = -ERESTARTSYS;  /* actually it should be -ERESTARTSYS */
+		goto EXIT;
+	}
+	/* timeout */
+	if (Timeout == 0) {
+		/* Store irqinfo status in here to redeuce time of spin_lock_irqsave */
+		spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+		irqStatus =
+		IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey];
+		spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+		LOG_NOTICE(
+		"ERRRR WaitIrq Clear(%d) Type(%d) StType(%d) Status(0x%08X) WaitStatus(0x%08X) Timeout(%d) key(%d)\n",
+		WaitIrq->EventInfo.Clear,
+		WaitIrq->Type,
+		WaitIrq->EventInfo.St_type,
+		irqStatus,
+		WaitIrq->EventInfo.Status,
+		WaitIrq->EventInfo.Timeout,
+		WaitIrq->EventInfo.UserKey);
+
+		Ret = -EFAULT;
+		goto EXIT;
+	}
+#ifdef ENABLE_WAITIRQ_LOG
+	else {
+		/* Store irqinfo status in here to redeuce time of spin_lock_irqsave */
+		spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+		irqStatus =
+			IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey];
+		spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+		LOG_INF(
+		"Done WaitIrq Clear(%d) Type(%d) StType(%d) Status(0x%08x) WaitStatus(0x%08x) Timeout(%d) key(%d)\n",
+		WaitIrq->EventInfo.Clear,
+		WaitIrq->Type,
+		WaitIrq->EventInfo.St_type,
+		irqStatus,
+		WaitIrq->EventInfo.Status,
+		WaitIrq->EventInfo.Timeout,
+		WaitIrq->EventInfo.UserKey);
+	}
+#endif
+
+NON_CLEAR_WAIT:
+	/* 3. get interrupt and update time related information that would be return to user */
+	/* do_gettimeofday(&time_ready2return); */
+	sec = cpu_clock(0);     /* ns */
+	do_div(sec, 1000);    /* usec */
+	usec = do_div(sec, 1000000);    /* sec and usec */
+	time_ready2return.tv_usec = usec;
+	time_ready2return.tv_sec = sec;
+
+
+	spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+	IspInfo.IrqInfo.Status[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey]
+		&= (~WaitIrq->EventInfo.Status); /* clear the status if someone get the irq */
+	spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+	LOG_INF(
+		"Done WaitIrq Clear(%d) Type(%d) StType(%d) Status(0x%08x) WaitStatus(0x%08x) Timeout(%d) key(%d)\n",
+		WaitIrq->EventInfo.Clear,
+		WaitIrq->Type,
+		WaitIrq->EventInfo.St_type,
+		irqStatus,
+		WaitIrq->EventInfo.Status,
+		WaitIrq->EventInfo.Timeout,
+		WaitIrq->EventInfo.UserKey);
+
+EXIT:
+	/* 4. clear mark flag / reset marked time / reset time related infor and passedby signal count */
+	spin_lock_irqsave(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+	if (WaitIrq->EventInfo.Status &
+	IspInfo.IrqInfo.MarkedFlag[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey]) {
+		IspInfo.IrqInfo.MarkedFlag[WaitIrq->Type][WaitIrq->EventInfo.St_type][WaitIrq->EventInfo.UserKey] &=
+		(~WaitIrq->EventInfo.Status);
+		IspInfo.IrqInfo.MarkedTime_usec[WaitIrq->Type][idx][WaitIrq->EventInfo.UserKey] = 0;
+		IspInfo.IrqInfo.MarkedTime_sec[WaitIrq->Type][idx][WaitIrq->EventInfo.UserKey] = 0;
+		IspInfo.IrqInfo.PassedBySigCnt[WaitIrq->Type][idx][WaitIrq->EventInfo.UserKey] = 0;
+	}
+	spin_unlock_irqrestore(&(IspInfo.SpinLockIrq[WaitIrq->Type]), flags);
+
+
+	return Ret;
+}
+
+
+#ifdef ENABLE_KEEP_ION_HANDLE
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void ISP_ion_init(void)
+{
+	if (!pIon_client && g_ion_device)
+		pIon_client = ion_client_create(g_ion_device, "camera_isp");
+
+	if (!pIon_client) {
+		LOG_NOTICE("invalid ion client!\n");
+		return;
+	}
+
+	if (IspInfo.DebugMask & ISP_DBG_ION_CTRL)
+		LOG_INF("create ion client 0x%p\n", pIon_client);
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void ISP_ion_uninit(void)
+{
+	if (!pIon_client) {
+		LOG_NOTICE("invalid ion client!\n");
+		return;
+	}
+
+	if (IspInfo.DebugMask & ISP_DBG_ION_CTRL)
+		LOG_INF("destroy ion client 0x%p\n", pIon_client);
+
+	ion_client_destroy(pIon_client);
+
+	pIon_client = NULL;
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void ISP_ion_free_handle(struct ion_client *client, struct ion_handle *handle)
+{
+	if (!client) {
+		LOG_NOTICE("invalid ion client!\n");
+		return;
+	}
+	if (!handle)
+		return;
+
+	if (IspInfo.DebugMask & ISP_DBG_ION_CTRL)
+		LOG_INF("[ion_free_hd] Hd(0x%p)\n", handle);
+
+	ion_free(client, handle);
+
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void ISP_ion_free_handle_by_module(unsigned int module)
+{
+	int i, j;
+	int nFd;
+	struct ion_handle *p_IonHnd;
+	struct T_ION_TBL *ptbl = &gION_TBL[module];
+
+	if (IspInfo.DebugMask & ISP_DBG_ION_CTRL)
+		LOG_INF("[ion_free_hd_by_module]%d\n", module);
+
+	for (i = 0; i < _dma_max_wr_; i++) {
+		unsigned int jump = i*_ion_keep_max_;
+
+		for (j = 0; j < _ion_keep_max_ ; j++) {
+			spin_lock(&(ptbl->pLock[i]));
+			/* */
+			if (ptbl->pIonFd[jump + j] == 0) {
+				spin_unlock(&(ptbl->pLock[i]));
+				continue;
+			}
+			nFd = ptbl->pIonFd[jump + j];
+			p_IonHnd = ptbl->pIonHnd[jump + j];
+			/* */
+			ptbl->pIonFd[jump + j] = 0;
+			ptbl->pIonHnd[jump + j] = NULL;
+			ptbl->pIonCt[jump + j] = 0;
+			spin_unlock(&(ptbl->pLock[i]));
+			/* */
+			if (IspInfo.DebugMask & ISP_DBG_ION_CTRL) {
+				LOG_INF("ion_free: dev(%d)dma(%d)j(%d)fd(%d)Hnd(0x%p)\n",
+					module, i, j, nFd, p_IonHnd);
+			}
+			ISP_ion_free_handle(pIon_client, p_IonHnd);/*can't in spin_lock*/
+		}
+	}
+}
+
+#endif
+
+/**************** Videobuf2 interface ****************/
+
+static void camsv_buffer_done(struct camsv_Module *camsv_m)
+{
+	struct list_head	*capture = &camsv_m->capture;
+	struct camsv_buffer *bufs;
+	int i = 0;
+	unsigned int next;
+	int bufs_queued_counter = camsv_m->bufs_queued.counter;
+
+	next = (((int)(camsv_m->bufs_next-bufs_queued_counter)) >= 0 ?
+		(camsv_m->bufs_next-bufs_queued_counter) :
+		(CAMSV_MAX_BUFFERS+camsv_m->bufs_next-bufs_queued_counter));
+
+	dprintk(4,
+		"%s &camsvq->capture[0] %p, &camsvq->bufs[0] %p, bufs_queued %d, camsvq->bufs_next %d, next %d\n",
+		__func__, &camsv_m->capture,
+		&camsv_m->bufs[0], bufs_queued_counter, camsv_m->bufs_next, next);
+
+	bufs = list_first_entry(capture, struct camsv_buffer, queue);
+
+	dprintk(4, "bufs %p\n", bufs);
+
+	if (bufs) {
+		dprintk(4, "bufs_userptr %lx, %lx, vb2_queue %p\n",
+			bufs->vbb.vb2_buf.planes[0].m.userptr,
+			bufs->vbb.vb2_buf.planes[1].m.userptr,
+			bufs->vbb.vb2_buf.vb2_queue);
+
+		for (i = next; i < (next+bufs_queued_counter); i++) {
+			/* Find out which buffer(s) are ready */
+			if (camsv_m->bufs[i]) {
+				do {
+					vb2_buffer_done(&camsv_m->bufs[i]->vbb.vb2_buf, VB2_BUF_STATE_DONE);
+				} while (0);
+
+				dprintk(4, "q->bufs[%d]->vbb.vb2_buf %p, vb2_queue %p, counter %d\n",
+					i, &camsv_m->bufs[i]->vbb.vb2_buf,  camsv_m->bufs[i]->vbb.vb2_buf.vb2_queue,
+					camsv_m->bufs_queued.counter);
+
+				atomic_inc(&camsv_m->frame_sequence);
+				atomic_dec(&camsv_m->bufs_queued);
+				camsv_m->bufs[i] = NULL;
+			}
+			list_del(&bufs->queue);
+			bufs = list_first_entry(capture, struct camsv_buffer, queue);
+			dprintk(4, "next bufs %p\n", bufs);
+		}
+		for (i = 0; i < CAMSV_MAX_BUFFERS; i++) {
+			if (camsv_m->bufs[i]) {
+				dprintk(3, "list q->bufs[%d]->vbb.vb2_buf %p, vb2_queue %p, counter %d\n",
+					i, &camsv_m->bufs[i]->vbb.vb2_buf,  camsv_m->bufs[i]->vbb.vb2_buf.vb2_queue,
+					camsv_m->bufs_queued.counter);
+			}
+		}
+	}
+
+}
+
+static void camsv_queue_event_sof(struct camsv_Module *camsv_m)
+{
+	unsigned long long  sec = 0;
+	unsigned long       usec = 0;
+	struct v4l2_event event = {
+		.type = V4L2_EVENT_FRAME_SYNC,
+		.u.frame_sync.frame_sequence =
+			atomic_read(&camsv_m->frame_sequence),
+	};
+
+	sec = cpu_clock(0);	/* ns */
+	do_div(sec, 1000);	/* usec */
+	usec = do_div(sec, 1000000);	/* sec and usec */
+	event.timestamp.tv_sec = sec;
+	event.timestamp.tv_nsec = usec;
+	dprintk(3, "time %lld.%ld\n", sec, usec);
+	v4l2_event_queue(camsv_m->subdev.devnode, &event);
+}
+
+/*
+ * camsv_find_format - lookup color format by fourcc or/and media bus code
+ * @pixelformat: fourcc to match, ignored if null
+ * @mbus_code: media bus code to match, ignored if null
+ */
+static const struct camsv_fmt *camsv_find_format(const u32 *pixelformat,
+						const u32 *mbus_code)
+{
+	unsigned int i;
+
+	for (i = 0; i < NUM_FORMATS; i++) {
+		if (pixelformat && *pixelformat != camsv_formats[i].fourcc)
+			continue;
+		if (mbus_code && *mbus_code != camsv_formats[i].mbus_code)
+			continue;
+
+		return &camsv_formats[i];
+	}
+
+	return NULL;
+}
+
+static void *camsv_vb2_get_userptr(struct device *dev,
+	unsigned long vaddr, unsigned long size, enum dma_data_direction dma_dir,
+	unsigned long dma_attrs)
+{
+	struct camsv_vb2_pridata *priv;
+
+	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return ERR_PTR(-ENOMEM);
+	priv->vaddr = (void *)vaddr;
+	priv->size = size;
+	priv->dev = dev;
+	dprintk(3, "%s vaddr %p, size %ld\n", __func__, priv->vaddr, size);
+	return priv;
+}
+
+static void camsv_vb2_put_userptr(void *buf_priv)
+{
+	struct camsv_vb2_pridata *priv = buf_priv;
+
+	dprintk(3, "%s vaddr %p, size %ld\n", __func__, priv->vaddr, priv->size);
+	kzfree(buf_priv);
+}
+
+static inline u32 camsv_bytesperline(const unsigned int width)
+{
+	return DIV_ROUND_UP(width, 16) * 16;
+}
+
+static void camsv_vb2_return_all_buffers(struct camsv_Module *camsv_m,
+					enum vb2_buffer_state state)
+{
+	unsigned int i;
+
+	for (i = 0; i < CAMSV_MAX_BUFFERS; i++) {
+		if (camsv_m->bufs[i]) {
+
+			dprintk(3, "camsv_m %p, q->bufs[%d]->vbb.vb2_buf %p, vb2_queue %p, state %d, counter %d\n",
+				camsv_m, i, &camsv_m->bufs[i]->vbb.vb2_buf,
+				camsv_m->bufs[i]->vbb.vb2_buf.vb2_queue,
+				camsv_m->bufs[i]->vbb.vb2_buf.state, camsv_m->bufs_queued.counter);
+
+			if (camsv_m->bufs[i]->vbb.vb2_buf.state != VB2_BUF_STATE_DONE &&
+				camsv_m->bufs[i]->vbb.vb2_buf.state != VB2_BUF_STATE_DEQUEUED) {
+				if (camsv_m->bufs_queued.counter > 0)
+					atomic_dec(&camsv_m->bufs_queued);
+				vb2_buffer_done(&camsv_m->bufs[i]->vbb.vb2_buf, state);
+			}
+		}
+	}
+}
+
+/* Called after each buffer is allocated */
+static int camsv_vb2_buf_init(struct vb2_buffer *vb)
+{
+	struct camsv_device *camsv = vb2_get_drv_priv(vb->vb2_queue);
+	unsigned int length = vb->planes[0].length;
+	unsigned int pages = DIV_ROUND_UP(length, CAMSV_PAGE_SIZE);
+	int lops  = DIV_ROUND_UP(pages + 1, CAMSV_PAGE_SIZE / sizeof(u32));
+	int i = 0;
+
+	dprintk(3, "%s &camsv->camsv_module[0] %p, u4HwModule %d,  %d, length %d, lops %d\n",
+	__func__, &camsv->camsv_module[0],
+	camsv->camsv_module[0].camsv_port_input.u4HwModule,
+	camsv->camsv_module[0].camsv_port_output.u4HwModule,
+	length, lops);
+
+	for (i = 0; i < CAMSV_MAX_MODULES; i++) {
+		dprintk(3, "i %d, u4HwModule %d %d\n",
+			i, camsv->camsv_module[i].camsv_port_input.u4HwModule,
+			camsv->camsv_module[i].camsv_port_output.u4HwModule);
+	}
+
+	return 0;
+}
+
+static void camsv_vb2_buf_queue(struct vb2_buffer *vb)
+{
+	struct camsv_device *camsv = vb2_get_drv_priv(vb->vb2_queue);
+	struct camsv_Module *camsv_m = vb2q_to_camsv_module(vb->vb2_queue);
+	struct camsv_buffer *b =
+		container_of(vb, struct camsv_buffer, vbb.vb2_buf);
+	unsigned long flags;
+	unsigned int i, j, next = camsv_m->bufs_next;
+	int bufs_queued = atomic_inc_return(&camsv_m->bufs_queued);
+	MUINT32 _sof_idx = 0;
+	struct CAMSV_BUF_CTRL camsv_buf_ctl = {0};
+	unsigned int regVal;
+	MUINT32 _reg_time_stamp;
+
+	dprintk(3, "queue buffer %d, %p, u4HwModule %d, u4HwModule %d, next %d\n",
+		vb->index, &camsv->camsv_module[0], camsv_m->camsv_port_input.u4HwModule,
+		camsv_m->camsv_port_output.u4HwModule, next);
+	dprintk(3, " %p, u4HwModule %d, bufs_queued %d\n",
+		camsv_m, camsv_m->camsv_port_input.u4HwModule, bufs_queued);
+	dprintk(3, "state %d, %d, %d, %d, %d, %d userptr %lx\n",
+		vb->state, vb->type, vb->memory,
+		vb->num_planes, vb->planes[0].bytesused, vb->planes[0].length,
+		vb->planes[0].m.userptr);
+	dprintk(3, "b %p, %p, discard %d, offset %d, bufnum %d\n", b, &camsv_m->bufs[0],
+		b->discard, b->offset, b->bufnum);
+
+	for (i = 0; i < CAMSV_MAX_MODULES; i++) {
+		dprintk(3, "i %d, u4HwModule %d %d\n",
+			i, camsv->camsv_module[i].camsv_port_input.u4HwModule,
+			camsv->camsv_module[i].camsv_port_output.u4HwModule);
+	}
+
+	local_irq_save(flags);
+
+	//ISP_GET_CUR_SOF
+	_sof_idx = sof_count[ISP_IRQ_TYPE_INT_CAMSV_0_ST];
+	dprintk(3, "_sof_idx %d\n", _sof_idx);
+
+	////fbc reg dbg log
+	camsv_buf_ctl.m_hwModule = camsv_m->camsv_port_input.u4HwModule;// ISP_CAMSV0_IDX;
+	BUF_CTRL_CAMSV_IMGO_FBC_STATUS(camsv_buf_ctl);
+
+	// CamsvIOPipe not support replacemode
+	// enque to hw directly
+	regVal = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(camsv_buf_ctl.m_hwModule));//[15]FBC_EN = 1?
+	if (((regVal & 0x00008000)>>15) != 1)
+		dprintk(3, "can't enque before enabe fbc, regVal %x\n", regVal);
+	//enque buf pa
+	ISP_WR32(CAMSV_REG_FBC_IMGO_ENQ_ADDR(camsv_buf_ctl.m_hwModule), vb->planes[0].m.userptr);
+	//enque buf header pa
+	ISP_WR32(CAMSV_REG_IMGO_FH_BASE_ADDR(camsv_buf_ctl.m_hwModule), vb->planes[1].m.userptr);
+
+	regVal = ISP_RD32(CAMSV_REG_IMGO_FBC(camsv_buf_ctl.m_hwModule));
+	ISP_WR32(CAMSV_REG_IMGO_FBC(camsv_buf_ctl.m_hwModule), (regVal)|(0x1));/*[0]RCNT_INC = 1*/
+
+	_reg_time_stamp = ISP_RD32(CAMSV_REG_TG_TIME_STAMP(camsv_buf_ctl.m_hwModule));
+	dprintk(3, "PA(0x%lx_0x%lx),FH_VA(%lx),size(0x%x),enque_sof(%d),reg_timestmp(%d)\n",
+		vb->planes[0].m.userptr,
+		vb->planes[1].m.userptr,
+		vb->planes[2].m.userptr,
+		vb->planes[0].length,
+		_sof_idx,
+		_reg_time_stamp);
+
+	for (i = 0; i < CAMSV_MAX_BUFFERS; i++) {
+
+		if (!camsv_m->bufs[next]) {
+			dprintk(3, " b %p, queue %p list next %p, prev %p\n",
+				b, &b->queue, b->queue.next, b->queue.prev);
+
+			list_add_tail(&b->queue, &camsv_m->capture);
+			camsv_m->bufs[next] = b;
+			local_irq_restore(flags);
+			camsv_m->bufs_next = (next + 1) % CAMSV_MAX_BUFFERS;
+			for (j = 0; j < vb->num_planes; j++) {
+				vb2_set_plane_payload(vb, i,
+					camsv_m->format.plane_fmt[j].sizeimage);
+				dprintk(3, "update at %i , sizeimage %d\n",
+					j, camsv_m->format.plane_fmt[j].sizeimage);
+			}
+			dprintk(3, "queue at %i\n", next);
+			return;
+		}
+
+		dprintk(3, "warning entry %i was full!\n", next);
+		next = (next + 1) % CAMSV_MAX_BUFFERS;
+	}
+
+	local_irq_restore(flags);
+	dprintk(3, "error: all camsv entries were full!\n");
+	atomic_dec(&camsv_m->bufs_queued);
+	vb2_buffer_done(vb, VB2_BUF_STATE_ERROR);
+}
+
+static int camsv_vb2_queue_setup(struct vb2_queue *vq,
+				unsigned int *num_buffers,
+				unsigned int *num_planes,
+				unsigned int sizes[], struct device *alloc_devs[])
+{
+	struct camsv_device *camsv = vb2_get_drv_priv(vq);
+	struct camsv_Module *camsv_m = vb2q_to_camsv_module(vq);
+	unsigned int i, j;
+
+	dprintk(3, "vb2_queue %p (%p, %p) sizeimage %d, num_planes %d, num_buffers %d\n",
+		camsv_m, vq, &camsv_m->vbq, camsv_m->format.plane_fmt[0].sizeimage,
+		camsv_m->format.num_planes, *num_buffers);
+
+	dprintk(3, "camsv sizeimage %d, num_planes %d, num_buffers %d, u4HwModule %d\n",
+		camsv->camsv_module[0].format.plane_fmt[0].sizeimage,
+		camsv->camsv_module[0].format.num_planes, *num_buffers,
+		camsv_m->camsv_port_input.u4HwModule);
+
+	for (i = 0; i < CAMSV_MAX_MODULES; i++) {
+		dprintk(3, "i %d, u4HwModule %d %d\n",
+			i, camsv->camsv_module[i].camsv_port_input.u4HwModule,
+			camsv->camsv_module[i].camsv_port_output.u4HwModule);
+
+	}
+
+	//*num_planes = q->format[0].num_planes;
+	*num_planes = camsv_m->format.num_planes;
+
+	for (i = 0; i < *num_planes; ++i) {
+
+		dprintk(3, "i %d camsv sizeimage %d, num_planes %d, width %d ",
+			i, camsv_m->format.plane_fmt[0].sizeimage, camsv_m->format.num_planes,
+			camsv_m->format.width);
+		dprintk(3, "pixelformat %x, format-ptr %p\n",
+			camsv_m->format.pixelformat, &camsv_m->format);
+
+		for (j = 0; j < CAMSV_MAX_MODULES; ++j) {
+			dprintk(3, "%d, sizeimage %d, num_planes %d, width %d\n",
+				j, camsv_m->format.plane_fmt[0].sizeimage, camsv_m->format.num_planes,
+				camsv_m->format.width);
+		}
+
+		if (i == VIDEO_MAX_PLANES) {
+			*num_planes = 1;
+			break;
+		}
+
+		sizes[i] = camsv_m->format.plane_fmt[0].sizeimage;
+	}
+
+	*num_buffers = clamp_val(*num_buffers, 1, CAMSV_MAX_BUFFERS);
+
+	/* Initialize buffer queue */
+	for (i = 0; i < CAMSV_MAX_BUFFERS; i++)
+		camsv_m->bufs[i] = NULL;
+
+	atomic_set(&camsv_m->bufs_queued, 0);
+	camsv_m->bufs_first = 0;
+	camsv_m->bufs_next = 0;
+	dprintk(3, "sizes %d, %x, num_buffers %d\n", sizes[0], sizes[0], *num_buffers);
+	return 0;
+}
+
+
+/* Called when each buffer is freed */
+static void camsv_vb2_buf_cleanup(struct vb2_buffer *vb)
+{
+	unsigned int length = vb->planes[0].length;
+	int lops = DIV_ROUND_UP(DIV_ROUND_UP(length, CAMSV_PAGE_SIZE),
+				CAMSV_PAGE_SIZE / sizeof(u32));
+	dprintk(3, "%s length %d, lops %d\n", __func__, length, lops);
+}
+
+static int camsv_vb2_start_streaming(struct vb2_queue *vq, unsigned int count)
+{
+	struct camsv_device *camsv = vb2_get_drv_priv(vq);
+	struct camsv_Module *camsv_m = vb2q_to_camsv_module(vq);
+	int r;
+	struct CAMSV_TOP_CTRL camsv_top_cfg;
+
+	dprintk(3, "%s %d, q %p, u4HwModule %d, %d\n",
+		__func__, camsv->streaming, camsv_m, camsv_m->camsv_port_input.u4HwModule,
+		camsv_m->camsv_port_output.u4HwModule);
+
+	camsv->cur_module = camsv_m;
+	atomic_set(&camsv_m->frame_sequence, 0);
+
+	camsv_top_cfg.m_hwModule = camsv_m->camsv_port_input.u4HwModule;
+	r = CAMSV_TOP_CTRL_enable(camsv_top_cfg);
+	if (r)
+		goto fail_camsv_subdev;
+
+	camsv->streaming = true;
+	return 0;
+
+fail_camsv_subdev:
+	dev_dbg(camsv->dev, "failed to start streaming (%d)\n", r);
+	camsv_vb2_return_all_buffers(camsv_m, VB2_BUF_STATE_QUEUED);
+
+	return r;
+}
+
+static void camsv_vb2_stop_streaming(struct vb2_queue *vq)
+{
+	struct camsv_device *camsv = vb2_get_drv_priv(vq);
+	struct camsv_Module *camsv_m = vb2q_to_camsv_module(vq);
+
+	int r;
+	struct CAMSV_TOP_CTRL camsv_top_cfg;
+	struct CAMSV_BUF_CTRL camsv_buf_ctl;
+	struct IspDMACfg dma_cfg;
+	struct CAMSV_TG_CTRL camsv_tg_cfg;
+
+	dprintk(3, "%s streaming %d, vbq(%p), u4HwModule %d\n",
+		__func__, camsv->streaming, &camsv_m->vbq,
+		camsv_m->camsv_port_input.u4HwModule);
+
+	camsv_vb2_return_all_buffers(camsv_m, VB2_BUF_STATE_ERROR);
+
+	camsv_top_cfg.m_hwModule = camsv_m->camsv_port_input.u4HwModule;
+	camsv_top_cfg.bForce = MFALSE;
+	camsv_buf_ctl.m_hwModule = camsv_m->camsv_port_input.u4HwModule;
+	dma_cfg.m_hwModule = camsv_m->camsv_port_input.u4HwModule;
+	camsv_tg_cfg.m_hwModule = camsv_m->camsv_port_input.u4HwModule;
+
+	r = CAMSV_TOP_CTRL_disable(camsv, camsv_top_cfg);
+	dprintk(3, "CAMSV_TOP_CTRL_disable return: %d\n", r);
+
+	r = CAMSV_BUF_CTRL_disable(camsv_buf_ctl);
+	dprintk(3, "CAMSV_BUF_CTRL_disable return: %d\n", r);
+
+	r = DMAO_CAMSV_disable(dma_cfg);
+	dprintk(3, "DMAO_CAMSV_disable return: %d\n", r);
+
+	CAMSV_TG_CTRL_disable(camsv_tg_cfg);
+
+	camsv->streaming = false;
+
+}
+
+
+/**************** V4L2 interface ****************/
+
+static int camsv_v4l2_querycap(struct file *file, void *fh,
+			      struct v4l2_capability *cap)
+{
+	struct camsv_device *camsv = video_drvdata(file);
+
+	strlcpy(cap->driver, CAMSV_NAME, sizeof(cap->driver));
+	strlcpy(cap->card, CAMSV_DEVICE_NAME, sizeof(cap->card));
+	snprintf(cap->bus_info, sizeof(cap->bus_info),
+		 "CAMSV:%s", dev_name(camsv->dev));
+	cap->device_caps = V4L2_CAP_VIDEO_CAPTURE_MPLANE | V4L2_CAP_STREAMING;
+	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
+
+	dprintk(3, "%s bus_info %s, version %d\n", __func__, cap->bus_info, cap->version);
+
+	return 0;
+}
+
+static int camsv_v4l2_enum_fmt(struct file *file, void *fh,
+			      struct v4l2_fmtdesc *f)
+{
+	if (f->index >= NUM_FORMATS)
+		return -EINVAL;
+
+	f->pixelformat = camsv_formats[f->index].fourcc;
+	return 0;
+}
+
+static int camsv_v4l2_g_fmt(struct file *file, void *fh, struct v4l2_format *f)
+{
+	struct camsv_device *camsv = video_get_drvdata(video_devdata(file));
+	struct camsv_Module *camsv_m = videodev_to_camsv_module(video_devdata(file));
+
+	dprintk(3, "%s num_planes %d, userCount %d, module %d\n",
+		__func__, camsv_m->format.num_planes, camsv->userCount, camsv_m->camsv_port_input.u4HwModule);
+
+	f->fmt.pix_mp = camsv_m->format;
+
+	return 0;
+}
+
+static int camsv_v4l2_try_fmt(struct file *file, void *fh, struct v4l2_format *f)
+{
+	const struct camsv_fmt *fmt;
+	struct v4l2_pix_format_mplane *mpix = &f->fmt.pix_mp;
+
+	dprintk(3, "%s num_planes %d\n", __func__, mpix->num_planes);
+	fmt = camsv_find_format(&mpix->pixelformat, NULL);
+	if (!fmt)
+		fmt = &camsv_formats[0];
+	/* Only supports up to 4224x3136 */
+	if (mpix->width > CAMSV_IMAGE_MAX_WIDTH)
+		mpix->width = CAMSV_IMAGE_MAX_WIDTH;
+	if (mpix->height > CAMSV_IMAGE_MAX_LENGTH)
+		mpix->height = CAMSV_IMAGE_MAX_LENGTH;
+
+	mpix->num_planes = 2;
+	mpix->pixelformat = fmt->fourcc;
+	mpix->colorspace = V4L2_COLORSPACE_RAW;
+	mpix->field = V4L2_FIELD_NONE;
+	memset(mpix->reserved, 0, sizeof(mpix->reserved));
+	mpix->plane_fmt[0].bytesperline = camsv_bytesperline(mpix->width);
+	mpix->plane_fmt[0].sizeimage = mpix->plane_fmt[0].bytesperline *
+							mpix->height;
+	memset(mpix->plane_fmt[0].reserved, 0,
+	       sizeof(mpix->plane_fmt[0].reserved));
+
+	mpix->plane_fmt[1].bytesperline = camsv_bytesperline(mpix->width);
+	mpix->plane_fmt[1].sizeimage = mpix->plane_fmt[1].bytesperline *
+							mpix->height;
+	memset(mpix->plane_fmt[1].reserved, 0,
+	       sizeof(mpix->plane_fmt[1].reserved));
+
+
+	/* use default */
+	mpix->ycbcr_enc = V4L2_YCBCR_ENC_DEFAULT;
+	mpix->quantization = V4L2_QUANTIZATION_DEFAULT;
+	mpix->xfer_func = V4L2_XFER_FUNC_DEFAULT;
+	dprintk(3, "0 bytesperline %d, sizeimage %d\n", mpix->plane_fmt[0].bytesperline, mpix->plane_fmt[0].sizeimage);
+	dprintk(3, "1 bytesperline %d, sizeimage %d\n", mpix->plane_fmt[1].bytesperline, mpix->plane_fmt[1].sizeimage);
+	return 0;
+}
+
+static int camsv_v4l2_s_fmt(struct file *file, void *fh, struct v4l2_format *f)
+{
+	struct camsv_device *camsv = video_get_drvdata(video_devdata(file));
+	struct camsv_Module *camsv_m = videodev_to_camsv_module(video_devdata(file));
+
+	camsv_v4l2_try_fmt(file, fh, f);
+
+	dprintk(3, "camsv_module %p, fh %p, userCount %d, u4HwModule %d\n",
+		camsv_m, fh, camsv->userCount, camsv_m->camsv_port_input.u4HwModule);
+
+	dprintk(3, "1 bytesperline %d, sizeimage %d\n",
+		camsv_m->format.plane_fmt[0].bytesperline, camsv_m->format.plane_fmt[0].sizeimage);
+
+	camsv_m->format = f->fmt.pix_mp;
+
+	dprintk(3, "2 addr %p, bytesperline %d, sizeimage %d\n",
+		&camsv_m->format, camsv_m->format.plane_fmt[0].bytesperline, camsv_m->format.plane_fmt[0].sizeimage);
+
+	return 0;
+}
+
+static int camsv_subdev_subscribe_event(struct v4l2_subdev *sd,
+				       struct v4l2_fh *fh,
+				       struct v4l2_event_subscription *sub)
+{
+
+	dprintk(3, "%s type %d, id %d\n",
+		__func__, sub->type, sub->id);
+
+	if (sub->type != V4L2_EVENT_FRAME_SYNC)
+		return -EINVAL;
+
+	/* Line number. For now only zero accepted. */
+	if (sub->id != 0)
+		return -EINVAL;
+
+	return v4l2_event_subscribe(fh, sub, 0, NULL);
+}
+
+/*
+ * camsv_subdev_get_fmt - Handle get format by pads subdev method
+ * @sd : pointer to v4l2 subdev structure
+ * @cfg: V4L2 subdev pad config
+ * @fmt: pointer to v4l2 subdev format structure
+ * return -EINVAL or zero on success
+ */
+static int camsv_subdev_get_fmt(struct v4l2_subdev *sd,
+				struct v4l2_subdev_pad_config *cfg,
+				struct v4l2_subdev_format *fmt)
+{
+	struct camsv_Module *camsv_m = container_of(sd, struct camsv_Module, subdev);
+
+	fmt->format = camsv_m->subdev_fmt;
+
+	return 0;
+}
+
+/*
+ * camsv_subdev_set_fmt - Handle set format by pads subdev method
+ * @sd : pointer to v4l2 subdev structure
+ * @cfg: V4L2 subdev pad config
+ * @fmt: pointer to v4l2 subdev format structure
+ * return -EINVAL or zero on success
+ */
+static int camsv_subdev_set_fmt(struct v4l2_subdev *sd,
+			       struct v4l2_subdev_pad_config *cfg,
+			       struct v4l2_subdev_format *fmt)
+{
+	struct camsv_Module *camsv_m = container_of(sd, struct camsv_Module, subdev);
+
+	dev_dbg(NULL, "%s pad %d\n", __func__, fmt->pad);
+	/*
+	 * Only allow setting sink pad format;
+	 * source always propagates from sink
+	 */
+	if (fmt->pad == CAMSV_PAD_SOURCE)
+		return camsv_subdev_get_fmt(sd, cfg, fmt);
+
+	if (fmt->which == V4L2_SUBDEV_FORMAT_TRY) {
+
+	} else {
+		/* It's the sink, allow changing frame size */
+		camsv_m->subdev_fmt.width = fmt->format.width;
+		camsv_m->subdev_fmt.height = fmt->format.height;
+		camsv_m->subdev_fmt.code = fmt->format.code;
+		fmt->format = camsv_m->subdev_fmt;
+	}
+
+	return 0;
+}
+
+static int camsv_subdev_enum_mbus_code(struct v4l2_subdev *sd,
+				      struct v4l2_subdev_pad_config *cfg,
+				      struct v4l2_subdev_mbus_code_enum *code)
+{
+	if (code->index >= NUM_FORMATS)
+		return -EINVAL;
+
+	code->code = camsv_formats[code->index].mbus_code;
+
+	return 0;
+}
+
+static MUINT32 camsv_SrcFmtToHwVal_TG(struct CAMSV_PORT_INFO *pCfg)
+{
+	enum EImageFormat imgFmt = (enum EImageFormat)pCfg->eImgFmt;
+
+	dprintk(3, "imgFmt(%x)\n", imgFmt);
+	switch (imgFmt) {
+	case eImgFmt_BAYER8: return TG_FMT_RAW8;
+		break;
+	case eImgFmt_BAYER10:return TG_FMT_RAW10;
+		break;
+	case eImgFmt_BAYER12:return TG_FMT_RAW12;
+		break;
+	case eImgFmt_BAYER14:return TG_FMT_RAW14;
+		break;
+	case eImgFmt_YUY2:
+	case eImgFmt_UYVY:
+	case eImgFmt_YVYU:
+	case eImgFmt_VYUY:
+		return TG_FMT_YUV422;
+	default:
+		LOG_DBG("eImgFmt:[%x] NOT Support\n", imgFmt);
+		return -1;
+	}
+	return -1;
+}
+
+
+static MUINT32 camsv_SrcFmtToHwVal_TG_SW(struct CAMSV_PORT_INFO *pCfg)
+{
+	enum EImageFormat imgFmt = (enum EImageFormat)pCfg->eImgFmt;
+
+	dprintk(3, "imgFmt(%x)\n", imgFmt);
+	switch (imgFmt) {
+	case eImgFmt_BAYER8:
+	case eImgFmt_BAYER10:
+	case eImgFmt_BAYER12:
+	case eImgFmt_BAYER14:
+		return TG_SW_UYVY; // 0
+	case eImgFmt_YUY2:
+		return TG_SW_YUYV;
+	case eImgFmt_UYVY:
+		return TG_SW_UYVY;
+	case eImgFmt_YVYU:
+		return TG_SW_YVYU;
+	case eImgFmt_VYUY:
+		return TG_SW_VYUY;
+	default:
+		LOG_DBG("eImgFmt:[%x] NOT Support\n", imgFmt);
+		return -1;
+	}
+	return -1;
+}
+
+//return HW register format
+static MUINT32 camsv_getOutPxlByteNFmt(struct CAMSV_PORT_INFO *pCfg)
+{
+
+	enum EImageFormat imgFmt = (enum EImageFormat)pCfg->eImgFmt;
+	MINT32 *pPixel_byte = &pCfg->pixel_byte_imgo;
+	MINT32 *pFmt = &pCfg->imgo_fmt;
+
+	dprintk(3, "imgFmt(%x)\n", imgFmt);
+	/**/
+	if (pPixel_byte == NULL) {
+		LOG_INF("ERROR:NULL pPixel_byte\n");
+		return -1;
+	}
+
+	/**/
+	switch (imgFmt) {
+	case eImgFmt_BAYER8:          //= 0x0001,   //Bayer format, 8-bit
+		*pPixel_byte = 1 << CAM_ISP_PIXEL_BYTE_FP;
+		*pFmt = IMGO_FMT_RAW8;
+		break;
+	case eImgFmt_FG_BAYER8:
+		*pPixel_byte = 1 << CAM_ISP_PIXEL_BYTE_FP;
+		*pFmt = RRZO_FMT_RAW8;
+		break;
+	case eImgFmt_BAYER10:         //= 0x0002,   //Bayer format, 10-bit
+		*pPixel_byte = (5 << CAM_ISP_PIXEL_BYTE_FP) >> 2; // 4 pixels-> 5 bytes, 1.25
+		*pFmt = IMGO_FMT_RAW10;
+		break;
+	case eImgFmt_FG_BAYER10:
+		*pPixel_byte = (5 << CAM_ISP_PIXEL_BYTE_FP) >> 2; // 4 pixels-> 5 bytes, 1.25
+		*pFmt = RRZO_FMT_RAW10;
+		break;
+	case eImgFmt_BAYER12:         //= 0x0004,   //Bayer format, 12-bit
+		*pPixel_byte = (3 << CAM_ISP_PIXEL_BYTE_FP) >> 1; // 2 pixels-> 3 bytes, 1.5
+		*pFmt = IMGO_FMT_RAW12;
+		break;
+	case eImgFmt_FG_BAYER12:
+		*pPixel_byte = (3 << CAM_ISP_PIXEL_BYTE_FP) >> 1; // 2 pixels-> 3 bytes, 1.5
+		*pFmt = RRZO_FMT_RAW12;
+		break;
+	case eImgFmt_BAYER14:         //= 0x0008,   //Bayer format, 14-bit
+		*pPixel_byte = (7 << CAM_ISP_PIXEL_BYTE_FP) >> 2; // 2 pixels-> 3 bytes, 1.5
+		*pFmt = IMGO_FMT_RAW14;
+		break;
+	case eImgFmt_FG_BAYER14:         //= 0x0008,   //Bayer format, 14-bit
+		*pPixel_byte = (7 << CAM_ISP_PIXEL_BYTE_FP) >> 2; // 2 pixels-> 3 bytes, 1.5
+		*pFmt = RRZO_FMT_RAW14;
+		break;
+	case eImgFmt_YUY2:            //= 0x0100,   //422 format, 1 plane (YUYV)
+	case eImgFmt_UYVY:            //= 0x0200,   //422 format, 1 plane (UYVY)
+	case eImgFmt_YVYU:            //= 0x080000,   //422 format, 1 plane (YVYU)
+	case eImgFmt_VYUY:            //= 0x100000,   //422 format, 1 plane (VYUY)
+		*pPixel_byte = 2 << CAM_ISP_PIXEL_BYTE_FP;
+		*pFmt = IMGO_FMT_YUV422_1P;
+		break;
+	default:
+		LOG_DBG("eImgFmt:[%x]NOT Support\n", imgFmt);
+		return -1;
+	}
+	dprintk(3, "input imgFmt(0x%x),output fmt:0x%x,*pPixel_byte(%d)\n", imgFmt, *pFmt, *pPixel_byte);
+	return 0;
+}
+
+bool camsv_configDmaPort(struct CAMSV_PORT_INFO *portInfo,
+	struct IspDMACfg *a_dma, MUINT32 pixel_Byte, MUINT32 swap, enum E_BufPlaneID planeNum)
+{
+	a_dma->memBuf.size        = portInfo->u4BufSize[planeNum];
+	a_dma->memBuf.base_vAddr  = portInfo->u4BufVA[planeNum];
+	a_dma->memBuf.base_pAddr  = portInfo->u4BufPA[planeNum];
+	//
+	a_dma->memBuf.alignment  = 0;
+	a_dma->pixel_byte        = pixel_Byte;
+	//original dimension  unit:PIXEL
+	a_dma->size.w            = portInfo->u4ImgWidth;
+	a_dma->size.h            = portInfo->u4ImgHeight;
+	//input stride unit:PIXEL
+	a_dma->size.stride       =  portInfo->u4Stride[planeNum];
+
+	//dma port capbility
+	a_dma->capbility = portInfo->capbility;
+	//input xsize unit:byte
+
+	a_dma->size.xsize        =  portInfo->u4ImgWidth;
+	//
+	//
+	if (a_dma->size.stride < a_dma->size.w &&  planeNum == ePlane_1st)
+		LOG_ERR("[Error]:stride size(%lu) < image width(%lu) byte size", a_dma->size.stride, a_dma->size.w);
+	//
+	a_dma->crop.x            = portInfo->crop1.x;
+	a_dma->crop.floatX       = 0;//portInfo->crop1.floatX;
+	a_dma->crop.y            = portInfo->crop1.y;
+	a_dma->crop.floatY       = 0;//portInfo->crop1.floatY;
+	a_dma->crop.w            = portInfo->crop1.w;
+	a_dma->crop.h            = portInfo->crop1.h;
+	//
+	a_dma->swap = swap;
+	//
+	a_dma->memBuf.ofst_addr = 0;//offset at isp function
+	//
+
+	switch (portInfo->eImgFmt) {
+	case eImgFmt_YUY2:      //= 0x0100,   //422 format, 1 plane (YUYV)
+		a_dma->format_en = 1;
+		a_dma->format = 1;
+		a_dma->bus_size_en = 1;
+		a_dma->bus_size = 1;
+		a_dma->swap = 1;
+		break;
+	case eImgFmt_UYVY:      //= 0x0200,   //422 format, 1 plane (UYVY)
+		a_dma->format_en = 1;
+		a_dma->format = 1;
+		a_dma->bus_size_en = 1;
+		a_dma->bus_size = 1;
+		a_dma->swap = 0;
+		break;
+	case eImgFmt_YVYU:      //= 0x00002000,   //422 format, 1 plane (YVYU)
+		a_dma->format_en = 1;
+		a_dma->format = 1;
+		a_dma->bus_size_en = 1;
+		a_dma->bus_size = 1;
+		a_dma->swap = 3;
+		break;
+	case eImgFmt_VYUY:      //= 0x00004000,   //422 format, 1 plane (VYUY)
+		a_dma->format_en = 1;
+		a_dma->format = 1;
+		a_dma->bus_size_en = 1;
+		a_dma->bus_size = 1;
+		a_dma->swap = 2;
+		break;
+	case eImgFmt_RGB565:    //= 0x0400,   //RGB 565 (16-bit), 1 plane
+		//a_dma->format_en=1;
+		//a_dma->format=2;
+		//a_dma->bus_size_en=1;
+		//a_dma->bus_size=1;
+		//break;
+	case eImgFmt_RGB888:    //= 0x0800,   //RGB 888 (24-bit), 1 plane
+		//a_dma->format_en=1;
+		//a_dma->format=2;
+		//a_dma->bus_size_en=1;
+		//a_dma->bus_size=2;
+		//break;
+	case eImgFmt_ARGB8888:   //= 0x1000,   //ARGB (32-bit), 1 plane
+		//a_dma->format_en=1;
+		//a_dma->format=2;
+		//a_dma->bus_size_en=1;
+		//a_dma->bus_size=3;
+		//break;
+	case eImgFmt_YV16:      //422 format, 3 plane
+	case eImgFmt_NV16:      //422 format, 2 plane
+		LOG_ERR("NOT support this format(0x%x) in cam\n", portInfo->eImgFmt);
+		break;
+	case eImgFmt_BAYER8:    /*!< Bayer format, 8-bit */
+	case eImgFmt_BAYER10:   /*!< Bayer format, 10-bit */
+	case eImgFmt_BAYER12:   /*!< Bayer format, 12-bit */
+	case eImgFmt_BAYER14:   /*!< Bayer format, 14-bit */
+		a_dma->format_en = 0;
+		a_dma->bus_size_en = 0;
+		a_dma->format = 0;
+		a_dma->bus_size = 1;
+		break;
+	case eImgFmt_NV21:      //= 0x00000100,   //420 format, 2 plane (VU)
+	case eImgFmt_NV12:      //= 0x00000040,   //420 format, 2 plane (UV)
+	case eImgFmt_YV12:      //= 0x00000800,   //420 format, 3 plane (YVU)
+	case eImgFmt_I420:      //= 0x00000400,   //420 format, 3 plane(YUV)
+	default:
+		a_dma->format_en = 0;
+		a_dma->bus_size_en = 0;
+		a_dma->format = 0;
+		a_dma->bus_size = 0;
+		break;
+	}
+
+	return MTRUE;
+}
+
+static void camsv_config(struct camsv_device *camsv_d)
+{
+	static unsigned int camsys_qos;
+	bool mWakelock = camsv_d->wakelock;
+	MUINT32 dfs_ctrl = camsv_d->dfs_ctrl;
+#ifndef CAMSV_V4L2
+	int i;
+#endif
+
+	/* ISP_WAKELOCK_CTRL, true */
+	if (mWakelock == 1) {       /* Enable     wakelock */
+		if (g_WaitLockCt) {
+			g_WaitLockCt++;
+			LOG_DBG("add wakelock cnt(%d)\n", g_WaitLockCt);
+		} else {
+#ifdef CONFIG_PM_WAKELOCKS
+			__pm_stay_awake(&isp_wake_lock);
+#else
+			wake_lock(&isp_wake_lock);
+#endif
+			g_WaitLockCt++;
+			LOG_DBG("wakelock enable!! cnt(%d)\n", g_WaitLockCt);
+		}
+	} else {        /* Disable wakelock */
+		if (g_WaitLockCt)
+			g_WaitLockCt--;
+
+		if (g_WaitLockCt)
+			LOG_DBG("subtract wakelock cnt(%d)\n", g_WaitLockCt);
+		else {
+#ifdef CONFIG_PM_WAKELOCKS
+			__pm_relax(&isp_wake_lock);
+#else
+			wake_unlock(&isp_wake_lock);
+#endif
+			LOG_DBG("wakelock disable!! cnt(%d)\n", g_WaitLockCt);
+		}
+	}
+	dprintk(3, "mWakelock %d, g_WaitLockCt %d\n", mWakelock, g_WaitLockCt);
+
+	/* ISP_DFS_CTRL, true */
+	if (dfs_ctrl == MTRUE) {
+		if (++camsys_qos == 1)
+			LOG_DBG("CAMSYS PMQoS turn on\n");
+	} else {
+		if (--camsys_qos == 0)
+			LOG_DBG("CAMSYS PMQoS turn off\n");
+	}
+	dprintk(1, "camsys_qos %d, dfs %d\n", camsys_qos, dfs_ctrl);
+
+#ifndef CAMSV_V4L2
+	if ((mWakelock == MTRUE) && (dfs_ctrl == MTRUE)) {
+		/* ISP_RESET_BY_HWMODULE, CAMA~CAMC */
+		for (i = ISP_CAM_A_IDX; i <= ISP_CAM_C_IDX; i++)
+			ISP_Reset(i);
+	}
+#endif
+
+}
+
+static int camsv_init(struct camsv_device *camsv,
+			  struct CAMSV_PORTS_INFO *cfg)
+{
+	struct camsv_Module *camsv_m;
+	struct CAMSV_PORTS_INFO *pCfg = cfg;
+	struct CAMSV_PORT_INFO *pIntCfg;
+	struct CAMSV_PORT_INFO *pOutCfg;
+	struct CAMSV_TG_CTRL *m_TGCtrl;
+	struct CAMSV_TOP_CTRL *m_TopCtrl;
+	struct IspDMACfg *m_DmaImgo;
+	struct CAMSV_BUF_CTRL *m_FbcImgo;
+	struct CAMSV_TIMESTAMP *pTime;
+	MINT32 InSrcFmt = -1;
+	MINT32 InSrcTGSw = -1;
+	MINT32 pixel_byte_imgo = -1;
+	MUINT32 imgo_fmt = 0;
+	MUINT32 ret = 0;
+	int i = 0;
+
+	if ((pCfg->camsv_inport_info[0].u4HwModule < ISP_CAMSV0_IDX) ||
+		(pCfg->camsv_inport_info[0].u4HwModule >= ISP_DEV_NODE_NUM)) {
+		LOG_ERR("unsupport camsv module index %d\n", pCfg->camsv_inport_info[0].u4HwModule);
+		return MFALSE;
+	}
+	camsv_m = &camsv->camsv_module[pCfg->camsv_inport_info[0].u4HwModule-ISP_CAMSV0_IDX];
+	m_TGCtrl = &camsv_m->camsv_TGCtrl;
+	m_TopCtrl = &camsv_m->camsv_TopCtrl;
+	m_DmaImgo = &camsv_m->camsv_DmaImgo;
+	m_FbcImgo = &camsv_m->camsv_FbcImgo;
+	pTime = &camsv_m->camsv_pTime;
+
+	dprintk(3, "1 camsvq %p, camsv_port_input[0] %p, u4HwModule(%d, %d), pCfg(%d, %d)\n",
+		camsv_m, &camsv_m->camsv_port_input,
+		camsv_m->camsv_port_input.u4HwModule, camsv_m->camsv_port_output.u4HwModule,
+		pCfg->camsv_inport_info[0].u4HwModule, pCfg->camsv_outport_info[0].u4HwModule);
+
+	//get input and output port info, using module number
+	pIntCfg = &camsv_m->camsv_port_input;
+	pOutCfg = &camsv_m->camsv_port_output;
+
+	//mapping in/out port info from user to kernel
+	memcpy(pIntCfg, &pCfg->camsv_inport_info[0], sizeof(struct CAMSV_PORT_INFO));
+	memcpy(pOutCfg, &pCfg->camsv_outport_info[0], sizeof(struct CAMSV_PORT_INFO));
+
+	dprintk(3, "g_CamSVUserCt %d, pCfg(%d, %d)\n",
+		g_CamSVUserCt, pIntCfg->u4HwModule, pOutCfg->u4HwModule);
+	dprintk(3, "2 u4HwModule_%d_(%d, %d)\n",
+		pCfg->camsv_inport_info[0].u4HwModule - ISP_CAMSV0_IDX,
+		camsv_m->camsv_port_input.u4HwModule,
+		camsv_m->camsv_port_output.u4HwModule);
+
+	for (i = 0; i < CAMSV_MAX_MODULES; i++) {
+		dprintk(3, "i %d, u4HwModule %d %d\n",
+			i, camsv->camsv_module[i].camsv_port_input.u4HwModule,
+			camsv->camsv_module[i].camsv_port_output.u4HwModule);
+	}
+
+	/* check user and usage counter*/
+	if (!g_CamSVUserCt) {
+		camsv->wakelock = true;
+		camsv->dfs_ctrl = true;
+		camsv_config(camsv);
+	}
+
+	camsv->userCount++;
+	g_CamSVUserCt++;
+
+	//input source
+	InSrcFmt = camsv_SrcFmtToHwVal_TG(pIntCfg);
+	InSrcTGSw = camsv_SrcFmtToHwVal_TG_SW(pIntCfg);
+
+	//output port
+	ret = camsv_getOutPxlByteNFmt(pOutCfg);
+	if (ret)
+		LOG_INF("camsv_getOutPxlByteNFmt fail\n");
+
+	pixel_byte_imgo = pOutCfg->pixel_byte_imgo;
+	imgo_fmt = pOutCfg->imgo_fmt;
+
+	m_TopCtrl->m_hwModule = m_TGCtrl->m_hwModule = pIntCfg->u4HwModule;
+	m_DmaImgo->m_hwModule = m_FbcImgo->m_hwModule = pIntCfg->u4HwModule;
+
+	// Top ctrl setting
+	//this->m_TopCtrl.m_pDrv = this->m_pIspDrvCamsv;
+
+	//subsample
+	m_TopCtrl->SubSample = pIntCfg->m_SubSample;
+
+	// fmt sel
+	m_TopCtrl->camsv_top_ctl.FMT_SEL.Raw = 0x00;
+	m_TopCtrl->camsv_top_ctl.FMT_SEL.Bits.TG1_FMT = InSrcFmt;
+	m_TopCtrl->camsv_top_ctl.FMT_SEL.Bits.TG1_SW = InSrcTGSw;
+	m_TopCtrl->m_PixMode = m_TGCtrl->m_PixMode = m_DmaImgo->m_PixMode = pIntCfg->ePxlMode;
+
+
+	dprintk(3, "FMT_SEL.Raw %x\n", m_TopCtrl->camsv_top_ctl.FMT_SEL.Raw);
+
+	/// TG setting
+	//m_TGCtrl.m_pDrv = this->m_pIspDrvCamsv;
+	m_TGCtrl->m_SubSample = pIntCfg->m_SubSample;
+	m_TGCtrl->m_continuous = MTRUE; //TG input support only continuous mode
+	m_TGCtrl->m_Crop.x = pIntCfg->crop1.x;
+	m_TGCtrl->m_Crop.y = pIntCfg->crop1.y;
+	m_TGCtrl->m_Crop.w = pIntCfg->crop1.w;
+	m_TGCtrl->m_Crop.h = pIntCfg->crop1.h;
+
+	//assign timestamp clk rate
+	pTime->m_hwModule = pIntCfg->u4HwModule;
+	pTime->m_stmpMode = GLOBAL_MODE;
+	pTime->m_TimeClk = pIntCfg->tTimeClk;
+	CAM_TIMESTAMP_CAMSV_Enable(*pTime);
+	CAM_TIMESTAMP_CAMSV_TimeStamp_SrcClk(*pTime);
+
+	/// IMGO setting
+	if (pOutCfg->crop1.floatX || pOutCfg->crop1.floatY)
+		LOG_ERR("imgo support no floating-crop_start , replaced by 0\n");
+
+	// use output dma crop
+	camsv_configDmaPort(pOutCfg, m_DmaImgo, (MUINT32)pixel_byte_imgo, (MUINT32)false, ePlane_1st);
+	//m_DmaImgo.m_pDrv = this->m_pIspDrvCamsv;
+	m_DmaImgo->fmt_sel.Raw = m_TopCtrl->camsv_top_ctl.FMT_SEL.Raw;
+	m_DmaImgo->m_fps = pOutCfg->tgFps;
+
+	/// IMGO FBC setting
+	//m_FbcImgo.m_pDrv = this->m_pIspDrvCamsv;
+	m_FbcImgo->m_fps = pOutCfg->tgFps;
+	m_FbcImgo->m_pTimeStamp = pTime;
+
+	/// 1. TG config, enable
+	/// 2. Top config
+	/// 3. IMGO & FBC config, enable
+	if (CAMSV_TG_CTRL_config(*m_TGCtrl) != 0) {
+		LOG_ERR("CAMSV_TG_CTRL_config fail\n");
+		return MFALSE;
+	}
+
+	if (CAMSV_TOP_CTRL_config(*m_TopCtrl) != 0) {
+		LOG_ERR("CAMSV_TOP_CTRL_config fail\n");
+		return MFALSE;
+	}
+
+	if (CAMSV_BUF_CTRL_config(m_FbcImgo) != 0) {
+		LOG_ERR("CAMSV_BUF_CTRL_config fail\n");
+		return MFALSE;
+	}
+
+	if (DMAO_CAMSV_config(*m_DmaImgo) != 0) {
+		LOG_ERR("DMAO_CAMSV_config fail\n");
+		return MFALSE;
+	}
+
+	CAMSV_TG_CTRL_enable(*m_TGCtrl);
+
+	if (CAMSV_BUF_CTRL_enable(*m_FbcImgo) != 0) {
+		LOG_ERR("CAMSV_BUF_CTRL_enable fail\n");
+		return MFALSE;
+	}
+
+	if (DMAO_CAMSV_enable(*m_DmaImgo) != 0) {
+		LOG_ERR("DMAO_CAMSV_enable fail\n");
+		return MFALSE;
+	}
+
+	return 0;
+}
+
+static int camsv_uninit(struct camsv_device *camsv,
+			  struct CAMSV_PORTS_INFO *cfg)
+{
+	struct camsv_Module *camsv_m;
+	struct CAMSV_PORTS_INFO *pCfg = cfg;
+	struct CAMSV_PORT_INFO *pIntCfg;
+	struct CAMSV_PORT_INFO *pOutCfg;
+
+	dprintk(1, "%s HwModule %d\n", __func__, pCfg->camsv_inport_info[0].u4HwModule);
+
+	if ((pCfg->camsv_inport_info[0].u4HwModule < ISP_CAMSV0_IDX) ||
+		(pCfg->camsv_inport_info[0].u4HwModule >= ISP_DEV_NODE_NUM)) {
+		LOG_ERR("unsupport camsv module index %d\n", pCfg->camsv_inport_info[0].u4HwModule);
+		return MFALSE;
+	}
+	camsv_m = &camsv->camsv_module[pCfg->camsv_inport_info[0].u4HwModule-ISP_CAMSV0_IDX];
+
+
+	//reset module in/out port info
+	//get input and output port info, using module number
+	pIntCfg = &camsv_m->camsv_port_input;
+	pOutCfg = &camsv_m->camsv_port_output;
+
+	memset(pIntCfg, 0x0, sizeof(struct CAMSV_PORT_INFO));
+	memset(pOutCfg, 0x0, sizeof(struct CAMSV_PORT_INFO));
+
+	dprintk(3, "g_CamSVUserCt %d\n", g_CamSVUserCt);
+	g_CamSVUserCt--;
+	camsv->userCount--;
+	/* check user and usage counter*/
+	if (!g_CamSVUserCt) {
+		camsv->wakelock = false;
+		camsv->dfs_ctrl = false;
+		camsv_config(camsv);
+	}
+
+	return 0;
+}
+
+static long camsv_v4l2_vidioc_default(struct file *file, void *fh, bool valid_prio, unsigned int cmd, void *arg)
+{
+	bool ret = MTRUE;
+	struct camsv_device *camsv = video_get_drvdata(video_devdata(file));
+	struct camsv_Module *camsv_m = videodev_to_camsv_module(video_devdata(file));
+
+	dprintk(4, "camsv_m %p, g_CamSVUserCt %d, cmd %x, %lx\n",
+		camsv_m, g_CamSVUserCt, cmd, ISP_CANMSV_INIT);
+	dprintk(4, "sizeof camsv_buffer %td file_handle %p, valid_prio %d\n",
+		sizeof(struct camsv_buffer), fh, valid_prio);
+
+	switch (cmd) {
+	case ISP_CANMSV_INIT:
+		return camsv_init(camsv, arg);
+
+	case ISP_CANMSV_UNINIT:
+		return camsv_uninit(camsv, arg);
+
+	case ISP_CANMSV_WAIT_IRQ:
+	{
+		ret = camsv_VF_WAIT_IRQ(camsv_m, arg);
+		if (ret == MFALSE) {
+			dprintk(4, "wait Irq fail\n");
+			return -EFAULT;
+		}
+		return 0;
+	}
+
+	case ISP_CANMSV_SUSPEND:
+	{
+		ret = CAMSV_BUF_CTRL_suspend(camsv_m, arg);
+		if (ret == MFALSE) {
+			dprintk(4, "CANMSV_SUSPEND fail\n");
+			return -EFAULT;
+		}
+		return 0;
+	}
+
+	case ISP_CANMSV_RESUME:
+	{
+		ret = CAMSV_BUF_CTRL_resume(camsv_m, arg);
+		if (ret == MFALSE) {
+			dprintk(4, "CANMSV_RESUME fail\n");
+			return -EFAULT;
+		}
+		return 0;
+	}
+
+	default:
+		return -ENOIOCTLCMD;
+	}
+}
+
+
+static long camsv_ioctl(struct v4l2_subdev *sd, unsigned int cmd, void *arg)
+{
+	bool ret = MTRUE;
+	struct camsv_device *camsv = v4l2_get_subdevdata(sd);
+	struct camsv_Module *camsv_m = subdev_to_camsv_module(sd);
+
+	dprintk(4, "camsv_m %p, g_CamSVUserCt %d, cmd %x, %lx\n",
+		camsv_m, g_CamSVUserCt, cmd, ISP_CANMSV_INIT);
+	dprintk(4, "sizeof CAMSV_PORTS_INFO %td, video_device %td, media_pad %td, vb2_queue %td\n",
+		sizeof(struct CAMSV_PORTS_INFO), sizeof(struct video_device),
+		sizeof(struct media_pad), sizeof(struct vb2_queue));
+	dprintk(4, "sizeof v4l2_pix_format_mplane %td, v4l2_subdev %td, v4l2_mbus_framefmt %td, camsv_device %td\n",
+		sizeof(struct v4l2_pix_format_mplane), sizeof(struct v4l2_subdev),
+		sizeof(struct v4l2_mbus_framefmt), sizeof(struct camsv_device));
+
+	dprintk(4, "sizeof camsv_buffer %td\n",
+		sizeof(struct camsv_buffer));
+
+	switch (cmd) {
+	case ISP_CANMSV_INIT:
+		return camsv_init(camsv, arg);
+
+	case ISP_CANMSV_UNINIT:
+		return camsv_uninit(camsv, arg);
+
+	case ISP_CANMSV_WAIT_IRQ:
+	{
+		ret = camsv_VF_WAIT_IRQ(camsv_m, arg);
+		if (ret == MFALSE) {
+			dprintk(4, "wait Irq fail\n");
+			return -EFAULT;
+		}
+		return 0;
+	}
+	default:
+		return -ENOIOCTLCMD;
+	}
+}
+
+#ifdef CONFIG_COMPAT
+static long _camsv_ioctl(struct v4l2_subdev *sd, unsigned int cmd, unsigned long arg)
+{
+	dprintk(3, "64 %s %d, cmd %x\n", __func__, g_CamSVUserCt, cmd);
+	return camsv_ioctl(sd, cmd, compat_ptr(arg));
+}
+#endif
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static int camsv_open(
+	struct file *pFile)
+{
+	int Ret = 0;
+	unsigned int i, j;
+	int q = 0, p = 0;
+	struct ISP_USER_INFO_STRUCT *pUserInfo;
+	struct camsv_fh *pCamsvfh;
+
+	dprintk(3, "- E. UserCount: %d.\n", IspInfo.UserCount);
+
+	/*  */
+	spin_lock(&(IspInfo.SpinLockIspRef));
+
+	pCamsvfh = kmalloc(sizeof(struct camsv_fh), GFP_ATOMIC);
+	if (pCamsvfh == NULL) {
+		LOG_INF("ERROR: kmalloc failed, (process, pid, tgid)=(%s, %d, %d)\n",
+			current->comm, current->pid, current->tgid);
+		Ret = -ENOMEM;
+	} else {
+		pUserInfo = (struct ISP_USER_INFO_STRUCT *)&(pCamsvfh->pUserInfo);
+		pUserInfo->Pid = current->pid;
+		pUserInfo->Tid = current->tgid;
+
+		//get video device
+		pCamsvfh->vdec = video_devdata(pFile);
+
+		//init v4l2 handle
+		v4l2_fh_init(&pCamsvfh->vfh, pCamsvfh->vdec);
+		pFile->private_data = &pCamsvfh->vfh;
+		v4l2_fh_add(&pCamsvfh->vfh);
+
+		dprintk(3, "vfh %p, pCamsvfh->vdec->queue %p, entity.name %s\n",
+			pFile->private_data, pCamsvfh->vdec->queue, pCamsvfh->vdec->entity.name);
+	}
+	/*  */
+	if (IspInfo.UserCount > 0) {
+		IspInfo.UserCount++;
+		spin_unlock(&(IspInfo.SpinLockIspRef));
+		dprintk(3, "Curr UserCount(%d), (process, pid, tgid)=(%s, %d, %d), users exist\n",
+			IspInfo.UserCount, current->comm, current->pid, current->tgid);
+		goto EXIT;
+	} else {
+		IspInfo.UserCount++;
+		spin_unlock(&(IspInfo.SpinLockIspRef));
+
+		dprintk(3, "Curr UserCount(%d), (process, pid, tgid)=(%s, %d, %d), first user\n",
+			IspInfo.UserCount, current->comm, current->pid, current->tgid);
+	}
+
+	/* do wait queue head init when re-enter in camera */
+	/*  */
+	for (i = 0; i < IRQ_USER_NUM_MAX; i++) {
+		FirstUnusedIrqUserKey = 1;
+		strncpy((void *)IrqUserKey_UserInfo[i].userName, "DefaultUserNametoAllocMem", USERKEY_STR_LEN);
+		IrqUserKey_UserInfo[i].userKey = -1;
+	}
+
+	IspInfo.BufInfo.Read.pData = kmalloc(ISP_BUF_SIZE, GFP_ATOMIC);
+	IspInfo.BufInfo.Read.Size = ISP_BUF_SIZE;
+	IspInfo.BufInfo.Read.Status = ISP_BUF_STATUS_EMPTY;
+	if (IspInfo.BufInfo.Read.pData == NULL) {
+		LOG_INF("ERROR: BufRead kmalloc failed\n");
+		Ret = -ENOMEM;
+		goto EXIT;
+	}
+
+	/*  */
+	for (i = 0; i < ISP_IRQ_TYPE_AMOUNT; i++) {
+		for (j = 0; j < ISP_IRQ_ST_AMOUNT; j++) {
+			for (q = 0; q < IRQ_USER_NUM_MAX; q++) {
+				IspInfo.IrqInfo.Status[i][j][q] = 0;
+				IspInfo.IrqInfo.MarkedFlag[i][j][q] = 0;
+				for (p = 0; p < 32; p++) {
+					IspInfo.IrqInfo.MarkedTime_sec[i][p][q] = 0;
+					IspInfo.IrqInfo.MarkedTime_usec[i][p][q] = 0;
+					IspInfo.IrqInfo.PassedBySigCnt[i][p][q] = 0;
+					IspInfo.IrqInfo.LastestSigTime_sec[i][p] = 0;
+					IspInfo.IrqInfo.LastestSigTime_usec[i][p] = 0;
+				}
+			}
+		}
+	}
+	/* reset backup regs*/
+	memset(g_BkReg, 0, sizeof(struct _isp_bk_reg_t) * ISP_IRQ_TYPE_AMOUNT);
+
+#ifdef ENABLE_KEEP_ION_HANDLE
+	/* create ion client*/
+	mutex_lock(&ion_client_mutex);
+	ISP_ion_init();
+	mutex_unlock(&ion_client_mutex);
+#endif
+
+#ifdef KERNEL_LOG
+	IspInfo.DebugMask = (ISP_DBG_INT);
+#endif
+	/*  */
+EXIT:
+	if (Ret < 0) {
+		if (IspInfo.BufInfo.Read.pData != NULL) {
+			kfree(IspInfo.BufInfo.Read.pData);
+			IspInfo.BufInfo.Read.pData = NULL;
+		}
+	} else {
+		/* Enable clock */
+		ISP_EnableClock(MTRUE);
+#ifndef CAMSV_V4L2
+		if (IspInfo.UserCount == 1)
+			ISP_ConfigDMAControl();
+#endif
+		dprintk(3, "isp open G_u4EnableClockCount: %d\n", G_u4EnableClockCount);
+	}
+
+	dprintk(3, "- X. Ret: %d. UserCount: %d. G_u4EnableClockCount:%d\n", Ret,
+		IspInfo.UserCount, G_u4EnableClockCount);
+
+	return Ret;
+
+}
+
+#ifndef CAMSV_V4L2
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline void camsv_StopHW(int module)
+{
+	unsigned int regTGSt, loopCnt;
+	int ret = 0;
+	struct ISP_WAIT_IRQ_STRUCT waitirq;
+	ktime_t             time;
+	unsigned long long  sec = 0, m_sec = 0;
+	unsigned long long  timeoutMs = 500000000;/*500ms*/
+	char moduleName[128];
+
+	/* wait TG idle*/
+	loopCnt = 3;
+	switch (module) {
+	case ISP_CAM_A_IDX:
+		strncpy(moduleName, "CAMA", 5);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAM_A_ST;
+		break;
+	case ISP_CAM_B_IDX:
+		strncpy(moduleName, "CAMB", 5);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAM_B_ST;
+		break;
+	default:
+		strncpy(moduleName, "CAMC", 5);
+		goto RESET;
+	}
+	waitirq.EventInfo.Clear = ISP_IRQ_CLEAR_WAIT;
+	waitirq.EventInfo.Status = VS_INT_ST;
+	waitirq.EventInfo.St_type = SIGNAL_INT;
+	waitirq.EventInfo.Timeout = 0x100;
+	waitirq.EventInfo.UserKey = 0x0;
+	waitirq.bDumpReg = 0;
+
+	do {
+		regTGSt = (ISP_RD32(CAM_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+		if (regTGSt == 1)
+			break;
+
+		dprintk(3, "%s: wait 1VD (%d)\n", moduleName, loopCnt);
+		ret = ISP_WaitIrq(&waitirq);
+		/* first wait is clear wait, others are non-clear wait */
+		waitirq.EventInfo.Clear = ISP_IRQ_CLEAR_NONE;
+	} while (--loopCnt);
+
+	if (-ERESTARTSYS == ret) {
+		dprintk(3, "%s: interrupt by system signal, wait idle\n", moduleName);
+		/* timer*/
+		time = ktime_get();
+		m_sec = time;
+
+		while (regTGSt != 1) {
+			regTGSt = (ISP_RD32(CAM_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+			/*timer*/
+			time = ktime_get();
+			sec = time;
+			/* wait time>timeoutMs, break */
+			if ((sec - m_sec) > timeoutMs)
+				break;
+		}
+		if (regTGSt == 1)
+			dprintk(3, "%s: wait idle done\n", moduleName);
+		else
+			dprintk(3, "%s: wait idle timeout(%lld)\n", moduleName, (sec - m_sec));
+	}
+
+RESET:
+	dprintk(3, "%s: reset\n", moduleName);
+	/* timer*/
+	time = ktime_get();
+	m_sec = time;
+
+	/* Reset*/
+	ISP_WR32(CAM_REG_CTL_SW_CTL(module), 0x0);
+	ISP_WR32(CAM_REG_CTL_SW_CTL(module), 0x1);
+	while (ISP_RD32(CAM_REG_CTL_SW_CTL(module)) != 0x2) {
+		/*LOG_DBG("%s resetting...\n", moduleName);*/
+		/*timer*/
+		time = ktime_get();
+		sec = time;
+		/* wait time>timeoutMs, break */
+		if ((sec  - m_sec) > timeoutMs) {
+			LOG_INF("%s: wait SW idle timeout\n", moduleName);
+			break;
+		}
+	}
+
+	ISP_WR32(CAM_REG_CTL_SW_CTL(module), 0x4);
+	ISP_WR32(CAM_REG_CTL_SW_CTL(module), 0x0);
+	regTGSt = (ISP_RD32(CAM_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+	dprintk(3, "%s_TG_ST(%d)_SW_ST(0x%x)\n", moduleName, regTGSt,
+		ISP_RD32(CAM_REG_CTL_SW_CTL(module)));
+
+	ISP_WR32(CAM_UNI_REG_TOP_SW_CTL(ISP_UNI_A_IDX), 0x1001);
+
+	time = ktime_get();
+	m_sec = time;
+	while ((ISP_RD32(CAM_UNI_REG_TOP_SW_CTL(ISP_UNI_A_IDX)) & 0x00000002) != 0x2) {
+		time = ktime_get();
+		sec = time;
+		/* wait time>timeoutMs, break */
+		if ((sec  - m_sec) > (timeoutMs/50000)) {
+			LOG_INF("%s: wait SW RST ST 50000 timeout\n", moduleName);
+			break;
+		}
+	}
+
+	ISP_WR32(CAM_UNI_REG_TOP_SW_CTL(ISP_UNI_A_IDX), 0x4);
+	ISP_WR32(CAM_UNI_REG_TOP_SW_CTL(ISP_UNI_A_IDX), 0x0);
+	/*disable CMOS*/
+	ISP_WR32(CAM_REG_TG_SEN_MODE(module),
+		(ISP_RD32(CAM_REG_TG_SEN_MODE(module))&0xfffffffe));
+
+}
+#endif
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static inline void camsv_StopSVHW(int module)
+{
+	unsigned int regTGSt, loopCnt;
+	int ret = 0;
+	struct ISP_WAIT_IRQ_STRUCT waitirq;
+	ktime_t             time;
+	unsigned long long  sec = 0, m_sec = 0;
+	unsigned long long  timeoutMs = 500000000;/*500ms*/
+	char moduleName[128];
+
+	/* wait TG idle*/
+	loopCnt = 3;
+	switch (module) {
+	case ISP_CAMSV0_IDX:
+		strncpy(moduleName, "CAMSV0", 7);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAMSV_0_ST;
+		break;
+	case ISP_CAMSV1_IDX:
+		strncpy(moduleName, "CAMSV1", 7);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAMSV_1_ST;
+		break;
+	case ISP_CAMSV2_IDX:
+		strncpy(moduleName, "CAMSV2", 7);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAMSV_2_ST;
+		break;
+	case ISP_CAMSV3_IDX:
+		strncpy(moduleName, "CAMSV3", 7);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAMSV_3_ST;
+		break;
+	case ISP_CAMSV4_IDX:
+		strncpy(moduleName, "CAMSV4", 7);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAMSV_4_ST;
+		break;
+	default:
+		strncpy(moduleName, "CAMSV5", 7);
+		waitirq.Type = ISP_IRQ_TYPE_INT_CAMSV_5_ST;
+		break;
+	}
+	waitirq.EventInfo.Clear = ISP_IRQ_CLEAR_WAIT;
+	waitirq.EventInfo.Status = VS_INT_ST;
+	waitirq.EventInfo.St_type = SIGNAL_INT;
+	waitirq.EventInfo.Timeout = 0x100;
+	waitirq.EventInfo.UserKey = 0x0;
+	waitirq.bDumpReg = 0;
+
+	do {
+		regTGSt = (ISP_RD32(CAMSV_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+		if (regTGSt == 1)
+			break;
+
+		dprintk(3, "%s: wait 1VD (%d)\n", moduleName, loopCnt);
+		ret = ISP_WaitIrq(&waitirq);
+		/* first wait is clear wait, others are non-clear wait */
+		waitirq.EventInfo.Clear = ISP_IRQ_CLEAR_NONE;
+	} while (--loopCnt);
+
+	if (-ERESTARTSYS == ret) {
+		dprintk(3, "%s: interrupt by system signal, wait idle\n", moduleName);
+		/* timer*/
+		time = ktime_get();
+		m_sec = time;
+
+		while (regTGSt != 1) {
+			regTGSt = (ISP_RD32(CAMSV_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+			/*timer*/
+			time = ktime_get();
+			sec = time;
+			/* wait time>timeoutMs, break */
+			if ((sec - m_sec) > timeoutMs)
+				break;
+		}
+		if (regTGSt == 1)
+			LOG_INF("%s: wait idle done\n", moduleName);
+		else
+			LOG_INF("%s: wait idle timeout(%lld)\n", moduleName, (sec - m_sec));
+	}
+
+	dprintk(3, "%s: reset\n", moduleName);
+	/* timer*/
+	time = ktime_get();
+	m_sec = time;
+
+	/* Reset*/
+	ISP_WR32(CAMSV_REG_SW_CTL(module), 0x4);
+	ISP_WR32(CAMSV_REG_SW_CTL(module), 0x0);
+	ISP_WR32(CAMSV_REG_SW_CTL(module), 0x1);
+	while (ISP_RD32(CAMSV_REG_SW_CTL(module)) != 0x3) {
+		/*LOG_DBG("%s resetting...\n", moduleName);*/
+		/*timer*/
+		time = ktime_get();
+		sec = time;
+		/* wait time>timeoutMs, break */
+		if ((sec  - m_sec) > timeoutMs) {
+			dprintk(3, "%s: wait SW idle timeout\n", moduleName);
+			break;
+		}
+	}
+	ISP_WR32(CAMSV_REG_SW_CTL(module), 0x0);
+	regTGSt = (ISP_RD32(CAMSV_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+	dprintk(3, "%s_TG_ST(%d)_SW_ST(0x%x)\n", moduleName, regTGSt,
+		ISP_RD32(CAMSV_REG_SW_CTL(module)));
+
+	/*disable CMOS*/
+	ISP_WR32(CAMSV_REG_TG_SEN_MODE(module),
+		(ISP_RD32(CAMSV_REG_TG_SEN_MODE(module))&0xfffffffe));
+
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static int camsv_release(
+	struct file *pFile)
+{
+	struct video_device *vdec;
+	struct v4l2_fh *vfh = pFile->private_data;
+	struct camsv_fh *pCamsvfh = container_of(vfh, struct camsv_fh, vfh);
+	unsigned int Reg;
+	unsigned int i = 0;
+
+	vdec = pCamsvfh->vdec;
+	dprintk(3, "- E. UserCount: %d. %p, vdec %p\n", IspInfo.UserCount, pCamsvfh, vdec);
+
+	/*  */
+	/* LOG_DBG("UserCount(%d)",IspInfo.UserCount); */
+	/*  */
+
+	if (pFile->private_data != NULL) {
+		/* Release the file handle. */
+		vb2_fop_release(pFile);
+		pFile->private_data = NULL;
+	}
+
+	/*      */
+	spin_lock(&(IspInfo.SpinLockIspRef));
+	IspInfo.UserCount--;
+	if (IspInfo.UserCount > 0) {
+		spin_unlock(&(IspInfo.SpinLockIspRef));
+		dprintk(3, "Curr UserCount(%d), (process, pid, tgid)=(%s, %d, %d),	users exist",
+			IspInfo.UserCount, current->comm, current->pid, current->tgid);
+		goto EXIT;
+	} else {
+		spin_unlock(&(IspInfo.SpinLockIspRef));
+	}
+
+	/*      */
+	dprintk(3, "Curr UserCount(%d), (process, pid, tgid)=(%s, %d, %d), log_limit_line(%d),	last user",
+		IspInfo.UserCount, current->comm, current->pid, current->tgid, pr_detect_count);
+
+#ifndef CAMSV_V4L2
+	for (i = ISP_CAM_A_IDX; i < ISP_CAMSV0_IDX; i++) {
+		/* Close VF when ISP_release */
+		/* reason of close vf is to make sure camera can serve regular after previous abnormal exit */
+		Reg = ISP_RD32(CAM_REG_TG_VF_CON(i));
+		Reg &= 0xfffffffE;/* close Vfinder */
+		ISP_WR32(CAM_REG_TG_VF_CON(i), Reg);
+
+/* Set DMX_SEL = 0 when ISP_release */
+/* Reson: If twin is enabled, the twin module's DMX_SEL will be set to 1.
+ *	  It will encounter err when run single path and other module dmx_sel = 1
+ **/
+		Reg = ISP_RD32(CAM_REG_CTL_SEL(i));
+		Reg &= 0xfffffff8;/* set dmx to 0 */
+		ISP_WR32(CAM_REG_CTL_SEL(i), Reg);
+
+/* Reset Twin status.
+ *  If previous camera run in twin mode,
+ *  then mediaserver died, no one clear this status.
+ *  Next camera runs in single mode, and it will not update CQ0
+ */
+		ISP_WR32(CAM_REG_CTL_TWIN_STATUS(i), 0x0);
+	}
+#endif
+	for (i = ISP_CAMSV0_IDX; i <= ISP_CAMSV5_IDX; i++) {
+		Reg = ISP_RD32(CAMSV_REG_TG_VF_CON(i));
+		Reg &= 0xfffffffE;/* close Vfinder */
+		ISP_WR32(CAMSV_REG_TG_VF_CON(i), Reg);
+	}
+
+	/* why i add this wake_unlock here, because     the     Ap is not expected to be dead. */
+	/* The driver must releae the wakelock, otherwise the system will not enter     */
+	/* the power-saving mode */
+	if (g_WaitLockCt) {
+		dprintk(3, "wakelock disable!! cnt(%d)\n", g_WaitLockCt);
+#ifdef CONFIG_PM_WAKELOCKS
+		__pm_relax(&isp_wake_lock);
+#else
+		wake_unlock(&isp_wake_lock);
+#endif
+		g_WaitLockCt = 0;
+	}
+	/* reset */
+	/*      */
+	for (i = 0; i < IRQ_USER_NUM_MAX; i++) {
+		FirstUnusedIrqUserKey = 1;
+		strncpy((void *)IrqUserKey_UserInfo[i].userName, "DefaultUserNametoAllocMem", USERKEY_STR_LEN);
+		IrqUserKey_UserInfo[i].userKey = -1;
+	}
+	if (IspInfo.BufInfo.Read.pData != NULL) {
+		kfree(IspInfo.BufInfo.Read.pData);
+		IspInfo.BufInfo.Read.pData = NULL;
+		IspInfo.BufInfo.Read.Size = 0;
+		IspInfo.BufInfo.Read.Status = ISP_BUF_STATUS_EMPTY;
+	}
+
+	/* reset backup regs*/
+	memset(g_BkReg, 0, sizeof(struct _isp_bk_reg_t) * ISP_IRQ_TYPE_AMOUNT);
+	/*  */
+#ifdef ENABLE_KEEP_ION_HANDLE
+	for (i = ISP_CAMSV0_IDX; i < ISP_CAMSV4_IDX; i++)
+		camsv_StopSVHW(i);
+
+#ifndef CAMSV_V4L2
+	camsv_StopHW(ISP_CAM_A_IDX);
+	camsv_StopHW(ISP_CAM_B_IDX);
+	camsv_StopHW(ISP_CAM_C_IDX);
+#endif
+
+	/* free keep ion handles, then destroy ion client*/
+	for (i = 0; i < ISP_DEV_NODE_NUM; i++) {
+		if (gION_TBL[i].node != ISP_DEV_NODE_NUM)
+			ISP_ion_free_handle_by_module(i);
+	}
+
+	mutex_lock(&ion_client_mutex);
+	ISP_ion_uninit();
+	mutex_unlock(&ion_client_mutex);
+#endif
+
+/* Disable clock.
+ *  1. clkmgr: G_u4EnableClockCount=0, call clk_enable/disable
+ *  2. CCF: call clk_enable/disable every time
+ *     -> when IspInfo.UserCount, disable all ISP clk
+ */
+	spin_lock(&(IspInfo.SpinLockClock));
+	i = G_u4EnableClockCount;
+	spin_unlock(&(IspInfo.SpinLockClock));
+	while (i > 0) {
+		ISP_EnableClock(MFALSE);
+		i--;
+	}
+
+EXIT:
+
+	dprintk(3, "- X. UserCount: %d. G_u4EnableClockCount:%d", IspInfo.UserCount,
+		G_u4EnableClockCount);
+	return 0;
+}
+
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static int camsv_mmap(struct file *pFile, struct vm_area_struct *pVma)
+{
+	unsigned long length = 0;
+	unsigned int pfn = 0x0;
+
+	/*LOG_DBG("- E.");*/
+	length = (pVma->vm_end - pVma->vm_start);
+	/*  */
+	pVma->vm_page_prot = pgprot_noncached(pVma->vm_page_prot);
+	pfn = pVma->vm_pgoff << PAGE_SHIFT;
+
+	dprintk(3, "ISP_mmap: vm_pgoff(0x%lx),pfn(0x%x),phy(0x%lx),vm_start(0x%lx),vm_end(0x%lx),length(0x%lx)\n",
+		pVma->vm_pgoff, pfn, pVma->vm_pgoff << PAGE_SHIFT, pVma->vm_start, pVma->vm_end, length);
+
+	switch (pfn) {
+	case CAM_A_BASE_HW:
+	case CAM_B_BASE_HW:
+	case CAM_C_BASE_HW:
+		if (length > ISP_REG_RANGE) {
+			LOG_NOTICE("mmap range error :module(0x%x) length(0x%lx),ISP_REG_RANGE(0x%lx)!\n",
+				pfn, length, ISP_REG_RANGE);
+			return -EAGAIN;
+		}
+		break;
+	case CAMSV_0_BASE_HW:
+	case CAMSV_1_BASE_HW:
+	case CAMSV_2_BASE_HW:
+	case CAMSV_3_BASE_HW:
+	case CAMSV_4_BASE_HW:
+	case CAMSV_5_BASE_HW:
+	case UNI_A_BASE_HW:
+		if (length > ISP_REG_RANGE/2) {
+			LOG_NOTICE("mmap range error :module(0x%x) length(0x%lx),ISP_REG_RANGE(0x%lx)!\n",
+				pfn, length, ISP_REG_RANGE/2);
+			return -EAGAIN;
+		}
+		break;
+	default:
+		LOG_NOTICE("Illegal starting HW addr for mmap!\n");
+		return -EAGAIN;
+	}
+	if (remap_pfn_range(pVma, pVma->vm_start, pVma->vm_pgoff, pVma->vm_end - pVma->vm_start, pVma->vm_page_prot))
+		return -EAGAIN;
+
+	/*  */
+	return 0;
+}
+
+
+
+static const struct v4l2_subdev_core_ops camsv_subdev_core_ops = {
+	.ioctl = camsv_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl32 = _camsv_ioctl,
+#endif
+	.subscribe_event = camsv_subdev_subscribe_event,
+	.unsubscribe_event = v4l2_event_subdev_unsubscribe,
+};
+
+static const struct v4l2_subdev_video_ops camsv_subdev_video_ops = {};
+
+static const struct v4l2_subdev_pad_ops camsv_subdev_pad_ops = {
+	.link_validate = v4l2_subdev_link_validate_default,
+	.get_fmt = camsv_subdev_get_fmt,
+	.set_fmt = camsv_subdev_set_fmt,
+	.enum_mbus_code = camsv_subdev_enum_mbus_code,
+};
+
+
+static const struct v4l2_subdev_ops camsv_subdev_ops = {
+	.core = &camsv_subdev_core_ops,
+	.video = &camsv_subdev_video_ops,
+	.pad = &camsv_subdev_pad_ops,
+};
+
+
+static const struct v4l2_file_operations camsv_v4l2_fops = {
+	.owner = THIS_MODULE,
+	.unlocked_ioctl = video_ioctl2,
+	.poll = vb2_fop_poll,
+	.open = camsv_open,
+	.release = camsv_release,
+	.mmap = camsv_mmap,
+};
+
+static const struct v4l2_ioctl_ops camsv_v4l2_ioctl_ops = {
+	.vidioc_querycap = camsv_v4l2_querycap,
+	.vidioc_enum_fmt_vid_cap_mplane = camsv_v4l2_enum_fmt,
+	.vidioc_g_fmt_vid_cap_mplane = camsv_v4l2_g_fmt,
+	.vidioc_s_fmt_vid_cap_mplane = camsv_v4l2_s_fmt,
+	.vidioc_try_fmt_vid_cap_mplane = camsv_v4l2_try_fmt,
+
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+
+	.vidioc_subscribe_event = v4l2_ctrl_subscribe_event,
+	.vidioc_unsubscribe_event = v4l2_event_unsubscribe,
+
+	.vidioc_default = camsv_v4l2_vidioc_default,
+};
+
+static const struct vb2_ops camsv_vb2_ops = {
+	.buf_init = camsv_vb2_buf_init,
+	.buf_queue = camsv_vb2_buf_queue,
+	.buf_cleanup = camsv_vb2_buf_cleanup,
+	.queue_setup = camsv_vb2_queue_setup,
+	.start_streaming = camsv_vb2_start_streaming,
+	.stop_streaming = camsv_vb2_stop_streaming,
+
+	.wait_prepare = vb2_ops_wait_prepare,
+	.wait_finish = vb2_ops_wait_finish,
+};
+
+static const struct vb2_mem_ops camsv_vb2_mem_op = {
+	.get_userptr		= camsv_vb2_get_userptr,
+	.put_userptr		= camsv_vb2_put_userptr,
+};
+
+/******* V4L2 sub-device asynchronous registration callbacks***********/
+
+struct sensor_async_subdev {
+	struct v4l2_async_subdev asd;
+	struct camsv_bus_info businfo;
+};
+
+
+/* The .bound() notifier callback when a match is found */
+static int camsv_notifier_bound(struct v4l2_async_notifier *notifier,
+			       struct v4l2_subdev *sd,
+			       struct v4l2_async_subdev *asd)
+{
+	struct camsv_device *camsv = container_of(notifier,
+					struct camsv_device, notifier);
+	struct sensor_async_subdev *s_asd = container_of(asd,
+					struct sensor_async_subdev, asd);
+	struct camsv_Module *camsv_m;
+
+	if (camsv->camsv_module[s_asd->businfo.port].sensor)
+		return -EBUSY;
+
+	camsv_m = &camsv->camsv_module[s_asd->businfo.port];
+
+	camsv_m->businfo = s_asd->businfo;
+	camsv_m->sensor = sd;
+	camsv_m->base = camsv->base;
+
+	return 0;
+}
+
+/* The .unbind callback */
+static void camsv_notifier_unbind(struct v4l2_async_notifier *notifier,
+				 struct v4l2_subdev *sd,
+				 struct v4l2_async_subdev *asd)
+{
+	struct camsv_device *camsv = container_of(notifier,
+						struct camsv_device, notifier);
+	struct sensor_async_subdev *s_asd = container_of(asd,
+					struct sensor_async_subdev, asd);
+
+	camsv->camsv_module[s_asd->businfo.port].sensor = NULL;
+}
+
+/* .complete() is called after all subdevices have been located */
+static int camsv_notifier_complete(struct v4l2_async_notifier *notifier)
+{
+	struct camsv_device *camsv = container_of(notifier, struct camsv_device,
+						notifier);
+	struct sensor_async_subdev *s_asd;
+	struct camsv_Module *camsv_m;
+	unsigned int i, pad;
+	int ret;
+
+	for (i = 0; i < notifier->num_subdevs; i++) {
+		s_asd = container_of(camsv->notifier.subdevs[i],
+				     struct sensor_async_subdev,
+				     asd);
+		camsv_m = &camsv->camsv_module[s_asd->businfo.port];
+
+		for (pad = 0; pad < camsv_m->sensor->entity.num_pads; pad++)
+			if (camsv_m->sensor->entity.pads[pad].flags &
+					MEDIA_PAD_FL_SOURCE)
+				break;
+
+		if (pad == camsv_m->sensor->entity.num_pads) {
+			dev_err(camsv->dev,
+				"failed to find src pad for %s\n",
+				camsv_m->sensor->name);
+
+			return -ENXIO;
+		}
+
+		ret = media_create_pad_link(
+				&camsv_m->sensor->entity, pad,
+				&camsv_m->subdev.entity, CAMSV_PAD_SINK,
+				MEDIA_LNK_FL_ENABLED);
+		if (ret) {
+			dev_err(camsv->dev,
+				"failed to create link for %s\n",
+				camsv->camsv_module[i].sensor->name);
+
+			return ret;
+		}
+	}
+
+	return v4l2_device_register_subdev_nodes(&camsv->v4l2_dev);
+}
+
+static int camsv_notifier_init(struct camsv_device *camsv)
+{
+	int ret;
+
+	camsv->notifier.bound = camsv_notifier_bound;
+	camsv->notifier.unbind = camsv_notifier_unbind;
+	camsv->notifier.complete = camsv_notifier_complete;
+
+	ret = v4l2_async_notifier_register(&camsv->v4l2_dev, &camsv->notifier);
+	if (ret) {
+		dev_err(camsv->dev,
+			"failed to register async notifier : %d\n", ret);
+		ret = 0;
+	}
+
+	return ret;
+}
+
+static int camsv_link_validate(struct media_link *link)
+{
+	return v4l2_subdev_link_validate(link);
+}
+
+/**************** Queue initialization ****************/
+static const struct media_entity_operations camsv_media_ops = {
+	.link_validate = camsv_link_validate,
+};
+
+static void v4l2_device_release_camsv_subdev_node(struct video_device *vdev)
+{
+	struct v4l2_subdev *sd = video_get_drvdata(vdev);
+
+	dev_dbg(sd->dev, "%s\n", __func__);
+	sd->devnode = NULL;
+	kzfree(vdev);
+}
+
+static int camsv_module_init(struct camsv_device *camsv, struct camsv_Module *camsv_m)
+{
+	static const u32 default_width = 1920;
+	static const u32 default_height = 1080;
+	const struct camsv_fmt dflt_fmt = camsv_formats[0];
+	struct video_device *vdev = &camsv_m->vdev;/* get 1st instance*/
+	struct video_device *cam_vdev;
+	struct vb2_queue *vbq = &camsv_m->vbq;/* get 1st instance*/
+	struct v4l2_subdev *subdev = &camsv_m->subdev;
+	struct v4l2_mbus_framefmt *fmt;
+	struct media_pad *vdev_pad = &camsv_m->vdev_pad;/* get 1st instance*/
+	struct v4l2_pix_format_mplane *format = &camsv_m->format;/* get 1st instance*/
+	struct CAMSV_PORT_INFO *in_ptr =  &camsv_m->camsv_port_input;
+	struct CAMSV_PORT_INFO *out_ptr =  &camsv_m->camsv_port_output;
+	struct list_head *capture =  &camsv_m->capture;
+	struct v4l2_ctrl_handler *hdl;
+	int r, i;
+
+	/* Initialize miscellaneous variables */
+	mutex_init(&camsv_m->lock);
+
+	/* Initialize formats to default values */
+	fmt = &camsv_m->subdev_fmt;
+	fmt->width = default_width;
+	fmt->height = default_height;
+	fmt->code = dflt_fmt.mbus_code;
+	fmt->field = V4L2_FIELD_NONE;
+	fmt->colorspace = V4L2_COLORSPACE_RAW;
+	fmt->ycbcr_enc = V4L2_YCBCR_ENC_DEFAULT;
+	fmt->quantization = V4L2_QUANTIZATION_DEFAULT;
+	fmt->xfer_func = V4L2_XFER_FUNC_DEFAULT;
+
+	/* Initialize media entities */
+	r = media_entity_pads_init(&subdev->entity, CAMSV_PADS, camsv_m->subdev_pads);
+	if (r) {
+		dev_err(camsv->dev,
+			"failed initialize subdev media entity (%d)\n", r);
+		goto fail_subdev_media_entity;
+	}
+
+	for (i = 0; i < (CAMSV_PADS/2); i++) {
+		camsv_m->subdev_pads[i].flags = (MEDIA_PAD_FL_SINK | MEDIA_PAD_FL_MUST_CONNECT);
+		camsv_m->subdev_pads[i+ISP_CAMSV0_SOURCE].flags = MEDIA_PAD_FL_SOURCE;
+	}
+	subdev->entity.ops = &camsv_media_ops;
+
+	/* Initialize subdev */
+	v4l2_subdev_init(subdev, &camsv_subdev_ops);
+	subdev->flags = V4L2_SUBDEV_FL_HAS_DEVNODE | V4L2_SUBDEV_FL_HAS_EVENTS;
+	subdev->owner = THIS_MODULE;
+	snprintf(subdev->name, sizeof(subdev->name),
+		 CAMSV_ENTITY_NAME " %td", camsv_m - camsv->camsv_module);
+	v4l2_set_subdevdata(subdev, camsv);
+	r = v4l2_device_register_subdev(&camsv->v4l2_dev, subdev);
+	if (r) {
+		dev_err(camsv->dev,
+			"failed initialize subdev (%d)\n", r);
+		goto fail_vdev_media_entity;
+	}
+
+	/* register subdevice */
+	if (!(subdev->flags & V4L2_SUBDEV_FL_HAS_DEVNODE)) {
+		r = EINVAL;
+		goto fail_vdev_media_entity;
+	}
+
+	cam_vdev = kzalloc(sizeof(*cam_vdev), GFP_KERNEL);
+	if (!cam_vdev) {
+		r = -ENOMEM;
+		goto fail_vdev_media_entity;
+	}
+
+	video_set_drvdata(cam_vdev, subdev);
+	strlcpy(cam_vdev->name, subdev->name, sizeof(cam_vdev->name));
+	cam_vdev->v4l2_dev = &camsv->v4l2_dev;
+	cam_vdev->fops = &v4l2_subdev_fops;
+	cam_vdev->release = v4l2_device_release_camsv_subdev_node;
+	cam_vdev->ctrl_handler = subdev->ctrl_handler;
+	r = __video_register_device(cam_vdev, VFL_TYPE_SUBDEV, -1, 1,
+					  subdev->owner);
+	if (r < 0)
+		goto fail_reg_subdev;
+
+#if defined(CONFIG_MEDIA_CONTROLLER)
+	subdev->entity.info.dev.major = VIDEO_MAJOR;
+	subdev->entity.info.dev.minor = cam_vdev->minor;
+	subdev->entity.name = video_device_node_name(cam_vdev);
+#endif
+	subdev->devnode = cam_vdev;
+
+	/* init video devices(CamSV output) */
+	vdev = &camsv_m->vdev;
+	vdev_pad = &camsv_m->vdev_pad;
+	r = media_entity_pads_init(&vdev->entity, CAMSV_PADS, vdev_pad);
+	if (r) {
+		dev_err(camsv->dev,
+			"failed initialize %d-th videodev media entity (%d)\n", i, r);
+		goto fail_reg_subdev;
+	}
+
+	vdev_pad = &camsv_m->vdev_pad;
+	vdev = &camsv_m->vdev;
+
+	vdev_pad->flags = (MEDIA_PAD_FL_SINK | MEDIA_PAD_FL_MUST_CONNECT);
+	vdev->entity.ops = &camsv_media_ops;
+
+	{
+		vdev = &camsv_m->vdev;
+		vbq = &camsv_m->vbq;
+		format = &camsv_m->format;
+		in_ptr = &camsv_m->camsv_port_input;
+		out_ptr = &camsv_m->camsv_port_output;
+		capture = &camsv_m->capture;
+		hdl = &camsv_m->hdl;
+
+		INIT_LIST_HEAD(capture);
+
+		format->width = default_width;
+		format->height = default_height;
+		format->pixelformat = dflt_fmt.fourcc;
+		format->colorspace = V4L2_COLORSPACE_RAW;
+		format->field = V4L2_FIELD_NONE;
+		format->num_planes = 1;
+		format->plane_fmt[0].bytesperline =
+					camsv_bytesperline(format->width);
+		format->plane_fmt[0].sizeimage = format->plane_fmt[0].bytesperline *
+							format->height;
+
+		/* Initialize vbq */
+		vbq->type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+		vbq->io_modes = VB2_USERPTR | VB2_MMAP | VB2_DMABUF;
+		vbq->ops = &camsv_vb2_ops;
+		vbq->mem_ops = &camsv_vb2_mem_op;
+		vbq->buf_struct_size = sizeof(struct camsv_buffer);
+		vbq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;
+		vbq->min_buffers_needed = 1;
+		vbq->drv_priv = camsv;
+		vbq->lock = &camsv_m->lock;
+		vbq->owner = NULL;
+		r = vb2_queue_init(vbq);
+		if (r) {
+			dev_err(camsv->dev,
+				"failed to initialize videobuf2 queue (%d)\n", r);
+			goto fail_vbq;
+		}
+
+		/* Initialize vdev */
+		snprintf(vdev->name, sizeof(vdev->name),
+			 "%s %td", CAMSV_NAME, camsv_m - camsv->camsv_module);
+		vdev->release = video_device_release_empty;
+		vdev->fops = &camsv_v4l2_fops;
+		vdev->ioctl_ops = &camsv_v4l2_ioctl_ops;
+		vdev->lock = &camsv->lock;
+		vdev->v4l2_dev = &camsv->v4l2_dev;
+		vdev->queue = &camsv_m->vbq;
+		vdev->ctrl_handler = hdl;
+		video_set_drvdata(vdev, camsv);
+
+		dprintk(3, "name %s\n", vdev->name);
+
+		r = video_register_device(vdev, VFL_TYPE_GRABBER, -1);
+		if (r) {
+			dev_err(camsv->dev,
+				"failed to register video device (%d)\n", r);
+			goto fail_vdev;
+		}
+#if defined(CONFIG_MEDIA_CONTROLLER)
+		vdev->entity.info.dev.major = VIDEO_MAJOR;
+		vdev->entity.info.dev.minor = vdev->minor;
+		vdev->entity.name = video_device_node_name(vdev);
+#endif
+
+		r = media_create_pad_link(
+			&subdev->entity, CAMSV_PAD_SOURCE, &vdev->entity, 0,
+			MEDIA_LNK_FL_ENABLED | MEDIA_LNK_FL_IMMUTABLE);
+		if (r)
+			goto fail_link;
+	}
+
+	return 0;
+
+fail_link:
+	video_unregister_device(&camsv_m->vdev);
+fail_vdev:
+	vb2_queue_release(vbq);
+fail_vbq:
+	v4l2_device_unregister_subdev(subdev);
+	media_entity_cleanup(&vdev->entity);
+fail_reg_subdev:
+	kfree(cam_vdev);
+fail_vdev_media_entity:
+	media_entity_cleanup(&subdev->entity);
+fail_subdev_media_entity:
+	mutex_destroy(&camsv_m->lock);
+
+	return r;
+}
+
+static void camsv_module_exit(struct camsv_device *camsv, struct camsv_Module *camsv_m)
+{
+	struct camsv_device *camsvTmp = camsv;
+
+	dprintk(3, "%s (%p) +\n", __func__, camsvTmp);
+
+	video_unregister_device(&camsv_m->vdev);
+	media_entity_cleanup(&camsv_m->vdev.entity);
+	vb2_queue_release(&camsv_m->vbq);
+	v4l2_device_unregister_subdev(&camsv_m->subdev);
+	media_entity_cleanup(&camsv_m->subdev.entity);
+	mutex_destroy(&camsv_m->lock);
+	dprintk(3, "%s (%p) -\n", __func__, camsvTmp);
+}
+
+static int camsv_queues_init(struct camsv_device *camsv)
+{
+	int i, r;
+
+	for (i = 0; i < CAMSV_MAX_MODULES; i++) {
+		r = camsv_module_init(camsv, &camsv->camsv_module[i]);
+		if (r)
+			break;
+	}
+
+	if (i == CAMSV_MAX_MODULES)
+		return 0;
+
+	for (i--; i >= 0; i--)
+		camsv_module_exit(camsv, &camsv->camsv_module[i]);
+
+	return r;
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static int ISP_camsv_probe(struct platform_device *pDev)
+{
+	int Ret = 0;
+	/*    struct resource *pRes = NULL;*/
+	int i = 0, j = 0;
+	unsigned char n;
+	unsigned int irq_info[3]; /* Record interrupts info from device tree */
+	struct isp_device *_ispdev = NULL;
+	struct device_node *node;
+	struct platform_device *pDevTmp = pDev;
+	struct device *dev;
+	static struct camsv_device *camsv_d;
+	int r;
+
+#ifdef CONFIG_OF
+	struct isp_device *isp_dev;
+#endif
+
+	dprintk(3, "- E. ISP driver probe. nr_isp_devs %d\n", nr_isp_devs);
+
+	/* Get platform_device parameters */
+#ifdef CONFIG_OF
+	if (pDev == NULL) {
+		dev_err(&pDev->dev, "pDev is NULL");
+		return -ENXIO;
+	}
+
+	nr_isp_devs += 1;
+	atomic_inc(&G_u4DevNodeCt);
+
+	_ispdev = krealloc(isp_devs, sizeof(struct isp_device) * nr_isp_devs, GFP_KERNEL);
+	if (!_ispdev) {
+		dev_err(&pDev->dev, "Unable to allocate isp_devs\n");
+		return -ENOMEM;
+	}
+	isp_devs = _ispdev;
+
+
+	isp_dev = &(isp_devs[nr_isp_devs - 1]);
+	isp_dev->dev = &pDev->dev;
+
+	/* iomap registers */
+	isp_dev->regs = of_iomap(pDev->dev.of_node, 0);
+	if (!isp_dev->regs) {
+		dev_err(&pDev->dev, "Unable to ioremap registers, of_iomap fail, nr_isp_devs=%d, devnode(%s).\n",
+			nr_isp_devs, pDev->dev.of_node->name);
+		return -ENOMEM;
+	}
+
+	dprintk(3, "nr_isp_devs=%d, devnode(%s), map_addr=0x%lx\n",
+		nr_isp_devs, pDev->dev.of_node->name, (unsigned long)isp_dev->regs);
+
+	/* Only register V4L2 driver in the 1st time */
+	if (nr_isp_devs == 1) {
+		//v4l2 --------------------------------------------------------------------
+		dprintk(3, "- v4l2 probe start\n");
+		camsv_d = devm_kzalloc(&pDev->dev, sizeof(*camsv_d), GFP_KERNEL);
+		if (!camsv_d)
+			return -ENOMEM;
+		camsv_d->dev = &pDev->dev;
+
+		camsv_d->base = of_iomap(pDev->dev.of_node, 0);
+
+		dev_set_drvdata(&pDev->dev, camsv_d);
+
+		mutex_init(&camsv_d->lock);
+		dprintk(3, "- v4l2 probe 0, camsv_device->base %p\n", camsv_d->base);
+
+		camsv_d->media_dev.dev = camsv_d->dev;
+		strlcpy(camsv_d->media_dev.model, CAMSV_DEVICE_NAME,
+			sizeof(camsv_d->media_dev.model));
+		snprintf(camsv_d->media_dev.bus_info, sizeof(camsv_d->media_dev.bus_info),
+			 "CAMSV:%s", dev_name(camsv_d->dev));
+
+		camsv_d->media_dev.topology_version = 1;
+		camsv_d->media_dev.hw_revision = 0;
+
+		r = media_device_register(&camsv_d->media_dev);
+		if (r < 0) {
+			LOG_INF("fail at vb2_dma_sg_init_ctx\n");
+			return -ENOMEM;
+		}
+
+		camsv_d->v4l2_dev.mdev = &camsv_d->media_dev;
+		r = v4l2_device_register(&pDev->dev, &camsv_d->v4l2_dev);
+		if (r) {
+			dev_err(&pDev->dev,
+				"failed to register V4L2 device (%d)\n", r);
+			return -ENOMEM;
+		}
+
+		r = camsv_queues_init(camsv_d);
+		if (r) {
+			LOG_INF("fail at vb2_dma_sg_init_ctx\n");
+			return -ENOMEM;
+		}
+
+		/* Register notifier for subdevices we care */
+		r = camsv_notifier_init(camsv_d);
+		if (r) {
+			LOG_INF("fail at vb2_dma_sg_init_ctx\n");
+			return -ENOMEM;
+		}
+		//v4l2 --------------------------------------------
+	}
+
+	/* get IRQ ID and request IRQ */
+	isp_dev->irq = irq_of_parse_and_map(pDev->dev.of_node, 0);
+
+	if (isp_dev->irq > 0) {
+		/* Get IRQ Flag from device node */
+		if (of_property_read_u32_array(pDev->dev.of_node, "interrupts", irq_info, ARRAY_SIZE(irq_info))) {
+			dev_err(&pDev->dev, "get irq flags from DTS fail!!\n");
+			return -ENODEV;
+		}
+
+		for (i = 0; i < ISP_IRQ_TYPE_AMOUNT; i++) {
+			if ((strcmp(pDev->dev.of_node->name, IRQ_CAMSV_CB_TBL[i].device_name) == 0) &&
+				(IRQ_CAMSV_CB_TBL[i].isr_fp != NULL)) {
+
+				Ret = request_irq(isp_dev->irq, (irq_handler_t)IRQ_CAMSV_CB_TBL[i].isr_fp,
+						  irq_info[2], (const char *)IRQ_CAMSV_CB_TBL[i].device_name, camsv_d);
+				if (Ret) {
+					dev_err(&pDev->dev,
+					"request_irq fail, nr_isp_devs=%d, devnode(%s), irq=%d, ISR: %s\n",
+					nr_isp_devs, pDev->dev.of_node->name,
+					isp_dev->irq, IRQ_CAMSV_CB_TBL[i].device_name);
+					return Ret;
+				}
+
+				dprintk(3, "nr_isp_devs=%d, devnode(%s), irq=%d, ISR: %s\n",
+					nr_isp_devs, pDev->dev.of_node->name, isp_dev->irq,
+					IRQ_CAMSV_CB_TBL[i].device_name);
+				break;
+			}
+		}
+
+		if (i >= ISP_IRQ_TYPE_AMOUNT)
+			LOG_INF("No corresponding ISR!!: nr_isp_devs=%d, devnode(%s), irq=%d\n",
+				nr_isp_devs, pDev->dev.of_node->name, isp_dev->irq);
+
+
+	} else {
+		LOG_INF("No IRQ!!: nr_isp_devs=%d, devnode(%s), irq=%d\n",
+			nr_isp_devs, pDev->dev.of_node->name, isp_dev->irq);
+	}
+
+	/* Only register char driver in the 1st time */
+	if (nr_isp_devs == 1) {
+#endif
+
+		/* Init spinlocks */
+		spin_lock_init(&(IspInfo.SpinLockIspRef));
+		spin_lock_init(&(IspInfo.SpinLockIsp));
+		for (n = 0; n < ISP_IRQ_TYPE_AMOUNT; n++) {
+			spin_lock_init(&(IspInfo.SpinLockIrq[n]));
+			spin_lock_init(&(IspInfo.SpinLockIrqCnt[n]));
+		}
+		spin_lock_init(&(IspInfo.SpinLockRTBC));
+		spin_lock_init(&(IspInfo.SpinLockClock));
+
+		spin_lock_init(&(SpinLock_UserKey));
+		#ifdef ENABLE_KEEP_ION_HANDLE
+		for (i = 0; i < ISP_DEV_NODE_NUM; i++) {
+			if (gION_TBL[i].node != ISP_DEV_NODE_NUM) {
+				for (n = 0; n < _dma_max_wr_; n++)
+					spin_lock_init(&(gION_TBL[i].pLock[n]));
+			}
+		}
+		#endif
+
+#ifndef EP_NO_CLKMGR /* CCF */
+
+		dev = &pDevTmp->dev;
+
+		node = of_parse_phandle(dev->of_node, "mediatek,larb", 0);
+		if (!node) {
+			LOG_ERR("no mediatek,larb found");
+			return -ENXIO;
+		}
+		pDevTmp = of_find_device_by_node(node);
+		if (!pDevTmp) {
+			LOG_ERR("no mediatek,larb device found");
+			return -ENXIO;
+		}
+		isp_clk.larbipu = &pDevTmp->dev;
+
+		node = of_parse_phandle(dev->of_node, "mediatek,larb", 1);
+		if (!node) {
+			LOG_ERR("no mediatek,larb found");
+			return -ENXIO;
+		}
+
+		pDevTmp = of_find_device_by_node(node);
+		if (!pDevTmp) {
+			LOG_ERR("no mediatek,larb device found");
+			return -ENXIO;
+		}
+
+		isp_clk.larbcam = &pDevTmp->dev;
+		isp_clk.dev = &pDev->dev;
+		pDevTmp = pDev;
+
+		if (!isp_clk.ISP_CAM_CAMSYS)
+			isp_clk.ISP_CAM_CAMSYS = devm_clk_get(&pDev->dev, "CAMSYS_CAM_CGPDN");
+		if (!isp_clk.ISP_CAM_CAMTG)
+			isp_clk.ISP_CAM_CAMTG = devm_clk_get(&pDev->dev, "CAMSYS_CAMTG_CGPDN");
+		if (!isp_clk.ISP_CAM_CAMSV0)
+			isp_clk.ISP_CAM_CAMSV0 = devm_clk_get(&pDev->dev, "CAMSYS_CAMSV0_CGPDN");
+		if (!isp_clk.ISP_CAM_CAMSV1)
+			isp_clk.ISP_CAM_CAMSV1 = devm_clk_get(&pDev->dev, "CAMSYS_CAMSV1_CGPDN");
+		if (!isp_clk.ISP_CAM_CAMSV2)
+			isp_clk.ISP_CAM_CAMSV2 = devm_clk_get(&pDev->dev, "CAMSYS_CAMSV2_CGPDN");
+
+		if (IS_ERR(isp_clk.ISP_CAM_CAMSYS)) {
+			LOG_NOTICE("cannot get ISP_CAM_CAMSYS clock\n");
+			return PTR_ERR(isp_clk.ISP_CAM_CAMSYS);
+		}
+		if (IS_ERR(isp_clk.ISP_CAM_CAMTG)) {
+			LOG_NOTICE("cannot get ISP_CAM_CAMTG clock\n");
+			return PTR_ERR(isp_clk.ISP_CAM_CAMTG);
+		}
+		if (IS_ERR(isp_clk.ISP_CAM_CAMSV0)) {
+			LOG_NOTICE("cannot get ISP_CAM_CAMSV0 clock\n");
+			return PTR_ERR(isp_clk.ISP_CAM_CAMSV0);
+		}
+		if (IS_ERR(isp_clk.ISP_CAM_CAMSV1)) {
+			LOG_NOTICE("cannot get ISP_CAM_CAMSV1 clock\n");
+			return PTR_ERR(isp_clk.ISP_CAM_CAMSV1);
+		}
+		if (IS_ERR(isp_clk.ISP_CAM_CAMSV2)) {
+			LOG_NOTICE("cannot get ISP_CAM_CAMSV2 clock\n");
+			return PTR_ERR(isp_clk.ISP_CAM_CAMSV2);
+		}
+		pm_runtime_enable(&pDev->dev);
+#endif
+		/*  */
+		for (i = 0 ; i < ISP_IRQ_TYPE_AMOUNT; i++)
+			init_waitqueue_head(&IspInfo.WaitQueueHead[i]);
+
+#ifdef CONFIG_PM_WAKELOCKS
+		wakeup_source_init(&isp_wake_lock, "isp_lock_wakelock");
+#else
+		wake_lock_init(&isp_wake_lock, WAKE_LOCK_SUSPEND, "isp_lock_wakelock");
+#endif
+
+		for (i = 0; i < ISP_IRQ_TYPE_AMOUNT; i++)
+			tasklet_init(isp_tasklet[i].pIsp_tkt, isp_tasklet[i].tkt_cb, 0);
+
+#if (ISP_BOTTOMHALF_WORKQ == 1)
+		for (i = 0 ; i < ISP_IRQ_TYPE_AMOUNT; i++) {
+			isp_workque[i].module = i;
+			memset((void *)&(isp_workque[i].isp_bh_work), 0,
+				sizeof(isp_workque[i].isp_bh_work));
+			INIT_WORK(&(isp_workque[i].isp_bh_work), ISP_BH_Workqueue);
+		}
+#endif
+
+
+		/* Init IspInfo*/
+		spin_lock(&(IspInfo.SpinLockIspRef));
+		IspInfo.UserCount = 0;
+		spin_unlock(&(IspInfo.SpinLockIspRef));
+		IspInfo.IrqInfo.Mask[ISP_IRQ_TYPE_INT_CAMSV_0_ST][SIGNAL_INT] = INT_ST_MASK_CAMSV;
+		IspInfo.IrqInfo.Mask[ISP_IRQ_TYPE_INT_CAMSV_1_ST][SIGNAL_INT] = INT_ST_MASK_CAMSV;
+		IspInfo.IrqInfo.Mask[ISP_IRQ_TYPE_INT_CAMSV_2_ST][SIGNAL_INT] = INT_ST_MASK_CAMSV;
+		IspInfo.IrqInfo.Mask[ISP_IRQ_TYPE_INT_CAMSV_3_ST][SIGNAL_INT] = INT_ST_MASK_CAMSV;
+		IspInfo.IrqInfo.Mask[ISP_IRQ_TYPE_INT_CAMSV_4_ST][SIGNAL_INT] = INT_ST_MASK_CAMSV;
+		IspInfo.IrqInfo.Mask[ISP_IRQ_TYPE_INT_CAMSV_5_ST][SIGNAL_INT] = INT_ST_MASK_CAMSV;
+
+		IspInfo.IrqInfo.ErrMask[ISP_IRQ_TYPE_INT_CAMSV_0_ST][SIGNAL_INT]  = INT_ST_MASK_CAMSV_ERR;
+		IspInfo.IrqInfo.ErrMask[ISP_IRQ_TYPE_INT_CAMSV_1_ST][SIGNAL_INT]  = INT_ST_MASK_CAMSV_ERR;
+		IspInfo.IrqInfo.ErrMask[ISP_IRQ_TYPE_INT_CAMSV_2_ST][SIGNAL_INT]  = INT_ST_MASK_CAMSV_ERR;
+		IspInfo.IrqInfo.ErrMask[ISP_IRQ_TYPE_INT_CAMSV_3_ST][SIGNAL_INT]  = INT_ST_MASK_CAMSV_ERR;
+		IspInfo.IrqInfo.ErrMask[ISP_IRQ_TYPE_INT_CAMSV_4_ST][SIGNAL_INT]  = INT_ST_MASK_CAMSV_ERR;
+		IspInfo.IrqInfo.ErrMask[ISP_IRQ_TYPE_INT_CAMSV_5_ST][SIGNAL_INT]  = INT_ST_MASK_CAMSV_ERR;
+
+		/* Init IrqCntInfo */
+		for (i = 0; i < ISP_IRQ_TYPE_AMOUNT; i++) {
+			for (j = 0; j < ISP_ISR_MAX_NUM; j++) {
+				IspInfo.IrqCntInfo.m_err_int_cnt[i][j] = 0;
+				IspInfo.IrqCntInfo.m_warn_int_cnt[i][j] = 0;
+			}
+			IspInfo.IrqCntInfo.m_err_int_mark[i] = 0;
+			IspInfo.IrqCntInfo.m_warn_int_mark[i] = 0;
+
+			IspInfo.IrqCntInfo.m_int_usec[i] = 0;
+		}
+
+	}
+
+	dprintk(3, "- X. ISP driver probe.\n");
+
+	return Ret;
+}
+
+/*******************************************************************************
+ * Called when the device is being detached from the driver
+ ********************************************************************************/
+static int ISP_camsv_remove(struct platform_device *pDev)
+{
+	/*    struct resource *pRes;*/
+	int IrqNum;
+	int i;
+	/*  */
+	dprintk(3, "- E.");
+
+	pm_runtime_disable(&pDev->dev);
+
+	/* Release IRQ */
+	disable_irq(IspInfo.IrqNum);
+	IrqNum = platform_get_irq(pDev, 0);
+	free_irq(IrqNum, NULL);
+
+	/* kill tasklet */
+	for (i = 0; i < ISP_IRQ_TYPE_AMOUNT; i++)
+		tasklet_kill(isp_tasklet[i].pIsp_tkt);
+
+	return 0;
+}
+
+static int ISP_camsv_suspend(
+	struct platform_device *pDev,
+	pm_message_t            Mesg
+)
+{
+	unsigned int regVal;
+	int IrqType, ret, module;
+	char moduleName[128];
+
+	unsigned int regTGSt, loopCnt;
+	struct ISP_WAIT_IRQ_STRUCT waitirq;
+	ktime_t             time;
+	unsigned long long  sec = 0, m_sec = 0;
+	unsigned long long  timeoutMs = 500000000;/*500ms*/
+
+	ret = 0;
+	module = -1;
+	strncpy(moduleName, pDev->dev.of_node->name, 127);
+
+	/* update device node count*/
+	atomic_dec(&G_u4DevNodeCt);
+
+/* Check clock counter instead of check IspInfo.UserCount
+ *  for ensuring current clocks are on or off
+ */
+	spin_lock(&(IspInfo.SpinLockClock));
+	if (!G_u4EnableClockCount) {
+		spin_unlock(&(IspInfo.SpinLockClock));
+		/* Only print cama log */
+		if (strcmp(moduleName, IRQ_CAMSV_CB_TBL[ISP_IRQ_TYPE_INT_CAMSV_0_ST].device_name) == 0) {
+			dprintk(3, "%s - X. UserCount=%d,wakelock:%d,devct:%d\n", moduleName,
+				IspInfo.UserCount, G_u4EnableClockCount, atomic_read(&G_u4DevNodeCt));
+		} else if (IspInfo.UserCount != 0) {
+			dprintk(3, "%s - X. UserCount=%d,G_u4EnableClockCount=0,wakelock:%d,devct:%d\n",
+				moduleName, IspInfo.UserCount, G_u4EnableClockCount, atomic_read(&G_u4DevNodeCt));
+		}
+
+		return ret;
+	}
+	spin_unlock(&(IspInfo.SpinLockClock));
+
+	for (IrqType = 0; IrqType < ISP_IRQ_TYPE_AMOUNT; IrqType++) {
+		if (strcmp(moduleName, IRQ_CAMSV_CB_TBL[IrqType].device_name) == 0)
+			break;
+	}
+
+	switch (IrqType) {
+	case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+		module = ISP_CAMSV0_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+		module = ISP_CAMSV1_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+		module = ISP_CAMSV2_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+		module = ISP_CAMSV3_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+		module = ISP_CAMSV4_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+		module = ISP_CAMSV5_IDX;
+		break;
+	case ISP_IRQ_TYPE_AMOUNT:
+		LOG_NOTICE("dev name is not found (%s)", moduleName);
+		break;
+	default:
+		/*don nothing*/
+		break;
+	}
+
+	if (module < 0)
+		goto EXIT;
+
+	regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(module));
+	/*LOG_DBG("%s: Rs_TG(0x%08x)\n", moduleName, regVal);*/
+
+	if (regVal & 0x01) {
+		dprintk(3, "%s_suspend,disable VF,wakelock:%d,clk:%d,devct:%d\n", moduleName,
+			g_WaitLockCt, G_u4EnableClockCount, atomic_read(&G_u4DevNodeCt));
+		SuspnedRecord[module] = 1;
+		/* disable VF */
+		ISP_WR32(CAMSV_REG_TG_VF_CON(module), (regVal & (~0x01)));
+
+		/* wait TG idle*/
+		loopCnt = 3;
+		waitirq.Type = IrqType;
+		waitirq.EventInfo.Clear = ISP_IRQ_CLEAR_WAIT;
+		waitirq.EventInfo.Status = VS_INT_ST;
+		waitirq.EventInfo.St_type = SIGNAL_INT;
+		waitirq.EventInfo.Timeout = 0x100;
+		waitirq.EventInfo.UserKey = 0x0;
+		waitirq.bDumpReg = 0;
+
+		do {
+			regTGSt = (ISP_RD32(CAMSV_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+			if (regTGSt == 1)
+				break;
+
+			dprintk(3, "%s: wait 1VD (%d)\n", moduleName, loopCnt);
+			ret = ISP_WaitIrq(&waitirq);
+			/* first wait is clear wait, others are non-clear wait */
+			waitirq.EventInfo.Clear = ISP_IRQ_CLEAR_NONE;
+		} while (--loopCnt);
+
+		if (-ERESTARTSYS == ret) {
+			LOG_INF("%s: interrupt by system signal, wait idle\n", moduleName);
+			/* timer*/
+			time = ktime_get();
+			m_sec = time;
+
+			while (regTGSt != 1) {
+				regTGSt = (ISP_RD32(CAMSV_REG_TG_INTER_ST(module)) & 0x00003F00) >> 8;
+				/*timer*/
+				time = ktime_get();
+				sec = time;
+				/* wait time>timeoutMs, break */
+				if ((sec - m_sec) > timeoutMs)
+					break;
+			}
+			if (regTGSt == 1)
+				dprintk(3, "%s: wait idle done\n", moduleName);
+			else
+				dprintk(3, "%s: wait idle timeout(%lld)\n", moduleName, (sec - m_sec));
+		}
+
+/*backup: frame CNT
+ * After VF enable, The frame count will be 0 at next VD;
+ * if it has P1_DON after set vf disable, g_BkReg no need to add 1
+ */
+		regTGSt = ISP_RD32_TG_CAM_FRM_CNT(IrqType, module);
+		g_BkReg[IrqType].CAM_TG_INTER_ST = regTGSt;
+		regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(module));
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(module), (regVal & (~0x01)));
+	} else {
+		dprintk(3, "%s_suspend,wakelock:%d,clk:%d,devct:%d\n", moduleName, g_WaitLockCt,
+			G_u4EnableClockCount, atomic_read(&G_u4DevNodeCt));
+		SuspnedRecord[module] = 0;
+	}
+
+EXIT:
+	/* last dev node will disable clk "G_u4EnableClockCount" times */
+	if (!atomic_read(&G_u4DevNodeCt)) {
+		spin_lock(&(IspInfo.SpinLockClock));
+		loopCnt = G_u4EnableClockCount;
+		spin_unlock(&(IspInfo.SpinLockClock));
+
+		dprintk(3, "%s - X. wakelock:%d, last dev node,disable clk:%d\n",
+			moduleName, g_WaitLockCt, loopCnt);
+		while (loopCnt > 0) {
+			ISP_EnableClock(MFALSE);
+			loopCnt--;
+		}
+	}
+
+	return 0;
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static int ISP_camsv_resume(struct platform_device *pDev)
+{
+	unsigned int regVal;
+	int IrqType, ret, module;
+	char moduleName[128];
+
+	ret = 0;
+	module = -1;
+	strncpy(moduleName, pDev->dev.of_node->name, 127);
+
+	/* update device node count*/
+	atomic_inc(&G_u4DevNodeCt);
+
+	if (IspInfo.UserCount == 0) {
+		/* Only print cama log */
+		if (strcmp(moduleName, IRQ_CAMSV_CB_TBL[ISP_IRQ_TYPE_INT_CAMSV_0_ST].device_name) == 0)
+			dprintk(3, "%s - X. UserCount=0\n", moduleName);
+
+		return 0;
+	}
+
+	for (IrqType = 0; IrqType < ISP_IRQ_TYPE_AMOUNT; IrqType++) {
+		if (strcmp(moduleName, IRQ_CAMSV_CB_TBL[IrqType].device_name) == 0)
+			break;
+	}
+
+	switch (IrqType) {
+	case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+		module = ISP_CAMSV0_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+		module = ISP_CAMSV1_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+		module = ISP_CAMSV2_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+		module = ISP_CAMSV3_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+		module = ISP_CAMSV4_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+		module = ISP_CAMSV5_IDX;
+		break;
+	case ISP_IRQ_TYPE_AMOUNT:
+		LOG_NOTICE("dev name is not found (%s)", moduleName);
+		break;
+	default:
+		/*don nothing*/
+		break;
+	}
+
+	if (module < 0)
+		return ret;
+
+	ISP_EnableClock(MTRUE);
+
+	if (SuspnedRecord[module]) {
+		dprintk(3, "%s_resume,enable VF,wakelock:%d,clk:%d,devct:%d\n", moduleName,
+			g_WaitLockCt, G_u4EnableClockCount, atomic_read(&G_u4DevNodeCt));
+		SuspnedRecord[module] = 0;
+
+		/*cmos*/
+		regVal = ISP_RD32(CAMSV_REG_TG_SEN_MODE(module));
+		ISP_WR32(CAMSV_REG_TG_SEN_MODE(module), (regVal | 0x01));
+		/*vf*/
+		regVal = ISP_RD32(CAMSV_REG_TG_VF_CON(module));
+		ISP_WR32(CAMSV_REG_TG_VF_CON(module), (regVal | 0x01));
+	} else {
+		dprintk(3, "%s_resume,wakelock:%d,clk:%d,devct:%d\n", moduleName,
+			g_WaitLockCt, G_u4EnableClockCount, atomic_read(&G_u4DevNodeCt));
+	}
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+#ifdef CONFIG_PM
+/*---------------------------------------------------------------------------*/
+int ISP_camsv_pm_suspend(struct device *device)
+{
+	struct platform_device *pdev = to_platform_device(device);
+
+	WARN_ON(pdev == NULL);
+
+	/*pr_debug("calling %s()\n", __func__);*/
+
+	return ISP_camsv_suspend(pdev, PMSG_SUSPEND);
+}
+
+int ISP_camsv_pm_resume(struct device *device)
+{
+	struct platform_device *pdev = to_platform_device(device);
+
+	WARN_ON(pdev == NULL);
+
+	/*pr_debug("calling %s()\n", __func__);*/
+
+	return ISP_camsv_resume(pdev);
+}
+
+/*---------------------------------------------------------------------------*/
+#else /*CONFIG_PM*/
+/*---------------------------------------------------------------------------*/
+#define ISP_pm_suspend NULL
+#define ISP_pm_resume  NULL
+#define ISP_pm_restore_noirq NULL
+/*---------------------------------------------------------------------------*/
+#endif /*CONFIG_PM*/
+/*---------------------------------------------------------------------------*/
+
+const struct dev_pm_ops ISP_camsv_pm_ops = {
+	.suspend = ISP_camsv_pm_suspend,
+	.resume = ISP_camsv_pm_resume,
+	.freeze = ISP_camsv_pm_suspend,
+	.thaw = ISP_camsv_pm_resume,
+	.poweroff = ISP_camsv_pm_suspend,
+	.restore = ISP_camsv_pm_resume,
+};
+
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static struct platform_driver IspCamSVDriver = {
+	.probe   = ISP_camsv_probe,
+	.remove  = ISP_camsv_remove,
+	.suspend = ISP_camsv_suspend,
+	.resume  = ISP_camsv_resume,
+	.driver  = {
+		.name  = ISP_DEV_NAME,
+		.owner = THIS_MODULE,
+#ifdef CONFIG_OF
+		.of_match_table = isp_camsv_of_ids,
+#endif
+#ifdef CONFIG_PM
+		.pm     = &ISP_camsv_pm_ops,
+#endif
+	}
+};
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+
+static int __init ISP_camsv_Init(void)
+{
+	int Ret = 0, i, j;
+	void *tmp;
+	struct device_node *node = NULL;
+
+	/*  */
+	LOG_INF("- E.");
+#ifdef ENABLE_KEEP_ION_HANDLE
+	/*  */
+	mutex_init(&ion_client_mutex);
+#endif
+	/*  */
+	atomic_set(&G_u4DevNodeCt, 0);
+	/*  */
+	Ret = platform_driver_register(&IspCamSVDriver);
+	if ((Ret) < 0) {
+		LOG_NOTICE("platform_driver_register fail");
+		return Ret;
+	}
+
+	/* Use of_find_compatible_node() sensor registers from device tree */
+	/* Don't use compatitble define in probe(). Otherwise, probe() of Seninf driver cannot be called. */
+	#if (SMI_LARB_MMU_CTL == 1)
+	do {
+		char *comp_str = NULL;
+
+		comp_str = kmalloc(64, GFP_KERNEL);
+		if (comp_str == NULL) {
+			LOG_NOTICE("kmalloc failed for finding compatible\n");
+			break;
+		}
+
+		for (i = 0; i < ARRAY_SIZE(SMI_LARB_BASE); i++) {
+
+			snprintf(comp_str, 64, "mediatek,smi_larb%d", i);
+			LOG_INF("Finding SMI_LARB compatible: %s\n", comp_str);
+
+			node = of_find_compatible_node(NULL, NULL, comp_str);
+			if (!node) {
+				LOG_NOTICE("find %s node failed!!!\n", comp_str);
+				SMI_LARB_BASE[i] = 0;
+				continue;
+			}
+			SMI_LARB_BASE[i] = of_iomap(node, 0);
+			if (!SMI_LARB_BASE[i]) {
+				LOG_NOTICE("unable to map SMI_LARB_BASE registers!!!\n");
+				break;
+			}
+			LOG_INF("SMI_LARB%d_BASE: %p\n", i, SMI_LARB_BASE[i]);
+		}
+
+		/* if (comp_str) coverity: no need if, kfree is safe */
+		kfree(comp_str);
+	} while (0);
+	#endif
+	node = of_find_compatible_node(NULL, NULL, "mediatek,mmsys_config");
+	if (!node) {
+		LOG_NOTICE("find mmsys_config node failed!!!\n");
+		return -ENODEV;
+	}
+
+	/* FIX-ME: linux-3.10 procfs API changed */
+	//proc_create("driver/ispcamsv_reg", 0, NULL, &fcameraisp_proc_fops);
+	//proc_create("driver/camsvio_reg", 0, NULL, &fcameraio_proc_fops);
+
+	for (j = 0; j < ISP_IRQ_TYPE_AMOUNT; j++) {
+		switch (j) {
+		case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+		case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+		case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+		case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+		case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+		case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+			if (sizeof(struct ISP_RT_BUF_STRUCT) > ((RT_BUF_TBL_NPAGES) * PAGE_SIZE)) {
+				i = 0;
+				while (i < sizeof(struct ISP_RT_BUF_STRUCT))
+					i += PAGE_SIZE;
+
+				pBuf_kmalloc[j] = kmalloc(i + 2 * PAGE_SIZE, GFP_KERNEL);
+				if ((pBuf_kmalloc[j]) == NULL) {
+					LOG_NOTICE("mem not enough\n");
+					return -ENOMEM;
+				}
+				memset(pBuf_kmalloc[j], 0x00, i);
+				Tbl_RTBuf_MMPSize[j] = i;
+			} else {
+				pBuf_kmalloc[j] = kmalloc((RT_BUF_TBL_NPAGES + 2) * PAGE_SIZE, GFP_KERNEL);
+				if ((pBuf_kmalloc[j]) == NULL) {
+					LOG_NOTICE("mem not enough\n");
+					return -ENOMEM;
+				}
+				memset(pBuf_kmalloc[j], 0x00, (RT_BUF_TBL_NPAGES + 2)*PAGE_SIZE);
+				Tbl_RTBuf_MMPSize[j] = (RT_BUF_TBL_NPAGES + 2);
+
+			}
+			/* round it up to the page bondary */
+			pTbl_RTBuf[j] = (int *)((((unsigned long)pBuf_kmalloc[j]) + PAGE_SIZE - 1) & PAGE_MASK);
+			pstRTBuf[j] = (struct ISP_RT_BUF_STRUCT *)pTbl_RTBuf[j];
+			pstRTBuf[j]->state = ISP_RTBC_STATE_INIT;
+			break;
+		default:
+			pBuf_kmalloc[j] = NULL;
+			pTbl_RTBuf[j] = NULL;
+			Tbl_RTBuf_MMPSize[j] = 0;
+			break;
+		}
+	}
+
+
+	/* isr log */
+	if (PAGE_SIZE < ((ISP_IRQ_TYPE_AMOUNT * NORMAL_STR_LEN * ((DBG_PAGE + INF_PAGE + ERR_PAGE) + 1))*LOG_PPNUM)) {
+		i = 0;
+		while (i < ((ISP_IRQ_TYPE_AMOUNT * NORMAL_STR_LEN * ((DBG_PAGE + INF_PAGE + ERR_PAGE) + 1))*LOG_PPNUM))
+			i += PAGE_SIZE;
+
+	} else {
+		i = PAGE_SIZE;
+	}
+	pLog_kmalloc = kmalloc(i, GFP_KERNEL);
+	if ((pLog_kmalloc) == NULL) {
+		LOG_NOTICE("mem not enough\n");
+		return -ENOMEM;
+	}
+	memset(pLog_kmalloc, 0x00, i);
+	tmp = pLog_kmalloc;
+	for (i = 0; i < LOG_PPNUM; i++) {
+		for (j = 0; j < ISP_IRQ_TYPE_AMOUNT; j++) {
+			gSvLog[j]._str[i][_LOG_DBG] = (char *)tmp;
+			/* tmp = (void*) ((unsigned int)tmp + (NORMAL_STR_LEN*DBG_PAGE)); */
+			tmp = (void *)((char *)tmp + (NORMAL_STR_LEN * DBG_PAGE));
+			gSvLog[j]._str[i][_LOG_INF] = (char *)tmp;
+			/* tmp = (void*) ((unsigned int)tmp + (NORMAL_STR_LEN*INF_PAGE)); */
+			tmp = (void *)((char *)tmp + (NORMAL_STR_LEN * INF_PAGE));
+			gSvLog[j]._str[i][_LOG_ERR] = (char *)tmp;
+			/* tmp = (void*) ((unsigned int)tmp + (NORMAL_STR_LEN*ERR_PAGE)); */
+			tmp = (void *)((char *)tmp + (NORMAL_STR_LEN * ERR_PAGE));
+		}
+		/* tmp = (void*) ((unsigned int)tmp + NORMAL_STR_LEN); //log buffer ,in case of overflow */
+		tmp = (void *)((char *)tmp + NORMAL_STR_LEN);  /* log buffer ,in case of overflow */
+	}
+	/* mark the pages reserved , FOR MMAP*/
+	for (j = 0; j < ISP_IRQ_TYPE_AMOUNT; j++) {
+		if (pTbl_RTBuf[j] != NULL) {
+			for (i = 0; i < Tbl_RTBuf_MMPSize[j] * PAGE_SIZE; i += PAGE_SIZE)
+				SetPageReserved(virt_to_page(((unsigned long)pTbl_RTBuf[j]) + i));
+
+		}
+	}
+
+	for (i = 0; i < ISP_DEV_NODE_NUM; i++)
+		SuspnedRecord[i] = 0;
+
+	LOG_INF("- E. Ret: %d.", Ret);
+	return Ret;
+}
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void __exit ISP_camsv_Exit(void)
+{
+	int i, j;
+
+	LOG_INF("- B.");
+	/*  */
+	platform_driver_unregister(&IspCamSVDriver);
+	/*  */
+
+	for (j = 0; j < ISP_IRQ_TYPE_AMOUNT; j++) {
+		if (pTbl_RTBuf[j] != NULL) {
+			/* unreserve the pages */
+			for (i = 0; i < Tbl_RTBuf_MMPSize[j] * PAGE_SIZE; i += PAGE_SIZE)
+				ClearPageReserved(virt_to_page(((unsigned long)pTbl_RTBuf[j]) + i));
+
+			/* free the memory areas */
+			kfree(pBuf_kmalloc[j]);
+		}
+	}
+
+	/* free the memory areas */
+	kfree(pLog_kmalloc);
+
+	LOG_INF("- E.");
+
+}
+
+static void IRQ_INT_ERR_CHECK_CAM(unsigned int WarnStatus, unsigned int ErrStatus,
+							unsigned int warnTwo, enum ISP_CAMSV_IRQ_TYPE_ENUM module)
+{
+	#if 1
+	/* ERR print */
+	if (ErrStatus) {
+		switch (module) {
+		case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+			g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_0_ST].ispIntErr |= (ErrStatus|WarnStatus);
+			g_ISPIntStatus_SMI[ISP_IRQ_TYPE_INT_CAMSV_0_ST].ispIntErr =
+				g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_0_ST].ispIntErr;
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_ERR,
+				"CAMSV0:int_err:0x%x_0x%x\n", WarnStatus, ErrStatus);
+			break;
+		case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+			g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_1_ST].ispIntErr |= (ErrStatus|WarnStatus);
+			g_ISPIntStatus_SMI[ISP_IRQ_TYPE_INT_CAMSV_1_ST].ispIntErr =
+				g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_1_ST].ispIntErr;
+
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_ERR,
+				"CAMSV1:int_err:0x%x_0x%x\n", WarnStatus, ErrStatus);
+			break;
+		case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+			g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_2_ST].ispIntErr |= (ErrStatus|WarnStatus);
+			g_ISPIntStatus_SMI[ISP_IRQ_TYPE_INT_CAMSV_2_ST].ispIntErr =
+				g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_2_ST].ispIntErr;
+
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_ERR,
+				"CAMSV2:int_err:0x%x_0x%x\n", WarnStatus, ErrStatus);
+			break;
+		case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+			g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_3_ST].ispIntErr |= (ErrStatus|WarnStatus);
+			g_ISPIntStatus_SMI[ISP_IRQ_TYPE_INT_CAMSV_3_ST].ispIntErr =
+				g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_3_ST].ispIntErr;
+
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_ERR,
+				"CAMSV3:int_err:0x%x_0x%x\n", WarnStatus, ErrStatus);
+			break;
+		case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+			g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_4_ST].ispIntErr |= (ErrStatus|WarnStatus);
+			g_ISPIntStatus_SMI[ISP_IRQ_TYPE_INT_CAMSV_4_ST].ispIntErr =
+				g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_4_ST].ispIntErr;
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_ERR,
+				"CAMSV4:int_err:0x%x_0x%x\n", WarnStatus, ErrStatus);
+			break;
+		case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+			g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_5_ST].ispIntErr |= (ErrStatus|WarnStatus);
+			g_ISPIntStatus_SMI[ISP_IRQ_TYPE_INT_CAMSV_5_ST].ispIntErr =
+				g_ISPIntStatus[ISP_IRQ_TYPE_INT_CAMSV_5_ST].ispIntErr;
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_ERR,
+				"CAMSV5:int_err:0x%x_0x%x\n", WarnStatus, ErrStatus);
+			break;
+		default:
+			break;
+		}
+	}
+	#endif
+}
+
+#if (TIMESTAMP_QUEUE_EN == 1)
+static void ISP_GetDmaPortsStatus(enum ISP_DEV_NODE_ENUM reg_module, unsigned int *DmaPortsStats)
+{
+	unsigned int dma_en = ISP_RD32(CAM_REG_CTL_DMA_EN(reg_module));
+
+	DmaPortsStats[_camsv_imgo_] = ((dma_en & 0x01) ? 1 : 0);
+}
+
+static enum CAM_FrameST Irq_CAM_SttFrameStatus(
+					enum ISP_DEV_NODE_ENUM module,
+					enum ISP_IRQ_TYPE_ENUM irq_mod,
+					unsigned int dma_id,
+					unsigned int delayCheck)
+{
+	static const int dma_arry_map[_camsv_max_] = {
+		-1, /* _camsv_imgo_*/
+	};
+
+	unsigned int     dma_en;
+	union FBC_CTRL_1  fbc_ctrl1;
+	union FBC_CTRL_2  fbc_ctrl2;
+	bool       bQueMode = MFALSE;
+	unsigned int     product = 1;
+	/* TSTP_V3 unsigned int     frmPeriod = 1; */
+
+	switch (module) {
+	case ISP_CAM_A_IDX:
+	case ISP_CAM_B_IDX:
+	case ISP_CAM_C_IDX:
+		if (dma_id >= _camsv_max_) {
+			LOG_NOTICE("LINE_%d ERROR: unsupported module:0x%x dma:%d\n", __LINE__, module, dma_id);
+			return CAM_FST_DROP_FRAME;
+		}
+		if (dma_arry_map[dma_id] < 0) {
+			LOG_NOTICE("LINE_%d ERROR: unsupported module:0x%x dma:%d\n", __LINE__, module, dma_id);
+			return CAM_FST_DROP_FRAME;
+		}
+		break;
+	default:
+		LOG_NOTICE("LINE_%d ERROR: unsupported module:0x%x dma:%d\n", __LINE__, module, dma_id);
+		return CAM_FST_DROP_FRAME;
+	}
+
+	fbc_ctrl1.Raw = 0x0;
+	fbc_ctrl2.Raw = 0x0;
+
+	dma_en = ISP_RD32(CAM_REG_CTL_DMA_EN(module));
+
+	if (_aao_ == dma_id) {
+		if (dma_en & 0x20) {
+			fbc_ctrl1.Raw = ISP_RD32(CAM_REG_FBC_AAO_CTL1(module));
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_AAO_CTL2(module));
+		}
+	}
+
+	if (_afo_ == dma_id) {
+		if (dma_en & 0x8) {
+			fbc_ctrl1.Raw = ISP_RD32(CAM_REG_FBC_AFO_CTL1(module));
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_AFO_CTL2(module));
+		}
+	}
+
+	if (_pdo_ == dma_id) {
+		if (dma_en & 0x400) {
+			fbc_ctrl1.Raw = ISP_RD32(CAM_REG_FBC_PDO_CTL1(module));
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_PDO_CTL2(module));
+		}
+	}
+
+	if (_flko_ == dma_id) {
+		if (dma_en & 0x2000) {
+			fbc_ctrl1.Raw = ISP_RD32(CAM_REG_FBC_FLKO_CTL1(module));
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_FLKO_CTL2(module));
+		}
+	}
+
+	if (_pso_ == dma_id) {
+		if (dma_en & 0x40) {
+			fbc_ctrl1.Raw = ISP_RD32(CAM_REG_FBC_PSO_CTL1(module));
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_PSO_CTL2(module));
+		}
+	}
+
+	bQueMode = fbc_ctrl1.Bits.FBC_MODE;
+
+	if (bQueMode) {
+		if (fbc_ctrl1.Raw != 0) {
+			product *= fbc_ctrl2.Bits.FBC_CNT;
+
+			if (product == 0)
+				return CAM_FST_DROP_FRAME;
+		} else
+			return CAM_FST_DROP_FRAME;
+	} else {
+		if (fbc_ctrl1.Raw != 0) {
+
+			product *= (fbc_ctrl1.Bits.FBC_NUM - fbc_ctrl2.Bits.FBC_CNT);
+
+			if (product == 0)
+				return CAM_FST_DROP_FRAME;
+
+		} else
+			return CAM_FST_DROP_FRAME;
+	}
+
+	if (product == 1)
+		return CAM_FST_LAST_WORKING_FRAME;
+	else
+		return CAM_FST_NORMAL;
+
+}
+
+static int32_t ISP_PushBufTimestamp(unsigned int module,
+		unsigned int dma_id, unsigned int sec, unsigned int usec, unsigned int frmPeriod)
+{
+	unsigned int wridx = 0;
+	union FBC_CTRL_2 fbc_ctrl2;
+	enum ISP_DEV_NODE_ENUM reg_module;
+
+	fbc_ctrl2.Raw = 0x0;
+
+	switch (module) {
+	case ISP_IRQ_TYPE_INT_CAM_A_ST:
+		reg_module = ISP_CAM_A_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAM_B_ST:
+		reg_module = ISP_CAM_B_IDX;
+		break;
+	case ISP_IRQ_TYPE_INT_CAM_C_ST:
+		reg_module = ISP_CAM_C_IDX;
+		break;
+	default:
+		LOG_NOTICE("Unsupport module:x%x\n", module);
+		return -EFAULT;
+	}
+
+	switch (module) {
+	case ISP_IRQ_TYPE_INT_CAM_A_ST:
+	case ISP_IRQ_TYPE_INT_CAM_B_ST:
+	case ISP_IRQ_TYPE_INT_CAM_C_ST:
+		switch (dma_id) {
+		case _camsv_imgo_:
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_IMGO_CTL2(reg_module));
+			break;
+		default:
+			LOG_NOTICE("Unsupport dma:x%x\n", dma_id);
+			return -EFAULT;
+		}
+		break;
+	default:
+		return -EFAULT;
+	}
+
+	if (frmPeriod > 1)
+		fbc_ctrl2.Bits.WCNT = (fbc_ctrl2.Bits.WCNT / frmPeriod) * frmPeriod;
+
+	if (((fbc_ctrl2.Bits.WCNT + frmPeriod) & 63) ==
+		IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt) {
+		IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+			"Cam:%d dma:%d ignore push wcnt_%d_%d\n",
+			module, dma_id, IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt,
+			fbc_ctrl2.Bits.WCNT);
+		return 0;
+	}
+
+	wridx = IspInfo.TstpQInfo[module].Dmao[dma_id].WrIndex;
+
+	IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[wridx].sec = sec;
+	IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[wridx].usec = usec;
+
+	if (IspInfo.TstpQInfo[module].Dmao[dma_id].WrIndex >= (ISP_TIMESTPQ_DEPTH-1))
+		IspInfo.TstpQInfo[module].Dmao[dma_id].WrIndex = 0;
+	else
+		IspInfo.TstpQInfo[module].Dmao[dma_id].WrIndex++;
+
+	IspInfo.TstpQInfo[module].Dmao[dma_id].TotalWrCnt++;
+
+	/* Update WCNT for patch timestamp when SOF ISR missing */
+	IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt =
+		((IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt + 1) & 0x3F);
+
+	return 0;
+}
+
+static int32_t ISP_PopBufTimestamp(unsigned int module, unsigned int dma_id, struct S_START_T *pTstp)
+{
+	switch (module) {
+	case ISP_IRQ_TYPE_INT_CAM_A_ST:
+	case ISP_IRQ_TYPE_INT_CAM_B_ST:
+	case ISP_IRQ_TYPE_INT_CAM_C_ST:
+		switch (dma_id) {
+		case _camsv_imgo_:
+			break;
+		default:
+			LOG_NOTICE("Unsupport dma:x%x\n", dma_id);
+			return -EFAULT;
+		}
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+		switch (dma_id) {
+		case _camsv_imgo_:
+			break;
+		default:
+			LOG_NOTICE("Unsupport dma:x%x\n", dma_id);
+			return -EFAULT;
+		}
+		break;
+	default:
+		LOG_NOTICE("Unsupport module:x%x\n", module);
+		return -EFAULT;
+	}
+
+	if (pTstp)
+		*pTstp =
+		IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[IspInfo.TstpQInfo[module].Dmao[dma_id].RdIndex];
+
+	if (IspInfo.TstpQInfo[module].Dmao[dma_id].RdIndex >= (ISP_TIMESTPQ_DEPTH-1))
+		IspInfo.TstpQInfo[module].Dmao[dma_id].RdIndex = 0;
+	else
+		IspInfo.TstpQInfo[module].Dmao[dma_id].RdIndex++;
+
+	IspInfo.TstpQInfo[module].Dmao[dma_id].TotalRdCnt++;
+
+	return 0;
+}
+
+
+static int32_t ISP_WaitTimestampReady(unsigned int module, unsigned int dma_id)
+{
+	unsigned int _timeout = 0;
+	unsigned int wait_cnt = 0;
+
+	if (IspInfo.TstpQInfo[module].Dmao[dma_id].TotalWrCnt > IspInfo.TstpQInfo[module].Dmao[dma_id].TotalRdCnt)
+		return 0;
+
+	LOG_INF("Wait module:%d dma:%d timestamp ready W/R:%d/%d\n", module, dma_id,
+		(unsigned int)IspInfo.TstpQInfo[module].Dmao[dma_id].TotalWrCnt,
+		(unsigned int)IspInfo.TstpQInfo[module].Dmao[dma_id].TotalRdCnt);
+
+	for (wait_cnt = 3; wait_cnt > 0; wait_cnt--) {
+		_timeout = wait_event_interruptible_timeout(
+			IspInfo.WaitQueueHead[module],
+			(IspInfo.TstpQInfo[module].Dmao[dma_id].TotalWrCnt >
+				IspInfo.TstpQInfo[module].Dmao[dma_id].TotalRdCnt),
+			ISP_MsToJiffies(2000));
+		/* check if user is interrupted by system signal */
+		if ((_timeout != 0) && (!(IspInfo.TstpQInfo[module].Dmao[dma_id].TotalWrCnt >
+				IspInfo.TstpQInfo[module].Dmao[dma_id].TotalRdCnt))) {
+			LOG_INF("interrupted by system signal, return value(%d)\n", _timeout);
+			return -ERESTARTSYS;
+		}
+
+		if (_timeout > 0)
+			break;
+
+		LOG_INF("WARNING: cam:%d dma:%d wait left count %d\n", module, dma_id, wait_cnt);
+	}
+	if (wait_cnt == 0) {
+		LOG_NOTICE("ERROR: cam:%d dma:%d wait timestamp timeout!!!\n", module, dma_id);
+		return -EFAULT;
+	}
+
+	return 0;
+}
+
+static int32_t ISP_CompensateMissingSofTime(enum ISP_DEV_NODE_ENUM reg_module,
+			unsigned int module, unsigned int dma_id, unsigned int sec,
+			unsigned int usec, unsigned int frmPeriod)
+{
+	union FBC_CTRL_2  fbc_ctrl2;
+	unsigned int     delta_wcnt = 0, wridx = 0, wridx_prev1 = 0, wridx_prev2 = 0, i = 0;
+	unsigned int     delta_time = 0, max_delta_time = 0;
+	struct S_START_T   time_prev1, time_prev2;
+	bool dmao_mask = MFALSE;/*To shrink error log, only rrzo print error log*/
+	/*
+	 * Patch timestamp and WCNT base on current HW WCNT and
+	 * previous SW WCNT value, and calculate difference
+	 */
+
+	fbc_ctrl2.Raw = 0;
+
+	switch (module) {
+	case ISP_IRQ_TYPE_INT_CAM_A_ST:
+	case ISP_IRQ_TYPE_INT_CAM_B_ST:
+	case ISP_IRQ_TYPE_INT_CAM_C_ST:
+		switch (dma_id) {
+		case _imgo_:
+			fbc_ctrl2.Raw = ISP_RD32(CAM_REG_FBC_IMGO_CTL2(reg_module));
+			break;
+		default:
+			LOG_NOTICE("Unsupport dma:x%x\n", dma_id);
+			return -EFAULT;
+		}
+		break;
+	case ISP_IRQ_TYPE_INT_CAMSV_0_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_1_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_2_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_3_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_4_ST:
+	case ISP_IRQ_TYPE_INT_CAMSV_5_ST:
+	default:
+		LOG_NOTICE("Unsupport module:x%x\n", module);
+		return -EFAULT;
+	}
+
+	if (frmPeriod > 1)
+		fbc_ctrl2.Bits.WCNT = (fbc_ctrl2.Bits.WCNT / frmPeriod) * frmPeriod;
+
+	if (((fbc_ctrl2.Bits.WCNT + frmPeriod) & 63) ==
+		IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt) {
+		if (dmao_mask)
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+				"Cam:%d dma:%d ignore compensate wcnt_%d_%d\n",
+				module, dma_id, IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt,
+				fbc_ctrl2.Bits.WCNT);
+		return 0;
+	}
+
+	if (IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt > fbc_ctrl2.Bits.WCNT)
+		delta_wcnt = fbc_ctrl2.Bits.WCNT + 64 - IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt;
+	else
+		delta_wcnt = fbc_ctrl2.Bits.WCNT - IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt;
+
+	if (delta_wcnt > 255) {
+		if (dmao_mask)
+			LOG_NOTICE("ERROR: Cam:%d dma:%d WRONG WCNT:%d_%d_%d\n",
+				module, dma_id, delta_wcnt,
+				IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt, fbc_ctrl2.Bits.WCNT);
+		return -EFAULT;
+	} else if (delta_wcnt > 6) {
+		if (dmao_mask)
+			LOG_NOTICE("WARNING: Cam:%d dma:%d SUSPICIOUS WCNT:%d_%d_%d\n",
+				module, dma_id, delta_wcnt,
+				IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt, fbc_ctrl2.Bits.WCNT);
+	} else if (delta_wcnt == 0) {
+		return 0;
+	}
+
+	/* delta_wcnt *= frmPeriod; */
+
+	/* Patch missing SOF timestamp */
+	wridx = IspInfo.TstpQInfo[module].Dmao[dma_id].WrIndex;
+	wridx_prev1 = (wridx == 0) ? (ISP_TIMESTPQ_DEPTH - 1) : (wridx - 1);
+	wridx_prev2 = (wridx_prev1 == 0) ? (ISP_TIMESTPQ_DEPTH - 1) : (wridx_prev1 - 1);
+
+	time_prev1.sec = IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[wridx_prev1].sec;
+	time_prev1.usec = IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[wridx_prev1].usec;
+
+	time_prev2.sec = IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[wridx_prev2].sec;
+	time_prev2.usec = IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[wridx_prev2].usec;
+
+	if ((sec > time_prev1.sec) ||
+		((sec == time_prev1.sec) && (usec > time_prev1.usec))) {
+		max_delta_time = ((sec - time_prev1.sec)*1000000 + usec) - time_prev1.usec;
+	} else {
+		if (dmao_mask)
+			LOG_NOTICE("ERROR: Cam:%d dma:%d current timestamp: cur: %d.%06d prev1: %d.%06d\n",
+				module, dma_id, sec, usec, time_prev1.sec, time_prev1.usec);
+		max_delta_time = 0;
+	}
+
+	if ((time_prev1.sec > time_prev2.sec) ||
+		((time_prev1.sec == time_prev2.sec) && (time_prev1.usec > time_prev2.usec)))
+		delta_time = ((time_prev1.sec - time_prev2.sec)*1000000 + time_prev1.usec) - time_prev2.usec;
+	else {
+		if (dmao_mask)
+			LOG_NOTICE("ERROR: Cam:%d dma:%d previous timestamp: prev1: %d.%06d prev2: %d.%06d\n",
+				module, dma_id, time_prev1.sec, time_prev1.usec, time_prev2.sec, time_prev2.usec);
+		delta_time = 0;
+	}
+
+	if (delta_time > (max_delta_time / delta_wcnt)) {
+		if (dmao_mask)
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+				"WARNING: Cam:%d dma:%d delta time too large: cur %dus max %dus patch wcnt: %d\n",
+				module, dma_id, delta_time, max_delta_time, delta_wcnt);
+		delta_time = max_delta_time / delta_wcnt;
+	}
+
+	for (i = 0; i < delta_wcnt; i++) {
+		time_prev1.usec += delta_time;
+		while (time_prev1.usec >= 1000000) {
+			time_prev1.usec -= 1000000;
+			time_prev1.sec++;
+		}
+		/* WCNT will be increase in this API */
+		ISP_PushBufTimestamp(module, dma_id, time_prev1.sec, time_prev1.usec, frmPeriod);
+	}
+
+	if (dmao_mask)
+		IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+			"Cam:%d dma:%d wcnt:%d_%d_%d T:%d.%06d_.%06d_%d.%06d\n",
+			module, dma_id, delta_wcnt, IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt,
+			fbc_ctrl2.Bits.WCNT, sec, usec, delta_time, time_prev1.sec, time_prev1.usec);
+
+	if (IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt != fbc_ctrl2.Bits.WCNT) {
+		if (dmao_mask)
+			LOG_NOTICE("ERROR: Cam:%d dma:%d strange WCNT SW_HW: %d_%d\n",
+				module, dma_id, IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt,
+				fbc_ctrl2.Bits.WCNT);
+		IspInfo.TstpQInfo[module].Dmao[dma_id].PrevFbcWCnt = fbc_ctrl2.Bits.WCNT;
+	}
+
+	return 0;
+}
+
+#if (TSTMP_SUBSAMPLE_INTPL == 1)
+static int32_t ISP_PatchTimestamp(unsigned int module, unsigned int dma_id, unsigned int frmPeriod,
+		unsigned long long refTimestp, unsigned long long prevTimestp)
+{
+	unsigned long long prev_tstp = prevTimestp, cur_tstp = refTimestp;
+	unsigned int target_wridx = 0, curr_wridx = 0, frm_dt = 0, last_frm_dt = 0, i = 1;
+
+	/* Only sub-sample case needs patch */
+	if (frmPeriod <= 1)
+		return 0;
+
+	curr_wridx = IspInfo.TstpQInfo[module].Dmao[dma_id].WrIndex;
+
+	if (curr_wridx < frmPeriod)
+		target_wridx = (curr_wridx + ISP_TIMESTPQ_DEPTH - frmPeriod);
+	else
+		target_wridx = curr_wridx - frmPeriod;
+
+	frm_dt = (((unsigned int)(cur_tstp - prev_tstp)) / frmPeriod);
+	last_frm_dt = ((cur_tstp - prev_tstp) - frm_dt*(frmPeriod-1));
+
+	if (frm_dt == 0)
+		LOG_INF("WARNING: timestamp delta too small: %d\n", (int)(cur_tstp - prev_tstp));
+
+	i = 0;
+	while (target_wridx != curr_wridx) {
+
+		if (i > frmPeriod) {
+			LOG_NOTICE("Error: too many intpl in sub-sample period %d_%d\n", target_wridx, curr_wridx);
+			return -EFAULT;
+		}
+
+		IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[target_wridx].usec += (frm_dt * i);
+
+		while (IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[target_wridx].usec >= 1000000) {
+
+			IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[target_wridx].usec -= 1000000;
+			IspInfo.TstpQInfo[module].Dmao[dma_id].TimeQue[target_wridx].sec++;
+		}
+
+		i++;
+		target_wridx++; /* patch from 2nd time */
+		if (target_wridx >= ISP_TIMESTPQ_DEPTH)
+			target_wridx = 0;
+	}
+
+	return 0;
+}
+#endif
+
+#endif
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV_0(int  Irq, void *DeviceId)
+{
+	return ISP_CAMSV_Irq_CAMSV(ISP_IRQ_TYPE_INT_CAMSV_0_ST, ISP_CAMSV0_IDX, "CAMSV0", DeviceId);
+}
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV_1(int  Irq, void *DeviceId)
+{
+	return ISP_CAMSV_Irq_CAMSV(ISP_IRQ_TYPE_INT_CAMSV_1_ST, ISP_CAMSV1_IDX, "CAMSV1", DeviceId);
+}
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV_2(int  Irq, void *DeviceId)
+{
+	return ISP_CAMSV_Irq_CAMSV(ISP_IRQ_TYPE_INT_CAMSV_2_ST, ISP_CAMSV2_IDX, "CAMSV2", DeviceId);
+}
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV_3(int  Irq, void *DeviceId)
+{
+	return ISP_CAMSV_Irq_CAMSV(ISP_IRQ_TYPE_INT_CAMSV_3_ST, ISP_CAMSV3_IDX, "CAMSV3", DeviceId);
+}
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV_4(int  Irq, void *DeviceId)
+{
+	return ISP_CAMSV_Irq_CAMSV(ISP_IRQ_TYPE_INT_CAMSV_4_ST, ISP_CAMSV4_IDX, "CAMSV4", DeviceId);
+}
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV_5(int  Irq, void *DeviceId)
+{
+	return ISP_CAMSV_Irq_CAMSV(ISP_IRQ_TYPE_INT_CAMSV_5_ST, ISP_CAMSV5_IDX, "CAMSV5", DeviceId);
+}
+
+irqreturn_t ISP_CAMSV_Irq_CAMSV(enum ISP_CAMSV_IRQ_TYPE_ENUM irq_module,
+	enum ISP_CAMSV_DEV_NODE_ENUM cam_idx, const char *str, void *DeviceId)
+{
+	unsigned int module = irq_module;
+	unsigned int reg_module = cam_idx;
+	unsigned int i, IrqStatus, ErrStatus, time_stamp, cur_v_cnt = 0;
+	unsigned int IrqEnableOrig, IrqEnableNew;
+	static int counter_isr;
+	union FBC_CTRL_1 fbc_ctrl1[2];
+	/* */
+	union FBC_CTRL_2 fbc_ctrl2[2];
+
+	struct timeval time_frmb;
+	unsigned long long  sec = 0;
+	unsigned long       usec = 0;
+	ktime_t             time;
+
+	struct camsv_device *camsv_d = DeviceId;
+
+	counter_isr = 0;
+	/* Avoid touch hwmodule when clock is disable. DEVAPC will moniter this kind of err */
+	if (G_u4EnableClockCount == 0)
+		return IRQ_HANDLED;
+
+	/*  */
+	sec = cpu_clock(0);     /* ns */
+	do_div(sec, 1000);    /* usec */
+	usec = do_div(sec, 1000000);    /* sec and usec */
+	time_frmb.tv_usec = usec;
+	time_frmb.tv_sec = sec;
+
+	#if (ISP_BOTTOMHALF_WORKQ == 1)
+	gSvLog[module]._lastIrqTime.sec = sec;
+	gSvLog[module]._lastIrqTime.usec = usec;
+	#endif
+
+	spin_lock(&(IspInfo.SpinLockIrq[module]));
+	IrqStatus = ISP_RD32(CAMSV_REG_INT_STATUS(reg_module));
+	spin_unlock(&(IspInfo.SpinLockIrq[module]));
+
+	if ((counter_isr%30) == 0) {
+		dprintk(3, "u4HwModule %d, vbq %p\n",
+			camsv_d->camsv_module[cam_idx-ISP_CAMSV0_IDX].camsv_port_input.u4HwModule,
+			&camsv_d->camsv_module[cam_idx-ISP_CAMSV0_IDX].vbq);
+		dprintk(3, "%s: irq_module %d, cam_idx %d\n", __func__, irq_module, cam_idx);
+		dprintk(3, "IrqStatus %x, time %ld.%ld\n", IrqStatus, time_frmb.tv_sec, time_frmb.tv_usec);
+	}
+	counter_isr++;
+
+	ErrStatus = IrqStatus & IspInfo.IrqInfo.ErrMask[module][SIGNAL_INT];
+	IrqStatus = IrqStatus & IspInfo.IrqInfo.Mask[module][SIGNAL_INT];
+
+/* Check ERR/WRN ISR times, if it occur too frequently, mark it for avoding keep enter ISR
+ * It will happen KE
+ */
+	for (i = 0; i < ISP_ISR_MAX_NUM; i++) {
+		/* Only check irq that un marked yet */
+		if (!(IspInfo.IrqCntInfo.m_err_int_mark[module] & (1 << i))) {
+
+			if (ErrStatus & (1 << i))
+				IspInfo.IrqCntInfo.m_err_int_cnt[module][i]++;
+
+			if (usec - IspInfo.IrqCntInfo.m_int_usec[module] <
+				INT_ERR_WARN_TIMER_THREAS) {
+				if (IspInfo.IrqCntInfo.m_err_int_cnt[module][i] >=
+					INT_ERR_WARN_MAX_TIME)
+					IspInfo.IrqCntInfo.m_err_int_mark[module] |= (1 << i);
+
+			} else {
+				IspInfo.IrqCntInfo.m_int_usec[module] = usec;
+				IspInfo.IrqCntInfo.m_err_int_cnt[module][i] = 0;
+			}
+		}
+
+	}
+
+	spin_lock(&(IspInfo.SpinLockIrq[module]));
+	IrqEnableOrig = ISP_RD32(CAMSV_REG_INT_EN(reg_module));
+	spin_unlock(&(IspInfo.SpinLockIrq[module]));
+
+	dprintk(4, "IrqEnableOrig %x, ErrStatus %x, IrqStatus %x\n", IrqEnableOrig, ErrStatus, IrqStatus);
+
+	IrqEnableNew = IrqEnableOrig &
+		~(IspInfo.IrqCntInfo.m_err_int_mark[module]);
+	ISP_WR32(CAMSV_REG_INT_EN(reg_module), IrqEnableNew);
+	/*  */
+	IRQ_INT_ERR_CHECK_CAM(0, ErrStatus, 0, module);
+
+	fbc_ctrl1[0].Raw = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(reg_module));
+	fbc_ctrl2[0].Raw = ISP_RD32(CAMSV_REG_FBC_IMGO_CTL2(reg_module));
+	time_stamp       = ISP_RD32(CAMSV_REG_TG_TIME_STAMP(reg_module));
+
+	dprintk(4, "time_stamp %d fbc_ctrl(1 %x, 2 %x)\n", time_stamp, fbc_ctrl1[0].Raw, fbc_ctrl2[0].Raw);
+
+	/* sof , done order chech . */
+	if ((IrqStatus & SV_HW_PASS1_DON_ST) || (IrqStatus & SV_SOF_INT_ST))
+		/*cur_v_cnt = ((ISP_RD32(CAMSV_REG_TG_INTER_ST(reg_module)) & 0x00FF0000) >> 16);*/
+		cur_v_cnt = ISP_RD32_TG_CAM_FRM_CNT(module, reg_module);
+
+	if ((IrqStatus & SV_HW_PASS1_DON_ST) && (IrqStatus & SV_SOF_INT_ST)) {
+		if (cur_v_cnt != sof_count[module])
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+				"isp sof_don block, %d_%d\n", cur_v_cnt, sof_count[module]);
+	}
+
+	dprintk(4, "cur_v_cnt %d\n", cur_v_cnt);
+
+	spin_lock(&(IspInfo.SpinLockIrq[module]));
+	if (IrqStatus & SV_SW_PASS1_DON_ST) {
+		sec = cpu_clock(0);     /* ns */
+		do_div(sec, 1000);    /* usec */
+		usec = do_div(sec, 1000000);    /* sec and usec */
+		/* update pass1 done time stamp for eis user(need match with the time stamp in image header) */
+		IspInfo.IrqInfo.LastestSigTime_usec[module][10] = (unsigned int)(usec);
+		IspInfo.IrqInfo.LastestSigTime_sec[module][10] = (unsigned int)(sec);
+
+		if (IspInfo.DebugMask & ISP_DBG_INT) {
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+				"%s P1_DON_%d(0x%08x_0x%08x) stamp[0x%08x]\n",
+				str,
+				(sof_count[module]) ?
+				(sof_count[module] - 1) : (sof_count[module]),
+				(unsigned int)(fbc_ctrl1[0].Raw), (unsigned int)(fbc_ctrl2[0].Raw),
+				time_stamp);
+		}
+
+		/* for dbg log only */
+		if (pstRTBuf[module]->ring_buf[_camsv_imgo_].active)
+			pstRTBuf[module]->ring_buf[_camsv_imgo_].img_cnt = sof_count[module];
+
+	}
+
+	if (IrqStatus & SV_SOF_INT_ST) {
+		time = ktime_get();     /* ns */
+		sec = time;
+		do_div(sec, 1000);    /* usec */
+		usec = do_div(sec, 1000000);    /* sec and usec */
+
+		if (IspInfo.DebugMask & ISP_DBG_INT) {
+			static unsigned int m_sec = 0, m_usec;
+
+			if (g1stSof[module]) {
+				m_sec = sec;
+				m_usec = usec;
+				gSTime[module].sec = sec;
+				gSTime[module].usec = usec;
+			}
+
+			IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF,
+				"%s P1_SOF_%d_%d(0x%08x_0x%08x,0x%08x),int_us:0x%08x, stamp[0x%08x]\n",
+				str,
+				sof_count[module], cur_v_cnt,
+				(unsigned int)(ISP_RD32(CAMSV_REG_FBC_IMGO_CTL1(reg_module))),
+				(unsigned int)(ISP_RD32(CAMSV_REG_FBC_IMGO_CTL2(reg_module))),
+				ISP_RD32(CAMSV_REG_IMGO_BASE_ADDR(reg_module)),
+				(unsigned int)((sec * 1000000 + usec) - (1000000 * m_sec + m_usec)),
+				time_stamp);
+			/* keep current time */
+			m_sec = sec;
+			m_usec = usec;
+
+			/* dbg information only */
+			if (cur_v_cnt != ((ISP_RD32(CAMSV_REG_TG_INTER_ST(reg_module)) & 0x00FF0000) >> 16))
+				IRQ_LOG_KEEPER(module, m_CurrentPPB, _LOG_INF, "SW ISR right on next hw p1_done\n");
+
+		}
+
+		/* update SOF time stamp for eis user(need match with the time stamp in image header) */
+		IspInfo.IrqInfo.LastestSigTime_usec[module][12] = (unsigned int)(sec);
+		IspInfo.IrqInfo.LastestSigTime_sec[module][12] = (unsigned int)(usec);
+
+		/* sw sof counter */
+		sof_count[module]++;
+		/* for match vsync cnt */
+		if (sof_count[module] > 255)
+			sof_count[module] -= 256;
+
+		g1stSof[module] = MFALSE;
+	}
+
+	for (i = 0; i < IRQ_USER_NUM_MAX; i++) {
+		/* 1. update interrupt status to all users */
+		IspInfo.IrqInfo.Status[module][SIGNAL_INT][i] |= IrqStatus;
+
+		/* 2. update signal time and passed by signal count */
+		if (IspInfo.IrqInfo.MarkedFlag[module][SIGNAL_INT][i] & IspInfo.IrqInfo.Mask[module][SIGNAL_INT]) {
+			unsigned int cnt = 0, tmp = IrqStatus;
+
+			while (tmp) {
+				if (tmp & 0x1) {
+					IspInfo.IrqInfo.LastestSigTime_usec[module][cnt] =
+						(unsigned int)time_frmb.tv_usec;
+					IspInfo.IrqInfo.LastestSigTime_sec[module][cnt] =
+						(unsigned int) time_frmb.tv_sec;
+					IspInfo.IrqInfo.PassedBySigCnt[module][cnt][i]++;
+				}
+				tmp = tmp >> 1;
+				cnt++;
+			}
+		} else {
+		/* no any interrupt is not marked and  in read mask in this irq type*/
+		}
+	}
+
+	//V4L2 buffer done
+	/* SW PASS1 done , do deq buffer. */
+	if ((IrqStatus & SV_SW_PASS1_DON_ST) /*|| (IrqStatus & SV_HW_PASS1_DON_ST)*/) {
+		camsv_buffer_done(&camsv_d->camsv_module[reg_module-ISP_CAMSV0_IDX]);
+		camsv_queue_event_sof(&camsv_d->camsv_module[reg_module-ISP_CAMSV0_IDX]);
+	}
+
+	spin_unlock(&(IspInfo.SpinLockIrq[module]));
+	/*  */
+	wake_up_interruptible(&IspInfo.WaitQueueHead[module]);
+
+	/* dump log, use tasklet */
+	if (IrqStatus & (SV_SOF_INT_ST | SV_SW_PASS1_DON_ST | SV_VS1_ST)) {
+		#if (ISP_BOTTOMHALF_WORKQ == 1)
+		schedule_work(&isp_workque[module].isp_bh_work);
+		#else
+		tasklet_schedule(isp_tasklet[module].pIsp_tkt);
+		#endif
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+static void SMI_INFO_DUMP(enum ISP_CAMSV_IRQ_TYPE_ENUM irq_module)
+{
+
+}
+
+static void ISP_TaskletFunc_SV_0(unsigned long data)
+{
+	IRQ_LOG_PRINTER(ISP_IRQ_TYPE_INT_CAMSV_0_ST, m_CurrentPPB, _LOG_INF);
+	SMI_INFO_DUMP(ISP_IRQ_TYPE_INT_CAMSV_0_ST);
+}
+
+static void ISP_TaskletFunc_SV_1(unsigned long data)
+{
+	IRQ_LOG_PRINTER(ISP_IRQ_TYPE_INT_CAMSV_1_ST, m_CurrentPPB, _LOG_INF);
+	SMI_INFO_DUMP(ISP_IRQ_TYPE_INT_CAMSV_1_ST);
+
+}
+
+static void ISP_TaskletFunc_SV_2(unsigned long data)
+{
+	IRQ_LOG_PRINTER(ISP_IRQ_TYPE_INT_CAMSV_2_ST, m_CurrentPPB, _LOG_INF);
+	SMI_INFO_DUMP(ISP_IRQ_TYPE_INT_CAMSV_2_ST);
+
+}
+
+static void ISP_TaskletFunc_SV_3(unsigned long data)
+{
+	IRQ_LOG_PRINTER(ISP_IRQ_TYPE_INT_CAMSV_3_ST, m_CurrentPPB, _LOG_INF);
+	SMI_INFO_DUMP(ISP_IRQ_TYPE_INT_CAMSV_3_ST);
+
+}
+
+static void ISP_TaskletFunc_SV_4(unsigned long data)
+{
+	IRQ_LOG_PRINTER(ISP_IRQ_TYPE_INT_CAMSV_4_ST, m_CurrentPPB, _LOG_INF);
+	SMI_INFO_DUMP(ISP_IRQ_TYPE_INT_CAMSV_4_ST);
+
+}
+
+static void ISP_TaskletFunc_SV_5(unsigned long data)
+{
+	IRQ_LOG_PRINTER(ISP_IRQ_TYPE_INT_CAMSV_5_ST, m_CurrentPPB, _LOG_INF);
+	SMI_INFO_DUMP(ISP_IRQ_TYPE_INT_CAMSV_5_ST);
+
+}
+
+#if (ISP_BOTTOMHALF_WORKQ == 1)
+static void ISP_BH_Workqueue(struct work_struct *pWork)
+{
+	struct IspWorkqueTable *pWorkTable = container_of(pWork, struct IspWorkqueTable, isp_bh_work);
+
+	IRQ_LOG_PRINTER(pWorkTable->module, m_CurrentPPB, _LOG_ERR);
+	IRQ_LOG_PRINTER(pWorkTable->module, m_CurrentPPB, _LOG_INF);
+}
+#endif
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+module_init(ISP_camsv_Init);
+module_exit(ISP_camsv_Exit);
+MODULE_DESCRIPTION("Camera ISP CAMSV driver");
+MODULE_AUTHOR("SW2");
+MODULE_LICENSE("GPL");
diff --git a/drivers/media/platform/mtk-isp/isp_50/camSV/inc/cam_regs.h b/drivers/media/platform/mtk-isp/isp_50/camSV/inc/cam_regs.h
new file mode 100644
index 000000000000..676dde1d8920
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/camSV/inc/cam_regs.h
@@ -0,0 +1,149 @@
+/*
+ * Copyright (C) 2016 MediaTek Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See http://www.gnu.org/licenses/gpl-2.0.html for more details.
+ */
+
+/******************************************************************************
+ * cam_regs.h - MT6758 cam registers
+ *
+ * DESCRIPTION:
+ *     This file provide register addresses and chip dependency infos in CAMSYS.
+ *
+ ******************************************************************************/
+
+/**
+ *    CAM interrupt status
+ */
+/* normal siganl */
+#define VS_INT_ST                 (1L<<0)
+#define TG_INT1_ST               (1L<<1)
+#define TG_INT2_ST               (1L<<2)
+#define EXPDON_ST                (1L<<3)
+#define HW_PASS1_DON_ST (1L<<11)
+#define SOF_INT_ST              (1L<<12)
+#define SW_PASS1_DON_ST (1L<<30)
+
+/**
+ *    CAMSV interrupt status
+ */
+/* normal signal */
+#define SV_VS1_ST           (1L<<0)
+#define SV_TG_ST1           (1L<<1)
+#define SV_TG_ST2           (1L<<2)
+#define SV_EXPDON_ST        (1L<<3)
+#define SV_TG_ERR_ST        (1L<<4)
+#define SV_TG_GBERR_ST      (1L<<5)
+#define SV_SOF_INT_ST       (1L<<7)
+#define SV_HW_PASS1_DON_ST  (1L<<10)
+#define SV_HW_IMGO_ERR_ST  (1L<<16)
+#define SV_HW_IMGO_OVERR_ST  (1L<<17)
+#define SV_SW_PASS1_DON_ST  (1L<<20)
+
+/* err status */
+#define SV_TG_ERR           (1L<<4)
+#define SV_TG_GBERR         (1L<<5)
+#define SV_IMGO_ERR         (1L<<16)
+#define SV_IMGO_OVERRUN     (1L<<17)
+
+/**
+ *    IRQ signal mask
+ */
+#define INT_ST_MASK_CAMSV       (\
+				 SV_VS1_ST |\
+				 SV_TG_ST1 |\
+				 SV_TG_ST2 |\
+				 SV_EXPDON_ST |\
+				 SV_SOF_INT_ST |\
+				 SV_HW_PASS1_DON_ST |\
+				 SV_SW_PASS1_DON_ST)
+/**
+ *    IRQ Error Mask
+ */
+#define INT_ST_MASK_CAMSV_ERR   (\
+				 SV_TG_ERR |\
+				 SV_TG_GBERR |\
+				 SV_IMGO_ERR |\
+				 SV_IMGO_OVERRUN)
+
+#define CAMSYS_REG_CG_CON               (ISP_CAMSYS_CONFIG_BASE + 0x0)
+
+/* CAMSV */
+#define CAMSV_REG_MODULE_EN(module)  (isp_devs[module].regs + 0x0510)
+#define CAMSV_REG_INT_EN(module)    (isp_devs[module].regs + 0x0518)
+#define CAMSV_REG_INT_STATUS(module)  (isp_devs[module].regs + 0x051C)
+#define CAMSV_REG_SW_CTL(module)  (isp_devs[module].regs + 0x0520)
+#define CAMSV_REG_FBC_IMGO_CTL1(module)  (isp_devs[module].regs + 0x0110)
+#define CAMSV_REG_FBC_IMGO_CTL2(module)  (isp_devs[module].regs + 0x0114)
+#define CAMSV_REG_IMGO_BASE_ADDR(module)  (isp_devs[module].regs + 0x0020)
+#define CAMSV_REG_TG_SEN_MODE(module)  (isp_devs[module].regs + 0x0230)
+#define CAMSV_REG_TG_VF_CON(module)  (isp_devs[module].regs + 0x0234)
+#define CAMSV_REG_TG_INTER_ST(module)  (isp_devs[module].regs + 0x026C)
+#define CAMSV_REG_TG_TIME_STAMP(module)  (isp_devs[module].regs + 0x02A0)
+/* V4L2 CAMSV*/
+#define CAMSV_REG_TG_SUB_PERIOD(module)  (isp_devs[module].regs + 0x02A4)
+#define CAMSV_REG_TG_SEN_GRAB_PXL(module)  (isp_devs[module].regs + 0x0238)
+#define CAMSV_REG_TG_SEN_GRAB_LIN(module)  (isp_devs[module].regs + 0x023C)
+#define CAMSV_REG_TG_FRMSIZE_ST(module)  (isp_devs[module].regs + 0x0268)
+#define CAMSV_REG_TG_FRMSIZE_ST_R(module)  (isp_devs[module].regs + 0x02AC)
+#define CAMSV_REG_TG_DAT_NO_R(module)  (isp_devs[module].regs + 0x02A8)
+
+#define CAMSV_REG_DMA_FRAME_HEADER_EN(module)  (isp_devs[module].regs + 0x0400)
+#define CAMSV_REG_DMA_RSV1(module)  (isp_devs[module].regs + 0x03B0)
+#define CAMSV_REG_DMA_RSV6(module)  (isp_devs[module].regs + 0x03C4)
+
+#define CAMSV_REG_IMGO_BASE_ADDR(module)  (isp_devs[module].regs + 0x0020)
+#define CAMSV_REG_IMGO_OFST_ADDR(module)  (isp_devs[module].regs + 0x0028)
+#define CAMSV_REG_IMGO_XSIZE(module)  (isp_devs[module].regs + 0x0030)
+#define CAMSV_REG_IMGO_YSIZE(module)  (isp_devs[module].regs + 0x0034)
+#define CAMSV_REG_IMGO_STRIDE(module)  (isp_devs[module].regs + 0x0038)
+#define CAMSV_REG_IMGO_CON(module)  (isp_devs[module].regs + 0x003C)
+#define CAMSV_REG_IMGO_CON2(module)  (isp_devs[module].regs + 0x0040)
+#define CAMSV_REG_IMGO_CON3(module)  (isp_devs[module].regs + 0x0044)
+#define CAMSV_REG_IMGO_CROP(module)  (isp_devs[module].regs + 0x0048)
+#define CAMSV_REG_IMGO_FH_BASE_ADDR(module)  (isp_devs[module].regs + 0x0404)
+
+#define CAMSV_REG_CLK_EN(module)  (isp_devs[module].regs + 0x0530)
+#define CAMSV_REG_SPECIAL_FUN_EN(module)  (isp_devs[module].regs + 0x0018)
+#define CAMSV_REG_FBC_IMGO_ENQ_ADDR(module)  (isp_devs[module].regs + 0x0118)
+#define CAMSV_REG_FMT_SEL(module)  (isp_devs[module].regs + 0x0514)
+#define CAMSV_REG_PAK(module)  (isp_devs[module].regs + 0x054C)
+#define CAMSV_REG_TIME_STAMP_CTL(module)  (isp_devs[module].regs + 0x02B0)
+#define CAMSV_REG_IMGO_FBC(module)  (isp_devs[module].regs + 0x052C)
+
+
+union FBC_CTRL_1 {
+	struct { /* 0x18004110 */
+		unsigned int  FBC_NUM                               :  6;      /*  0.. 5, 0x0000003F */
+		unsigned int  rsv_6                                 :  9;      /*  6..14, 0x00007FC0 */
+		unsigned int  FBC_EN                                :  1;      /* 15..15, 0x00008000 */
+		unsigned int  FBC_MODE                              :  1;      /* 16..16, 0x00010000 */
+		unsigned int  LOCK_EN                               :  1;      /* 17..17, 0x00020000 */
+		unsigned int  rsv_18                                :  2;      /* 18..19, 0x000C0000 */
+		unsigned int  DROP_TIMING                           :  1;      /* 20..20, 0x00100000 */
+		unsigned int  rsv_21                                :  3;      /* 21..23, 0x00E00000 */
+		unsigned int  SUB_RATIO                             :  8;      /* 24..31, 0xFF000000 */
+	} Bits;
+	unsigned int Raw;
+};  /* CAM_A_FBC_IMGO_CTL1 */
+
+union FBC_CTRL_2 {
+	struct { /* 0x18004114 */
+		unsigned int  FBC_CNT                               :  7;      /*  0.. 6, 0x0000007F */
+		unsigned int  rsv_7                                 :  1;      /*  7.. 7, 0x00000080 */
+		unsigned int  RCNT                                  :  6;      /*  8..13, 0x00003F00 */
+		unsigned int  rsv_14                                :  2;      /* 14..15, 0x0000C000 */
+		unsigned int  WCNT                                  :  6;      /* 16..21, 0x003F0000 */
+		unsigned int  rsv_22                                :  2;      /* 22..23, 0x00C00000 */
+		unsigned int  DROP_CNT                              :  8;      /* 24..31, 0xFF000000 */
+	} Bits;
+	unsigned int Raw;
+};  /* CAM_A_FBC_IMGO_CTL2 */
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/camSV/inc/camerasv_isp.h b/drivers/media/platform/mtk-isp/isp_50/camSV/inc/camerasv_isp.h
new file mode 100644
index 000000000000..ac67284ca920
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/camSV/inc/camerasv_isp.h
@@ -0,0 +1,1256 @@
+/**
+ * Copyright (C) 2015 MediaTek Inc.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _MT_CAMSV_ISP_H
+#define _MT_CAMSV_ISP_H
+
+#ifndef CONFIG_OF
+extern void mt_irq_set_sens(unsigned int irq, unsigned int sens);
+extern void mt_irq_set_polarity(unsigned int irq, unsigned int polarity);
+#endif
+
+/**
+ * enforce kernel log enable
+ */
+#define KERNEL_LOG
+
+/*******************************************************************************
+ *
+ ********************************************************************************/
+
+#define FIELD unsigned int
+#define UINT32 unsigned int
+#define ISP_DEV_MAJOR_NUMBER    251
+#define ISP_CAMSV_MAGIC         'V'
+#define _MAGIC_NUM_ERR_HANDLING_
+
+#define UNI_A_BASE_HW   0x1A003000
+#define CAM_A_BASE_HW   0x1A004000
+#define CAM_B_BASE_HW   0x1A006000
+#define CAM_C_BASE_HW   0x1A008000
+#define CAMSV_0_BASE_HW 0x1A050000
+#define CAMSV_1_BASE_HW 0x1A051000
+#define CAMSV_2_BASE_HW 0x1A052000
+#define CAMSV_3_BASE_HW 0x1A053000
+#define CAMSV_4_BASE_HW 0x1A054000
+#define CAMSV_5_BASE_HW 0x1A055000
+
+#define ISP_REG_RANGE           (PAGE_SIZE*2)
+#define MUINT32 unsigned int
+#define MINT32 signed int
+#define MUINT64 unsigned long long
+
+#define CAM_ISP_PIXEL_BYTE_FP               (3)
+
+#define CAMSV_IMAGE_MAX_WIDTH				4224
+#define CAMSV_IMAGE_MAX_LENGTH				3136
+#define CAMSV_PAD_SINK			0 /* sinking data */
+#define CAMSV_PAD_SOURCE		1 /* sourcing data */
+#define CAMSV_PADS			16
+#define CAMSV_MAX_MODULES	8
+#define CAMSV_MAX_BUFFER	8
+#define CAMSV_MAX_LOPS		8
+#define CAMSV_PAGE_SIZE		0x400
+#define CAMSV_MAX_BUFFERS	32
+#define CAMSV_QUEUES		1 /* 1 subdevice, 8x2 video device */
+#define CAMSV_NAME			"mtk-camsv"
+#define CAMSV_DEVICE_NAME		"MTK CAMSV"
+#define CAMSV_ENTITY_NAME		"mtk-camsv-entity"
+#ifndef PROPERTY_VALUE_MAX
+#define PROPERTY_VALUE_MAX 32
+#endif
+#define MIN_GRPFRM_TIME_MS          (200)  //subsampled frame time minimum difference
+#define MAX_RECENT_GRPFRM_TIME      (2)
+
+/* CamSV pad enumarate */
+enum ISP_DEV_PAD_ENUM {
+	ISP_CAMSV0_SINK = 0,
+	ISP_CAMSV1_SINK,
+	ISP_CAMSV2_SINK,
+	ISP_CAMSV3_SINK,
+	ISP_CAMSV4_SINK,
+	ISP_CAMSV5_SINK,
+	ISP_CAMSV6_SINK,
+	ISP_CAMSV7_SINK,
+	ISP_CAMSV0_SOURCE,// 8
+	ISP_CAMSV1_SOURCE,
+	ISP_CAMSV2_SOURCE,
+	ISP_CAMSV3_SOURCE,
+	ISP_CAMSV4_SOURCE,
+	ISP_CAMSV5_SOURCE,
+	ISP_CAMSV6_SOURCE,
+	ISP_CAMSV7_SOURCE,
+	ISP_DEV_PAD_NUM
+};
+
+/* In order with the suquence of device nodes defined in dtsi */
+/* in dtsi rule, one hw module should mapping to one node. */
+enum ISP_CAMSV_DEV_NODE_ENUM {
+	ISP_CAMSYS_CONFIG_IDX = 0,
+	ISP_CAMSV0_IDX,
+	ISP_CAMSV1_IDX,
+	ISP_CAMSV2_IDX,
+	ISP_CAMSV3_IDX,
+	ISP_CAMSV4_IDX,
+	ISP_CAMSV5_IDX,
+	ISP_DEV_NODE_NUM
+};
+
+/*
+ * frame status
+ */
+enum CAM_FrameST {
+	CAM_FST_NORMAL = 0,
+	CAM_FST_DROP_FRAME = 1,
+	CAM_FST_LAST_WORKING_FRAME = 2,
+};
+
+/**
+ * interrupt clear type
+ */
+enum ISP_IRQ_CLEAR_ENUM {
+	ISP_IRQ_CLEAR_NONE, /* non-clear wait, clear after wait */
+	ISP_IRQ_CLEAR_WAIT, /* clear wait, clear before and after wait */
+	ISP_IRQ_CLEAR_STATUS, /* clear specific status only */
+	ISP_IRQ_CLEAR_ALL /* clear all status */
+};
+
+/**
+ * module's interrupt , each module should have its own isr.
+ * note:
+ * mapping to isr table,ISR_TABLE when using no device tree
+ */
+enum ISP_CAMSV_IRQ_TYPE_ENUM {
+	ISP_IRQ_TYPE_INT_CAMSV_0_ST,
+	ISP_IRQ_TYPE_INT_CAMSV_1_ST,
+	ISP_IRQ_TYPE_INT_CAMSV_2_ST,
+	ISP_IRQ_TYPE_INT_CAMSV_3_ST,
+	ISP_IRQ_TYPE_INT_CAMSV_4_ST,
+	ISP_IRQ_TYPE_INT_CAMSV_5_ST,
+	ISP_IRQ_TYPE_AMOUNT
+};
+
+enum ISP_ST_ENUM {
+	SIGNAL_INT = 0,
+	DMA_INT,
+	ISP_IRQ_ST_AMOUNT
+};
+
+struct isp_device {
+	void __iomem *regs;
+	struct device *dev;
+	int irq;
+};
+
+/* IRQ time information */
+struct ISP_IRQ_TIME_STRUCT {
+	unsigned int tLastSig_sec; /* time stamp of the latest occurring signal*/
+	/* time stamp of the latest occurring signal*/
+	unsigned int tLastSig_usec;
+	/* time period from marking a signal to user try to wait and get the signal*/
+	unsigned int tMark2WaitSig_sec;
+	/* time period from marking a signal to user try to wait and get the signal*/
+	unsigned int tMark2WaitSig_usec;
+	/* time period from latest signal to user try to wait and get the signal*/
+	unsigned int tLastSig2GetSig_sec;
+	/* time period from latest signal to user try to wait and get the signal*/
+	unsigned int tLastSig2GetSig_usec;
+	int passedbySigcnt; /* the count for the signal passed by  */
+};
+
+/* IRQ event information */
+struct ISP_WAIT_IRQ_ST {
+	enum ISP_IRQ_CLEAR_ENUM Clear;
+	enum ISP_ST_ENUM St_type;
+	unsigned int Status; /*ref. enum:ENUM_CAM_INT / ENUM_CAM_DMA_INT ...etc in isp_drv_stddef.h*/
+	int UserKey; /* user key for doing interrupt operation */
+	unsigned int Timeout;
+	struct ISP_IRQ_TIME_STRUCT TimeInfo;
+};
+
+/* IRQ structure */
+struct ISP_WAIT_IRQ_STRUCT {
+	enum ISP_CAMSV_IRQ_TYPE_ENUM Type;
+	unsigned int bDumpReg;
+	struct ISP_WAIT_IRQ_ST EventInfo;
+};
+
+struct ISP_REGISTER_USERKEY_STRUCT {
+	int userKey;
+	char userName[32]; /* this size must the same as the icamiopipe api - registerIrq(...) */
+};
+
+struct ISP_CLEAR_IRQ_ST {
+	int UserKey; /* user key for doing interrupt operation */
+	enum ISP_ST_ENUM St_type;
+	unsigned int Status;
+};
+
+struct ISP_CLEAR_IRQ_STRUCT {
+	enum ISP_CAMSV_IRQ_TYPE_ENUM Type;
+	struct ISP_CLEAR_IRQ_ST EventInfo;
+};
+
+/* clear IRQ event information */
+struct ISP_REG_STRUCT {
+	unsigned int module; /*plz refer to ISP_CAMSV_DEV_NODE_ENUM */
+	unsigned int Addr; /* register's addr */
+	unsigned int Val; /* register's value */
+};
+
+/* clear IRQ structure */
+struct ISP_REG_IO_STRUCT {
+	struct ISP_REG_STRUCT *pData; /* pointer to ISP_REG_STRUCT */
+	unsigned int Count; /* count */
+};
+
+#ifdef CONFIG_COMPAT
+struct compat_ISP_REG_IO_STRUCT {
+	compat_uptr_t pData;
+	unsigned int Count; /* count */
+};
+#endif
+/*******************************************************************************
+ *
+ ********************************************************************************/
+struct ISP_USER_INFO_STRUCT {
+	pid_t   Pid;
+	pid_t   Tid;
+};
+
+struct ISP_DUMP_BUFFER_STRUCT {
+	unsigned int DumpCmd;
+	unsigned int *pBuffer;
+	unsigned int BytesofBufferSize;
+};
+
+enum ISP_MEMORY_INFO_CMD {
+	ISP_MEMORY_INFO_TPIPE_CMD = 1,
+	ISP_MEMORY_INFO_CMDQ_CMD
+};
+
+struct ISP_GET_DUMP_INFO_STRUCT {
+	unsigned int extracmd;
+	unsigned int imgi_baseaddr;
+	unsigned int tdri_baseaddr;
+	unsigned int dmgi_baseaddr;
+};
+#ifdef CONFIG_COMPAT
+struct compat_ISP_DUMP_BUFFER_STRUCT {
+	unsigned int DumpCmd;
+	compat_uptr_t pBuffer;
+	unsigned int BytesofBufferSize;
+};
+
+#endif
+
+/* length of the two memory areas */
+#define P1_DEQUE_CNT    1
+#define RT_BUF_TBL_NPAGES 16
+#define ISP_RT_BUF_SIZE 16
+#define ISP_RT_CQ0C_BUF_SIZE (ISP_RT_BUF_SIZE)/* (ISP_RT_BUF_SIZE>>1) */
+/* pass1 setting sync index */
+#define ISP_REG_P1_CFG_IDX 0x4090
+/* how many clk levels */
+#define ISP_CLK_LEVEL_CNT 10
+
+enum _isp_tg_enum_ {
+	_cam_tg_ = 0,
+	_cam_tg2_,
+	_camsv_tg_,
+	_camsv2_tg_,
+	_cam_tg_max_
+};
+
+enum _isp_dma_enum_ {
+	_camsv_imgo_ = 0,
+	_camsv_max_,
+};
+
+
+struct ISP_LARB_MMU_STRUCT {
+	unsigned int LarbNum;
+	unsigned int regOffset;
+	unsigned int regVal;
+};
+
+struct ISP_RT_IMAGE_INFO_STRUCT {
+	unsigned int w; /* tg size */
+	unsigned int h;
+	unsigned int xsize; /* dmao xsize */
+	unsigned int stride;
+	unsigned int fmt;
+	unsigned int pxl_id;
+	unsigned int wbn;
+	unsigned int ob;
+	unsigned int lsc;
+	unsigned int rpg;
+	unsigned int m_num_0;
+	unsigned int frm_cnt;
+	unsigned int bus_size;
+};
+
+struct ISP_RT_RRZ_INFO_STRUCT {
+	unsigned int srcX; /* crop window start point */
+	unsigned int srcY;
+	unsigned int srcW; /* crop window size */
+	unsigned int srcH;
+	unsigned int dstW; /* rrz out size */
+	unsigned int dstH;
+};
+
+struct ISP_RT_DMAO_CROPPING_STRUCT {
+	unsigned int x; /* in pix */
+	unsigned int y; /* in pix */
+	unsigned int w; /* in byte */
+	unsigned int h; /* in byte */
+};
+
+struct ISP_RT_BUF_INFO_STRUCT {
+	unsigned int memID;
+	unsigned int size;
+	long long base_vAddr;
+	unsigned int base_pAddr;
+	unsigned int timeStampS;
+	unsigned int timeStampUs;
+	unsigned int bFilled;
+	unsigned int bProcessRaw;
+	struct ISP_RT_IMAGE_INFO_STRUCT image;
+	struct ISP_RT_RRZ_INFO_STRUCT rrzInfo;
+	struct ISP_RT_DMAO_CROPPING_STRUCT dmaoCrop; /* imgo */
+	unsigned int bDequeued;
+	signed int bufIdx; /* used for replace buffer */
+};
+
+struct ISP_DEQUE_BUF_INFO_STRUCT {
+	unsigned int count;
+	unsigned int sof_cnt; /* cnt for current sof */
+	unsigned int img_cnt; /* cnt for mapping to which sof */
+	/* support only deque 1 image at a time */
+	/* ISP_RT_BUF_INFO_STRUCT  data[ISP_RT_BUF_SIZE]; */
+	struct ISP_RT_BUF_INFO_STRUCT data[P1_DEQUE_CNT];
+};
+
+struct ISP_RT_RING_BUF_INFO_STRUCT {
+	unsigned int start; /* current DMA accessing buffer */
+	unsigned int total_count; /* total buffer number.Include Filled and empty */
+	unsigned int empty_count; /* total empty buffer number include current DMA accessing buffer */
+	/* previous total empty buffer number include current DMA accessing buffer */
+	unsigned int pre_empty_count;
+	unsigned int active;
+	unsigned int read_idx;
+	unsigned int img_cnt; /* cnt for mapping to which sof */
+	struct ISP_RT_BUF_INFO_STRUCT data[ISP_RT_BUF_SIZE];
+};
+
+enum ISP_RT_BUF_CTRL_ENUM {
+	ISP_RT_BUF_CTRL_DMA_EN, ISP_RT_BUF_CTRL_CLEAR, ISP_RT_BUF_CTRL_MAX
+};
+
+enum ISP_RTBC_STATE_ENUM {
+	ISP_RTBC_STATE_INIT,
+	ISP_RTBC_STATE_SOF,
+	ISP_RTBC_STATE_DONE,
+	ISP_RTBC_STATE_MAX
+};
+
+enum ISP_RTBC_BUF_STATE_ENUM {
+	ISP_RTBC_BUF_EMPTY,
+	ISP_RTBC_BUF_FILLED,
+	ISP_RTBC_BUF_LOCKED,
+};
+
+enum ISP_RAW_TYPE_ENUM {
+	ISP_RROCESSED_RAW,
+	ISP_PURE_RAW,
+};
+
+struct ISP_RT_BUF_STRUCT {
+	enum ISP_RTBC_STATE_ENUM state;
+	unsigned long dropCnt;
+	struct ISP_RT_RING_BUF_INFO_STRUCT ring_buf[_camsv_max_];
+};
+
+struct ISP_BUFFER_CTRL_STRUCT {
+	enum ISP_RT_BUF_CTRL_ENUM ctrl;
+	enum ISP_CAMSV_IRQ_TYPE_ENUM module;
+	enum _isp_dma_enum_ buf_id;
+	struct ISP_RT_BUF_INFO_STRUCT *data_ptr;
+	struct ISP_RT_BUF_INFO_STRUCT *ex_data_ptr; /* exchanged buffer */
+	unsigned char *pExtend;
+};
+
+/* reference count */
+#define _use_kernel_ref_cnt_
+
+enum ISP_REF_CNT_CTRL_ENUM {
+	ISP_REF_CNT_GET,
+	ISP_REF_CNT_INC,
+	ISP_REF_CNT_DEC,
+	ISP_REF_CNT_DEC_AND_RESET_P1_P2_IF_LAST_ONE,
+	ISP_REF_CNT_DEC_AND_RESET_P1_IF_LAST_ONE,
+	ISP_REF_CNT_DEC_AND_RESET_P2_IF_LAST_ONE,
+	ISP_REF_CNT_MAX
+};
+
+enum ISP_REF_CNT_ID_ENUM {
+	ISP_REF_CNT_ID_IMEM,
+	ISP_REF_CNT_ID_ISP_FUNC,
+	ISP_REF_CNT_ID_GLOBAL_PIPE,
+	ISP_REF_CNT_ID_P1_PIPE,
+	ISP_REF_CNT_ID_P2_PIPE,
+	ISP_REF_CNT_ID_MAX,
+};
+
+struct ISP_REF_CNT_CTRL_STRUCT {
+	enum ISP_REF_CNT_CTRL_ENUM ctrl;
+	enum ISP_REF_CNT_ID_ENUM id;
+	signed int *data_ptr;
+};
+
+struct ISP_CLK_INFO {
+	unsigned char clklevelcnt; /* how many clk levels */
+	unsigned int clklevel[ISP_CLK_LEVEL_CNT]; /* Reocrd each clk level */
+};
+
+struct ISP_GET_CLK_INFO {
+	unsigned int curClk;
+	unsigned int targetClk;
+};
+
+struct ISP_PM_QOS_STRUCT {
+	unsigned int       fps;
+	unsigned int       bw_sum;
+};
+
+struct ISP_PM_QOS_INFO_STRUCT {
+	unsigned int       bw_value;
+	unsigned int       module;
+	unsigned int       fps;
+};
+
+struct ISP_MULTI_RAW_CONFIG {
+	unsigned char HWmodule;
+	unsigned char master_module;
+	unsigned char slave_cam_num;
+	unsigned char twin_module;
+	uintptr_t        cq_base_pAddr;
+};
+
+struct ISP_RAW_INT_STATUS {
+	unsigned int ispIntErr;
+	unsigned int ispInt3Err;
+};
+
+enum E_CamPixelMode {
+	ePixMode_NONE = 0,
+	ePixMode_1,
+	ePixMode_2,
+	ePixMode_4,
+	ePixMode_MAX,
+	_UNKNOWN_PIX_MODE = ePixMode_NONE,
+	_1_PIX_MODE = ePixMode_1,
+	_2_PIX_MODE = ePixMode_2,
+	_4_PIX_MODE = ePixMode_4,
+	_MAX_PIX_MODE = ePixMode_MAX,
+};
+
+/**
+ *    SV TG data format
+ */
+enum E_CAMSV_TG_FMT {
+	SV_TG_FMT_RAW8      = 0,
+	SV_TG_FMT_RAW10     = 1,
+	SV_TG_FMT_RAW12     = 2,
+	SV_TG_FMT_YUV422    = 3,
+	SV_TG_FMT_RAW14     = 4,
+	SV_TG_FMT_JPG       = 7,
+};
+
+enum E_STATE {
+	E_NORMAL,
+	E_SUSPEND,
+	E_RESUME,
+};
+
+enum E_BC_STATUS {
+	eCmd_Fail = 0,			//fail
+	eCmd_Pass = 1,			//ok
+	eCmd_Stop_Pass,			//this state is for stopped already
+	eCmd_Suspending_Pass,	//this state is for starting suspending
+};
+
+struct C_FSM {
+	enum E_STATE	m_State;
+	//mutable Mutex			m_lock;
+};
+
+struct IspSize {
+	unsigned long w;
+	unsigned long h;
+	unsigned long stride;
+	unsigned long xsize;    //unit:byte
+};
+
+struct IspPoint {
+	long    x;
+	long    y;
+};
+
+struct IspRect {
+	unsigned int    x;
+	unsigned int    y;
+	unsigned int    floatX; /* x float precise - 32 bit */
+	unsigned int    floatY; /* y float precise - 32 bit */
+	unsigned long   w;
+	unsigned long   h;
+};
+
+struct IspMemBuffer {
+	unsigned int size;
+	unsigned int base_vAddr;//ptr
+	unsigned int base_pAddr;//ptr
+	unsigned int ofst_addr;
+	unsigned int alignment;
+};
+
+struct IspOffset {
+	unsigned int x;
+	unsigned int y;
+};
+
+union {
+	struct {
+		MUINT32 bin_off          :  1;       // 1: force to off frontal binning
+		MUINT32 DATA_PATTERN     :  3;       //plz reference to E_CamPattern
+		MUINT32 SUBSAMPLE        :  5;       //subsample function,no subsample is subsample = 0.
+		MUINT32 PBN_SEP_MODE     :  1;       //plz reference to E_CAMIO_SepMode
+		MUINT32 Density          :  2;       // for Dual PD, 0 for Low,1 for High
+		MUINT32 SensorNum        :  2;       // plz reference to E_CAMIO_SEN
+		MUINT32 DynamicTwin      :  1;       // ON/OFF dynamic twin flow.
+		MUINT32 IQlv             :  1;       //plz reference to E_CamIQLevel
+		MUINT32 RMB_SEL          :  2;       //plz reference to E_CamRMBSel
+		MUINT32 rsv              : 14;
+	} Bits;
+	MUINT32 Raw;
+} CAMIO_Func;
+
+union CAMSV_REG_MODULE_EN_U {
+	struct /* 0x1A050510 */{
+		FIELD  TG_EN                                 :  1;      /*  0.. 0, 0x00000001 */
+		FIELD  rsv_1                                 :  1;      /*  1.. 1, 0x00000002 */
+		FIELD  PAK_EN                                :  1;      /*  2.. 2, 0x00000004 */
+		FIELD  PAK_SEL                               :  1;      /*  3.. 3, 0x00000008 */
+		FIELD  IMGO_EN                               :  1;      /*  4.. 4, 0x00000010 */
+		FIELD  DOWN_SAMPLE_EN                        :  1;      /*  5.. 5, 0x00000020 */
+		FIELD  rsv_6                                 :  2;      /*  6.. 7, 0x000000C0 */
+		FIELD  DOWN_SAMPLE_PERIOD                    :  6;      /*  8..13, 0x00003F00 */
+		FIELD  rsv_14                                :  2;      /* 14..15, 0x0000C000 */
+		FIELD  SW_PASS1_DONE_FRAME_CNT               :  6;      /* 16..21, 0x003F0000 */
+		FIELD  rsv_22                                :  8;      /* 22..29, 0x3FC00000 */
+		FIELD  DB_EN                                 :  1;      /* 30..30, 0x40000000 */
+		FIELD  DB_LOCK                               :  1;      /* 31..31, 0x80000000 */
+	} Bits;
+	UINT32 Raw;
+};   /* CAMSV_MODULE_EN, CAMSV_0_MODULE_EN*/
+
+union CAMSV_REG_FMT_SEL_U {
+	struct /* 0x1A050514 */{
+		FIELD  TG1_FMT                               :  3;      /*  0.. 2, 0x00000007 */
+		FIELD  rsv_3                                 :  1;      /*  3.. 3, 0x00000008 */
+		FIELD  TG1_SW                                :  2;      /*  4.. 5, 0x00000030 */
+		FIELD  rsv_6                                 :  2;      /*  6.. 7, 0x000000C0 */
+		FIELD  LP_MODE                               :  1;      /*  8.. 8, 0x00000100 */
+		FIELD  HLR_MODE                              :  1;      /*  9.. 9, 0x00000200 */
+		FIELD  rsv_10                                : 22;      /* 10..31, 0xFFFFFC00 */
+	} Bits;
+	UINT32 Raw;
+}; /* CAMSV_FMT_SEL, CAMSV_0_FMT_SEL*/
+
+union CAMSV_REG_INT_STATUS_U {
+	struct /* 0x1A05051C */ {
+		FIELD  VS1_ST                                :  1;      /*  0.. 0, 0x00000001 */
+		FIELD  TG_ST1                                :  1;      /*  1.. 1, 0x00000002 */
+		FIELD  TG_ST2                                :  1;      /*  2.. 2, 0x00000004 */
+		FIELD  EXPDON1_ST                            :  1;      /*  3.. 3, 0x00000008 */
+		FIELD  TG_ERR_ST                             :  1;      /*  4.. 4, 0x00000010 */
+		FIELD  TG_GBERR_ST_T                           :  1;      /*  5.. 5, 0x00000020 */
+		FIELD  TG_DROP_INT_ST                        :  1;      /*  6.. 6, 0x00000040 */
+		FIELD  TG_SOF1_INT_ST                        :  1;      /*  7.. 7, 0x00000080 */
+		FIELD  rsv_8                                 :  2;      /*  8.. 9, 0x00000300 */
+		FIELD  PASS1_DON_ST                          :  1;      /* 10..10, 0x00000400 */
+		FIELD  rsv_11                                :  5;      /* 11..15, 0x0000F800 */
+		FIELD  IMGO_ERR_ST                           :  1;      /* 16..16, 0x00010000 */
+		FIELD  IMGO_OVERR_ST                         :  1;      /* 17..17, 0x00020000 */
+		FIELD  rsv_18                                :  1;      /* 18..18, 0x00040000 */
+		FIELD  IMGO_DROP_ST                          :  1;      /* 19..19, 0x00080000 */
+		FIELD  SW_PASS1_DON_ST                       :  1;      /* 20..20, 0x00100000 */
+		FIELD  TG_SOF_WAIT_ST                        :  1;      /* 21..21, 0x00200000 */
+		FIELD  rsv_22                                : 10;      /* 22..31, 0xFFC00000 */
+	} Bits;
+	UINT32 Raw;
+};  /* , CAMSV_0_INT_STATUS*/
+
+union CAMSV_REG_TG_SEN_GRAB_PXL {
+	struct /* 0x1A050238 */
+	{
+		FIELD  PXL_S                                 : 15;      /*  0..14, 0x00007FFF */
+		FIELD  rsv_15                                :  1;      /* 15..15, 0x00008000 */
+		FIELD  PXL_E                                 : 15;      /* 16..30, 0x7FFF0000 */
+		FIELD  rsv_31                                :  1;      /* 31..31, 0x80000000 */
+	} Bits;
+	UINT32 Raw;
+}; /* CAMSV_TG_SEN_GRAB_PXL, CAMSV_0_TG_SEN_GRAB_PXL*/
+
+union CAMSV_REG_TG_SEN_GRAB_LIN {
+	struct /* 0x1A05023C */
+	{
+		FIELD  LIN_S                                 : 14;      /*  0..13, 0x00003FFF */
+		FIELD  rsv_14                                :  2;      /* 14..15, 0x0000C000 */
+		FIELD  LIN_E                                 : 14;      /* 16..29, 0x3FFF0000 */
+		FIELD  rsv_30                                :  2;      /* 30..31, 0xC0000000 */
+	} Bits;
+	UINT32 Raw;
+}; /* CAMSV_TG_SEN_GRAB_LIN, CAMSV_0_TG_SEN_GRAB_LIN*/
+
+
+union CAMSV_REG_TG_FRM_CNT_ST {
+	struct /* 0x1A050264 */
+	{
+		FIELD  REZ_OVRUN_FCNT                        :  4;      /*  0.. 3, 0x0000000F */
+		FIELD  rsv_4                                 :  4;      /*  4.. 7, 0x000000F0 */
+		FIELD  GRAB_ERR_FCNT                         :  4;      /*  8..11, 0x00000F00 */
+		FIELD  rsv_12                                : 20;      /* 12..31, 0xFFFFF000 */
+	} Bits;
+	UINT32 Raw;
+};   /* CAMSV_TG_FRM_CNT_ST, CAMSV_0_TG_FRM_CNT_ST*/
+
+union CAMSV_REG_TG_FRMSIZE_ST {
+	struct /* 0x1A050268 */
+	{
+		FIELD  LINE_CNT                              : 14;      /*  0..13, 0x00003FFF */
+		FIELD  rsv_14                                :  2;      /* 14..15, 0x0000C000 */
+		FIELD  PXL_CNT                               : 15;      /* 16..30, 0x7FFF0000 */
+		FIELD  rsv_31                                :  1;      /* 31..31, 0x80000000 */
+	} Bits;
+	UINT32 Raw;
+};   /* CAMSV_TG_FRMSIZE_ST, CAMSV_0_TG_FRMSIZE_ST*/
+
+union CAMSV_REG_TG_INTER_ST {
+	struct /* 0x1A05026C */
+	{
+		FIELD  SYN_VF_DATA_EN                        :  1;      /*  0.. 0, 0x00000001 */
+		FIELD  OUT_RDY                               :  1;      /*  1.. 1, 0x00000002 */
+		FIELD  OUT_REQ                               :  1;      /*  2.. 2, 0x00000004 */
+		FIELD  rsv_3                                 :  5;      /*  3.. 7, 0x000000F8 */
+		FIELD  TG_CAM_CS                             :  6;      /*  8..13, 0x00003F00 */
+		FIELD  rsv_14                                :  2;      /* 14..15, 0x0000C000 */
+		FIELD  CAM_FRM_CNT                           :  8;      /* 16..23, 0x00FF0000 */
+		FIELD  rsv_24                                :  8;      /* 24..31, 0xFF000000 */
+	} Bits;
+	UINT32 Raw;
+}; /* CAMSV_TG_INTER_ST, CAMSV_0_TG_INTER_ST*/
+
+union CAMSV_REG_TG_FRMSIZE_ST_R {
+	struct /* 0x1A0502AC */
+	{
+		FIELD  LINE_CNT                              : 14;      /*  0..13, 0x00003FFF */
+		FIELD  rsv_14                                :  2;      /* 14..15, 0x0000C000 */
+		FIELD  PXL_CNT                               : 15;      /* 16..30, 0x7FFF0000 */
+		FIELD  rsv_31                                :  1;      /* 31..31, 0x80000000 */
+	} Bits;
+	UINT32 Raw;
+}; /* CAMSV_TG_FRMSIZE_ST_R, CAMSV_0_TG_FRMSIZE_ST_R*/
+
+enum EImageRotation {
+	eImgRot_0      = 0, //
+	eImgRot_90,         //90 CW
+	eImgRot_180,
+	eImgRot_270
+};
+
+/*******************************************************************************
+ * Image Rotation.
+ ********************************************************************************/
+enum EImageFlip {
+	eImgFlip_OFF     = 0, //
+	eImgFlip_ON      = 1, //
+};
+
+/*******************************************************************************
+ * raw image pixel ID
+ ********************************************************************************/
+enum ERawPxlID {
+	ERawPxlID_B   = 0,  // B Gb Gr R
+	ERawPxlID_Gb,       // Gb B R Gr
+	ERawPxlID_Gr,       // Gr R B Gb
+	ERawPxlID_R         // R Gr Gb B
+};
+
+
+/*******************************************************************************
+ * Muti-Plane Buffer Index
+ ********************************************************************************/
+enum E_BufPlaneID {
+	ePlane_1st = 0,
+	ePlane_2nd,
+	ePlane_3rd,
+	ePlane_max,
+};
+
+
+/*******************************************************************************
+ * image resizer
+ ********************************************************************************/
+struct STImgResize {
+	MUINT32 src_x;
+	MUINT32 src_y;
+	MUINT32 src_w;
+	MUINT32 src_h;
+	MUINT32 tar_x;
+	MUINT32 tar_y;
+	MUINT32 tar_w;
+	MUINT32 tar_h;
+};
+
+/*******************************************************************************
+ * image crop
+ ********************************************************************************/
+struct STImgCrop {
+	MUINT32      x;
+	MUINT32      y;
+	MUINT32      floatX; /* x float precise - 32 bit */
+	MUINT32      floatY; /* y float precise - 32 bit */
+	MUINT32      w;
+	MUINT32      h;
+	MUINT32		 img_fmt; //EImageFormat
+	MUINT32      enqueue_img_stride;
+};
+
+/**
+ *    TG data format
+ */
+enum E_CAM_CTL_TG_FMT {
+	TG_FMT_RAW8     = 0,
+	TG_FMT_RAW10    = 1,
+	TG_FMT_RAW12    = 2,
+	TG_FMT_YUV422   = 3,
+	TG_FMT_RAW14    = 4,
+	TG_FMT_RGB565   = 5,
+	TG_FMT_RGB888   = 6,
+	TG_FMT_JPG      = 7,
+};
+
+/**
+ *    IMGO WDMA data format
+ */
+enum E_CAM_CTL_IMGO_FMT {
+	IMGO_FMT_YUV422_1P  = 0,
+	IMGO_FMT_RAW8       = 8,
+	IMGO_FMT_RAW10      = 9,
+	IMGO_FMT_RAW12      = 10,
+	IMGO_FMT_RAW14      = 11,
+	IMGO_FMT_RAW8_2B    = 12,
+	IMGO_FMT_RAW10_2B   = 13,
+	IMGO_FMT_RAW12_2B   = 14,
+	IMGO_FMT_RAW14_2B   = 15,
+	IMGO_FMT_RAW10_MIPI = 16,
+};
+
+/**
+ *    RRZO WDMA data format
+ */
+
+enum E_CAM_CTL_RRZO_FMT {
+	RRZO_FMT_RAW8       = 0,
+	RRZO_FMT_RAW10      = 1,
+	RRZO_FMT_RAW12      = 2,
+	RRZO_FMT_RAW14      = 3,
+};
+
+/**
+ *    TG data swap(YUV,RGB only)
+ */
+
+enum E_CAM_CTL_TG_SWAP {
+	TG_SW_UYVY = 0,
+	TG_SW_YUYV = 1,
+	TG_SW_VYUY = 2,
+	TG_SW_YVYU = 3,
+
+	TG_SW_RGB  = 0,
+
+	TG_SW_BGR  = 2,
+};
+
+/******************************************************************************
+ *
+ * @enum EImageFormat
+ * @brief Image format Enumeration.
+ *
+ ******************************************************************************/
+enum EImageFormat {
+/*
+ * This format is used to carry task-specific data which does not have a
+ * standard image structure. The details of the format are left to the two
+ * endpoints.
+ *
+ * Buffers of this format must have a height of 1, and width equal to their
+ * size in bytes.
+ */
+	eImgFmt_RGBA8888 = 1, /*!< RGBA (32-bit; LSB:R, MSB:A), 1 plane */
+	eImgFmt_RGBX8888 = 2, /*!< RGBX (32-bit; LSB:R, MSB:X), 1 plane */
+	eImgFmt_RGB888 = 3, /*!< RGB 888 (24-bit), 1 plane (RGB) */
+	eImgFmt_RGB565 = 4, /*!< RGB 565 (16-bit), 1 plane */
+	eImgFmt_BGRA8888 = 5, /*!< BGRA (32-bit; LSB:B, MSB:A), 1 plane */
+
+	eImgFmt_YUY2 = 0x14,/* !< 422 format, 1 plane (YUYV) */
+
+	eImgFmt_NV16 = 0x10, /* !< 422 format, 2 plane (Y),(UV) */
+	eImgFmt_NV21 = 0x11, /* !< 420 format, 2 plane (Y),(VU) */
+
+	eImgFmt_YV12  = 842094169, /*!< 420 format, 3 plane (Y),(V),(U) */
+
+/**************************************************************************
+ * 0x2000 - 0x2FFF
+ *
+ * This range is reserved for pixel formats that are specific to the HAL implementation.
+ **************************************************************************/
+	eImgFmt_UNKNOWN = 0x0000, /*!< unknown */
+	eImgFmt_VENDOR_DEFINED_START = 0x2000, /*!< vendor definition start */
+
+	/* please add YUV format after eImgFmt_YUV_START */
+	eImgFmt_YUV_START = eImgFmt_VENDOR_DEFINED_START,
+	eImgFmt_YVYU = eImgFmt_YUV_START, /*!< 422 format, 1 plane (YVYU) */
+	eImgFmt_UYVY, /*!< 422 format, 1 plane (UYVY) */
+	eImgFmt_VYUY, /*!< 422 format, 1 plane (VYUY) */
+
+	eImgFmt_NV61, /*!< 422 format, 2 plane (Y),(VU) */
+	eImgFmt_NV12, /*!< 420 format, 2 plane (Y),(UV) */
+	eImgFmt_NV12_BLK, /*!< 420 format block mode, 2 plane (Y),(UV) */
+	eImgFmt_NV21_BLK, /*!< 420 format block mode, 2 plane (Y),(VU) */
+
+	eImgFmt_YV16, /*!< 422 format, 3 plane (Y),(V),(U) */
+	eImgFmt_I420, /*!< 420 format, 3 plane (Y),(U),(V) */
+	eImgFmt_I422, /*!< 422 format, 3 plane (Y),(U),(V) */
+
+	/* please add RGB format after eImgFmt_RGB_START */
+	eImgFmt_RGB_START = 0x2100,
+	eImgFmt_ARGB8888 = eImgFmt_RGB_START, /*!< ARGB (32-bit; LSB:A, MSB:B), 1 plane */
+	eImgFmt_ARGB888 = eImgFmt_ARGB8888, /*!< deprecated; Replace it with eImgFmt_ARGB8888 */
+	eImgFmt_RGB48, /*!< RGB 48(16x3, 48-bit; LSB:R, MSB:B), 1 plane */
+
+	/* please add RAW format after eImgFmt_RAW_START */
+	eImgFmt_RAW_START = 0x2200,
+	eImgFmt_BAYER8 = eImgFmt_RAW_START, /*!< Bayer format, 8-bit */
+	eImgFmt_BAYER10, /*!< Bayer format, 10-bit */
+	eImgFmt_BAYER12, /*!< Bayer format, 12-bit */
+	eImgFmt_BAYER14, /*!< Bayer format, 14-bit */
+
+	eImgFmt_FG_BAYER8, /*!< Full-G (8-bit) */
+	eImgFmt_FG_BAYER10, /*!< Full-G (10-bit) */
+	eImgFmt_FG_BAYER12, /*!< Full-G (12-bit) */
+	eImgFmt_FG_BAYER14, /*!< Full-G (14-bit) */
+};
+
+/**
+ *
+ * @brief Camera point type.
+ *
+ */
+struct MPoint {
+	int                  x;
+	int                  y;
+};
+
+/**
+ *
+ * @brief Camera size type.
+ *
+ */
+struct MSize {
+	int                  w;
+	int                  h;
+};
+
+/*
+ *
+ * @brief Camera rectangle type.
+ *
+ */
+struct MRect {
+	struct MPoint                      p;      //  left-top corner
+	struct MSize                       s;      //  width, height
+};
+
+
+/*
+ * @enum E_CamIQLevel
+ *
+ * @Image Quality level for dynamic bin
+ *
+ */
+enum E_CamIQLevel {
+	eCamIQ_L = 0,
+	eCamIQ_H,
+	eCamIQ_MAX,
+};
+
+/**
+ * buffer extension info
+ */
+struct BufInfo_Ext {
+	bool       bReplace;
+	MUINT32     u4BufSize[ePlane_max];
+	MUINT32    u4BufVA[ePlane_max];
+	MUINT32    u4BufPA[ePlane_max];
+	MINT32      memID[ePlane_max];
+	MINT32      bufSecu[ePlane_max];
+	MINT32      bufCohe[ePlane_max];
+};
+
+
+struct CAMSV_PORT_INFO {
+	MUINT32     u4HwModule;     //  CamSV module
+	bool        wakelock;
+	MUINT32     dfs_ctrl;
+	MUINT32     userCount;
+	char *userName;
+	MUINT32       eImgFmt;        //  Image Pixel Format
+	enum EImageRotation       eImgRot;        //  Image Rotation degree in CW
+	enum EImageFlip      eImgFlip;       //  Image Flip ON/OFF
+	enum ERawPxlID     eRawPxlID;      //  raw data pixel ID
+	enum E_CamPixelMode  ePxlMode;       //  seninf/tg sampling mode
+	MUINT32 imgo_fmt;
+	MINT32 pixel_byte_imgo;
+
+	MUINT32     u4MagicNum;     //  magic number for tuning queue
+	MUINT32     u4PureRaw;
+	MUINT32     u4PureRawPak;
+	MUINT32     u4ImgWidth;     //  Image Width
+	MUINT32     u4ImgHeight;    //  Image Height
+	MUINT32     u4Offset;       //  Image offset byte size
+	//  Image line byte size,0 for one or Y plae/1 for u or uv plane/2 for v plane
+	MUINT32     u4Stride[ePlane_max];
+	struct STImgCrop   crop1;           // image crop info. (ring buffer use curz to run crop)
+	struct STImgResize resize1;
+	struct STImgCrop   crop2;           // image crop info. (ring buffer use curz to run crop)
+	struct STImgResize resize2;
+	struct STImgCrop   crop3;           // image crop info. (ring buffer use curz to run crop)
+	struct STImgResize resize3;
+
+	//PortID
+	MUINT32     type     :   8;      //  EPortType
+	MUINT32     index    :   8;      //  port index
+	MUINT32     inout    :   1;      //  0:in/1:out
+	MUINT32     capbility:   2;      // dma port capbility
+	MUINT32     bOver4lane:   1;      // 0:flase/1:true
+	MUINT32     tgFps;              // fps x 10
+	MUINT32     tTimeClk;           // 10 -> 1mhz.   20->2mhz
+
+	//BufInfo
+	MUINT32     u4BufSize[ePlane_max];  //  Per buffer size
+	MUINT32    u4BufVA[ePlane_max];    //  Vir Address of pool
+	MUINT32    u4BufPA[ePlane_max];    //  Phy Address of pool
+	MUINT32    u4BufOffset[ePlane_max];
+	MINT32      memID[ePlane_max];      //  memory ID
+	MINT32      bufSecu[ePlane_max];
+	MINT32      bufCohe[ePlane_max];
+	struct BufInfo_Ext replace;
+	struct BufInfo_Ext Frame_Header;
+	MUINT64     i4TimeStamp_sec;//  time stamp in seconds.
+	MUINT32     i4TimeStamp_us; //  time stamp in microseconds
+	MUINT32     img_w;
+	MUINT32     img_h;
+	MUINT32     img_stride;
+	MUINT32     img_fmt;
+	MUINT32     img_pxl_id;
+	MUINT32     m_num;
+	MUINT32     frm_cnt;
+	MUINT32     raw_type;   //0:proc, 1:pure, 2 before lsc
+	MUINT32     jpg_size;
+	MUINT32     xoffset;    //starting x-offset of dma
+	MUINT32     yoffset;    //starting y-offset of dma
+	struct MRect       crop_win;   //crop windon, IN TG coordinate axis
+	struct MSize       DstSize;    // image w/h on dram
+	MUINT32 *m_pPrivate; //reserved pointer
+	bool       m_highlightData;
+	enum E_CamIQLevel  eIQlv;
+	bool        bUF_DataFmt;
+
+	//CAMIO_Func
+	MUINT32 m_SubSample;
+};
+
+struct CAMSV_PORTS_INFO {
+	struct CAMSV_PORT_INFO camsv_inport_info[CAMSV_MAX_MODULES];
+	struct CAMSV_PORT_INFO camsv_outport_info[CAMSV_MAX_MODULES];
+};
+
+struct ST_CAMSV_TOP_CTRL {
+	union CAMSV_REG_MODULE_EN_U            FUNC_EN;
+	union CAMSV_REG_FMT_SEL_U              FMT_SEL;
+};
+
+struct CAMSV_TG_CTRL {
+	enum ISP_CAMSV_DEV_NODE_ENUM m_hwModule;
+	unsigned int m_continuous;
+	unsigned int m_SubSample;
+	struct IspRect m_Crop;
+	enum E_CamPixelMode m_PixMode;
+};
+
+struct CAMSV_TOP_CTRL {
+	enum ISP_CAMSV_DEV_NODE_ENUM m_hwModule;
+	struct ST_CAMSV_TOP_CTRL     camsv_top_ctl;
+	//signal subample . 0: no subsample. Vsync/SOF/P1_DONE use the sample subsample
+	unsigned int               SubSample;
+	enum E_CamPixelMode        m_PixMode; // Seninf pixel mode
+	bool m_bBusy;
+	bool bForce;
+};
+
+struct IspDMACfg {
+	enum ISP_CAMSV_DEV_NODE_ENUM m_hwModule;
+	struct IspMemBuffer    memBuf;
+	struct IspSize         size;
+	struct IspOffset       offset;
+	struct IspRect         crop;
+	int             pixel_byte;
+	int             swap;
+	int             format_en;
+	int             format;
+	int             bus_size_en;
+	int             bus_size;
+	int             memBuf_c_ofst;
+	int             memBuf_v_ofst;
+	int             v_flip_en;
+	unsigned int         capbility;      //port capbility
+	unsigned int         Header_Addr;
+	MUINT32         m_fps;
+	enum E_CamPixelMode  m_PixMode;
+	union CAMSV_REG_FMT_SEL_U fmt_sel;
+};
+
+//////////////////////////////////////////////////////////////////////////////
+/**
+ *    class for timestamp asscess
+ */
+enum TSTMP_MODE {
+	LOCAL_MODE = 0,
+	GLOBAL_MODE = 1
+};
+
+struct S_START_T {
+	MUINT32 sec;
+	MUINT32 usec;
+};
+
+struct CAMSV_TIMESTAMP {
+	enum ISP_CAMSV_DEV_NODE_ENUM m_hwModule;
+	enum TSTMP_MODE      m_stmpMode;
+	struct S_START_T     m_startTime;            // systemT of 1st SOF
+	MUINT32             m_TimeClk;             // 10 -> 1mhz, 20-> 2mhz
+};
+
+/**
+ *class for CAMSV DAMO ctrl, support only deque/enque 1 image at 1 time.
+ */
+struct CAMSV_BUF_CTRL {
+	enum ISP_CAMSV_DEV_NODE_ENUM m_hwModule;
+	MUINT32  m_fps;//fps here is sw operation frequency, m_fps = sensor fps / signal subsample.
+	//upadted through normalpipe enque, for dynamic change deque timeout
+	MUINT32  m_recentFrmTimeMs[ISP_DEV_NODE_NUM][MAX_RECENT_GRPFRM_TIME];
+	struct CAMSV_TIMESTAMP *m_pTimeStamp;
+	MUINT32                 m_buf_cnt;
+	MUINT32                 m_sub_ratio;
+
+	struct C_FSM                   m_FSM;
+#undef MAX_DEPTH
+#define MAX_DEPTH   (32)
+};
+
+struct camsv_fmt {
+	u32 mbus_code;
+	u32 fourcc;
+};
+
+static const struct camsv_fmt camsv_formats[] = {
+	{	/* put default entry at beginning */
+		.mbus_code	= MEDIA_BUS_FMT_SBGGR8_1X8,
+		.fourcc		= V4L2_PIX_FMT_SBGGR8,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SGBRG8_1X8,
+		.fourcc		= V4L2_PIX_FMT_SGBRG8,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SGRBG8_1X8,
+		.fourcc		= V4L2_PIX_FMT_SGRBG8,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SRGGB8_1X8,
+		.fourcc		= V4L2_PIX_FMT_SRGGB8,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SBGGR10_1X10,
+		.fourcc		= V4L2_PIX_FMT_SBGGR10,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SGBRG10_1X10,
+		.fourcc		= V4L2_PIX_FMT_SGBRG10,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SGRBG10_1X10,
+		.fourcc		= V4L2_PIX_FMT_SGRBG10,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SRGGB10_1X10,
+		.fourcc		= V4L2_PIX_FMT_SRGGB10,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SBGGR12_1X12,
+		.fourcc		= V4L2_PIX_FMT_SBGGR12,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SGBRG12_1X12,
+		.fourcc		= V4L2_PIX_FMT_SGBRG12,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SGRBG12_1X12,
+		.fourcc		= V4L2_PIX_FMT_SGRBG12,
+	}, {
+		.mbus_code	= MEDIA_BUS_FMT_SRGGB12_1X12,
+		.fourcc		= V4L2_PIX_FMT_SRGGB12,
+	},
+};
+
+#define NUM_FORMATS ARRAY_SIZE(camsv_formats)
+
+struct camsv_vb2_pridata {
+	void *vaddr;
+	unsigned long size;
+	struct device *dev;
+};
+
+struct camsv_bus_info {
+	u32 port;
+	u32 lanes;
+};
+
+struct camsv_Module {
+	/* mutex to be used by vb2_queue */
+	struct mutex lock;
+	struct media_pipeline pipe;
+	struct camsv_bus_info businfo;
+	struct v4l2_subdev *sensor;
+	void __iomem *base;
+
+	/* Subdev, CamSV input /dev/v4l-subdevX */
+	struct v4l2_subdev subdev;
+	struct media_pad subdev_pads[CAMSV_PADS];
+	struct v4l2_mbus_framefmt subdev_fmt;
+	atomic_t frame_sequence;
+
+	/* Video device, CamSV output /dev/videoX */
+	struct v4l2_fh vfh;
+	struct v4l2_ctrl_handler hdl;
+	struct video_device vdev;
+	struct media_pad vdev_pad;
+	struct v4l2_pix_format_mplane format;
+	struct vb2_queue vbq;
+
+	/* port information */
+	struct CAMSV_PORT_INFO camsv_port_input;
+	struct CAMSV_PORT_INFO camsv_port_output;
+	struct CAMSV_TG_CTRL camsv_TGCtrl;
+	struct CAMSV_TOP_CTRL camsv_TopCtrl;
+	struct IspDMACfg camsv_DmaImgo;
+	struct CAMSV_BUF_CTRL camsv_FbcImgo;
+	struct CAMSV_TIMESTAMP camsv_pTime;
+
+	union {
+		struct v4l2_pix_format		pix;     /* V4L2_BUF_TYPE_VIDEO_CAPTURE */
+		struct v4l2_pix_format_mplane	pix_mp;  /* V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE */
+	} fmt;
+
+	/* Buffer queue related */
+	dma_addr_t fbpt_bus_addr;
+	struct camsv_buffer *bufs[CAMSV_MAX_BUFFERS];
+	unsigned int bufs_first;	/* Index of the first used entry */
+	unsigned int bufs_next;	/* Index of the first unused entry */
+	atomic_t bufs_queued;
+
+	struct list_head	capture;
+	struct isp_device ispDevice;
+};
+
+
+struct camsv_device {
+	struct device *dev;
+	void __iomem *base;
+	struct v4l2_device v4l2_dev;
+	struct camsv_Module camsv_module[CAMSV_MAX_MODULES];
+	struct camsv_Module *cur_module;
+	/* mutex to be used by video_device */
+	struct mutex lock;
+	void *vb2_alloc_ctx;
+	bool streaming;
+	bool        wakelock;
+	MUINT32     dfs_ctrl;
+	MUINT32     userCount;
+
+	struct v4l2_async_notifier notifier;
+	struct media_device media_dev;
+
+};
+
+struct camsv_buffer {
+	struct vb2_v4l2_buffer vbb;
+	u32 *lop;
+	dma_addr_t lop_bus_addr;
+	unsigned int offset;
+	struct list_head	queue;
+	int				bufnum;
+	bool			discard;
+};
+
+struct camsv_fh {
+	struct v4l2_fh vfh;
+	struct video_device *vdec;
+	struct vb2_queue *queue;
+	struct v4l2_format format;
+	struct ISP_USER_INFO_STRUCT pUserInfo;
+};
+
+static inline struct camsv_Module *vb2q_to_camsv_module(struct vb2_queue *vq)
+{
+	return container_of(vq, struct camsv_Module, vbq);
+}
+
+static inline struct camsv_Module *videodev_to_camsv_module(struct video_device *vdev)
+{
+	return container_of(vdev, struct camsv_Module, vdev);
+}
+
+static inline struct camsv_Module *subdev_to_camsv_module(struct v4l2_subdev *sdev)
+{
+	return container_of(sdev, struct camsv_Module, subdev);
+}
+
+enum ISP_CAMSV_CMD_ENUM {
+	ISP_CAMSV_CMD_INIT = BASE_VIDIOC_PRIVATE + 1,
+	ISP_CAMSV_CMD_UNINIT = BASE_VIDIOC_PRIVATE + 2,
+	ISP_CAMSV_CMD_WAIT_IRQ = BASE_VIDIOC_PRIVATE + 3,
+	ISP_CAMSV_CMD_SUSPEND = BASE_VIDIOC_PRIVATE + 4,
+	ISP_CAMSV_CMD_RESUME = BASE_VIDIOC_PRIVATE + 5,
+};
+
+#define ISP_CANMSV_INIT _IOWR(ISP_CAMSV_MAGIC, ISP_CAMSV_CMD_INIT, struct CAMSV_PORTS_INFO)
+#define ISP_CANMSV_UNINIT _IOWR(ISP_CAMSV_MAGIC, ISP_CAMSV_CMD_UNINIT, struct CAMSV_PORTS_INFO)
+#define ISP_CANMSV_WAIT_IRQ _IOWR(ISP_CAMSV_MAGIC, ISP_CAMSV_CMD_WAIT_IRQ, struct ISP_WAIT_IRQ_ST)
+#define ISP_CANMSV_SUSPEND _IOWR(ISP_CAMSV_MAGIC, ISP_CAMSV_CMD_SUSPEND, unsigned int)
+#define ISP_CANMSV_RESUME _IOWR(ISP_CAMSV_MAGIC, ISP_CAMSV_CMD_RESUME, unsigned int)
+
+#endif
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/Makefile b/drivers/media/platform/mtk-isp/isp_50/dip/Makefile
new file mode 100644
index 000000000000..9a08c62f1434
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/Makefile
@@ -0,0 +1,35 @@
+#
+# Copyright (C) 2018 MediaTek Inc.
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License version 2 as
+# published by the Free Software Foundation.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+$(info $(srctree))
+ccflags-y += -I$(srctree)/drivers/media/platform/mtk-mdp3
+ccflags-y += -I$(srctree)/drivers/media/platform/mtk-vpu
+
+obj-y += mtk_dip.o
+obj-y += mtk_dip-v4l2.o
+
+# To provide alloc context managing memory shared
+# between CPU and ISP coprocessor
+mtk_dip_smem-objs := \
+mtk_dip-smem-drv.o
+
+obj-y += mtk_dip_smem.o
+
+# Utilits to provide frame-based streaming model
+# with v4l2 user interfaces
+mtk_dip_util-objs := \
+mtk_dip-dev.o \
+mtk_dip-v4l2-util.o \
+mtk_dip-dev-ctx-core.o \
+mtk_dip-ctrl.o \
+
+obj-y += mtk_dip_util.o
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-core.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-core.h
new file mode 100644
index 000000000000..f80acf49ed5b
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-core.h
@@ -0,0 +1,190 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2018 MediaTek Inc.
+ * Author: Holmes Chiou <holmes.chiou@mediatek.com>
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_CORE_H
+#define __MTK_DIP_CORE_H
+
+#include <linux/clk.h>
+
+#include "mtk-img-ipi.h"
+#include "mtk_dip-dev.h"
+
+enum dip_user_state {
+	DIP_STATE_INIT	= 0,
+	DIP_STATE_STREAMON,
+	DIP_STATE_STREAMOFF
+};
+
+struct dip_frame_job {
+	struct img_frameparam fparam;
+	int sequence;
+};
+
+struct dip_user_id {
+	struct list_head list_entry;
+	u16 id;
+	u32 num;
+	u16 state;
+};
+
+struct dip_subframe {
+	struct img_addr buffer;
+	struct sg_table table;
+	struct img_sw_addr config_data;
+	struct img_addr tuning_buf;
+	struct img_sw_addr frameparam;
+	struct list_head list_entry;
+};
+
+struct dip_queue {
+	struct list_head queue;
+	struct mutex queuelock; /* protect queue and queue_cnt */
+	u32 queue_cnt;
+};
+
+struct dip_joblist {
+	struct list_head queue;
+	spinlock_t queuelock; /* protect queue and queue_cnt */
+	u32 queue_cnt;
+};
+
+struct dip_thread {
+	struct task_struct *thread;
+	wait_queue_head_t wq;
+};
+
+struct mtk_dip_work {
+	struct list_head	    list_entry;
+	struct img_ipi_frameparam   frameparams;
+	struct dip_user_id          *user_id;
+};
+
+struct mtk_dip_submit_work {
+	struct work_struct          frame_work;
+	struct mtk_dip_hw_ctx          *dip_ctx;
+};
+
+struct mtk_mdpcb_work {
+	struct work_struct		frame_work;
+	struct img_ipi_frameparam	*frameparams;
+};
+
+struct DIP_CLK_STRUCT {
+	struct clk *DIP_IMG_LARB5;
+	struct clk *DIP_IMG_DIP;
+};
+
+struct mtk_dip_hw_ctx {
+	struct dip_joblist dip_gcejoblist;
+	struct dip_queue dip_freebufferlist;
+	struct dip_queue dip_usedbufferlist;
+
+	struct dip_thread dip_runner_thread;
+
+	struct dip_queue dip_useridlist;
+	struct dip_queue dip_worklist;
+	struct workqueue_struct *composer_wq;
+	struct mtk_dip_submit_work submit_work;
+	wait_queue_head_t composing_wq;
+	wait_queue_head_t flushing_wq;
+	atomic_t num_composing;	/* increase after ipi */
+
+	/* increase after calling MDP driver */
+	atomic_t num_running;
+
+	/*MDP/GCE callback workqueue */
+	struct workqueue_struct *mdpcb_workqueue;
+
+	/* for MDP driver  */
+	struct platform_device *mdp_pdev;
+
+	/* for VPU driver  */
+	struct platform_device *vpu_pdev;
+	struct rproc *rproc_handle;
+
+	phys_addr_t scp_workingbuf_addr;
+
+	/* increase after enqueue */
+	atomic_t dip_enque_cnt;
+	/* increase after Stream ON, decrease when Stream OFF */
+	atomic_t dip_stream_cnt;
+	/* increase after open, decrease when close */
+	atomic_t dip_user_cnt;
+};
+
+struct dip_device {
+	struct platform_device *pdev;
+
+	struct DIP_CLK_STRUCT dip_clk;
+
+	struct device *larb_dev;
+
+	dev_t dip_devno;
+	struct cdev   dip_cdev;
+	struct class *dip_class;
+
+	struct mtk_dip_hw_ctx dip_ctx;
+};
+
+struct mtk_isp_dip_drv_data {
+	struct mtk_dip_dev isp_preview_dev;
+	struct mtk_dip_dev isp_capture_dev;
+	struct mtk_dip_dev isp_reprocess_dev;
+	struct dip_device dip_dev;
+};
+
+static inline struct dip_device *get_dip_device(struct device *dev)
+{
+	struct mtk_isp_dip_drv_data *drv_data =
+		dev_get_drvdata(dev);
+	if (drv_data)
+		return &drv_data->dip_dev;
+	else
+		return NULL;
+}
+
+static inline void frame_param_ipi_to_ctx(struct img_ipi_frameparam *iparam,
+					  struct mtk_dip_ctx_finish_param
+					  *fparam)
+{
+	if (!iparam || !fparam) {
+		pr_err("frame conversion failed, iparam and fparam can't be NULL\n");
+		return;
+	}
+
+	fparam->frame_id = iparam->index;
+	fparam->timestamp = iparam->timestamp;
+	fparam->state = iparam->state;
+}
+
+#define dip_dev_to_drv(__dip_dev) \
+	container_of(__dip_dev, \
+	struct mtk_isp_dip_drv_data, dip_dev)
+
+#define dip_hw_ctx_to_dev(__hw_ctx) \
+	container_of(__hw_ctx, \
+	struct dip_device, dip_ctx)
+
+#define mtk_dip_fparam_to_job(__fparam) \
+	container_of(__fparam,\
+	struct dip_frame_job, fparam)
+
+#define mtk_dip_ipi_fparam_to_job(__ipi_fparam) \
+	container_of(__ipi_fparam, \
+	struct dip_frame_job, \
+	fparam.frameparam)
+
+#endif /* __MTK_DIP_CORE_H */
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.c
new file mode 100644
index 000000000000..9b6be120d911
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.c
@@ -0,0 +1,172 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include "mtk_dip-dev.h"
+#include "mtk_dip-ctrl.h"
+
+#define CONFIG_MTK_DIP_COMMON_UT
+
+static void handle_buf_usage_config(struct v4l2_ctrl *ctrl);
+static void handle_buf_rotate_config(struct v4l2_ctrl *ctrl);
+static int mtk_dip_ctx_s_ctrl(struct v4l2_ctrl *ctrl);
+
+static void handle_buf_usage_config(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_dip_ctx_queue *queue =
+		container_of(ctrl->handler,
+			     struct mtk_dip_ctx_queue, ctrl_handler);
+
+	if (ctrl->val < MTK_DIP_V4l2_BUF_USAGE_DEFAULT ||
+	    ctrl->val >= MTK_DIP_V4l2_BUF_USAGE_NONE) {
+		pr_err("Invalid buffer usage id %d", ctrl->val);
+		return;
+	}
+	queue->buffer_usage = ctrl->val;
+}
+
+static void handle_buf_rotate_config(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_dip_ctx_queue *queue =
+		container_of(ctrl->handler,
+			     struct mtk_dip_ctx_queue, ctrl_handler);
+
+	if (ctrl->val != 0 || ctrl->val != 90 ||
+	    ctrl->val != 180 || ctrl->val != 270) {
+		pr_err("Invalid buffer rotation %d", ctrl->val);
+		return;
+	}
+	queue->rotation = ctrl->val;
+}
+
+static const struct v4l2_ctrl_ops mtk_dip_ctx_ctrl_ops = {
+	.s_ctrl = mtk_dip_ctx_s_ctrl,
+};
+
+#ifdef CONFIG_MTK_DIP_COMMON_UT
+
+static void handle_ctrl_common_util_ut_set_debug_mode
+	(struct v4l2_ctrl *ctrl)
+{
+	struct mtk_dip_ctx *dev_ctx =
+		container_of(ctrl->handler, struct mtk_dip_ctx, ctrl_handler);
+	dev_ctx->mode = ctrl->val;
+	dev_dbg(&dev_ctx->pdev->dev, "Set ctx(id = %d) mode to %d\n",
+		dev_ctx->ctx_id, dev_ctx->mode);
+}
+
+static const struct v4l2_ctrl_config mtk_dip_mode_config = {
+	.ops	= &mtk_dip_ctx_ctrl_ops,
+	.id	= V4L2_CID_PRIVATE_SET_CTX_MODE_NUM,
+	.name	= "MTK ISP UNIT TEST CASE",
+	.type	= V4L2_CTRL_TYPE_INTEGER,
+	.min	= 0,
+	.max	= 65535,
+	.step	= 1,
+	.def	= 0,
+	.flags	= V4L2_CTRL_FLAG_SLIDER | V4L2_CTRL_FLAG_EXECUTE_ON_WRITE,
+};
+#endif /* CONFIG_MTK_DIP_COMMON_UT */
+
+static int mtk_dip_ctx_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	switch (ctrl->id) {
+	#ifdef CONFIG_MTK_DIP_COMMON_UT
+	case V4L2_CID_PRIVATE_SET_CTX_MODE_NUM:
+		handle_ctrl_common_util_ut_set_debug_mode(ctrl);
+		break;
+	#endif /* CONFIG_MTK_DIP_COMMON_UT */
+	default:
+			break;
+	}
+	return 0;
+}
+
+static int mtk_dip_ctx_queue_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	switch (ctrl->id) {
+	case V4L2_CID_PRIVATE_SET_BUFFER_USAGE:
+		handle_buf_usage_config(ctrl);
+		break;
+	case V4L2_CID_ROTATE:
+		handle_buf_rotate_config(ctrl);
+		break;
+	default:
+			break;
+	}
+	return 0;
+}
+
+static const struct v4l2_ctrl_ops mtk_dip_ctx_queue_ctrl_ops = {
+	.s_ctrl = mtk_dip_ctx_queue_s_ctrl,
+};
+
+static const struct v4l2_ctrl_config mtk_dip_buf_usage_config = {
+	.ops	= &mtk_dip_ctx_queue_ctrl_ops,
+	.id	= V4L2_CID_PRIVATE_SET_BUFFER_USAGE,
+	.name	= "MTK ISP SET BUFFER USAGE",
+	.type	= V4L2_CTRL_TYPE_INTEGER,
+	.min	= MTK_DIP_V4l2_BUF_USAGE_DEFAULT,
+	.max	= MTK_DIP_V4l2_BUF_USAGE_POSTPROC,
+	.step	= 1,
+	.def	= MTK_DIP_V4l2_BUF_USAGE_DEFAULT,
+	.flags	= V4L2_CTRL_FLAG_SLIDER | V4L2_CTRL_FLAG_EXECUTE_ON_WRITE,
+	};
+
+int mtk_dip_ctrl_init(struct mtk_dip_ctx *ctx)
+{
+	struct v4l2_ctrl_handler *hdl = &ctx->ctrl_handler;
+	int i = 0;
+
+	/* Initialized HW controls, allow V4L2_CID_MTK_DIP_MAX ctrls */
+	v4l2_ctrl_handler_init(hdl, V4L2_CID_MTK_DIP_MAX);
+	if (hdl->error) {
+		pr_err("Failed in v4l2_ctrl_handler_init\n");
+		return hdl->error;
+}
+
+#ifdef CONFIG_MTK_DIP_COMMON_UT
+if (!v4l2_ctrl_new_custom(hdl, &mtk_dip_mode_config, NULL)) {
+	pr_err("Failed in v4l2_ctrl_new_custom: mtk_dip_mode_config\n");
+	return hdl->error;
+}
+#endif /* CONFIG_MTK_DIP_COMMON_UT */
+
+/* Enumerate all nodes and setup the node specified ctrl */
+for (i = 0; i < ctx->queues_attr.total_num; i++) {
+	struct v4l2_ctrl_handler *node_hdl =
+		&ctx->queue[i].ctrl_handler;
+
+	if (!node_hdl) {
+		pr_err("ctrl_handler can't be NULL\n");
+	} else {
+		v4l2_ctrl_handler_init(node_hdl, V4L2_CID_MTK_DIP_MAX);
+
+		if (v4l2_ctrl_new_custom(node_hdl,
+					 &mtk_dip_buf_usage_config,
+					 NULL) == NULL)
+			pr_err("Node (%d) create buf_usage_config ctrl failed:(%d)",
+			       i, node_hdl->error);
+		if (v4l2_ctrl_new_std(&ctx->ctrl_handler,
+				      &mtk_dip_ctx_queue_ctrl_ops,
+				V4L2_CID_ROTATE, 0, 270, 90, 0)	== NULL)
+			pr_err("Node (%d) create rotate ctrl failed:(%d)",
+			       i, node_hdl->error);
+	}
+}
+
+return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctrl_init);
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.h
new file mode 100644
index 000000000000..1095d4733aa2
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctrl.h
@@ -0,0 +1,42 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_CTRL_H__
+#define __MTK_DIP_CTRL_H__
+
+#include <media/v4l2-ctrls.h>
+
+#define V4L2_CID_PRIVATE_UT_NUM  (V4L2_CID_USER_BASE | 0x1001)
+#define V4L2_CID_PRIVATE_SET_CTX_MODE_NUM \
+	(V4L2_CID_PRIVATE_UT_NUM + 1)
+#define V4L2_CID_PRIVATE_SET_BUFFER_USAGE \
+	(V4L2_CID_PRIVATE_UT_NUM + 2)
+#define V4L2_CID_MTK_DIP_MAX 100
+
+#define MTK_DIP_COMMON_UTIL_UT_OPEN (0)
+#define MTK_DIP_COMMON_UTIL_UT_CLOSE (1)
+#define MTK_DIP_COMMON_UTIL_UT_START (2)
+#define MTK_DIP_COMMON_UTIL_UT_STREAMON (3)
+#define MTK_DIP_COMMON_UTIL_UT_STREAMOFF (4)
+
+enum mtk_dip_v4l2_buffer_usage {
+		MTK_DIP_V4l2_BUF_USAGE_DEFAULT = 0,
+		MTK_DIP_V4l2_BUF_USAGE_FD,
+		MTK_DIP_V4l2_BUF_USAGE_POSTPROC,
+		MTK_DIP_V4l2_BUF_USAGE_NONE,
+};
+
+int mtk_dip_ctrl_init(struct mtk_dip_ctx *ctx);
+
+#endif /*__MTK_DIP_CTRL_H__*/
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctx.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctx.h
new file mode 100644
index 000000000000..2dd014e86dc1
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-ctx.h
@@ -0,0 +1,319 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_CTX_H__
+#define __MTK_DIP_CTX_H__
+
+#include <linux/types.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ctrls.h>
+#include <media/videobuf2-core.h>
+#include <media/v4l2-subdev.h>
+#include "mtk_dip-v4l2-util.h"
+
+#define MTK_DIP_CTX_QUEUES (16)
+#define MTK_DIP_CTX_FRAME_BUNDLE_BUFFER_MAX (MTK_DIP_CTX_QUEUES)
+#define MTK_DIP_CTX_DESC_MAX (MTK_DIP_CTX_QUEUES)
+
+#define MTK_DIP_CTX_MODE_DEBUG_OFF (0)
+#define MTK_DIP_CTX_MODE_DEBUG_BYPASS_JOB_TRIGGER (1)
+#define MTK_DIP_CTX_MODE_DEBUG_BYPASS_ALL (2)
+
+#define MTK_DIP_GET_CTX_ID_FROM_SEQUENCE(sequence) \
+	((sequence) >> 16 & 0x0000FFFF)
+
+#define MTK_DIP_CTX_META_BUF_DEFAULT_SIZE (1110 * 1024)
+
+struct mtk_dip_ctx;
+struct mtk_dip_ctx_open_param;
+struct mtk_dip_ctx_release_param;
+struct mtk_dip_ctx_streamon_param;
+struct mtk_dip_ctx_streamoff_param;
+struct mtk_dip_ctx_start_param;
+struct mtk_dip_ctx_finish_param;
+
+/* Attributes setup by device context owner */
+struct mtk_dip_ctx_queue_desc {
+	int id;	/* id of the context queue */
+	char *name;
+	/* Will be exported to media entity name */
+	int capture;
+	/* 1 for capture queue (device to user), 0 for output queue */
+	/* (from user to device) */
+	int image;
+	/* Using the cam_smem_drv as alloc ctx or not */
+	int smem_alloc;
+	/* 1 for image, 0 for meta data */
+	int dynamic;
+	/* can be enabled or disabled while streaming media data*/
+	unsigned int dma_port; /*The dma port associated to the buffer*/
+	/* Supported format */
+	struct mtk_dip_ctx_format *fmts;
+	int num_fmts;
+	/* Default format of this queue */
+	int default_fmt_idx;
+};
+
+/* Supported format and the information used for */
+/* size calculation */
+struct mtk_dip_ctx_meta_format {
+	u32 dataformat;
+	u32 max_buffer_size;
+	u8 flags;
+};
+
+/* MDP module's private format definitation */
+/* (the same as struct mdp_format) */
+/* It will be removed and changed to MDP's external interface */
+/* after the integration with MDP module. */
+struct mtk_dip_ctx_mdp_format {
+	u32	pixelformat;
+	u32	mdp_color;
+	u8	depth[VIDEO_MAX_PLANES];
+	u8	row_depth[VIDEO_MAX_PLANES];
+	u8	num_planes;
+	u8	walign;
+	u8	halign;
+	u8	salign;
+	u32	flags;
+};
+
+struct mtk_dip_ctx_format {
+	union {
+		struct mtk_dip_ctx_meta_format meta;
+		struct mtk_dip_ctx_mdp_format img;
+	} fmt;
+};
+
+union mtk_v4l2_fmt {
+	struct v4l2_pix_format_mplane pix_mp;
+	struct v4l2_meta_format	meta;
+};
+
+/* Attributes setup by device context owner */
+struct mtk_dip_ctx_queues_setting {
+	int master;
+	/* The master input node to trigger the frame data enqueue */
+	struct mtk_dip_ctx_queue_desc *output_queue_descs;
+	int total_output_queues;
+	struct mtk_dip_ctx_queue_desc *capture_queue_descs;
+	int total_capture_queues;
+};
+
+struct mtk_dip_ctx_queue_attr {
+	int master;
+	int input_offset;
+	int total_num;
+};
+
+/* Video node context. Since we use */
+/* mtk_dip_ctx_frame_bundle to manage enqueued */
+/* buffers by frame now, we don't use bufs filed of */
+/* mtk_dip_ctx_queue now */
+struct mtk_dip_ctx_queue {
+	union mtk_v4l2_fmt fmt;
+	struct mtk_dip_ctx_format *ctx_fmt;
+	/* Currently we used in standard v4l2 image format */
+	/* in the device context */
+	unsigned int width_pad;	/* bytesperline, reserved */
+	struct mtk_dip_ctx_queue_desc desc;
+	struct v4l2_ctrl_handler ctrl_handler; /* Ctrl handler of the queue */
+	unsigned int buffer_usage; /* Current buffer usage of the queue */
+	int rotation;
+	struct list_head bufs; /* Reserved, not used now */
+};
+
+enum mtk_dip_ctx_frame_bundle_state {
+	MTK_DIP_CTX_FRAME_NEW,	/* Not allocated */
+	MTK_DIP_CTX_FRAME_PREPARED, /* Allocated but has not be processed */
+	MTK_DIP_CTX_FRAME_PROCESSING,	/* Queued, waiting to be filled */
+};
+
+/* The definiation is compatible with DIP driver's state definiation */
+/* currently and will be decoupled after further integration */
+enum mtk_dip_ctx_frame_data_state {
+	MTK_DIP_CTX_FRAME_DATA_EMPTY = 0, /* FRAME_STATE_INIT */
+	MTK_DIP_CTX_FRAME_DATA_DONE = 3, /* FRAME_STATE_DONE */
+	MTK_DIP_CTX_FRAME_DATA_STREAMOFF_DONE = 4, /*FRAME_STATE_STREAMOFF*/
+	MTK_DIP_CTX_FRAME_DATA_ERROR = 5, /*FRAME_STATE_ERROR*/
+};
+
+struct mtk_dip_ctx_frame_bundle {
+	struct mtk_dip_ctx_buffer*
+		buffers[MTK_DIP_CTX_FRAME_BUNDLE_BUFFER_MAX];
+	int id;
+	int num_img_capture_bufs;
+	int num_img_output_bufs;
+	int num_meta_capture_bufs;
+	int num_meta_output_bufs;
+	int last_index;
+	int state;
+	struct list_head list;
+};
+
+struct mtk_dip_ctx_frame_bundle_list {
+	struct list_head list;
+};
+
+struct mtk_dip_ctx {
+	struct platform_device *pdev;
+	struct platform_device *smem_device;
+	struct v4l2_ctrl_handler ctrl_handler;
+	/* buffer queues will be added later */
+	unsigned short ctx_id;
+	char *device_name;
+	struct mtk_dip_dev_node_mapping *mtk_dip_dev_node_map;
+	unsigned int dev_node_num;
+	/* mtk_dip_ctx_queue is the context for the video nodes */
+	struct mtk_dip_ctx_queue queue[MTK_DIP_CTX_QUEUES];
+	struct mtk_dip_ctx_queue_attr queues_attr;
+	atomic_t frame_param_sequence;
+	int streaming;
+	void *default_vb2_alloc_ctx;
+	void *smem_vb2_alloc_ctx;
+	struct v4l2_subdev_fh *fh;
+	struct mtk_dip_ctx_frame_bundle frame_bundles[VB2_MAX_FRAME];
+	struct mtk_dip_ctx_frame_bundle_list processing_frames;
+	struct mtk_dip_ctx_frame_bundle_list free_frames;
+	int enabled_dma_ports;
+	int num_frame_bundle;
+	int mode; /* Reserved for debug */
+	spinlock_t qlock;
+};
+
+enum mtk_dip_ctx_buffer_state {
+	MTK_DIP_CTX_BUFFER_NEW,
+	MTK_DIP_CTX_BUFFER_PROCESSING,
+	MTK_DIP_CTX_BUFFER_DONE,
+	MTK_DIP_CTX_BUFFER_FAILED,
+};
+
+struct mtk_dip_ctx_buffer {
+	union mtk_v4l2_fmt fmt;
+	struct mtk_dip_ctx_format *ctx_fmt;
+	int capture;
+	int image;
+	int frame_id;
+	dma_addr_t daddr;
+	void *vaddr;
+	phys_addr_t paddr;
+	unsigned int queue;
+	unsigned int buffer_usage;
+	enum mtk_dip_ctx_buffer_state state;
+	int rotation;
+	struct list_head list;
+};
+
+struct mtk_dip_ctx_setting {
+	char *device_name;
+};
+
+struct mtk_dip_ctx_desc {
+	char *proc_dev_phandle;
+	/* The context device's compatble string name in device tree*/
+	int (*init)(struct mtk_dip_ctx *ctx);
+	/* configure the core functions of the device context */
+};
+
+struct mtk_dip_ctx_init_table {
+	int total_dev_ctx;
+	struct mtk_dip_ctx_desc *ctx_desc_tbl;
+};
+
+struct mtk_dip_ctx_open_param {
+	/* Bitmask used to notify that the DMA port is enabled or not */
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_dip_ctx_streamon_param {
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_dip_ctx_streamoff_param {
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_dip_ctx_start_param {
+	/* carry buffer information of the frame */
+	struct mtk_dip_ctx_frame_bundle *frame_bundle;
+};
+
+struct mtk_dip_ctx_release_param {
+	unsigned int enabled_dma_ports;
+};
+
+struct mtk_dip_ctx_start_param_wrapper {
+	struct mtk_dip_ctx_start_param param;
+	/* Private fields */
+	/* Don't change any field outside mtk_dip-dev-ctx-core */
+	/* Since it may corrupt the common framework */
+	struct mtk_dip_ctx *ctx;
+};
+
+struct mtk_dip_ctx_finish_param {
+	unsigned int frame_id;
+	u64 timestamp;
+	unsigned int state;
+};
+
+int mtk_dip_ctx_is_streaming(struct mtk_dip_ctx *ctx);
+int mtk_dip_ctx_core_job_finish(struct mtk_dip_ctx *ctx,
+				struct mtk_dip_ctx_finish_param *param);
+int mtk_dip_ctx_core_init(struct mtk_dip_ctx *ctx,
+			  struct platform_device *pdev, int ctx_id,
+			  struct mtk_dip_ctx_desc *ctx_desc,
+			  struct platform_device *proc_pdev,
+			  struct platform_device *smem_pdev);
+int mtk_dip_ctx_core_exit(struct mtk_dip_ctx *ctx);
+void mtk_dip_ctx_buf_init(struct mtk_dip_ctx_buffer *b,
+			  unsigned int queue, dma_addr_t daddr);
+extern enum mtk_dip_ctx_buffer_state
+	mtk_dip_ctx_get_buffer_state(struct mtk_dip_ctx_buffer *b);
+extern int mtk_dip_ctx_next_global_frame_sequence
+	(struct mtk_dip_ctx *ctx, int locked);
+extern int mtk_dip_ctx_core_steup
+	(struct mtk_dip_ctx *ctx, struct mtk_dip_ctx_setting *ctx_setting);
+int mtk_dip_ctx_core_queue_setup(struct mtk_dip_ctx *ctx,
+				 struct mtk_dip_ctx_queues_setting
+				 *queues_setting);
+int mtk_dip_ctx_core_finish_param_init(void *param,
+				       int frame_id, int state);
+int mtk_dip_ctx_finish_frame(struct mtk_dip_ctx *dev_ctx,
+			     struct mtk_dip_ctx_frame_bundle *frame_bundle,
+			     int done);
+extern int mtk_dip_ctx_frame_bundle_init
+	(struct mtk_dip_ctx_frame_bundle *frame_bundle);
+void mtk_dip_ctx_frame_bundle_add(struct mtk_dip_ctx *ctx,
+				  struct mtk_dip_ctx_frame_bundle *bundle,
+				  struct mtk_dip_ctx_buffer *ctx_buf);
+extern int mtk_dip_ctx_trigger_job
+	(struct mtk_dip_ctx *dev_ctx,
+	 struct mtk_dip_ctx_frame_bundle *bundle_data);
+extern int mtk_dip_ctx_fmt_set_img
+	(struct mtk_dip_ctx *dev_ctx, int queue_id,
+	 struct v4l2_pix_format_mplane *user_fmt,
+	 struct v4l2_pix_format_mplane *node_fmt);
+extern int mtk_dip_ctx_fmt_set_meta
+	(struct mtk_dip_ctx *dev_ctx, int queue_id,
+	 struct v4l2_meta_format *user_fmt,
+	 struct v4l2_meta_format *node_fmt);
+int mtk_dip_ctx_format_load_default_fmt
+	(struct mtk_dip_ctx_queue *queue,
+	 struct v4l2_format *fmt_to_fill);
+int mtk_dip_ctx_streamon(struct mtk_dip_ctx *dev_ctx);
+int mtk_dip_ctx_streamoff(struct mtk_dip_ctx *dev_ctx);
+int mtk_dip_ctx_release(struct mtk_dip_ctx *dev_ctx);
+int mtk_dip_ctx_open(struct mtk_dip_ctx *dev_ctx);
+#endif /*__MTK_DIP_CTX_H__*/
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev-ctx-core.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev-ctx-core.c
new file mode 100644
index 000000000000..46a638ab2ca5
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev-ctx-core.c
@@ -0,0 +1,1643 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include <linux/dma-mapping.h>
+#include <media/v4l2-event.h>
+#include "mtk_dip.h"
+#include "mtk_dip-dev.h"
+#include "mtk_dip-v4l2.h"
+#include "mtk_dip-v4l2-util.h"
+#include "mtk_dip-smem.h"
+#include "mtk-mdp3-regs.h"
+#include "mtk-img-ipi.h"
+
+static struct mtk_dip_ctx_format *mtk_dip_ctx_find_fmt
+	(struct mtk_dip_ctx *dev_ctx,
+	 struct mtk_dip_ctx_queue *queue,
+	 u32 format);
+
+static int mtk_dip_ctx_process_frame(struct mtk_dip_ctx *dev_ctx,
+				     struct mtk_dip_ctx_frame_bundle
+				     *frame_bundle);
+
+static int mtk_dip_ctx_free_frame(struct mtk_dip_ctx *dev_ctx,
+				  struct mtk_dip_ctx_frame_bundle
+				  *frame_bundle);
+
+static struct mtk_dip_ctx_frame_bundle *mtk_dip_ctx_get_free_frame
+	(struct mtk_dip_ctx *dev_ctx);
+
+static struct mtk_dip_ctx_frame_bundle *mtk_dip_ctx_get_processing_frame
+(struct mtk_dip_ctx *dev_ctx, int frame_id);
+
+static int mtk_dip_ctx_init_frame_bundles(struct mtk_dip_ctx *dev_ctx);
+
+static void mtk_dip_ctx_queue_event_frame_done
+	(struct mtk_dip_ctx *dev_ctx,
+	struct mtk_dip_dev_frame_done_event_data *fdone);
+
+static int mtk_dip_ctx_core_job_start(struct mtk_dip_ctx *dev_ctx,
+				      struct mtk_dip_ctx_start_param *param);
+
+static void debug_bundle(struct mtk_dip_ctx  *dev_ctx,
+			 struct mtk_dip_ctx_frame_bundle *bundle_data);
+
+struct vb2_v4l2_buffer *mtk_dip_ctx_buffer_get_vb2_v4l2_buffer
+(struct mtk_dip_ctx_buffer *ctx_buf)
+{
+	struct mtk_dip_dev_buffer *dev_buf = NULL;
+
+	if (!ctx_buf) {
+		pr_err("Failed to convert ctx_buf to dev_buf: NULL\n");
+		return NULL;
+	}
+
+	dev_buf	= mtk_dip_ctx_buf_to_dev_buf(ctx_buf);
+
+	return &dev_buf->m2m2_buf.vbb;
+}
+
+/* The helper to configure the device context */
+int mtk_dip_ctx_core_steup(struct mtk_dip_ctx *ctx,
+			   struct mtk_dip_ctx_setting *ctx_setting)
+{
+	if (!ctx || !ctx_setting)
+		return -EINVAL;
+
+	ctx->device_name = ctx_setting->device_name;
+
+	return 0;
+}
+
+int mtk_dip_ctx_core_queue_setup(struct mtk_dip_ctx *ctx,
+				 struct mtk_dip_ctx_queues_setting
+				 *queues_setting)
+{
+	int queue_idx = 0;
+	int i = 0;
+
+	for (i = 0; i < queues_setting->total_output_queues; i++) {
+		struct mtk_dip_ctx_queue_desc *queue_desc =
+			queues_setting->output_queue_descs + i;
+
+		if (!queue_desc)
+			return -EINVAL;
+
+		ctx->queue[queue_idx].desc = *queue_desc;
+		queue_idx++;
+	}
+
+	ctx->queues_attr.input_offset = queue_idx;
+
+	/* Setup the capture queue */
+	for (i = 0; i < queues_setting->total_capture_queues; i++) {
+		struct mtk_dip_ctx_queue_desc *queue_desc =
+			queues_setting->capture_queue_descs + i;
+
+		if (!queue_desc)
+			return -EINVAL;
+
+		ctx->queue[queue_idx].desc = *queue_desc;
+		queue_idx++;
+	}
+
+	ctx->queues_attr.master = queues_setting->master;
+	ctx->queues_attr.total_num = queue_idx;
+	ctx->dev_node_num = ctx->queues_attr.total_num;
+	return 0;
+}
+
+/* Mediatek ISP context core initialization */
+int mtk_dip_ctx_core_init(struct mtk_dip_ctx *ctx,
+			  struct platform_device *pdev, int ctx_id,
+	struct mtk_dip_ctx_desc *ctx_desc,
+	struct platform_device *proc_pdev,
+	struct platform_device *smem_pdev)
+{
+	/* Initialize main data structure */
+	int r = 0;
+
+	ctx->smem_vb2_alloc_ctx = &smem_pdev->dev;
+	ctx->default_vb2_alloc_ctx = &pdev->dev;
+
+	if (IS_ERR((__force void *)ctx->smem_vb2_alloc_ctx))
+		dev_err(&pdev->dev,
+			"Failed to alloc vb2 dma ctx: smem_vb2_alloc_ctx");
+
+	if (IS_ERR((__force void *)ctx->default_vb2_alloc_ctx))
+		dev_err(&pdev->dev,
+			"Failed to alloc vb2 dma ctx: default_vb2_alloc_ctx");
+
+	ctx->pdev = pdev;
+	ctx->ctx_id = ctx_id;
+	/* keep th smem pdev to use related iommu functions */
+	ctx->smem_device = smem_pdev;
+
+	/* Will set default enabled after passing the unit test */
+	ctx->mode = MTK_DIP_CTX_MODE_DEBUG_OFF;
+
+	/* initialized the global frame index of the device context */
+	atomic_set(&ctx->frame_param_sequence, 0);
+	spin_lock_init(&ctx->qlock);
+
+	/* setup the core operation of the device context */
+	if (ctx_desc && ctx_desc->init)
+		r = ctx_desc->init(ctx);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_core_init);
+
+int mtk_dip_ctx_core_exit(struct mtk_dip_ctx *ctx)
+{
+	ctx->smem_vb2_alloc_ctx = NULL;
+	ctx->default_vb2_alloc_ctx = NULL;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_core_exit);
+
+/* Get the corrospnd FH of a specific buffer */
+int mtk_dip_ctx_next_global_frame_sequence(struct mtk_dip_ctx *ctx,
+					   int locked)
+{
+	int global_frame_sequence =
+		atomic_inc_return(&ctx->frame_param_sequence);
+
+	if (!locked)
+		spin_lock(&ctx->qlock);
+
+	global_frame_sequence =
+		(global_frame_sequence & 0x0000FFFF) | (ctx->ctx_id << 16);
+
+	if (!locked)
+		spin_unlock(&ctx->qlock);
+
+	return global_frame_sequence;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_next_global_frame_sequence);
+
+static void mtk_dip_ctx_buffer_done
+	(struct mtk_dip_ctx_buffer *ctx_buf, int state)
+{
+		if (!ctx_buf ||
+		    state != MTK_DIP_CTX_BUFFER_DONE ||
+			state != MTK_DIP_CTX_BUFFER_FAILED)
+			return;
+
+		ctx_buf->state = state;
+}
+
+int mtk_dip_ctx_core_job_finish(struct mtk_dip_ctx *dev_ctx,
+				struct mtk_dip_ctx_finish_param *param)
+{
+	int i = 0;
+	struct platform_device *pdev = dev_ctx->pdev;
+	struct mtk_dip_ctx_finish_param *fram_param =
+		(struct mtk_dip_ctx_finish_param *)param;
+	struct mtk_dip_dev *isp_dev = NULL;
+	struct mtk_dip_ctx_frame_bundle *frame = NULL;
+	enum vb2_buffer_state vbf_state = VB2_BUF_STATE_DONE;
+	enum mtk_dip_ctx_buffer_state ctxf_state =
+		MTK_DIP_CTX_BUFFER_DONE;
+	int master_queue = 0;
+
+	struct mtk_dip_dev_frame_done_event_data fdone;
+	const int ctx_id =
+		MTK_DIP_GET_CTX_ID_FROM_SEQUENCE(fram_param->frame_id);
+	u64 timestamp = 0;
+
+	dev_dbg(&dev_ctx->pdev->dev,
+		"mtk_dip_ctx_core_job_finish_cb:param(%llx),pdev(%llx)\n",
+		(unsigned long long)param, (unsigned long long)pdev);
+
+	if (!dev_ctx)
+		dev_err(&dev_ctx->pdev->dev,
+			"dev_ctx can't be null, can't release the frame\n");
+
+	isp_dev = mtk_dip_ctx_to_dev(dev_ctx);
+
+	if (fram_param) {
+		dev_dbg(&isp_dev->pdev->dev,
+			"CB recvied from ctx(%d), frame(%d), state(%d), isp_dev(%llx)\n",
+			ctx_id, fram_param->frame_id,
+			fram_param->state, (long long)isp_dev);
+	} else {
+		dev_err(&isp_dev->pdev->dev,
+			"CB recvied from ctx(%d), frame param is NULL\n",
+			ctx_id);
+			return -EINVAL;
+	}
+
+	/* Get the buffers of the processed frame */
+	frame = mtk_dip_ctx_get_processing_frame(&isp_dev->ctx,
+						 fram_param->frame_id);
+
+	if (!frame) {
+		dev_err(&isp_dev->pdev->dev,
+			"Can't find the frame boundle, Frame(%d)\n",
+			fram_param->frame_id);
+		return -EINVAL;
+	}
+
+	if (fram_param->state == MTK_DIP_CTX_FRAME_DATA_ERROR) {
+		vbf_state = VB2_BUF_STATE_ERROR;
+		ctxf_state = MTK_DIP_CTX_BUFFER_FAILED;
+	}
+
+	/* Set the buffer's VB2 status so that the user can dequeue */
+	/* the buffer */
+	timestamp = ktime_get_ns();
+	for (i = 0; i <= frame->last_index; i++) {
+		struct mtk_dip_ctx_buffer *ctx_buf = frame->buffers[i];
+
+		if (!ctx_buf) {
+			dev_dbg(&isp_dev->pdev->dev,
+				"ctx_buf(queue id= %d) of frame(%d)is NULL\n",
+				i, fram_param->frame_id);
+			continue;
+		} else {
+			struct vb2_v4l2_buffer *b =
+				mtk_dip_ctx_buffer_get_vb2_v4l2_buffer(ctx_buf);
+			b->vb2_buf.timestamp = ktime_get_ns();
+			mtk_dip_ctx_buffer_done(ctx_buf, ctxf_state);
+			mtk_dip_v4l2_buffer_done(&b->vb2_buf, vbf_state);
+		}
+	}
+
+	master_queue = isp_dev->ctx.queues_attr.master;
+
+	fdone.frame_id = frame->id;
+
+	/* Notify the user frame process done */
+	mtk_dip_ctx_queue_event_frame_done(&isp_dev->ctx, &fdone);
+	mtk_dip_ctx_free_frame(&isp_dev->ctx, frame);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_core_job_finish);
+
+/* structure mtk_dip_ctx_finish_param must be the first elemt of param */
+/* So that the buffer can be return to vb2 queue successfully */
+int mtk_dip_ctx_core_finish_param_init(void *param, int frame_id, int state)
+{
+	struct mtk_dip_ctx_finish_param *fram_param =
+		(struct mtk_dip_ctx_finish_param *)param;
+	fram_param->frame_id = frame_id;
+	fram_param->state = state;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_core_finish_param_init);
+
+void mtk_dip_ctx_frame_bundle_add(struct mtk_dip_ctx *ctx,
+				  struct mtk_dip_ctx_frame_bundle *bundle,
+	struct mtk_dip_ctx_buffer *ctx_buf)
+{
+	int queue_id = 0;
+	struct mtk_dip_ctx_queue *ctx_queue = NULL;
+
+	if (!bundle || !ctx_buf) {
+		dev_err(&ctx->pdev->dev,
+			"Add buffer to frame bundle failed, bundle(%llx),buf(%llx)\n",
+			(long long)bundle, (long long)ctx_buf);
+		return;
+	}
+
+	queue_id = ctx_buf->queue;
+
+	if (bundle->buffers[queue_id])
+		dev_warn(&ctx->pdev->dev,
+			 "Queue(%d) buffer overwrite\n",
+			 queue_id);
+
+	dev_dbg(&ctx->pdev->dev, "Add queue(%d) buffer%llx\n",
+		queue_id, (unsigned long long)ctx_buf);
+		bundle->buffers[queue_id] = ctx_buf;
+
+	/* Fill context queue related information */
+	ctx_queue = &ctx->queue[queue_id];
+
+	if (!ctx_queue) {
+		dev_err(&ctx->pdev->dev,
+			"Can't find ctx queue (%d)\n", queue_id);
+		return;
+	}
+
+	if (ctx->queue[ctx_buf->queue].desc.image) {
+		if (ctx->queue[ctx_buf->queue].desc.capture)
+			bundle->num_img_capture_bufs++;
+		else
+			bundle->num_img_output_bufs++;
+	} else {
+		if (ctx->queue[ctx_buf->queue].desc.capture)
+			bundle->num_meta_capture_bufs++;
+		else
+			bundle->num_meta_output_bufs++;
+	}
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_frame_bundle_add);
+
+static void debug_bundle(struct mtk_dip_ctx *dev_ctx,
+			 struct mtk_dip_ctx_frame_bundle *bundle_data)
+{
+	int i = 0;
+
+	if (!dev_ctx)
+		return;
+
+	if (!bundle_data) {
+		dev_dbg(&dev_ctx->pdev->dev, "bundle_data is NULL\n");
+		return;
+	}
+
+	dev_dbg(&dev_ctx->pdev->dev, "bundle buf nums (%d, %d,%d,%d)\n",
+		bundle_data->num_img_capture_bufs,
+		bundle_data->num_img_output_bufs,
+		bundle_data->num_meta_capture_bufs,
+		bundle_data->num_meta_output_bufs);
+
+	for (i = 0; i < 16 ; i++) {
+		dev_dbg(&dev_ctx->pdev->dev, "Bundle, buf[%d] = %llx\n",
+			i,
+			(unsigned long long)bundle_data->buffers[i]);
+	}
+
+	dev_dbg(&dev_ctx->pdev->dev, "Bundle last idx: %d\n",
+		bundle_data->last_index);
+}
+
+int mtk_dip_ctx_trigger_job(struct mtk_dip_ctx *dev_ctx,
+			    struct mtk_dip_ctx_frame_bundle *bundle_data)
+{
+	/* Scan all buffers and filled the ipi frame data*/
+	int i = 0;
+	struct mtk_dip_ctx_start_param s_param;
+	struct mtk_dip_ctx_finish_param fram_param;
+
+	struct mtk_dip_ctx_frame_bundle *bundle	=
+		mtk_dip_ctx_get_free_frame(dev_ctx);
+
+	memset(&s_param, 0,
+	       sizeof(struct mtk_dip_ctx_start_param));
+
+	dev_dbg(&dev_ctx->pdev->dev,
+		"trigger job of ctx(%d)\n", dev_ctx->ctx_id);
+
+	debug_bundle(dev_ctx, bundle_data);
+
+	if (!bundle) {
+		dev_err(&dev_ctx->pdev->dev, "bundle can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+	if (!bundle_data) {
+		dev_err(&dev_ctx->pdev->dev,
+			"bundle_data can't be NULL\n");
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	memcpy(bundle->buffers, bundle_data->buffers,
+	       sizeof(struct mtk_dip_ctx_buffer *)
+			* MTK_DIP_CTX_FRAME_BUNDLE_BUFFER_MAX);
+
+	dev_dbg(&dev_ctx->pdev->dev, "bundle setup (%d,%d,%d,%d)\n",
+		bundle_data->num_img_capture_bufs,
+		bundle_data->num_img_output_bufs,
+		bundle_data->num_meta_capture_bufs,
+		bundle_data->num_meta_output_bufs);
+
+	bundle->num_img_capture_bufs =
+		bundle_data->num_img_capture_bufs;
+	bundle->num_img_output_bufs =
+		 bundle_data->num_img_output_bufs;
+	bundle->num_meta_capture_bufs =
+		bundle_data->num_meta_capture_bufs;
+	bundle->num_meta_output_bufs =
+		bundle_data->num_meta_output_bufs;
+	bundle->id =
+		mtk_dip_ctx_next_global_frame_sequence(dev_ctx,
+						       dev_ctx->ctx_id);
+	bundle->last_index = dev_ctx->queues_attr.total_num - 1;
+
+	debug_bundle(dev_ctx, bundle);
+
+	s_param.frame_bundle = bundle;
+
+	dev_dbg(&dev_ctx->pdev->dev, "Fill Address data\n");
+
+	for (i = 0; i <= bundle->last_index; i++) {
+		struct mtk_dip_ctx_buffer *ctx_buf = bundle->buffers[i];
+		struct vb2_v4l2_buffer *b = NULL;
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"Process queue[%d], ctx_buf:(%llx)\n",
+			i,
+			(unsigned long long)ctx_buf);
+
+		if (!ctx_buf) {
+			dev_dbg(&dev_ctx->pdev->dev,
+				"queue[%d], ctx_buf is NULL!!\n", i);
+			continue;
+		}
+
+		b = mtk_dip_ctx_buffer_get_vb2_v4l2_buffer(ctx_buf);
+
+		ctx_buf->image = dev_ctx->queue[ctx_buf->queue].desc.image;
+		ctx_buf->capture = dev_ctx->queue[ctx_buf->queue].desc.capture;
+		/* copy the fmt setting for queue's fmt*/
+		ctx_buf->fmt = dev_ctx->queue[ctx_buf->queue].fmt;
+		ctx_buf->ctx_fmt = dev_ctx->queue[ctx_buf->queue].ctx_fmt;
+			ctx_buf->frame_id = bundle->id;
+		ctx_buf->daddr =
+			vb2_dma_contig_plane_dma_addr(&b->vb2_buf, 0);
+		dev_dbg(&dev_ctx->pdev->dev,
+			"%s:vb2_buf: type(%d),idx(%d),mem(%d)\n",
+			 __func__,
+			 b->vb2_buf.type,
+			 b->vb2_buf.index,
+			 b->vb2_buf.memory);
+		ctx_buf->vaddr = vb2_plane_vaddr(&b->vb2_buf, 0);
+		ctx_buf->buffer_usage = dev_ctx->queue[i].buffer_usage;
+		ctx_buf->rotation = dev_ctx->queue[i].rotation;
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"Buf: queue(%d), vaddr(%llx), daddr(%llx)",
+			ctx_buf->queue, (unsigned long long)ctx_buf->vaddr,
+			(unsigned long long)ctx_buf->daddr);
+
+		if (dev_ctx->queue[ctx_buf->queue].desc.smem_alloc) {
+			ctx_buf->paddr =
+				mtk_dip_smem_iova_to_phys
+				(&dev_ctx->smem_device->dev,
+				 ctx_buf->daddr);
+		} else {
+			dev_dbg(&dev_ctx->pdev->dev,
+				"No pa provided: not physical continuous\n");
+			ctx_buf->paddr = 0;
+		}
+		ctx_buf->state = MTK_DIP_CTX_BUFFER_PROCESSING;
+	}
+
+	if (mtk_dip_ctx_process_frame(dev_ctx, bundle)) {
+		dev_err(&dev_ctx->pdev->dev,
+			"mtk_dip_ctx_process_frame failed: frame(%d)\n",
+			bundle->id);
+		goto FAILE_JOB_NOT_TRIGGER;
+	}
+
+	if (dev_ctx->mode ==
+			MTK_DIP_CTX_MODE_DEBUG_BYPASS_JOB_TRIGGER) {
+		memset(&fram_param, 0,
+		       sizeof(struct mtk_dip_ctx_finish_param));
+		fram_param.frame_id = bundle->id;
+		fram_param.state = MTK_DIP_CTX_FRAME_DATA_DONE;
+		dev_dbg(&dev_ctx->pdev->dev,
+			"Ctx(%d) in HW bypass mode, will not trigger hw\n",
+			dev_ctx->ctx_id);
+		mtk_dip_ctx_core_job_finish(dev_ctx,
+					    (void *)&fram_param);
+		return 0;
+	}
+
+	if (mtk_dip_ctx_core_job_start(dev_ctx, &s_param))
+		goto FAILE_JOB_NOT_TRIGGER;
+
+	return 0;
+
+FAILE_JOB_NOT_TRIGGER:
+	dev_err(&dev_ctx->pdev->dev,
+		"FAILE_JOB_NOT_TRIGGER: init fram_param: %llx\n",
+		(unsigned long long)&fram_param);
+	memset(&fram_param, 0, sizeof(struct mtk_dip_ctx_finish_param));
+	fram_param.frame_id = bundle->id;
+	fram_param.state = MTK_DIP_CTX_FRAME_DATA_ERROR;
+	dev_dbg(&dev_ctx->pdev->dev,
+		"Call mtk_dip_ctx_core_job_finish_cb: fram_param: %llx",
+		(unsigned long long)&fram_param);
+	mtk_dip_ctx_core_job_finish(dev_ctx, (void *)&fram_param);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_trigger_job);
+
+void mtk_dip_ctx_buf_init(struct mtk_dip_ctx_buffer *b,
+			  unsigned int queue, dma_addr_t daddr)
+{
+	b->state = MTK_DIP_CTX_BUFFER_NEW;
+	b->queue = queue;
+	b->daddr = daddr;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_buf_init);
+
+enum mtk_dip_ctx_buffer_state
+	mtk_dip_ctx_get_buffer_state(struct mtk_dip_ctx_buffer *b)
+{
+	return b->state;
+}
+
+int mtk_dip_ctx_is_streaming(struct mtk_dip_ctx *ctx)
+{
+	return ctx->streaming;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_is_streaming);
+
+int mtk_dip_ctx_init_frame_bundles(struct mtk_dip_ctx *dev_ctx)
+{
+	int i = 0;
+
+	dev_ctx->num_frame_bundle = VB2_MAX_FRAME;
+
+	spin_lock(&dev_ctx->qlock);
+
+	/* Reset the queue*/
+	INIT_LIST_HEAD(&dev_ctx->processing_frames.list);
+	INIT_LIST_HEAD(&dev_ctx->free_frames.list);
+
+	for (i = 0; i < dev_ctx->num_frame_bundle; i++) {
+		struct mtk_dip_ctx_frame_bundle *frame_bundle =
+			&dev_ctx->frame_bundles[i];
+		frame_bundle->state = MTK_DIP_CTX_FRAME_NEW;
+		list_add_tail(&frame_bundle->list, &dev_ctx->free_frames.list);
+	}
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return 0;
+}
+
+static int mtk_dip_ctx_process_frame(struct mtk_dip_ctx *dev_ctx,
+				     struct mtk_dip_ctx_frame_bundle
+				     *frame_bundle)
+{
+	spin_lock(&dev_ctx->qlock);
+
+	frame_bundle->state = MTK_DIP_CTX_FRAME_PROCESSING;
+	list_del(&frame_bundle->list);
+	list_add_tail(&frame_bundle->list, &dev_ctx->processing_frames.list);
+
+	spin_unlock(&dev_ctx->qlock);
+	return 0;
+}
+
+/* Since the ISP physical doesn't guanartee FIFO order when processing */
+/* the frame, for example, flushing buffers when streaming off, */
+/* we search the list to get the frame by frame id */
+struct mtk_dip_ctx_frame_bundle *mtk_dip_ctx_get_processing_frame
+(struct mtk_dip_ctx *dev_ctx, int frame_id)
+{
+	struct mtk_dip_ctx_frame_bundle *frame_bundle = NULL;
+
+	spin_lock(&dev_ctx->qlock);
+
+	list_for_each_entry(frame_bundle,
+			    &dev_ctx->processing_frames.list, list) {
+		if (frame_bundle->id == frame_id) {
+			spin_unlock(&dev_ctx->qlock);
+			return frame_bundle;
+		}
+	}
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return NULL;
+}
+
+static int mtk_dip_ctx_free_frame(struct mtk_dip_ctx *dev_ctx,
+				  struct mtk_dip_ctx_frame_bundle *frame_bundle)
+{
+	spin_lock(&dev_ctx->qlock);
+
+	frame_bundle->state = MTK_DIP_CTX_FRAME_NEW;
+	list_del(&frame_bundle->list);
+	list_add_tail(&frame_bundle->list, &dev_ctx->free_frames.list);
+
+	spin_unlock(&dev_ctx->qlock);
+
+	return 0;
+}
+
+static struct mtk_dip_ctx_frame_bundle *mtk_dip_ctx_get_free_frame
+	(struct mtk_dip_ctx *dev_ctx)
+{
+	struct mtk_dip_ctx_frame_bundle *frame_bundle = NULL;
+
+	spin_lock(&dev_ctx->qlock);
+	list_for_each_entry(frame_bundle,
+			    &dev_ctx->free_frames.list, list){
+		dev_dbg(&dev_ctx->pdev->dev,
+			"Check frame: state %d, new should be %d\n",
+			frame_bundle->state, MTK_DIP_CTX_FRAME_NEW);
+		if (frame_bundle->state == MTK_DIP_CTX_FRAME_NEW) {
+			frame_bundle->state = MTK_DIP_CTX_FRAME_PREPARED;
+			dev_dbg(&dev_ctx->pdev->dev, "Found free frame\n");
+			spin_unlock(&dev_ctx->qlock);
+			return frame_bundle;
+		}
+	}
+	spin_unlock(&dev_ctx->qlock);
+	dev_err(&dev_ctx->pdev->dev,
+		"Can't found any bundle is MTK_DIP_CTX_FRAME_NEW\n");
+	return NULL;
+}
+
+int mtk_dip_ctx_finish_frame(struct mtk_dip_ctx *dev_ctx,
+			     struct mtk_dip_ctx_frame_bundle *frame_bundle,
+			     int done)
+{
+	spin_lock(&dev_ctx->qlock);
+	frame_bundle->state = MTK_DIP_CTX_FRAME_PROCESSING;
+	list_add_tail(&frame_bundle->list, &dev_ctx->processing_frames.list);
+	spin_unlock(&dev_ctx->qlock);
+	return 0;
+}
+
+static void mtk_dip_ctx_queue_event_frame_done
+	(struct mtk_dip_ctx *dev_ctx,
+	struct mtk_dip_dev_frame_done_event_data *fdone)
+{
+	struct v4l2_event event;
+	/* Carried the frame done information in */
+	/* data field of event */
+	struct mtk_dip_dev_frame_done_event_data *evt_frame_data =
+		(void *)event.u.data;
+
+	memset(&event, 0, sizeof(event));
+
+	evt_frame_data->frame_id = fdone->frame_id;
+
+	event.type = V4L2_EVENT_MTK_DIP_FRAME_DONE;
+	v4l2_event_queue_fh(&dev_ctx->fh->vfh, &event);
+}
+
+static void set_img_fmt(struct v4l2_pix_format_mplane *mfmt_to_fill,
+			struct mtk_dip_ctx_format *ctx_fmt)
+{
+	int i = 0;
+
+	mfmt_to_fill->pixelformat = ctx_fmt->fmt.img.pixelformat;
+	mfmt_to_fill->num_planes = ctx_fmt->fmt.img.num_planes;
+
+	pr_debug("%s: Fmt(%d),w(%d),h(%d)\n",
+		 __func__,
+		 mfmt_to_fill->pixelformat,
+		 mfmt_to_fill->width,
+		 mfmt_to_fill->height);
+
+	/* The implementation wil be adjust after integrating MDP module */
+	/* since it provides the common format suppporting function */
+	for (i = 0 ; i < mfmt_to_fill->num_planes; ++i) {
+		int bpl = (mfmt_to_fill->width *
+			ctx_fmt->fmt.img.row_depth[i]) / 8;
+		int sizeimage = (mfmt_to_fill->width * mfmt_to_fill->height *
+			ctx_fmt->fmt.img.depth[i]) / 8;
+
+		mfmt_to_fill->plane_fmt[i].bytesperline = bpl;
+
+		mfmt_to_fill->plane_fmt[i].sizeimage = sizeimage;
+
+		pr_debug("plane(%d):bpl(%d),sizeimage(%u)\n",
+			 i,  bpl,
+			 mfmt_to_fill->plane_fmt[i].sizeimage);
+	}
+}
+
+static void set_meta_fmt(struct v4l2_meta_format *metafmt_to_fill,
+			 struct mtk_dip_ctx_format *ctx_fmt)
+{
+	metafmt_to_fill->dataformat = ctx_fmt->fmt.meta.dataformat;
+
+	if (ctx_fmt->fmt.meta.max_buffer_size <= 0 ||
+	    ctx_fmt->fmt.meta.max_buffer_size
+				> MTK_DIP_CTX_META_BUF_DEFAULT_SIZE){
+		pr_warn("Invalid meta buf size(%u), use default(%u)\n",
+			ctx_fmt->fmt.meta.max_buffer_size,
+			MTK_DIP_CTX_META_BUF_DEFAULT_SIZE);
+		metafmt_to_fill->buffersize = MTK_DIP_CTX_META_BUF_DEFAULT_SIZE;
+	} else {
+		pr_debug("Use meta size(%u)\n",
+			 ctx_fmt->fmt.meta.max_buffer_size);
+		metafmt_to_fill->buffersize = ctx_fmt->fmt.meta.max_buffer_size;
+	}
+}
+
+/* Get the default format setting */
+int mtk_dip_ctx_format_load_default_fmt(struct mtk_dip_ctx_queue *queue,
+					struct v4l2_format *fmt_to_fill)
+{
+	struct mtk_dip_ctx_format *ctx_fmt = NULL;
+
+	if (queue->desc.num_fmts == 0)
+		return 0; /* no format support list associated to this queue */
+
+	if (queue->desc.default_fmt_idx >= queue->desc.num_fmts) {
+		pr_warn("Queue(%s) err: default idx(%d) must < num_fmts(%d)\n",
+			queue->desc.name, queue->desc.default_fmt_idx,
+			queue->desc.num_fmts);
+		queue->desc.default_fmt_idx = 0;
+		pr_warn("Queue(%s) : reset default idx(%d)\n",
+			queue->desc.name, queue->desc.default_fmt_idx);
+	}
+
+	ctx_fmt	= &queue->desc.fmts[queue->desc.default_fmt_idx];
+
+	/* Check the type of the buffer */
+	if (queue->desc.image) {
+		struct v4l2_pix_format_mplane *node_fmt =
+			&fmt_to_fill->fmt.pix_mp;
+
+		if (queue->desc.capture) {
+			fmt_to_fill->type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+			node_fmt->width = MTK_DIP_OUTPUT_MAX_WIDTH;
+			node_fmt->height = MTK_DIP_OUTPUT_MAX_HEIGHT;
+		} else {
+			fmt_to_fill->type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+			node_fmt->width = MTK_DIP_INPUT_MAX_WIDTH;
+			node_fmt->height = MTK_DIP_INPUT_MAX_HEIGHT;
+		}
+		set_img_fmt(node_fmt, ctx_fmt);
+	}	else {
+		/* meta buffer type */
+		struct v4l2_meta_format *node_fmt = &fmt_to_fill->fmt.meta;
+
+		if (queue->desc.capture)
+			fmt_to_fill->type = V4L2_BUF_TYPE_META_CAPTURE;
+		else
+			fmt_to_fill->type = V4L2_BUF_TYPE_META_OUTPUT;
+
+		set_meta_fmt(node_fmt, ctx_fmt);
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_format_load_default_fmt);
+
+static struct mtk_dip_ctx_format *mtk_dip_ctx_find_fmt
+	(struct mtk_dip_ctx *dev_ctx,
+	 struct mtk_dip_ctx_queue *queue,
+	 u32 format)
+{
+	int i;
+	struct mtk_dip_ctx_format *ctx_fmt;
+
+	dev_dbg(&dev_ctx->pdev->dev, "fmt to find(%x)\n", format);
+	for (i = 0; i < queue->desc.num_fmts; i++) {
+		ctx_fmt = &queue->desc.fmts[i];
+		if (queue->desc.image) {
+			dev_dbg(&dev_ctx->pdev->dev,
+				"idx(%d), pixelformat(%x), fmt(%x)\n",
+				i, ctx_fmt->fmt.img.pixelformat, format);
+			if (ctx_fmt->fmt.img.pixelformat == format)
+				return ctx_fmt;
+		} else {
+			if (ctx_fmt->fmt.meta.dataformat == format)
+				return ctx_fmt;
+		}
+	}
+	return NULL;
+}
+
+int mtk_dip_ctx_fmt_set_meta(struct mtk_dip_ctx *dev_ctx,
+			     int queue_id,
+	struct v4l2_meta_format *user_fmt,
+	struct v4l2_meta_format *node_fmt
+	)
+{
+	struct mtk_dip_ctx_queue *queue = NULL;
+	struct mtk_dip_ctx_format *ctx_fmt;
+
+	if (queue_id >= dev_ctx->queues_attr.total_num) {
+		pr_err("Invalid queue id:%d\n", queue_id);
+		return -EINVAL;
+	}
+
+	queue = &dev_ctx->queue[queue_id];
+
+	if (!user_fmt || !node_fmt)
+		return -EINVAL;
+
+	ctx_fmt = mtk_dip_ctx_find_fmt(dev_ctx, queue,
+				       user_fmt->dataformat);
+
+	if (!ctx_fmt)
+		return -EINVAL;
+
+	queue->ctx_fmt = ctx_fmt;
+	set_meta_fmt(node_fmt, ctx_fmt);
+	*user_fmt = *node_fmt;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_fmt_set_meta);
+
+int mtk_dip_ctx_fmt_set_img(struct mtk_dip_ctx *dev_ctx,
+			    int queue_id,
+	struct v4l2_pix_format_mplane *user_fmt,
+	struct v4l2_pix_format_mplane *node_fmt)
+{
+	struct mtk_dip_ctx_queue *queue = NULL;
+	struct mtk_dip_ctx_format *ctx_fmt;
+
+	if (queue_id >= dev_ctx->queues_attr.total_num) {
+		pr_err("Invalid queue id:%d\n", queue_id);
+		return -EINVAL;
+	}
+
+	queue = &dev_ctx->queue[queue_id];
+
+	if (!user_fmt || !node_fmt)
+		return -EINVAL;
+
+	ctx_fmt = mtk_dip_ctx_find_fmt(dev_ctx, queue,
+				       user_fmt->pixelformat);
+
+	if (!ctx_fmt)
+		return -EINVAL;
+
+	queue->ctx_fmt = ctx_fmt;
+	node_fmt->width = user_fmt->width;
+	node_fmt->height = user_fmt->height;
+
+	set_img_fmt(node_fmt, ctx_fmt);
+
+	*user_fmt = *node_fmt;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_fmt_set_img);
+
+int mtk_dip_ctx_streamon(struct mtk_dip_ctx *dev_ctx)
+{
+	int r = 0;
+
+	if (!dev_ctx)
+		return -EINVAL;
+
+	if (dev_ctx->streaming) {
+		dev_dbg(&dev_ctx->pdev->dev,
+			"ctx(%d): device already stream on\n",
+			dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	r = mtk_dip_streamon(dev_ctx->pdev, dev_ctx->ctx_id);
+
+	if (r) {
+		dev_err(&dev_ctx->pdev->dev,
+			"ctx(%d):failed to start hw\n",
+			dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	dev_ctx->streaming = 1;
+
+	dev_dbg(&dev_ctx->pdev->dev,
+		"ctx(%d):start hw\n", dev_ctx->ctx_id);
+
+	r = mtk_dip_dev_queue_buffers(mtk_dip_ctx_to_dev(dev_ctx),
+				      1);
+
+	if (r)
+		dev_err(&dev_ctx->pdev->dev,
+			"ctx(%d):failed to queue initial buffers (%d)",
+			dev_ctx->ctx_id, r);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_streamon);
+
+int mtk_dip_ctx_streamoff(struct mtk_dip_ctx *dev_ctx)
+{
+	int r = 0;
+
+	if (!dev_ctx)
+		return -EINVAL;
+
+	if (!dev_ctx->streaming) {
+		dev_warn(&dev_ctx->pdev->dev,
+			 "ctx(%d):device already stream off\n",
+			 dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	r = mtk_dip_streamoff(dev_ctx->pdev, dev_ctx->ctx_id);
+
+	if (r) {
+		dev_warn(&dev_ctx->pdev->dev,
+			 "ctx(%d):failed to stop hw\n",
+			 dev_ctx->ctx_id);
+		return -EBUSY;
+	}
+
+	dev_ctx->streaming = 0;
+
+	dev_dbg(&dev_ctx->pdev->dev, "ctx(%d):stop hw\n",
+		dev_ctx->ctx_id);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_streamoff);
+
+int mtk_dip_ctx_open(struct mtk_dip_ctx *dev_ctx)
+{
+	if (!dev_ctx)
+		return -EINVAL;
+
+	dev_dbg(&dev_ctx->pdev->dev, "open ctx(%d):dev(%llx)\n",
+		dev_ctx->ctx_id,
+		(long long)&dev_ctx->pdev->dev);
+
+	/* Workaround for SCP EMI access */
+	mtk_dip_smem_enable_mpu(&dev_ctx->smem_device->dev);
+
+	/* Init the frame bundle pool */
+	mtk_dip_ctx_init_frame_bundles(dev_ctx);
+
+	return mtk_dip_open(dev_ctx->pdev);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_open);
+
+int mtk_dip_ctx_release(struct mtk_dip_ctx *dev_ctx)
+{
+	if (!dev_ctx)
+		return -EINVAL;
+
+	dev_dbg(&dev_ctx->pdev->dev, "release ctx(%d):dev(%llx)\n",
+		dev_ctx->ctx_id,
+		(long long)&dev_ctx->pdev->dev);
+
+	return mtk_dip_release(dev_ctx->pdev);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_release);
+
+#ifdef MTK_DIP_CTX_DIP_V4L2_UT
+static int check_and_refill_dip_ut_start_ipi_param
+	(struct img_ipi_frameparam *ipi_param,
+	 struct mtk_dip_ctx_buffer *ctx_buf_in,
+	 struct mtk_dip_ctx_buffer *ctx_buf_out)
+{
+	/* Check the buffer size information from user space */
+	int ret = 0;
+	unsigned char *buffer_ptr = NULL;
+	const unsigned int src_width = 3264;
+	const unsigned int src_height = 1836;
+	const unsigned int dst_width = 1920;
+	const unsigned int dst_height = 1080;
+	const unsigned int in_stride_size =
+		sizeof(g_imgi_array_3264x1836_b10) / src_height;
+	const unsigned int out_size = dst_width * dst_height * 2;
+	const unsigned int out_stride_size = dst_width * 2;
+	const unsigned int crop_top = 0;
+	const unsigned int crop_left = 0;
+	const unsigned int crop_width = src_width;
+	const unsigned int crop_height = src_height;
+	const unsigned int crop_left_subpix = 0;
+	const unsigned int crop_top_subpix = 0;
+	const unsigned int crop_width_subpix = 0;
+	const unsigned int crop_height_subpix = 0;
+	const unsigned int rotation = 0;
+
+	/* Copy the image to the buffer address */
+	if (!ctx_buf_in) {
+		pr_err("[CHK] ctx_buf_in(%llx) can't be NULL\n",
+		       (unsigned long long)ctx_buf_in);
+		ret = -EINVAL;
+	} else {
+		if (!ctx_buf_in->vaddr) {
+			pr_err("[CHK] ctx_buf_in(%llx)->vaddr(%llx) can't be NULL\n",
+			       (unsigned long long)ctx_buf_in,
+				(unsigned long long)ctx_buf_in->vaddr);
+			ret = -EINVAL;
+		}
+		buffer_ptr = ctx_buf_in->vaddr;
+		pr_err("[CHK] Load image data(%llx) to vaddr(%llx)\n",
+		       (unsigned long long)g_imgi_array_3264x1836_b10,
+		(unsigned long long)buffer_ptr);
+		memcpy(buffer_ptr, g_imgi_array_3264x1836_b10,
+		       sizeof(g_imgi_array_3264x1836_b10));
+	}
+
+	if (ipi_param->num_inputs != 1 ||
+	    ipi_param->num_outputs != 1 ||
+	    ipi_param->type != STREAM_ISP_IC) {
+		pr_err("PARAM-CHK:Failed,num_in(%d),num_out(%d),type(%d)\n",
+		       ipi_param->num_inputs, ipi_param->num_outputs,
+			ipi_param->type);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->inputs[0].buffer.format.width !=
+			src_width ||
+		ipi_param->inputs[0].buffer.format.height !=
+			src_height) {
+		pr_err("PARAM-CHK:Failed,input w(%d),h(%d) should be w(%d),h(%d)\n",
+		       ipi_param->inputs[0].buffer.format.width,
+			ipi_param->inputs[0].buffer.format.height,
+			src_width,
+			src_height);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->inputs[0].buffer.format.colorformat
+			!= MDP_COLOR_BAYER10) {
+		pr_err("PARAM-CHK:Failed,input colorformat(%d) should be(%d)\n",
+		       ipi_param->inputs[0].buffer.format.colorformat,
+			MDP_COLOR_BAYER10);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->inputs[0].buffer.format.plane_fmt[0].size
+			!= sizeof(g_imgi_array_3264x1836_b10)) {
+		pr_err("[CHK]Failed,input size(%u) should be(%ld)\n",
+		       ipi_param->inputs[0].buffer.format.plane_fmt[0].size,
+			sizeof(g_imgi_array_3264x1836_b10));
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->inputs[0].buffer.format.plane_fmt[0].stride
+			!= in_stride_size) {
+		pr_err("[CHK]Failed,intput stride size(%d) should be(%d)\n",
+		       ipi_param->inputs[0].buffer.format.plane_fmt[0].stride,
+			in_stride_size);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->inputs[0].buffer.format.ycbcr_prof != 1) {
+		pr_err("[CHK]Failed,intput ycbcr_prof(%d) should be(%d)\n",
+		       ipi_param->inputs[0].buffer.format.ycbcr_prof,
+			1);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->inputs[0].buffer.usage != 0) {
+		pr_err("[CHK]Failed, input buffer usage (%d) should be(%d)\n",
+		       ipi_param->inputs[0].buffer.usage,
+			0);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].buffer.usage != 0) {
+		pr_err("[CHK]Failed, output buffer usage (%d) should be(%d)\n",
+		       ipi_param->outputs[0].buffer.usage,
+			0);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].buffer.format.width != dst_width ||
+	    ipi_param->outputs[0].buffer.format.height != dst_height) {
+		pr_err("[CHK]Failed,output w(%d),h(%d) should be w(%d),h(%d)\n",
+		       ipi_param->outputs[0].buffer.format.width,
+			ipi_param->outputs[0].buffer.format.height,
+			dst_width,
+			dst_width);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].buffer.format.colorformat
+			!= MDP_COLOR_YUYV) {
+		pr_err("[CHK]Failed,input colorformat(%d) should be(%d)\n",
+		       ipi_param->outputs[0].buffer.format.colorformat,
+			MDP_COLOR_YUYV);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].buffer.format.ycbcr_prof
+			!= 0) {
+		pr_err("[CHK]Failed,intput ycbcr_prof(%d) should be(%d)\n",
+		       ipi_param->outputs[0].buffer.format.ycbcr_prof,
+			0);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].buffer.format.plane_fmt[0].size
+			!= out_size) {
+		pr_err("[CHK]Failed,input size(%u) should be(%u)\n",
+		       ipi_param->outputs[0].buffer.format.plane_fmt[0].size,
+			out_size);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].buffer.format.plane_fmt[0].stride
+			!= out_stride_size) {
+		pr_err("[CHK]Failed,output stride size(%d) should be(%d)\n",
+		       ipi_param->outputs[0].buffer.format.plane_fmt[0].stride,
+			out_stride_size);
+		ret = -EINVAL;
+	}
+
+	if (ipi_param->outputs[0].crop.left != crop_left ||
+	    ipi_param->outputs[0].crop.top != crop_top ||
+		ipi_param->outputs[0].crop.width != crop_width ||
+		ipi_param->outputs[0].crop.height != crop_height ||
+		ipi_param->outputs[0].crop.left_subpix != crop_left_subpix ||
+		ipi_param->outputs[0].crop.top_subpix != crop_top_subpix ||
+		ipi_param->outputs[0].crop.width_subpix != crop_width_subpix ||
+		ipi_param->outputs[0].crop.height_subpix !=
+			crop_height_subpix ||
+		ipi_param->outputs[0].rotation != rotation) {
+		pr_err("[CHK]Failed, crop setting: c_l(%d),c_t(%d),c_w(%d),c_h(%d)\n"
+			ipi_param->outputs[0].crop.left,
+			ipi_param->outputs[0].crop.top,
+			ipi_param->outputs[0].crop.width,
+			ipi_param->outputs[0].crop.height);
+		pr_err("c_ls(%d),c_ts(%d),c_ws(%d),c_hs(%d),r(%d)\n",
+		       ipi_param->outputs[0].crop.left_subpix,
+			ipi_param->outputs[0].crop.top_subpix,
+			ipi_param->outputs[0].crop.width_subpix,
+			ipi_param->outputs[0].crop.height_subpix,
+			ipi_param->outputs[0].rotation);
+
+		pr_err("[CHK]crop setting must be: c_l(%d),c_t(%d),c_w(%d),c_h(%d)\n"
+			crop_left, crop_top, crop_width, crop_height);
+
+		pr_err("c_ls(%d),c_ts(%d),c_ws(%d),c_hs(%d),r(%d)\n",
+		       crop_left_subpix, crop_top_subpix, crop_width_subpix,
+			crop_height_subpix, rotation);
+		ret = -EINVAL;
+	}
+
+	return ret;
+}
+#endif /* MTK_DIP_CTX_DIP_V4L2_UT */
+
+static enum mdp_ycbcr_profile map_ycbcr_prof_mplane
+	(struct v4l2_pix_format_mplane *pix_mp,
+	 u32 mdp_color)
+{
+	if (MDP_COLOR_IS_RGB(mdp_color))
+		return MDP_YCBCR_PROFILE_FULL_BT601;
+
+	switch (pix_mp->colorspace) {
+	case V4L2_COLORSPACE_JPEG:
+		return MDP_YCBCR_PROFILE_JPEG;
+	case V4L2_COLORSPACE_REC709:
+	case V4L2_COLORSPACE_DCI_P3:
+		if (pix_mp->quantization == V4L2_QUANTIZATION_FULL_RANGE)
+			return MDP_YCBCR_PROFILE_FULL_BT709;
+		return MDP_YCBCR_PROFILE_BT709;
+	case V4L2_COLORSPACE_BT2020:
+		if (pix_mp->quantization == V4L2_QUANTIZATION_FULL_RANGE)
+			return MDP_YCBCR_PROFILE_FULL_BT2020;
+		return MDP_YCBCR_PROFILE_BT2020;
+	}
+	/* V4L2_COLORSPACE_SRGB or else */
+	if (pix_mp->quantization == V4L2_QUANTIZATION_FULL_RANGE)
+		return MDP_YCBCR_PROFILE_FULL_BT601;
+	return MDP_YCBCR_PROFILE_BT601;
+}
+
+/* Stride that is accepted by MDP HW */
+/* Required MDP macro: */
+/* - MDP_COLOR_BITS_PER_PIXEL */
+/* - MDP_COLOR_GET_PLANE_COUNT */
+/* - MDP_COLOR_IS_BLOCK_MODE */
+static u32 dip_mdp_fmt_get_stride(const struct mtk_dip_ctx_mdp_format *fmt,
+				  u32 bytesperline, unsigned int plane)
+{
+	enum mdp_color c = fmt->mdp_color;
+	u32 stride;
+
+	stride = (bytesperline * MDP_COLOR_BITS_PER_PIXEL(c))
+		/ fmt->row_depth[0];
+	if (plane == 0)
+		return stride;
+	if (plane < MDP_COLOR_GET_PLANE_COUNT(c)) {
+		if (MDP_COLOR_IS_BLOCK_MODE(c))
+			stride = stride / 2;
+		return stride;
+	}
+	return 0;
+}
+
+/* Stride that is accepted by MDP HW of format with contiguous planes */
+/* - MDP_COLOR_GET_PLANE_COUNT */
+/* - MDP_COLOR_GET_H_SUBSAMPLE */
+/* - MDP_COLOR_IS_UV_COPLANE */
+/* - MDP_COLOR_IS_BLOCK_MODE */
+static u32 dip_mdp_fmt_get_stride_contig
+	(const struct mtk_dip_ctx_mdp_format *fmt,
+	 u32 pix_stride, unsigned int plane)
+{
+	enum mdp_color c = fmt->mdp_color;
+	u32 stride = pix_stride;
+
+	if (plane == 0)
+		return stride;
+	if (plane < MDP_COLOR_GET_PLANE_COUNT(c)) {
+		stride = stride >> MDP_COLOR_GET_H_SUBSAMPLE(c);
+		if (MDP_COLOR_IS_UV_COPLANE(c) && !MDP_COLOR_IS_BLOCK_MODE(c))
+			stride = stride * 2;
+		return stride;
+	}
+	return 0;
+}
+
+/* Plane size that is accepted by MDP HW */
+/* Stride that is accepted by MDP HW of format with contiguous planes */
+/* - MDP_COLOR_BITS_PER_PIXEL */
+/* - MDP_COLOR_GET_PLANE_COUNT */
+/* - MDP_COLOR_GET_V_SUBSAMPLE */
+/* - MDP_COLOR_IS_BLOCK_MODE */
+static u32 dip_mdp_fmt_get_plane_size
+	(const struct mtk_dip_ctx_mdp_format *fmt,
+	 u32 stride, u32 height, unsigned int plane)
+{
+	enum mdp_color c = fmt->mdp_color;
+	u32 bytesperline;
+
+	bytesperline = (stride * fmt->row_depth[0])
+		/ MDP_COLOR_BITS_PER_PIXEL(c);
+	if (plane == 0)
+		return bytesperline * height;
+	if (plane < MDP_COLOR_GET_PLANE_COUNT(c)) {
+		height = height >> MDP_COLOR_GET_V_SUBSAMPLE(c);
+		if (MDP_COLOR_IS_BLOCK_MODE(c))
+			bytesperline = bytesperline * 2;
+		return bytesperline * height;
+	}
+	return 0;
+}
+
+static int is_contig_mp_buffer(struct mtk_dip_ctx_buffer *ctx_buf)
+{
+	struct v4l2_pix_format_mplane *pix_mp = &ctx_buf->fmt.pix_mp;
+
+	if (MDP_COLOR_GET_PLANE_COUNT(ctx_buf->ctx_fmt->fmt.img.mdp_color)
+	    == 1) {
+		/* debug only */
+		if (pix_mp->pixelformat == V4L2_PIX_FMT_YVU420)
+			pr_err("YVU420 should not be contig_mp_buffer\n");
+		return 0;
+	} else {
+		return 1;
+	}
+}
+
+static int fill_ipi_img_param_mp(struct mtk_dip_ctx *dev_ctx,
+				 struct img_image_buffer *b,
+				 struct mtk_dip_ctx_buffer *ctx_buf,
+				 char *buf_name)
+{
+	struct v4l2_pix_format_mplane *pix_mp = NULL;
+	struct mtk_dip_ctx_mdp_format *mdp_fmt = NULL;
+	unsigned int i;
+	unsigned int total_plane_size = 0;
+
+	if (!ctx_buf->ctx_fmt) {
+		dev_err(&dev_ctx->pdev->dev,
+			"%s's ctx format not set\n", buf_name);
+		return -EINVAL;
+	}
+
+	pix_mp = &ctx_buf->fmt.pix_mp;
+	mdp_fmt = &ctx_buf->ctx_fmt->fmt.img;
+
+	b->format.colorformat = ctx_buf->ctx_fmt->fmt.img.mdp_color;
+	b->format.width = ctx_buf->fmt.pix_mp.width;
+	b->format.height = ctx_buf->fmt.pix_mp.height;
+	b->format.ycbcr_prof =
+		map_ycbcr_prof_mplane(pix_mp,
+				      ctx_buf->ctx_fmt->fmt.img.mdp_color);
+
+	dev_dbg(&dev_ctx->pdev->dev,
+		"IPI(%s): w(%d),h(%d),c(%x)\n",
+		buf_name,
+		b->format.width,
+		b->format.height,
+		b->format.colorformat);
+
+	for (i = 0; i < pix_mp->num_planes; ++i) {
+		u32 stride =
+			dip_mdp_fmt_get_stride
+			(mdp_fmt, pix_mp->plane_fmt[i].bytesperline, i);
+
+		b->format.plane_fmt[i].stride = stride;
+		b->format.plane_fmt[i].size =
+			dip_mdp_fmt_get_plane_size(mdp_fmt,
+						   stride,
+						   pix_mp->height, i);
+		b->iova[i] = ctx_buf->daddr;
+		dev_dbg(&dev_ctx->pdev->dev,
+			"Contiguous-mp-buf:plane(%i),stride(%d),size(%d),iova(%llx)",
+			i,
+			b->format.plane_fmt[i].stride,
+			b->format.plane_fmt[i].size,
+			(unsigned long long)b->iova[i]);
+		total_plane_size = b->format.plane_fmt[i].size;
+	}
+
+	for (; i < MDP_COLOR_GET_PLANE_COUNT(b->format.colorformat); ++i) {
+		u32 stride =
+			dip_mdp_fmt_get_stride_contig
+			(mdp_fmt, b->format.plane_fmt[0].stride, i);
+
+		b->format.plane_fmt[i].stride = stride;
+		b->format.plane_fmt[i].size =
+			dip_mdp_fmt_get_plane_size(mdp_fmt, stride,
+						   pix_mp->height, i);
+		b->iova[i] = b->iova[i - 1] + b->format.plane_fmt[i - 1].size;
+		dev_dbg(&dev_ctx->pdev->dev,
+			"Contiguous-mp-buf:plane(%i),stride(%d),size(%d),iova(%llx)",
+			i,
+			b->format.plane_fmt[i].stride,
+			b->format.plane_fmt[i].size,
+			(unsigned long long)b->iova[i]);
+		total_plane_size += b->format.plane_fmt[i].size;
+	}
+
+	b->usage = ctx_buf->buffer_usage;
+
+	dev_dbg(&dev_ctx->pdev->dev,
+		"Contiguous-mp-buf(%s),v4l2-sizeimage(%d),total-plane-size(%d)\n",
+		buf_name,
+		pix_mp->plane_fmt[0].sizeimage,
+		total_plane_size);
+
+	return 0;
+}
+
+static int fill_ipi_img_param(struct mtk_dip_ctx *dev_ctx,
+			      struct img_image_buffer *img,
+			      struct mtk_dip_ctx_buffer *ctx_buf,
+			      char *buf_name)
+{
+		img->format.width = ctx_buf->fmt.pix_mp.width;
+		img->format.height = ctx_buf->fmt.pix_mp.height;
+
+		if (ctx_buf->ctx_fmt) {
+			img->format.colorformat =
+				ctx_buf->ctx_fmt->fmt.img.mdp_color;
+		} else {
+			dev_err(&dev_ctx->pdev->dev,
+				"%s's ctx format not set\n", buf_name);
+			return -EINVAL;
+		}
+
+		img->format.plane_fmt[0].size =
+			ctx_buf->fmt.pix_mp.plane_fmt[0].sizeimage;
+		img->format.plane_fmt[0].stride =
+			ctx_buf->fmt.pix_mp.plane_fmt[0].bytesperline;
+		img->iova[0] = ctx_buf->daddr;
+		img->usage = ctx_buf->buffer_usage;
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"IPI(%s): w(%d),h(%d),c(%x),size(%d)\n",
+			buf_name,
+			img->format.width,
+			img->format.height,
+			img->format.colorformat);
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"stride(%d),ycbcr(%d),iova(%llx),u(%d)\n",
+			img->format.plane_fmt[0].size,
+			img->format.plane_fmt[0].stride,
+			img->format.ycbcr_prof,
+			(unsigned long long)img->iova[0],
+			img->usage);
+
+		return 0;
+}
+
+static int fill_input_ipi_param(struct mtk_dip_ctx *dev_ctx,
+				struct img_input *iin,
+				struct mtk_dip_ctx_buffer *ctx_buf,
+				char *buf_name)
+{
+		struct img_image_buffer *img = &iin->buffer;
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"To fill ipi param for ctx(%d)\n",
+			dev_ctx->ctx_id);
+
+		/* Will map the vale with V4L2 color space in the future */
+		img->format.ycbcr_prof = 1;
+		if (is_contig_mp_buffer(ctx_buf))
+			return fill_ipi_img_param_mp(dev_ctx, img, ctx_buf,
+						     buf_name);
+		else
+			return fill_ipi_img_param(dev_ctx, img, ctx_buf,
+						  buf_name);
+}
+
+static int fill_output_ipi_param(struct mtk_dip_ctx *dev_ctx,
+				 struct img_output *iout,
+				 struct mtk_dip_ctx_buffer *ctx_buf_out,
+				 struct mtk_dip_ctx_buffer *ctx_buf_in,
+				 char *buf_name)
+{
+		int r = 0;
+		struct img_image_buffer *img = &iout->buffer;
+
+		/* Will map the vale with V4L2 color space in the future */
+		img->format.ycbcr_prof = 0;
+
+		if (is_contig_mp_buffer(ctx_buf_out))
+			r = fill_ipi_img_param_mp(dev_ctx, img, ctx_buf_out,
+						  buf_name);
+		else
+			r = fill_ipi_img_param(dev_ctx, img, ctx_buf_out,
+					       buf_name);
+
+		iout->crop.left = 0;
+		iout->crop.top = 0;
+		iout->crop.width = ctx_buf_in->fmt.pix_mp.width;
+		iout->crop.height = ctx_buf_in->fmt.pix_mp.height;
+		iout->crop.left_subpix = 0;
+		iout->crop.top_subpix = 0;
+		iout->crop.width_subpix = 0;
+		iout->crop.height_subpix = 0;
+		iout->rotation = ctx_buf_out->rotation;
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"IPI-ext(%s):c_l(%d),c_t(%d),c_w(%d),c_h(%d)\n",
+			buf_name, iout->crop.left, iout->crop.top,
+			iout->crop.width,
+			iout->crop.height);
+
+		dev_dbg(&dev_ctx->pdev->dev,
+			"c_ls(%d),c_ts(%d),c_ws(%d),c_hs(%d),r(%d)\n",
+			iout->crop.left_subpix,
+			iout->crop.top_subpix,
+			iout->crop.width_subpix, iout->crop.height_subpix,
+			iout->rotation);
+
+		return r;
+}
+
+static int mtk_dip_ctx_core_job_start(struct mtk_dip_ctx *dev_ctx,
+				      struct mtk_dip_ctx_start_param *param)
+{
+	struct platform_device *pdev = dev_ctx->pdev;
+	int i = 0;
+	int ret = 0;
+	int out_img_buf_idx = 0;
+	struct img_ipi_frameparam dip_param;
+	struct mtk_dip_ctx_buffer *ctx_buf_in = NULL;
+	struct mtk_dip_ctx_buffer *ctx_buf_out = NULL;
+	struct mtk_dip_ctx_buffer *ctx_buf_tuning = NULL;
+
+	int scan_queue_idx[] = {
+		MTK_DIP_CTX_P2_RAW_QUEUE_IN, MTK_DIP_CTX_P2_TUNING_QUEUE_IN,
+		MTK_DIP_CTX_P2_MDP0_QUEUE_OUT,	MTK_DIP_CTX_P2_MDP1_QUEUE_OUT};
+	int total_buffer_scan = ARRAY_SIZE(scan_queue_idx);
+
+	if (!pdev || !param) {
+		dev_err(&pdev->dev,
+			"pdev(%llx) and param(%llx) in start can't be NULL\n",
+			(long long)pdev, (long long)param);
+		return -EINVAL;
+	}
+
+	dev_dbg(&pdev->dev,
+		"trigger mtk_dip_dip_start: pdev(%llx), frame(%x)\n",
+		(long long)pdev, param->frame_bundle->id);
+
+	/* Fill ipi params for P2 driver */
+	memset(&dip_param, 0, sizeof(struct img_ipi_frameparam));
+
+	dip_param.index = param->frame_bundle->id;
+	dip_param.num_outputs = param->frame_bundle->num_img_capture_bufs;
+	dip_param.num_inputs = param->frame_bundle->num_img_output_bufs;
+	dip_param.type = STREAM_ISP_IC;
+
+	dev_dbg(&pdev->dev, "DIP frame idx(%d),num_out(%d),num_in(%d)\n",
+		param->frame_bundle->id,
+		dip_param.num_outputs,
+		dip_param.num_inputs);
+
+	/* Tuning buffer */
+	ctx_buf_tuning =
+		param->frame_bundle->buffers[MTK_DIP_CTX_P2_TUNING_QUEUE_IN];
+	if (ctx_buf_tuning) {
+		dev_dbg(&pdev->dev,
+			"Tuning buf queued: pa(%llx),va(%llx),iova(%llx)\n",
+			(unsigned long long)ctx_buf_tuning->paddr,
+			(unsigned long long)ctx_buf_tuning->vaddr,
+			(unsigned long long)ctx_buf_tuning->daddr);
+		dip_param.tuning_data.pa = (uint32_t)ctx_buf_tuning->paddr;
+		dip_param.tuning_data.va = (uint64_t)ctx_buf_tuning->vaddr;
+		dip_param.tuning_data.iova = (uint32_t)ctx_buf_tuning->daddr;
+	} else {
+		dev_dbg(&pdev->dev,
+			"Doesn't enqueued tuning buffer, by-pass\n");
+	dip_param.tuning_data.pa = 0;
+	dip_param.tuning_data.va = 0;
+	dip_param.tuning_data.iova = 0;
+	}
+
+	/* Raw-in buffer */
+	ctx_buf_in =
+		param->frame_bundle->buffers[MTK_DIP_CTX_P2_RAW_QUEUE_IN];
+	if (ctx_buf_in) {
+		struct img_input *iin = &dip_param.inputs[0];
+
+		fill_input_ipi_param(dev_ctx, iin, ctx_buf_in, "RAW");
+	}
+
+	/* MDP 0 buffer */
+	ctx_buf_out =
+		param->frame_bundle->buffers[MTK_DIP_CTX_P2_MDP0_QUEUE_OUT];
+	if (ctx_buf_out) {
+		struct img_output *iout = &dip_param.outputs[out_img_buf_idx];
+
+		fill_output_ipi_param(dev_ctx, iout, ctx_buf_out,
+				      ctx_buf_in, "MPD0");
+		out_img_buf_idx++;
+	}
+
+	/* MDP 0 buffer */
+	ctx_buf_out =
+		param->frame_bundle->buffers[MTK_DIP_CTX_P2_MDP1_QUEUE_OUT];
+	if (ctx_buf_out) {
+		struct img_output *iout = &dip_param.outputs[out_img_buf_idx];
+
+		fill_output_ipi_param(dev_ctx, iout, ctx_buf_out,
+				      ctx_buf_in,  "MPD1");
+		out_img_buf_idx++;
+	}
+
+	/* Dump all information carried in this param */
+	for (i = 0; i < total_buffer_scan; i++) {
+		int queue_idx = scan_queue_idx[i];
+		dma_addr_t daddr;
+		void *vaddr = NULL;
+		struct mtk_dip_ctx_buffer *buf =
+			param->frame_bundle->buffers[queue_idx];
+
+		dev_dbg(&pdev->dev, "get buf, queue = %d, addr = 0x%llx\n",
+			queue_idx, (long long)buf);
+
+		if (!buf) {
+			dev_dbg(&pdev->dev, "CTX buf(frame=%d, queue=%d) is NULL(disabled)\n",
+				param->frame_bundle->id, queue_idx);
+			continue;
+		}
+
+		daddr = buf->daddr;
+		vaddr = buf->vaddr;
+
+		if (buf->image) {
+			struct v4l2_pix_format_mplane *pix_fmt =
+				&buf->fmt.pix_mp;
+
+			if (!pix_fmt)
+				dev_warn(&pdev->dev, "v4l2_pix_format is NULL,  queue=%d\n",
+					 queue_idx);
+			else
+				dev_dbg(&pdev->dev,
+					"Buf from frame(%d):w(%d),h(%d),fmt(%d),color(%d),size(%d)\n",
+				buf->frame_id,
+				pix_fmt->width,	pix_fmt->height,
+				pix_fmt->pixelformat,
+				pix_fmt->colorspace,
+				pix_fmt->plane_fmt[0].sizeimage);
+		} else {
+			struct v4l2_meta_format *meta_fmt = &buf->fmt.meta;
+
+			if (!meta_fmt)
+				dev_warn(&pdev->dev, "meta_fmt is NULL,  queue=%d(disabled)\n",
+					 queue_idx);
+			else
+				dev_dbg(&pdev->dev,
+					"Buf from frame(%d):metatype(%d), size(%d)\n",
+				buf->frame_id, meta_fmt->dataformat,
+				meta_fmt->buffersize);
+		}
+	}
+
+	dev_dbg(&pdev->dev,
+		"Delegate job to mtk_dip_enqueue: pdev(%llx), frame(%d)\n",
+		(long long)pdev, param->frame_bundle->id);
+#ifdef MTK_DIP_CTX_DIP_V4L2_UT
+	ret = check_and_refill_dip_ut_start_ipi_param(&dip_param,
+						      ctx_buf_in, ctx_buf_out);
+	if (ret)
+		dev_err(&dev_ctx->pdev->dev, "DIP ipi param check failed!\n");
+	else
+		mtk_dip_enqueue(pdev, &dip_param);
+#else
+	ret = mtk_dip_enqueue(pdev, &dip_param);
+#endif /* MTK_DIP_CTX_DIP_V4L2_UT */
+
+	if (ret) {
+		dev_warn(&pdev->dev,
+			 "mtk_dip_enqueue failed: %d, will return buffer to user directly\n",
+			 ret);
+		return -EBUSY;
+	}
+
+	return ret;
+}
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.c
new file mode 100644
index 000000000000..b7db1199f033
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.c
@@ -0,0 +1,374 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ * Copyright (C) 2017 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_DIP-dev is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk_dip-dev.h"
+#include "mtk_dip-ctrl.h"
+
+static struct platform_device *mtk_dip_dev_of_find_smem_dev
+	(struct platform_device *pdev);
+
+/* Initliaze a mtk_dip_dev representing a completed HW ISP */
+/* device */
+int mtk_dip_dev_init(struct mtk_dip_dev *isp_dev,
+		     struct platform_device *pdev,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	int r = 0;
+
+	isp_dev->pdev = pdev;
+
+	mutex_init(&isp_dev->lock);
+	atomic_set(&isp_dev->qbuf_barrier, 0);
+	init_waitqueue_head(&isp_dev->buf_drain_wq);
+
+	r = mtk_dip_ctrl_init(&isp_dev->ctx);
+
+	if (r) {
+		dev_err(&isp_dev->pdev->dev,
+			"failed to initialize ctrls (%d)\n", r);
+		goto failed_ctrl;
+	}
+
+	/* v4l2 sub-device registration */
+	r = mtk_dip_dev_mem2mem2_init(isp_dev, media_dev, v4l2_dev);
+
+	if (r) {
+		dev_err(&isp_dev->pdev->dev,
+			"failed to create V4L2 devices (%d)\n", r);
+		goto failed_mem2mem2;
+	}
+
+	return 0;
+
+failed_ctrl:
+failed_mem2mem2:
+	mutex_destroy(&isp_dev->lock);
+	return r;
+}
+
+int mtk_dip_dev_get_total_node(struct mtk_dip_dev *mtk_dip_dev)
+{
+	return mtk_dip_dev->ctx.queues_attr.total_num;
+}
+
+int mtk_dip_dev_mem2mem2_init(struct mtk_dip_dev *isp_dev,
+			      struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	int r, i;
+	const int queue_master = isp_dev->ctx.queues_attr.master;
+
+	pr_info("mem2mem2.name: %s\n", isp_dev->ctx.device_name);
+	isp_dev->mem2mem2.name = isp_dev->ctx.device_name;
+	isp_dev->mem2mem2.model = isp_dev->ctx.device_name;
+	isp_dev->mem2mem2.num_nodes =
+		mtk_dip_dev_get_total_node(isp_dev);
+	isp_dev->mem2mem2.vb2_mem_ops = &vb2_dma_contig_memops;
+	isp_dev->mem2mem2.buf_struct_size =
+		sizeof(struct mtk_dip_dev_buffer);
+
+	/* support UT only currently */
+	isp_dev->mem2mem2.ctrl_handler =
+		&isp_dev->ctx.ctrl_handler;
+
+	isp_dev->mem2mem2.nodes = isp_dev->mem2mem2_nodes;
+	isp_dev->mem2mem2.dev = &isp_dev->pdev->dev;
+
+	for (i = 0; i < isp_dev->ctx.dev_node_num; i++) {
+		isp_dev->mem2mem2.nodes[i].name =
+			mtk_dip_dev_get_node_name(isp_dev, i);
+		isp_dev->mem2mem2.nodes[i].output =
+				i < isp_dev->ctx.queues_attr.input_offset;
+		isp_dev->mem2mem2.nodes[i].dynamic =
+			isp_dev->ctx.queue[i].desc.dynamic;
+		isp_dev->mem2mem2.nodes[i].immutable = 0;
+		isp_dev->mem2mem2.nodes[i].enabled = 0;
+		atomic_set(&isp_dev->mem2mem2.nodes[i].sequence, 0);
+	}
+
+	/* Master queue is always enabled */
+	isp_dev->mem2mem2.nodes[queue_master].immutable = 1;
+	isp_dev->mem2mem2.nodes[queue_master].enabled = 1;
+
+	pr_info("register v4l2 for %llx\n",
+		(unsigned long long)isp_dev);
+	r = mtk_dip_mem2mem2_v4l2_register(isp_dev, media_dev, v4l2_dev);
+
+	if (r) {
+		pr_err("v4l2 init failed, dev(ctx:%d)\n",
+		       isp_dev->ctx.ctx_id);
+		return r;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_mem2mem2_init);
+
+void mtk_dip_dev_mem2mem2_exit(struct mtk_dip_dev *isp_dev)
+{
+	mtk_dip_v4l2_unregister(isp_dev);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_mem2mem2_exit);
+
+char *mtk_dip_dev_get_node_name
+	(struct mtk_dip_dev *isp_dev, int node)
+{
+	struct mtk_dip_ctx_queue_desc *mapped_queue_desc =
+		&isp_dev->ctx.queue[node].desc;
+
+	return mapped_queue_desc->name;
+}
+
+/* Get a free buffer from a video node */
+static struct mtk_dip_ctx_buffer __maybe_unused *mtk_dip_dev_queue_getbuf
+	(struct mtk_dip_dev *isp_dev, int node)
+{
+	struct mtk_dip_dev_buffer *buf;
+	int queue = -1;
+
+	if (node > isp_dev->ctx.dev_node_num || node < 0) {
+		dev_err(&isp_dev->pdev->dev, "Invalid mtk_dip_dev node.\n");
+		return NULL;
+	}
+
+	/* Get the corrosponding queue id of the video node */
+	/* Currently the queue id is the same as the node number */
+	queue = node;
+
+	if (queue < 0) {
+		dev_err(&isp_dev->pdev->dev, "Invalid mtk_dip_dev node.\n");
+		return NULL;
+	}
+
+	/* Find first free buffer from the node */
+	list_for_each_entry(buf, &isp_dev->mem2mem2.nodes[node].buffers,
+			    m2m2_buf.list) {
+		if (mtk_dip_ctx_get_buffer_state(&buf->ctx_buf)
+			== MTK_DIP_CTX_BUFFER_NEW)
+			return &buf->ctx_buf;
+	}
+
+	/* There were no free buffers*/
+	return NULL;
+}
+
+int mtk_dip_dev_get_queue_id_of_dev_node(struct mtk_dip_dev *isp_dev,
+					 struct mtk_dip_dev_video_device *node)
+{
+	return (node - isp_dev->mem2mem2.nodes);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_get_queue_id_of_dev_node);
+
+int mtk_dip_dev_queue_buffers(struct mtk_dip_dev *isp_dev,
+			      int initial)
+{
+	unsigned int node;
+	int r = 0;
+	struct mtk_dip_dev_buffer *ibuf;
+	struct mtk_dip_ctx_frame_bundle bundle;
+	const int mtk_dip_dev_node_num = mtk_dip_dev_get_total_node(isp_dev);
+	const int queue_master = isp_dev->ctx.queues_attr.master;
+
+	memset(&bundle, 0, sizeof(struct mtk_dip_ctx_frame_bundle));
+
+	dev_dbg(&isp_dev->pdev->dev, "%s, init(%d)\n", __func__, initial);
+
+	if (!mtk_dip_ctx_is_streaming(&isp_dev->ctx)) {
+		pr_info("%s: stream is off, no hw enqueue triggered\n",
+			__func__);
+		return 0;
+	}
+
+	mutex_lock(&isp_dev->lock);
+
+	/* Buffer set is queued to background driver (e.g. DIP, FD, and P1) */
+	/* only when master input buffer is ready */
+	if (!mtk_dip_dev_queue_getbuf(isp_dev, queue_master)) {
+		mutex_unlock(&isp_dev->lock);
+		return 0;
+	}
+
+	/* Check all node from the node after the master node */
+	for (node = (queue_master + 1) % mtk_dip_dev_node_num;
+		1; node = (node + 1) % mtk_dip_dev_node_num) {
+		dev_dbg(&isp_dev->pdev->dev,
+			"Check node(%d),queue enabled(%d),node enabled(%d)\n",
+			node, isp_dev->queue_enabled[node],
+			isp_dev->mem2mem2.nodes[node].enabled);
+
+		/* May skip some node according the scenario in the future */
+		if (isp_dev->queue_enabled[node] ||
+		    isp_dev->mem2mem2.nodes[node].enabled) {
+			struct mtk_dip_ctx_buffer *buf =
+				mtk_dip_dev_queue_getbuf(isp_dev, node);
+			char *node_name =
+				mtk_dip_dev_get_node_name(isp_dev, node);
+
+			if (!buf) {
+				dev_dbg(&isp_dev->pdev->dev,
+					"No free buffer of enabled node %s\n",
+					node_name);
+				break;
+			}
+
+			/* To show the debug message */
+			ibuf = container_of(buf,
+					    struct mtk_dip_dev_buffer, ctx_buf);
+			dev_dbg(&isp_dev->pdev->dev,
+				"may queue user %s buffer idx(%d) to ctx\n",
+				node_name,
+				ibuf->m2m2_buf.vbb.vb2_buf.index);
+			mtk_dip_ctx_frame_bundle_add(&isp_dev->ctx,
+						     &bundle, buf);
+		}
+
+		/* Stop if there is no free buffer in master input node */
+		if (node == queue_master) {
+			if (mtk_dip_dev_queue_getbuf(isp_dev, queue_master)) {
+				/* Has collected all buffer required */
+				mtk_dip_ctx_trigger_job(&isp_dev->ctx, &bundle);
+			} else {
+				pr_debug("no new buffer found in master node, not trigger job\n");
+				break;
+			}
+		}
+	}
+	mutex_unlock(&isp_dev->lock);
+
+	if (r && r != -EBUSY)
+		goto failed;
+
+	return 0;
+
+failed:
+	/*
+	 * On error, mark all buffers as failed which are not
+	 * yet queued to CSS
+	 */
+	dev_err(&isp_dev->pdev->dev,
+		"failed to queue buffer to ctx on queue %i (%d)\n",
+		node, r);
+
+	if (initial)
+		/* If we were called from streamon(), no need to finish bufs */
+		return r;
+
+	for (node = 0; node < mtk_dip_dev_node_num; node++) {
+		struct mtk_dip_dev_buffer *buf, *buf0;
+
+		if (!isp_dev->queue_enabled[node])
+			continue;	/* Skip disabled queues */
+
+		mutex_lock(&isp_dev->lock);
+		list_for_each_entry_safe(buf, buf0,
+					 &isp_dev->mem2mem2.nodes[node].buffers,
+			m2m2_buf.list) {
+			if (mtk_dip_ctx_get_buffer_state(&buf->ctx_buf) ==
+				MTK_DIP_CTX_BUFFER_PROCESSING)
+				continue;	/* Was already queued, skip */
+
+			mtk_dip_v4l2_buffer_done(&buf->m2m2_buf.vbb.vb2_buf,
+						 VB2_BUF_STATE_ERROR);
+		}
+		mutex_unlock(&isp_dev->lock);
+	}
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_queue_buffers);
+
+int mtk_dip_dev_core_init(struct platform_device *pdev,
+			  struct mtk_dip_dev *isp_dev,
+	struct mtk_dip_ctx_desc *ctx_desc)
+{
+	return mtk_dip_dev_core_init_ext(pdev,
+		isp_dev, ctx_desc, NULL, NULL);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_core_init);
+
+int mtk_dip_dev_core_init_ext(struct platform_device *pdev,
+			      struct mtk_dip_dev *isp_dev,
+	struct mtk_dip_ctx_desc *ctx_desc,
+	struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	int r;
+	struct platform_device *smem_dev = NULL;
+
+	smem_dev = mtk_dip_dev_of_find_smem_dev(pdev);
+
+	if (!smem_dev)
+		dev_err(&pdev->dev, "failed to find smem_dev\n");
+
+	/* Device context must be initialized before device instance */
+	r = mtk_dip_ctx_core_init(&isp_dev->ctx, pdev,
+				  0, ctx_desc, pdev, smem_dev);
+
+	dev_info(&pdev->dev, "init isp_dev: %llx\n",
+		 (unsigned long long)isp_dev);
+	/* init other device level members */
+	mtk_dip_dev_init(isp_dev, pdev, media_dev, v4l2_dev);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_core_init_ext);
+
+int mtk_dip_dev_core_release(struct platform_device *pdev,
+			     struct mtk_dip_dev *isp_dev)
+{
+	mtk_dip_dev_mem2mem2_exit(isp_dev);
+	v4l2_ctrl_handler_free(&isp_dev->ctx.ctrl_handler);
+	mtk_dip_ctx_core_exit(&isp_dev->ctx);
+	mutex_destroy(&isp_dev->lock);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_dev_core_release);
+
+static struct platform_device *mtk_dip_dev_of_find_smem_dev
+	(struct platform_device *pdev)
+{
+	struct device_node *smem_dev_node = NULL;
+
+	if (!pdev) {
+		pr_err("Find_smem_dev failed, pdev can't be NULL\n");
+		return NULL;
+	}
+
+	smem_dev_node = of_parse_phandle(pdev->dev.of_node,
+					 "smem_device", 0);
+
+	if (!smem_dev_node) {
+		dev_err(&pdev->dev,
+			"failed to find isp smem device for (%s)\n",
+			pdev->name);
+		return NULL;
+	}
+
+	dev_dbg(&pdev->dev, "smem of node found, try to discovery device\n");
+	return of_find_device_by_node(smem_dev_node);
+}
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.h
new file mode 100644
index 000000000000..95a39071dd6b
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-dev.h
@@ -0,0 +1,191 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_DIP-dev is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#ifndef __MTK_DIP_DEV_H__
+#define __MTK_DIP_DEV_H__
+
+#include <linux/platform_device.h>
+#include <linux/version.h>
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+#include "mtk_dip-ctx.h"
+
+/* Added the macro for early stage verification */
+/* based on kernel 4.4 environment. */
+/* I will remove the version check after getting */
+/* the devlopment platform based on 4.14 */
+#define MTK_DIP_KERNEL_BASE_VERSION KERNEL_VERSION(4, 14, 0)
+
+#define MTK_DIP_DEV_NODE_MAX			(MTK_DIP_CTX_QUEUES)
+
+#define MTK_DIP_INPUT_MIN_WIDTH		0U
+#define MTK_DIP_INPUT_MIN_HEIGHT		0U
+#define MTK_DIP_INPUT_MAX_WIDTH		480U
+#define MTK_DIP_INPUT_MAX_HEIGHT		640U
+#define MTK_DIP_OUTPUT_MIN_WIDTH		2U
+#define MTK_DIP_OUTPUT_MIN_HEIGHT		2U
+#define MTK_DIP_OUTPUT_MAX_WIDTH		480U
+#define MTK_DIP_OUTPUT_MAX_HEIGHT		640U
+
+#define file_to_mtk_dip_node(__file) \
+	container_of(video_devdata(__file),\
+	struct mtk_dip_dev_video_device, vdev)
+
+#define mtk_dip_ctx_to_dev(__ctx) \
+	container_of(__ctx,\
+	struct mtk_dip_dev, ctx)
+
+#define mtk_dip_m2m_to_dev(__m2m) \
+	container_of(__m2m,\
+	struct mtk_dip_dev, mem2mem2)
+
+#define mtk_dip_subdev_to_dev(__sd) \
+	container_of(__sd, \
+	struct mtk_dip_dev, mem2mem2.subdev)
+
+#define mtk_dip_vbq_to_isp_node(__vq) \
+	container_of(__vq, \
+	struct mtk_dip_dev_video_device, vbq)
+
+#define mtk_dip_ctx_buf_to_dev_buf(__ctx_buf) \
+	container_of(__ctx_buf, \
+	struct mtk_dip_dev_buffer, ctx_buf)
+
+#define mtk_dip_vb2_buf_to_dev_buf(__vb) \
+	container_of(vb, \
+	struct mtk_dip_dev_buffer, \
+	m2m2_buf.vbb.vb2_buf)
+
+#define mtk_dip_vb2_buf_to_m2m_buf(__vb) \
+	container_of(__vb, \
+	struct mtk_dip_mem2mem2_buffer, \
+	vbb.vb2_buf)
+
+#define mtk_dip_subdev_to_m2m(__sd) \
+	container_of(__sd, \
+	struct mtk_dip_mem2mem2_device, subdev)
+
+struct mtk_dip_mem2mem2_device;
+
+struct mtk_dip_mem2mem2_buffer {
+	struct vb2_v4l2_buffer vbb;
+	struct list_head list;
+};
+
+struct mtk_dip_dev_buffer {
+	struct mtk_dip_mem2mem2_buffer m2m2_buf;
+	/* Intenal part */
+	struct mtk_dip_ctx_buffer ctx_buf;
+};
+
+struct mtk_dip_dev_video_device {
+	const char *name;
+	int output;
+	int immutable;
+	int enabled;
+	int dynamic;
+	int queued;
+	struct v4l2_format vdev_fmt;
+	struct video_device vdev;
+	struct media_pad vdev_pad;
+	struct v4l2_mbus_framefmt pad_fmt;
+	struct vb2_queue vbq;
+	struct list_head buffers;
+	struct mutex lock; /* Protect node data */
+	atomic_t sequence;
+};
+
+struct mtk_dip_mem2mem2_device {
+	const char *name;
+	const char *model;
+	struct device *dev;
+	int num_nodes;
+	struct mtk_dip_dev_video_device *nodes;
+	const struct vb2_mem_ops *vb2_mem_ops;
+	unsigned int buf_struct_size;
+	int streaming;
+	struct v4l2_ctrl_handler *ctrl_handler;
+	struct v4l2_device *v4l2_dev;
+	struct media_device *media_dev;
+	struct media_pipeline pipeline;
+	struct v4l2_subdev subdev;
+	struct media_pad *subdev_pads;
+	struct v4l2_file_operations v4l2_file_ops;
+	const struct file_operations fops;
+};
+
+struct mtk_dip_dev {
+	struct platform_device *pdev;
+	struct mtk_dip_dev_video_device mem2mem2_nodes[MTK_DIP_DEV_NODE_MAX];
+	int queue_enabled[MTK_DIP_DEV_NODE_MAX];
+	struct mtk_dip_mem2mem2_device mem2mem2;
+	struct v4l2_device v4l2_dev;
+	struct media_device media_dev;
+	struct mtk_dip_ctx ctx;
+	struct mutex lock; /* queue protection */
+	atomic_t qbuf_barrier;
+	int suspend_in_stream;
+	wait_queue_head_t buf_drain_wq;
+};
+
+int mtk_dip_media_register(struct device *dev,
+			   struct media_device *media_dev,
+			   const char *model);
+
+int mtk_dip_v4l2_register(struct device *dev,
+			  struct media_device *media_dev,
+			  struct v4l2_device *v4l2_dev,
+			  struct v4l2_ctrl_handler *ctrl_handler);
+
+int mtk_dip_v4l2_unregister(struct mtk_dip_dev *dev);
+int mtk_dip_mem2mem2_v4l2_register(struct mtk_dip_dev *dev,
+				   struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev);
+
+void mtk_dip_v4l2_buffer_done(struct vb2_buffer *vb,
+			      enum vb2_buffer_state state);
+extern int mtk_dip_dev_queue_buffers
+	(struct mtk_dip_dev *dev, int initial);
+extern int mtk_dip_dev_get_total_node
+	(struct mtk_dip_dev *mtk_dip_dev);
+extern char *mtk_dip_dev_get_node_name
+	(struct mtk_dip_dev *mtk_dip_dev_obj, int node);
+int mtk_dip_dev_init(struct mtk_dip_dev *isp_dev,
+		     struct platform_device *pdev,
+		     struct media_device *media_dev,
+		     struct v4l2_device *v4l2_dev);
+extern void mtk_dip_dev_mem2mem2_exit
+	(struct mtk_dip_dev *mtk_dip_dev_obj);
+int mtk_dip_dev_mem2mem2_init(struct mtk_dip_dev *isp_dev,
+			      struct media_device *media_dev,
+			      struct v4l2_device *v4l2_dev);
+int mtk_dip_dev_get_queue_id_of_dev_node(struct mtk_dip_dev *isp_dev,
+					 struct mtk_dip_dev_video_device
+					 *node);
+int mtk_dip_dev_core_init(struct platform_device *pdev,
+			  struct mtk_dip_dev *isp_dev,
+			  struct mtk_dip_ctx_desc *ctx_desc);
+int mtk_dip_dev_core_init_ext(struct platform_device *pdev,
+			      struct mtk_dip_dev *isp_dev,
+			      struct mtk_dip_ctx_desc *ctx_desc,
+			      struct media_device *media_dev,
+			      struct v4l2_device *v4l2_dev);
+extern int mtk_dip_dev_core_release
+	(struct platform_device *pdev, struct mtk_dip_dev *isp_dev);
+
+#endif /* __MTK_DIP_DEV_H__ */
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem-drv.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem-drv.c
new file mode 100644
index 000000000000..0c754cc458d0
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem-drv.c
@@ -0,0 +1,454 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/of.h>
+#include <linux/of_fdt.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/dma-contiguous.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/iommu.h>
+#include <asm/cacheflush.h>
+
+#define MTK_DIP_SMEM_DEV_NAME "MTK-DIP-SMEM"
+
+struct mtk_dip_smem_drv {
+	struct platform_device *pdev;
+	struct sg_table sgt;
+	struct page **smem_pages;
+	int num_smem_pages;
+	phys_addr_t smem_base;
+	dma_addr_t smem_dma_base;
+	int smem_size;
+};
+
+static struct reserved_mem *isp_reserved_smem;
+
+static int mtk_dip_smem_setup_dma_ops(struct device *smem_dev,
+				      const struct dma_map_ops *smem_ops);
+
+static int mtk_dip_smem_get_sgtable(struct device *dev,
+				    struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, unsigned long attrs);
+
+static const struct dma_map_ops smem_dma_ops = {
+	.get_sgtable = mtk_dip_smem_get_sgtable,
+};
+
+static int mtk_dip_smem_init(struct mtk_dip_smem_drv **mtk_dip_smem_drv_out,
+			     struct platform_device *pdev)
+{
+	struct mtk_dip_smem_drv *isp_sys = NULL;
+	struct device *dev = &pdev->dev;
+
+	isp_sys = devm_kzalloc(dev,
+			       sizeof(*isp_sys), GFP_KERNEL);
+
+	isp_sys->pdev = pdev;
+
+	*mtk_dip_smem_drv_out = isp_sys;
+
+	return 0;
+}
+
+static int mtk_dip_smem_drv_probe(struct platform_device *pdev)
+{
+	struct mtk_dip_smem_drv *smem_drv = NULL;
+	int r = 0;
+	struct device *dev = &pdev->dev;
+
+	dev_dbg(dev, "probe mtk_dip_smem_drv\n");
+
+	r = mtk_dip_smem_init(&smem_drv, pdev);
+
+	if (!smem_drv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, smem_drv);
+
+	if (isp_reserved_smem) {
+		dma_addr_t dma_addr;
+		phys_addr_t addr;
+		struct iommu_domain *smem_dom;
+		int i = 0;
+		int size_align = 0;
+		struct page **pages = NULL;
+		int n_pages = 0;
+		struct sg_table *sgt = &smem_drv->sgt;
+
+		size_align = round_down(isp_reserved_smem->size,
+					PAGE_SIZE);
+		n_pages = size_align >> PAGE_SHIFT;
+
+		pages = kmalloc_array(n_pages, sizeof(struct page *),
+				      GFP_KERNEL);
+
+		if (!pages)
+			return -ENOMEM;
+
+		for (i = 0; i < n_pages; i++)
+			pages[i] = phys_to_page(isp_reserved_smem->base
+						+ i * PAGE_SIZE);
+
+		r = sg_alloc_table_from_pages(sgt, pages, n_pages, 0,
+					      size_align, GFP_KERNEL);
+
+		if (r) {
+			dev_err(dev, "failed to get alloca sg table\n");
+			return -ENOMEM;
+		}
+
+		dma_map_sg_attrs(dev, sgt->sgl, sgt->nents,
+				 DMA_BIDIRECTIONAL,
+				 DMA_ATTR_SKIP_CPU_SYNC);
+
+		dma_addr = sg_dma_address(sgt->sgl);
+		smem_dom = iommu_get_domain_for_dev(dev);
+		addr = iommu_iova_to_phys(smem_dom, dma_addr);
+
+		if (addr != isp_reserved_smem->base)
+			dev_err(dev,
+				"incorrect pa(%llx) from iommu_iova_to_phys, should be %llx\n",
+			(unsigned long long)addr,
+			(unsigned long long)isp_reserved_smem->base);
+
+		r = dma_declare_coherent_memory(dev,
+						isp_reserved_smem->base,
+			dma_addr, size_align, DMA_MEMORY_EXCLUSIVE);
+
+		dev_dbg(dev,
+			"Coherent mem base(%llx,%llx),size(%lx),ret(%d)\n",
+			isp_reserved_smem->base,
+			dma_addr, size_align, r);
+
+		smem_drv->smem_base = isp_reserved_smem->base;
+		smem_drv->smem_size = size_align;
+		smem_drv->smem_pages = pages;
+		smem_drv->num_smem_pages = n_pages;
+		smem_drv->smem_dma_base = dma_addr;
+
+		dev_dbg(dev, "smem_drv setting (%llx,%lx,%llx,%d)\n",
+			smem_drv->smem_base, smem_drv->smem_size,
+			(unsigned long long)smem_drv->smem_pages,
+			smem_drv->num_smem_pages);
+	}
+
+	r = mtk_dip_smem_setup_dma_ops(dev, &smem_dma_ops);
+
+	return r;
+}
+
+phys_addr_t mtk_dip_smem_iova_to_phys(struct device *dev,
+				      dma_addr_t iova)
+{
+		struct iommu_domain *smem_dom;
+		phys_addr_t addr;
+		phys_addr_t limit;
+		struct mtk_dip_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+
+		if (!smem_dev)
+			return 0;
+
+		smem_dom = iommu_get_domain_for_dev(dev);
+
+		if (!smem_dom)
+			return 0;
+
+		addr = iommu_iova_to_phys(smem_dom, iova);
+
+		limit = smem_dev->smem_base + smem_dev->smem_size;
+
+		if (addr < smem_dev->smem_base || addr >= limit) {
+			dev_err(dev,
+				"Unexpected paddr %pa (must >= %pa and <%pa)\n",
+				&addr, &smem_dev->smem_base, &limit);
+			return 0;
+		}
+		dev_dbg(dev, "Pa verifcation pass: %pa(>=%pa, <%pa)\n",
+			&addr, &smem_dev->smem_base, &limit);
+		return addr;
+}
+
+static int mtk_dip_smem_drv_remove(struct platform_device *pdev)
+{
+	struct mtk_dip_smem_drv *smem_drv =
+		dev_get_drvdata(&pdev->dev);
+
+	kfree(smem_drv->smem_pages);
+	return 0;
+}
+
+static int mtk_dip_smem_drv_suspend(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_dip_smem_drv_resume(struct device *dev)
+{
+	return 0;
+}
+
+static int mtk_dip_smem_drv_dummy_cb(struct device *dev)
+{
+	return 0;
+}
+
+static const struct dev_pm_ops mtk_dip_smem_drv_pm_ops = {
+	SET_RUNTIME_PM_OPS(&mtk_dip_smem_drv_dummy_cb,
+			   &mtk_dip_smem_drv_dummy_cb, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS
+		(&mtk_dip_smem_drv_suspend, &mtk_dip_smem_drv_resume)
+};
+
+static const struct of_device_id mtk_dip_smem_drv_of_match[] = {
+	{
+		.compatible = "mediatek,dip_smem",
+	},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, mtk_dip_smem_drv_of_match);
+
+static struct platform_driver mtk_dip_smem_driver = {
+	.probe = mtk_dip_smem_drv_probe,
+	.remove = mtk_dip_smem_drv_remove,
+	.driver = {
+		.name = MTK_DIP_SMEM_DEV_NAME,
+		.of_match_table =
+			of_match_ptr(mtk_dip_smem_drv_of_match),
+		.pm = &mtk_dip_smem_drv_pm_ops,
+	},
+};
+
+static int __init mtk_dip_smem_dma_setup(struct reserved_mem
+					 *rmem)
+{
+	unsigned long node = rmem->fdt_node;
+
+	if (of_get_flat_dt_prop(node, "reusable", NULL))
+		return -EINVAL;
+
+	if (!of_get_flat_dt_prop(node, "no-map", NULL)) {
+		pr_err("Reserved memory: regions without no-map are not yet supported\n");
+		return -EINVAL;
+	}
+
+	isp_reserved_smem = rmem;
+
+	pr_debug("Reserved memory: created DMA memory pool at %pa, size %ld MiB\n",
+		 &rmem->base, (unsigned long)rmem->size / SZ_1M);
+	return 0;
+}
+
+RESERVEDMEM_OF_DECLARE(mtk_dip_smem,
+		       "mediatek,reserve-memory-dip_smem",
+		       mtk_dip_smem_dma_setup);
+
+int __init mtk_dip_smem_drv_init(void)
+{
+	int ret = 0;
+
+	pr_debug("platform_driver_register: mtk_dip_smem_driver\n");
+	ret = platform_driver_register(&mtk_dip_smem_driver);
+
+	if (ret)
+		pr_warn("isp smem drv init failed, driver didn't probe\n");
+
+	return ret;
+}
+subsys_initcall(mtk_dip_smem_drv_init);
+
+void __exit mtk_dip_smem_drv_ext(void)
+{
+	platform_driver_unregister(&mtk_dip_smem_driver);
+}
+module_exit(mtk_dip_smem_drv_ext);
+
+/********************************************
+ * MTK DIP SMEM DMA ops *
+ ********************************************/
+
+struct dma_coherent_mem {
+	void		*virt_base;
+	dma_addr_t	device_base;
+	unsigned long	pfn_base;
+	int		size;
+	int		flags;
+	unsigned long	*bitmap;
+	spinlock_t	spinlock;
+	bool		use_dev_dma_pfn_offset;
+};
+
+static struct dma_coherent_mem *dev_get_coherent_memory(struct device *dev)
+{
+	if (dev && dev->dma_mem)
+		return dev->dma_mem;
+	return NULL;
+}
+
+static int mtk_dip_smem_get_sgtable(struct device *dev,
+				    struct sg_table *sgt,
+	void *cpu_addr, dma_addr_t dma_addr,
+	size_t size, unsigned long attrs)
+{
+	struct mtk_dip_smem_drv *smem_dev = dev_get_drvdata(dev);
+	int n_pages_align = 0;
+	int size_align = 0;
+	int page_start = 0;
+	unsigned long long offset_p = 0;
+	unsigned long long offset_d = 0;
+
+	phys_addr_t paddr = mtk_dip_smem_iova_to_phys(dev, dma_addr);
+
+	offset_d = (unsigned long long)dma_addr -
+		(unsigned long long)smem_dev->smem_dma_base;
+
+	offset_p = (unsigned long long)paddr -
+		(unsigned long long)smem_dev->smem_base;
+
+	dev_dbg(dev, "%s:dma_addr:%llx,cpu_addr:%llx,pa:%llx,size:%d\n",
+		__func__,
+		(unsigned long long)dma_addr,
+		(unsigned long long)cpu_addr,
+		(unsigned long long)paddr,
+		size
+		);
+
+	dev_dbg(dev, "%s:offset p:%llx,offset d:%llx\n",
+		__func__,
+		(unsigned long long)offset_p,
+		(unsigned long long)offset_d
+		);
+
+	size_align = round_up(size, PAGE_SIZE);
+	n_pages_align = size_align >> PAGE_SHIFT;
+	page_start = offset_p >> PAGE_SHIFT;
+
+	dev_dbg(dev,
+		"%s:page idx:%d,page pa:%llx,pa:%llx, aligned size:%d\n",
+		__func__,
+		page_start,
+		(unsigned long long)page_to_phys(*(smem_dev->smem_pages
+			+ page_start)),
+		(unsigned long long)paddr,
+		size_align
+		);
+
+	if (!smem_dev) {
+		dev_err(dev, "can't get sgtable from smem_dev\n");
+		return -EINVAL;
+	}
+
+	dev_dbg(dev, "get sgt of the smem: %d pages\n", n_pages_align);
+
+	return sg_alloc_table_from_pages(sgt,
+		smem_dev->smem_pages + page_start,
+		n_pages_align,
+		0, size_align, GFP_KERNEL);
+}
+
+static void *mtk_dip_smem_get_cpu_addr(struct mtk_dip_smem_drv *smem_dev,
+				       struct scatterlist *sg)
+{
+	struct device *dev = &smem_dev->pdev->dev;
+	struct dma_coherent_mem *dma_mem =
+		dev_get_coherent_memory(dev);
+
+	phys_addr_t addr = (phys_addr_t)sg_phys(sg);
+
+	if (addr < smem_dev->smem_base ||
+	    addr > smem_dev->smem_base + smem_dev->smem_size) {
+		dev_err(dev, "Invalid paddr 0x%llx from sg\n", addr);
+		return NULL;
+	}
+
+	return dma_mem->virt_base + (addr - smem_dev->smem_base);
+}
+
+static void mtk_dip_smem_sync_sg_for_cpu(struct device *dev,
+					 struct scatterlist *sgl, int nelems,
+					 enum dma_data_direction dir)
+{
+	struct mtk_dip_smem_drv *smem_dev =
+		dev_get_drvdata(dev);
+	void *cpu_addr;
+
+	cpu_addr = mtk_dip_smem_get_cpu_addr(smem_dev, sgl);
+
+	dev_dbg(dev,
+		  "__dma_unmap_area:paddr(0x%llx),vaddr(0x%llx),size(%d)\n",
+		  (unsigned long long)sg_phys(sgl),
+		  (unsigned long long)cpu_addr,
+		  sgl->length);
+
+	__dma_unmap_area(cpu_addr, sgl->length, dir);
+}
+
+static void mtk_dip_smem_sync_sg_for_device(struct device *dev,
+					    struct scatterlist *sgl, int nelems,
+					    enum dma_data_direction dir)
+{
+	struct mtk_dip_smem_drv *smem_dev =
+			dev_get_drvdata(dev);
+	void *cpu_addr;
+
+	cpu_addr = mtk_dip_smem_get_cpu_addr(smem_dev, sgl);
+
+	__dma_flush_area(cpu_addr, sgl->length); /* flush for cached mmap */
+
+	dev_dbg(dev,
+		  "__dma_map_area:pa(0x%llx),va(0x%llx),size(%d),dir(%d)\n",
+		  (unsigned long long)sg_phys(sgl),
+		  (unsigned long long)cpu_addr,
+		  sgl->length, dir);
+
+	__dma_map_area(cpu_addr, sgl->length, dir);
+}
+
+static int mtk_dip_smem_setup_dma_ops(struct device *dev,
+				      const struct dma_map_ops *smem_ops)
+{
+	if (!dev->dma_ops)
+		return -EINVAL;
+
+	memcpy((void *)smem_ops, dev->dma_ops, sizeof(*smem_ops));
+
+	((struct dma_map_ops *)smem_ops)->get_sgtable =
+		mtk_dip_smem_get_sgtable;
+	((struct dma_map_ops *)smem_ops)->sync_sg_for_device =
+		mtk_dip_smem_sync_sg_for_device;
+	((struct dma_map_ops *)smem_ops)->sync_sg_for_cpu =
+		mtk_dip_smem_sync_sg_for_cpu;
+
+	dev->dma_ops = smem_ops;
+
+	return 0;
+}
+
+void mtk_dip_smem_enable_mpu(struct device *dev)
+{
+	dev_warn(dev, "MPU enabling func is not ready now\n");
+}
+
+MODULE_AUTHOR("Frederic Chen <frederic.chen@mediatek.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Mediatek DIP shared memory driver");
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem.h
new file mode 100644
index 000000000000..6098181a1e9d
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-smem.h
@@ -0,0 +1,24 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_SMEM_H__
+#define __MTK_DIP_SMEM_H__
+
+#include <linux/dma-mapping.h>
+
+phys_addr_t mtk_dip_smem_iova_to_phys(struct device *smem_dev,
+				      dma_addr_t iova);
+void mtk_dip_smem_enable_mpu(struct device *smem_dev);
+#endif /*__MTK_DIP_SMEM_H__*/
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.c
new file mode 100644
index 000000000000..62a6f1c881f1
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.c
@@ -0,0 +1,1002 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 Mediatek Corporation.
+ * Copyright (c) 2017 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * MTK_DIP-v4l2 is highly based on Intel IPU 3 chrome driver
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/pm_runtime.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf2-dma-contig.h>
+#include <media/v4l2-subdev.h>
+#include <media/v4l2-event.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+
+#include "mtk_dip-dev.h"
+#include "mtk_dip-v4l2-util.h"
+
+static u32 mtk_dip_node_get_v4l2_cap
+	(struct mtk_dip_ctx_queue *node_ctx);
+
+static int mtk_dip_videoc_s_meta_fmt(struct file *file,
+				     void *fh, struct v4l2_format *f);
+
+static int mtk_dip_subdev_open(struct v4l2_subdev *sd,
+			       struct v4l2_subdev_fh *fh)
+{
+	struct mtk_dip_dev *isp_dev = mtk_dip_subdev_to_dev(sd);
+
+	isp_dev->ctx.fh = fh;
+
+	return mtk_dip_ctx_open(&isp_dev->ctx);
+}
+
+static int mtk_dip_subdev_close(struct v4l2_subdev *sd,
+				struct v4l2_subdev_fh *fh)
+{
+	struct mtk_dip_dev *isp_dev = mtk_dip_subdev_to_dev(sd);
+
+	return mtk_dip_ctx_release(&isp_dev->ctx);
+}
+
+static int mtk_dip_subdev_s_stream(struct v4l2_subdev *sd,
+				   int enable)
+{
+	int ret = 0;
+
+	struct mtk_dip_dev *isp_dev = mtk_dip_subdev_to_dev(sd);
+
+	if (enable) {
+		ret = mtk_dip_ctx_streamon(&isp_dev->ctx);
+
+		if (!ret)
+			ret = mtk_dip_dev_queue_buffers
+				(mtk_dip_ctx_to_dev(&isp_dev->ctx), 1);
+		if (ret)
+			pr_err("failed to queue initial buffers (%d)", ret);
+	}	else {
+		ret = mtk_dip_ctx_streamoff(&isp_dev->ctx);
+	}
+
+	if (!ret)
+		isp_dev->mem2mem2.streaming = enable;
+
+	return ret;
+}
+
+int mtk_dip_subdev_subscribe_event(struct v4l2_subdev *subdev,
+				   struct v4l2_fh *fh,
+				   struct v4l2_event_subscription *sub)
+{
+	pr_info("sub type(%x)", sub->type);
+	if (sub->type != V4L2_EVENT_PRIVATE_START &&
+	    sub->type != V4L2_EVENT_MTK_DIP_FRAME_DONE)
+		return -EINVAL;
+
+	return v4l2_event_subscribe(fh, sub, 0, NULL);
+}
+
+int mtk_dip_subdev_unsubscribe_event(struct v4l2_subdev *subdev,
+				     struct v4l2_fh *fh,
+	struct v4l2_event_subscription *sub)
+{
+	return v4l2_event_unsubscribe(fh, sub);
+}
+
+static int mtk_dip_link_setup(struct media_entity *entity,
+			      const struct media_pad *local,
+	const struct media_pad *remote, u32 flags)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 =
+			container_of(entity,
+				     struct mtk_dip_mem2mem2_device,
+				     subdev.entity);
+	struct mtk_dip_dev *isp_dev =
+		container_of(m2m2, struct mtk_dip_dev, mem2mem2);
+
+	u32 pad = local->index;
+
+	dev_dbg(&isp_dev->pdev->dev,
+		"link setup: %d --> %d\n", pad, remote->index);
+
+	WARN_ON(entity->obj_type != MEDIA_ENTITY_TYPE_V4L2_SUBDEV);
+
+	WARN_ON(pad >= m2m2->num_nodes);
+
+	m2m2->nodes[pad].enabled = !!(flags & MEDIA_LNK_FL_ENABLED);
+
+	/* queue_enable can be phase out in the future since */
+	/* we don't have internal queue of each node in */
+	/* v4l2 common module */
+	isp_dev->queue_enabled[pad] = m2m2->nodes[pad].enabled;
+
+	return 0;
+}
+
+static void mtk_dip_vb2_buf_queue(struct vb2_buffer *vb)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = vb2_get_drv_priv(vb->vb2_queue);
+
+	struct mtk_dip_dev *mtk_dip_dev = mtk_dip_m2m_to_dev(m2m2);
+
+	struct device *dev = &mtk_dip_dev->pdev->dev;
+
+	struct mtk_dip_dev_buffer *buf = NULL;
+
+	struct vb2_v4l2_buffer *v4l2_buf = NULL;
+
+	struct mtk_dip_dev_video_device *node =
+		mtk_dip_vbq_to_isp_node(vb->vb2_queue);
+
+	int queue = mtk_dip_dev_get_queue_id_of_dev_node(mtk_dip_dev, node);
+
+	dev_dbg(dev,
+		"queue vb2_buf: Node(%s) queue id(%d)\n",
+		node->name,
+		queue);
+
+	if (queue < 0) {
+		dev_err(m2m2->dev, "Invalid mtk_dip_dev node.\n");
+		return;
+	}
+
+	if (mtk_dip_dev->ctx.mode == MTK_DIP_CTX_MODE_DEBUG_BYPASS_ALL) {
+		dev_dbg(m2m2->dev, "By pass mode, just loop back the buffer\n");
+		vb2_buffer_done(vb, VB2_BUF_STATE_DONE);
+		return;
+	}
+
+	if (!vb)
+		pr_err("VB can't be null\n");
+
+	buf = mtk_dip_vb2_buf_to_dev_buf(vb);
+
+	if (!buf)
+		pr_err("buf can't be null\n");
+
+	v4l2_buf = to_vb2_v4l2_buffer(vb);
+
+	if (!v4l2_buf)
+		pr_err("v4l2_buf can't be null\n");
+
+	mutex_lock(&mtk_dip_dev->lock);
+
+	/* the dma address will be filled in later frame buffer handling*/
+	mtk_dip_ctx_buf_init(&buf->ctx_buf, queue, (dma_addr_t)0);
+
+	/* Added the buffer into the tracking list */
+	list_add_tail(&buf->m2m2_buf.list,
+		      &m2m2->nodes[node - m2m2->nodes].buffers);
+	mutex_unlock(&mtk_dip_dev->lock);
+
+	/* Enqueue the buffer */
+	if (mtk_dip_dev->mem2mem2.streaming) {
+		dev_dbg(dev, "%s: mtk_dip_dev_queue_buffers\n",
+		        node->name);
+		mtk_dip_dev_queue_buffers(mtk_dip_dev, 0);
+	}
+}
+
+static int mtk_dip_vb2_queue_setup(struct vb2_queue *vq,
+				   unsigned int *num_buffers,
+				unsigned int *num_planes,
+				unsigned int sizes[],
+				struct device *alloc_devs[])
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_dip_dev_video_device *node =
+		mtk_dip_vbq_to_isp_node(vq);
+	struct mtk_dip_dev *isp_dev = mtk_dip_m2m_to_dev(m2m2);
+	struct device *dev = &isp_dev->pdev->dev;
+	void *buf_alloc_ctx = NULL;
+	int queue_id = mtk_dip_dev_get_queue_id_of_dev_node(isp_dev, node);
+
+	/* Get V4L2 format with the following method */
+	const struct v4l2_format *fmt = &node->vdev_fmt;
+
+	*num_planes = 1;
+	*num_buffers = clamp_val(*num_buffers, 1, VB2_MAX_FRAME);
+
+	if (isp_dev->ctx.queue[queue_id].desc.smem_alloc) {
+		buf_alloc_ctx = isp_dev->ctx.smem_vb2_alloc_ctx;
+		dev_dbg(dev, "Select smem_vb2_alloc_ctx(%llx)\n",
+			(unsigned long long)buf_alloc_ctx);
+	} else {
+		buf_alloc_ctx = isp_dev->ctx.default_vb2_alloc_ctx;
+		dev_dbg(dev, "Select default_vb2_alloc_ctx(%llx)\n",
+			(unsigned long long)buf_alloc_ctx);
+	}
+
+	vq->dma_attrs |= DMA_ATTR_NON_CONSISTENT;
+	dev_dbg(dev, "queue(%d): cached mmap enabled\n", queue_id);
+
+	if (vq->type == V4L2_BUF_TYPE_META_CAPTURE ||
+	    vq->type == V4L2_BUF_TYPE_META_OUTPUT)
+		sizes[0] = fmt->fmt.meta.buffersize;
+	else
+		sizes[0] = fmt->fmt.pix_mp.plane_fmt[0].sizeimage;
+
+	alloc_devs[0] = (struct device *)buf_alloc_ctx;
+
+	dev_dbg(dev, "queue(%d):type(%d),size(%d),alloc_ctx(%llx)\n",
+		queue_id, vq->type, sizes[0],
+		(unsigned long long)buf_alloc_ctx);
+
+	/* Initialize buffer queue */
+	INIT_LIST_HEAD(&node->buffers);
+
+	return 0;
+}
+
+static int
+	mtk_dip_all_nodes_streaming(struct mtk_dip_mem2mem2_device *m2m2,
+				    struct mtk_dip_dev_video_device *except)
+{
+	int i;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		struct mtk_dip_dev_video_device *node = &m2m2->nodes[i];
+
+		if (node == except)
+			continue;
+		if (node->enabled && !vb2_start_streaming_called(&node->vbq))
+			return 0;
+	}
+
+	return 1;
+}
+
+static void mtk_dip_return_all_buffers(struct mtk_dip_mem2mem2_device *m2m2,
+				       struct mtk_dip_dev_video_device *node,
+					enum vb2_buffer_state state)
+{
+	struct mtk_dip_dev *mtk_dip_dev = mtk_dip_m2m_to_dev(m2m2);
+	struct mtk_dip_mem2mem2_buffer *b, *b0;
+
+	/* Return all buffers */
+	mutex_lock(&mtk_dip_dev->lock);
+	list_for_each_entry_safe(b, b0, &node->buffers, list) {
+		list_del(&b->list);
+		vb2_buffer_done(&b->vbb.vb2_buf, state);
+	}
+	mutex_unlock(&mtk_dip_dev->lock);
+}
+
+static int mtk_dip_vb2_start_streaming(struct vb2_queue *vq, unsigned int count)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_dip_dev_video_device *node =
+		mtk_dip_vbq_to_isp_node(vq);
+	int r;
+
+	if (m2m2->streaming) {
+		r = -EBUSY;
+		goto fail_return_bufs;
+	}
+
+	if (!node->enabled) {
+		pr_err("Node (%ld) is not enable\n", node - m2m2->nodes);
+		r = -EINVAL;
+		goto fail_return_bufs;
+	}
+
+	r = media_pipeline_start(&node->vdev.entity, &m2m2->pipeline);
+	if (r < 0) {
+		pr_err("Node (%ld) media_pipeline_start failed\n",
+		       node - m2m2->nodes);
+		goto fail_return_bufs;
+	}
+
+	if (!mtk_dip_all_nodes_streaming(m2m2, node))
+		return 0;
+
+	/* Start streaming of the whole pipeline now */
+
+	r = v4l2_subdev_call(&m2m2->subdev, video, s_stream, 1);
+	if (r < 0) {
+		pr_err("Node (%ld) v4l2_subdev_call s_stream failed\n",
+		       node - m2m2->nodes);
+		goto fail_stop_pipeline;
+	}
+	return 0;
+
+fail_stop_pipeline:
+	media_pipeline_stop(&node->vdev.entity);
+fail_return_bufs:
+	mtk_dip_return_all_buffers(m2m2, node, VB2_BUF_STATE_QUEUED);
+
+	return r;
+}
+
+static void mtk_dip_vb2_stop_streaming(struct vb2_queue *vq)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = vb2_get_drv_priv(vq);
+	struct mtk_dip_dev_video_device *node =
+		mtk_dip_vbq_to_isp_node(vq);
+	int r;
+
+	WARN_ON(!node->enabled);
+
+	/* Was this the first node with streaming disabled? */
+	if (mtk_dip_all_nodes_streaming(m2m2, node)) {
+		/* Yes, really stop streaming now */
+		r = v4l2_subdev_call(&m2m2->subdev, video, s_stream, 0);
+		if (r)
+			dev_err(m2m2->dev, "failed to stop streaming\n");
+	}
+
+	mtk_dip_return_all_buffers(m2m2, node, VB2_BUF_STATE_ERROR);
+	media_pipeline_stop(&node->vdev.entity);
+}
+
+static int mtk_dip_videoc_querycap(struct file *file, void *fh,
+				   struct v4l2_capability *cap)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+	struct mtk_dip_dev *isp_dev = mtk_dip_m2m_to_dev(m2m2);
+	int queue_id =
+		mtk_dip_dev_get_queue_id_of_dev_node(isp_dev, node);
+	struct mtk_dip_ctx_queue *node_ctx = &isp_dev->ctx.queue[queue_id];
+
+	strlcpy(cap->driver, m2m2->name, sizeof(cap->driver));
+	strlcpy(cap->card, m2m2->model, sizeof(cap->card));
+	snprintf(cap->bus_info, sizeof(cap->bus_info),
+		 "platform:%s", node->name);
+
+	cap->device_caps =
+		mtk_dip_node_get_v4l2_cap(node_ctx) | V4L2_CAP_STREAMING;
+	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
+
+	return 0;
+}
+
+/* Propagate forward always the format from the CIO2 subdev */
+static int mtk_dip_videoc_g_fmt(struct file *file, void *fh,
+				struct v4l2_format *f)
+{
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+static int mtk_dip_videoc_try_fmt(struct file *file,
+				  void *fh,
+	 struct v4l2_format *f)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_dip_dev *isp_dev = mtk_dip_m2m_to_dev(m2m2);
+	struct mtk_dip_ctx *dev_ctx = &isp_dev->ctx;
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+	int queue_id =
+		mtk_dip_dev_get_queue_id_of_dev_node(isp_dev, node);
+	int ret = 0;
+
+	ret = mtk_dip_ctx_fmt_set_img(dev_ctx, queue_id,
+				      &f->fmt.pix_mp,
+		&node->vdev_fmt.fmt.pix_mp);
+
+	/* Simply set the format to the node context in the initial version */
+	if (ret) {
+		pr_warn("Fmt(%d) not support for queue(%d), will load default fmt\n",
+			f->fmt.pix_mp.pixelformat, queue_id);
+
+		ret =	mtk_dip_ctx_format_load_default_fmt
+			(&dev_ctx->queue[queue_id], f);
+	}
+
+	if (!ret) {
+		node->vdev_fmt.fmt.pix_mp = f->fmt.pix_mp;
+		dev_ctx->queue[queue_id].fmt.pix_mp = node->vdev_fmt.fmt.pix_mp;
+	}
+
+	return ret;
+}
+
+static int mtk_dip_videoc_s_fmt(struct file *file, void *fh,
+				struct v4l2_format *f)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_dip_dev *isp_dev = mtk_dip_m2m_to_dev(m2m2);
+	struct mtk_dip_ctx *dev_ctx = &isp_dev->ctx;
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+	int queue_id = mtk_dip_dev_get_queue_id_of_dev_node(isp_dev, node);
+	int ret = 0;
+
+	ret = mtk_dip_ctx_fmt_set_img(dev_ctx, queue_id,
+				      &f->fmt.pix_mp,
+		&node->vdev_fmt.fmt.pix_mp);
+
+	/* Simply set the format to the node context in the initial version */
+	if (!ret)
+		dev_ctx->queue[queue_id].fmt.pix_mp = node->vdev_fmt.fmt.pix_mp;
+	else
+		dev_warn(&isp_dev->pdev->dev,
+			 "s_fmt, format not support\n");
+
+	return ret;
+}
+
+static int mtk_dip_meta_enum_format(struct file *file,
+				    void *fh, struct v4l2_fmtdesc *f)
+{
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+
+	if (f->index > 0 || f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->pixelformat = node->vdev_fmt.fmt.meta.dataformat;
+
+	return 0;
+}
+
+static int mtk_dip_videoc_s_meta_fmt(struct file *file,
+				     void *fh, struct v4l2_format *f)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = video_drvdata(file);
+	struct mtk_dip_dev *isp_dev = mtk_dip_m2m_to_dev(m2m2);
+	struct mtk_dip_ctx *dev_ctx = &isp_dev->ctx;
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+	int queue_id = mtk_dip_dev_get_queue_id_of_dev_node(isp_dev, node);
+
+	int ret = 0;
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	ret = mtk_dip_ctx_format_load_default_fmt(&dev_ctx->queue[queue_id], f);
+
+	if (!ret) {
+		node->vdev_fmt.fmt.meta = f->fmt.meta;
+		dev_ctx->queue[queue_id].fmt.meta = node->vdev_fmt.fmt.meta;
+	} else {
+		dev_warn(&isp_dev->pdev->dev,
+			 "s_meta_fm failed, format not support\n");
+	}
+
+	return ret;
+}
+
+static int mtk_dip_videoc_g_meta_fmt(struct file *file,
+				     void *fh, struct v4l2_format *f)
+{
+	struct mtk_dip_dev_video_device *node = file_to_mtk_dip_node(file);
+
+	if (f->type != node->vbq.type)
+		return -EINVAL;
+
+	f->fmt = node->vdev_fmt.fmt;
+
+	return 0;
+}
+
+/******************** function pointers ********************/
+
+/* subdev internal operations */
+static const struct v4l2_subdev_internal_ops mtk_dip_subdev_internal_ops = {
+	.open = mtk_dip_subdev_open,
+	.close = mtk_dip_subdev_close,
+};
+
+static const struct v4l2_subdev_core_ops mtk_dip_subdev_core_ops = {
+	.subscribe_event = mtk_dip_subdev_subscribe_event,
+	.unsubscribe_event = mtk_dip_subdev_unsubscribe_event,
+};
+
+static const struct v4l2_subdev_video_ops mtk_dip_subdev_video_ops = {
+	.s_stream = mtk_dip_subdev_s_stream,
+};
+
+static const struct v4l2_subdev_ops mtk_dip_subdev_ops = {
+	.core = &mtk_dip_subdev_core_ops,
+	.video = &mtk_dip_subdev_video_ops,
+};
+
+static const struct media_entity_operations mtk_dip_media_ops = {
+	.link_setup = mtk_dip_link_setup,
+	.link_validate = v4l2_subdev_link_validate,
+};
+
+static const struct vb2_ops mtk_dip_vb2_ops = {
+	.buf_queue = mtk_dip_vb2_buf_queue,
+	.queue_setup = mtk_dip_vb2_queue_setup,
+	.start_streaming = mtk_dip_vb2_start_streaming,
+	.stop_streaming = mtk_dip_vb2_stop_streaming,
+	.wait_prepare = vb2_ops_wait_prepare,
+	.wait_finish = vb2_ops_wait_finish,
+};
+
+static const struct v4l2_file_operations mtk_dip_v4l2_fops = {
+	.unlocked_ioctl = video_ioctl2,
+	.open = v4l2_fh_open,
+	.release = vb2_fop_release,
+	.poll = vb2_fop_poll,
+	.mmap = vb2_fop_mmap,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl32 = v4l2_compat_ioctl32,
+#endif
+};
+
+static const struct v4l2_ioctl_ops mtk_dip_v4l2_ioctl_ops = {
+	.vidioc_querycap = mtk_dip_videoc_querycap,
+
+	.vidioc_g_fmt_vid_cap_mplane = mtk_dip_videoc_g_fmt,
+	.vidioc_s_fmt_vid_cap_mplane = mtk_dip_videoc_s_fmt,
+	.vidioc_try_fmt_vid_cap_mplane = mtk_dip_videoc_try_fmt,
+
+	.vidioc_g_fmt_vid_out_mplane = mtk_dip_videoc_g_fmt,
+	.vidioc_s_fmt_vid_out_mplane = mtk_dip_videoc_s_fmt,
+	.vidioc_try_fmt_vid_out_mplane = mtk_dip_videoc_try_fmt,
+
+	/* buffer queue management */
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static const struct v4l2_ioctl_ops mtk_dip_v4l2_meta_ioctl_ops = {
+	.vidioc_querycap = mtk_dip_videoc_querycap,
+
+	.vidioc_enum_fmt_meta_cap = mtk_dip_meta_enum_format,
+	.vidioc_g_fmt_meta_cap = mtk_dip_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_cap = mtk_dip_videoc_s_meta_fmt,
+	.vidioc_try_fmt_meta_cap = mtk_dip_videoc_g_meta_fmt,
+
+	.vidioc_enum_fmt_meta_out = mtk_dip_meta_enum_format,
+	.vidioc_g_fmt_meta_out = mtk_dip_videoc_g_meta_fmt,
+	.vidioc_s_fmt_meta_out = mtk_dip_videoc_s_meta_fmt,
+	.vidioc_try_fmt_meta_out = mtk_dip_videoc_g_meta_fmt,
+
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+};
+
+static u32 mtk_dip_node_get_v4l2_cap(struct mtk_dip_ctx_queue *node_ctx)
+{
+	u32 cap = 0;
+
+	if (node_ctx->desc.capture)
+		if (node_ctx->desc.image)
+			cap = V4L2_CAP_VIDEO_CAPTURE_MPLANE;
+		else
+			cap = V4L2_CAP_META_CAPTURE;
+	else
+		if (node_ctx->desc.image)
+			cap = V4L2_CAP_VIDEO_OUTPUT_MPLANE;
+		else
+			cap = V4L2_CAP_META_OUTPUT;
+
+	return cap;
+}
+
+static u32 mtk_dip_node_get_format_type(struct mtk_dip_ctx_queue *node_ctx)
+{
+	u32 type;
+
+	if (node_ctx->desc.capture)
+		if (node_ctx->desc.image)
+			type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+		else
+			type = V4L2_BUF_TYPE_META_CAPTURE;
+	else
+		if (node_ctx->desc.image)
+			type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+		else
+			type = V4L2_BUF_TYPE_META_OUTPUT;
+
+	return type;
+}
+
+static const struct v4l2_ioctl_ops *mtk_dip_node_get_ioctl_ops
+	(struct mtk_dip_ctx_queue *node_ctx)
+{
+	const struct v4l2_ioctl_ops *ops = NULL;
+
+	if (node_ctx->desc.image)
+		ops = &mtk_dip_v4l2_ioctl_ops;
+	else
+		ops = &mtk_dip_v4l2_meta_ioctl_ops;
+	return ops;
+}
+
+/* Config node's video properties */
+/* according to the device context requirement */
+static void mtk_dip_node_to_v4l2(struct mtk_dip_dev *isp_dev,
+				 u32 node,
+				 struct video_device *vdev,
+				 struct v4l2_format *f)
+{
+	u32 cap;
+	struct mtk_dip_ctx *device_ctx = &isp_dev->ctx;
+	struct mtk_dip_ctx_queue *node_ctx = &device_ctx->queue[node];
+
+	WARN_ON(node >= mtk_dip_dev_get_total_node(isp_dev));
+	WARN_ON(!node_ctx);
+
+	/* set cap of the node */
+	cap = mtk_dip_node_get_v4l2_cap(node_ctx);
+	f->type = mtk_dip_node_get_format_type(node_ctx);
+	vdev->ioctl_ops = mtk_dip_node_get_ioctl_ops(node_ctx);
+
+	if (mtk_dip_ctx_format_load_default_fmt(&device_ctx->queue[node], f)) {
+		dev_err(&isp_dev->pdev->dev,
+			"Can't load default for node (%d): (%s)",
+		node, device_ctx->queue[node].desc.name);
+	}	else {
+		if (device_ctx->queue[node].desc.image) {
+			dev_dbg(&isp_dev->pdev->dev,
+				"Node (%d): (%s), dfmt (f:0x%x w:%d: h:%d s:%d)\n",
+			node, device_ctx->queue[node].desc.name,
+			f->fmt.pix_mp.pixelformat,
+			f->fmt.pix_mp.width,
+			f->fmt.pix_mp.height,
+			f->fmt.pix_mp.plane_fmt[0].sizeimage
+			);
+			node_ctx->fmt.pix_mp = f->fmt.pix_mp;
+		} else {
+			dev_info(&isp_dev->pdev->dev,
+				 "Node (%d): (%s), dfmt (f:0x%x s:%u)\n",
+			node, device_ctx->queue[node].desc.name,
+			f->fmt.meta.dataformat,
+			f->fmt.meta.buffersize
+			);
+			node_ctx->fmt.meta = f->fmt.meta;
+		}
+	}
+
+	vdev->device_caps = V4L2_CAP_STREAMING | cap;
+}
+
+int mtk_dip_media_register(struct device *dev,
+			   struct media_device *media_dev,
+	const char *model)
+{
+	int r = 0;
+
+	media_dev->dev = dev;
+	dev_info(dev, "setup media_dev.dev: %llx\n",
+		 (unsigned long long)media_dev->dev);
+
+	strlcpy(media_dev->model, model,
+		sizeof(media_dev->model));
+	dev_info(dev, "setup media_dev.model: %s\n",
+		 media_dev->model);
+
+	snprintf(media_dev->bus_info, sizeof(media_dev->bus_info),
+		 "%s", dev_name(dev));
+	dev_info(dev, "setup media_dev.bus_info: %s\n",
+		 media_dev->bus_info);
+
+	media_dev->hw_revision = 0;
+	dev_info(dev, "setup media_dev.hw_revision: %d\n",
+		 media_dev->hw_revision);
+
+
+	dev_info(dev, "media_device_init: media_dev:%llx\n",
+		 (unsigned long long)media_dev);
+	media_device_init(media_dev);
+
+	pr_info("Register media device: %s, %llx",
+		media_dev->model,
+		(unsigned long long)media_dev);
+
+	r = media_device_register(media_dev);
+
+	if (r) {
+		dev_err(dev, "failed to register media device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+	media_device_cleanup(media_dev);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_media_register);
+
+int mtk_dip_v4l2_register(struct device *dev,
+			  struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev,
+	struct v4l2_ctrl_handler *ctrl_handler
+	)
+{
+	int r = 0;
+	/* Set up v4l2 device */
+	v4l2_dev->mdev = media_dev;
+	dev_info(dev, "setup v4l2_dev->mdev: %llx",
+		 (unsigned long long)v4l2_dev->mdev);
+	v4l2_dev->ctrl_handler = ctrl_handler;
+	dev_info(dev, "setup v4l2_dev->ctrl_handler: %llx",
+		 (unsigned long long)v4l2_dev->ctrl_handler);
+
+	pr_info("Register v4l2 device: %llx",
+		(unsigned long long)v4l2_dev);
+
+	r = v4l2_device_register(dev, v4l2_dev);
+
+	if (r) {
+		dev_err(dev, "failed to register V4L2 device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+
+	return 0;
+
+fail_v4l2_dev:
+	media_device_unregister(media_dev);
+	media_device_cleanup(media_dev);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_v4l2_register);
+
+int mtk_dip_mem2mem2_v4l2_register(struct mtk_dip_dev *dev,
+				   struct media_device *media_dev,
+	struct v4l2_device *v4l2_dev)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = &dev->mem2mem2;
+
+	int i, r;
+
+	/* If media_dev or v4l2_dev is not set, */
+	/* use the default one in mtk_dip_dev */
+	if (!media_dev) {
+		m2m2->media_dev = &dev->media_dev;
+		r = mtk_dip_media_register(&dev->pdev->dev,
+					   m2m2->media_dev,
+		m2m2->model);
+
+	if (r) {
+		dev_err(m2m2->dev, "failed to register media device (%d)\n", r);
+		goto fail_media_dev;
+	}
+	} else {
+		m2m2->media_dev = media_dev;
+	}
+
+	if (!v4l2_dev) {
+		m2m2->v4l2_dev = &dev->v4l2_dev;
+		m2m2->v4l2_dev->ctrl_handler = &dev->ctx.ctrl_handler;
+		r = mtk_dip_v4l2_register(&dev->pdev->dev,
+					  m2m2->media_dev,
+			m2m2->v4l2_dev,
+			m2m2->v4l2_dev->ctrl_handler);
+
+	if (r) {
+		dev_err(m2m2->dev, "failed to register V4L2 device (%d)\n", r);
+		goto fail_v4l2_dev;
+	}
+	} else {
+		m2m2->v4l2_dev = v4l2_dev;
+	}
+
+	/* Initialize miscellaneous variables */
+	m2m2->streaming = 0;
+	m2m2->v4l2_file_ops = mtk_dip_v4l2_fops;
+
+	/* Initialize subdev media entity */
+	m2m2->subdev_pads = kcalloc(m2m2->num_nodes,
+				    sizeof(*m2m2->subdev_pads),
+				    GFP_KERNEL);
+	if (!m2m2->subdev_pads) {
+		r = -ENOMEM;
+		goto fail_subdev_pads;
+	}
+
+	r = media_entity_pads_init(&m2m2->subdev.entity, m2m2->num_nodes,
+				   m2m2->subdev_pads);
+	if (r) {
+		dev_err(m2m2->dev,
+			"failed initialize subdev media entity (%d)\n", r);
+		goto fail_media_entity;
+	}
+
+	/* Initialize subdev */
+	v4l2_subdev_init(&m2m2->subdev, &mtk_dip_subdev_ops);
+
+	m2m2->subdev.entity.function =
+		MEDIA_ENT_F_PROC_VIDEO_PIXEL_FORMATTER;
+
+	m2m2->subdev.entity.ops = &mtk_dip_media_ops;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		m2m2->subdev_pads[i].flags = m2m2->nodes[i].output ?
+			MEDIA_PAD_FL_SINK : MEDIA_PAD_FL_SOURCE;
+	}
+
+	m2m2->subdev.flags =
+		V4L2_SUBDEV_FL_HAS_DEVNODE | V4L2_SUBDEV_FL_HAS_EVENTS;
+	snprintf(m2m2->subdev.name, sizeof(m2m2->subdev.name),
+		 "%s", m2m2->name);
+	v4l2_set_subdevdata(&m2m2->subdev, m2m2);
+	m2m2->subdev.ctrl_handler = &dev->ctx.ctrl_handler;
+	m2m2->subdev.internal_ops = &mtk_dip_subdev_internal_ops;
+
+	pr_info("register subdev: %s\n", m2m2->subdev.name);
+	r = v4l2_device_register_subdev(m2m2->v4l2_dev, &m2m2->subdev);
+	if (r) {
+		dev_err(m2m2->dev, "failed initialize subdev (%d)\n", r);
+		goto fail_subdev;
+	}
+	r = v4l2_device_register_subdev_nodes(m2m2->v4l2_dev);
+	if (r) {
+		dev_err(m2m2->dev, "failed to register subdevs (%d)\n", r);
+		goto fail_subdevs;
+	}
+
+	/* Create video nodes and links */
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		struct mtk_dip_dev_video_device *node = &m2m2->nodes[i];
+		struct video_device *vdev = &node->vdev;
+		struct vb2_queue *vbq = &node->vbq;
+		u32 flags;
+
+		/* Initialize miscellaneous variables */
+		mutex_init(&node->lock);
+		INIT_LIST_HEAD(&node->buffers);
+
+		/* Initialize formats to default values */
+		mtk_dip_node_to_v4l2(dev, i, vdev, &node->vdev_fmt);
+
+		/* Initialize media entities */
+
+		r = media_entity_pads_init(&vdev->entity, 1, &node->vdev_pad);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed initialize media entity (%d)\n", r);
+			goto fail_vdev_media_entity;
+		}
+		node->vdev_pad.flags = node->output ?
+			MEDIA_PAD_FL_SOURCE : MEDIA_PAD_FL_SINK;
+		vdev->entity.ops = NULL;
+
+		/* Initialize vbq */
+		vbq->type = node->vdev_fmt.type;
+		vbq->io_modes = VB2_MMAP | VB2_DMABUF;
+		vbq->ops = &mtk_dip_vb2_ops;
+		vbq->mem_ops = m2m2->vb2_mem_ops;
+		m2m2->buf_struct_size = sizeof(struct mtk_dip_dev_buffer);
+		vbq->buf_struct_size = m2m2->buf_struct_size;
+		vbq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;
+		vbq->min_buffers_needed = 0;	/* Can streamon w/o buffers */
+		/* Put the process hub sub device in the vb2 private data*/
+		vbq->drv_priv = m2m2;
+		vbq->lock = &node->lock;
+		r = vb2_queue_init(vbq);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed to initialize video queue (%d)\n", r);
+			goto fail_vdev;
+		}
+
+		/* Initialize vdev */
+		snprintf(vdev->name, sizeof(vdev->name), "%s %s",
+			 m2m2->name, node->name);
+		vdev->release = video_device_release_empty;
+		vdev->fops = &m2m2->v4l2_file_ops;
+		vdev->lock = &node->lock;
+		vdev->ctrl_handler = &dev->ctx.queue[i].ctrl_handler;
+		vdev->v4l2_dev = m2m2->v4l2_dev;
+		vdev->queue = &node->vbq;
+		vdev->vfl_dir = node->output ? VFL_DIR_TX : VFL_DIR_RX;
+		video_set_drvdata(vdev, m2m2);
+		pr_info("register vdev: %s\n", vdev->name);
+		r = video_register_device(vdev, VFL_TYPE_GRABBER, -1);
+		if (r) {
+			dev_err(m2m2->dev,
+				"failed to register video device (%d)\n", r);
+			goto fail_vdev;
+		}
+
+		/* Create link between video node and the subdev pad */
+		flags = 0;
+		if (node->dynamic)
+			flags |= MEDIA_LNK_FL_DYNAMIC;
+		if (node->enabled)
+			flags |= MEDIA_LNK_FL_ENABLED;
+		if (node->immutable)
+			flags |= MEDIA_LNK_FL_IMMUTABLE;
+		if (node->output) {
+			r = media_create_pad_link(&vdev->entity, 0,
+						  &m2m2->subdev.entity,
+						  i, flags);
+		} else {
+			r = media_create_pad_link(&m2m2->subdev.entity,
+						  i, &vdev->entity, 0,
+						  flags);
+		}
+		if (r)
+			goto fail_link;
+	}
+
+	return 0;
+
+	for (; i >= 0; i--) {
+fail_link:
+		video_unregister_device(&m2m2->nodes[i].vdev);
+fail_vdev:
+		media_entity_cleanup(&m2m2->nodes[i].vdev.entity);
+fail_vdev_media_entity:
+		mutex_destroy(&m2m2->nodes[i].lock);
+	}
+fail_subdevs:
+	v4l2_device_unregister_subdev(&m2m2->subdev);
+fail_subdev:
+	media_entity_cleanup(&m2m2->subdev.entity);
+fail_media_entity:
+	kfree(m2m2->subdev_pads);
+fail_subdev_pads:
+	v4l2_device_unregister(m2m2->v4l2_dev);
+fail_v4l2_dev:
+fail_media_dev:
+	pr_err("fail_v4l2_dev: media_device_unregister and clenaup:%llx",
+	       (unsigned long long)m2m2->media_dev);
+	media_device_unregister(m2m2->media_dev);
+	media_device_cleanup(m2m2->media_dev);
+
+	return r;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_mem2mem2_v4l2_register);
+
+int mtk_dip_v4l2_unregister(struct mtk_dip_dev *dev)
+{
+	struct mtk_dip_mem2mem2_device *m2m2 = &dev->mem2mem2;
+	unsigned int i;
+
+	for (i = 0; i < m2m2->num_nodes; i++) {
+		video_unregister_device(&m2m2->nodes[i].vdev);
+		media_entity_cleanup(&m2m2->nodes[i].vdev.entity);
+		mutex_destroy(&m2m2->nodes[i].lock);
+	}
+
+	v4l2_device_unregister_subdev(&m2m2->subdev);
+	media_entity_cleanup(&m2m2->subdev.entity);
+	kfree(m2m2->subdev_pads);
+	v4l2_device_unregister(m2m2->v4l2_dev);
+	media_device_unregister(m2m2->media_dev);
+	media_device_cleanup(m2m2->media_dev);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mtk_dip_v4l2_unregister);
+
+void mtk_dip_v4l2_buffer_done(struct vb2_buffer *vb,
+			      enum vb2_buffer_state state)
+{
+	struct mtk_dip_mem2mem2_buffer *b =
+		container_of(vb, struct mtk_dip_mem2mem2_buffer, vbb.vb2_buf);
+
+	list_del(&b->list);
+	vb2_buffer_done(&b->vbb.vb2_buf, state);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_v4l2_buffer_done);
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.h
new file mode 100644
index 000000000000..0d0deabcb77e
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2-util.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_DEV_V4L2_H__
+#define __MTK_DIP_DEV_V4L2_H__
+
+#include <media/v4l2-device.h>
+#include <media/videobuf2-v4l2.h>
+
+/*
+ * Events
+ *
+ * V4L2_EVENT_MTK_DIP_FRAME_DONE: Hardware has finished a frame
+ */
+
+#define V4L2_EVENT_MTK_DIP_CLASS	\
+	(V4L2_EVENT_PRIVATE_START | 0x200)
+#define V4L2_EVENT_MTK_DIP_FRAME_DONE	\
+	(V4L2_EVENT_MTK_DIP_CLASS | 0x2)
+
+
+struct mtk_dip_dev_frame_done_event_data {
+	__u32 frame_id;	/* The frame id of mtk_dip_ctx_buf */
+	__u32 user_sequence;	/* reserved and not used now */
+};
+
+#endif /* __MTK_DIP_DEV_V4L2_H__ */
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.c
new file mode 100644
index 000000000000..0318c4043309
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.c
@@ -0,0 +1,360 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include "mtk_dip-ctx.h"
+#include "mtk_dip.h"
+#include "mtk_dip-v4l2.h"
+#include "mtk-mdp3-regs.h"
+
+#define MTK_DIP_DEV_DIP_MEDIA_MODEL_NAME "MTK-ISP-DIP-V4L2"
+#define MTK_DIP_DEV_DIP_PREVIEW_NAME \
+	MTK_DIP_DEV_DIP_MEDIA_MODEL_NAME
+#define MTK_DIP_DEV_DIP_CAPTURE_NAME "MTK-ISP-DIP-CAP-V4L2"
+#define MTK_DIP_DEV_DIP_REPROCESS_NAME "MTK-ISP-DIP-REP-V4L2"
+
+/* The setting for the quick conifgurtion provided */
+/* by mtk_dip_ctx_core_steup */
+struct mtk_dip_ctx_setting mtk_dip_ctx_dip_preview_setting = {
+	.device_name = MTK_DIP_DEV_DIP_PREVIEW_NAME,
+};
+
+struct mtk_dip_ctx_setting mtk_dip_ctx_dip_capture_setting = {
+	.device_name = MTK_DIP_DEV_DIP_CAPTURE_NAME,
+};
+
+struct mtk_dip_ctx_setting mtk_dip_ctx_dip_reprocess_setting = {
+	.device_name = MTK_DIP_DEV_DIP_REPROCESS_NAME,
+};
+
+static struct mtk_dip_ctx_format fw_param_fmts[] = {
+	{
+		.fmt.meta = {
+			.dataformat = V4L2_META_FMT_MTISP_PARAMS,
+			.max_buffer_size = 1024 * 128,
+		},
+	},
+};
+
+static struct mtk_dip_ctx_format in_fmts[] = {
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_MTISP_B10,
+			.mdp_color = MDP_COLOR_BAYER10,
+			.depth = { 10 },
+			.row_depth = { 10 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_MTISP_F10,
+			.mdp_color = MDP_COLOR_FULLG10,
+			.depth = { 15 },
+			.row_depth = { 15 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_VYUY,
+			.mdp_color = MDP_COLOR_VYUY,
+			.depth	 = { 16 },
+			.row_depth = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_YUYV,
+			.mdp_color = MDP_COLOR_YUYV,
+			.depth	 = { 16 },
+			.row_depth = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_YVYU,
+			.mdp_color = MDP_COLOR_YVYU,
+			.depth	 = { 16 },
+			.row_depth = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_NV12,
+			.mdp_color = MDP_COLOR_NV12,
+			.depth = { 12 },
+			.row_depth = { 8 },
+			.num_planes = 1,
+		},
+	}
+};
+
+static struct mtk_dip_ctx_format out_fmts[] = {
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_VYUY,
+			.mdp_color = MDP_COLOR_VYUY,
+			.depth = { 16 },
+			.row_depth = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_YUYV,
+			.mdp_color = MDP_COLOR_YUYV,
+			.depth = { 16 },
+			.row_depth = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_YVYU,
+			.mdp_color = MDP_COLOR_YVYU,
+			.depth = { 16 },
+			.row_depth = { 16 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_YVU420,
+			.mdp_color = MDP_COLOR_YV12,
+			.depth = { 12 },
+			.row_depth = { 8 },
+			.num_planes = 1,
+		},
+	},
+	{
+		.fmt.img = {
+			.pixelformat = V4L2_PIX_FMT_NV12,
+			.mdp_color = MDP_COLOR_NV12,
+			.depth = { 12 },
+			.row_depth = { 8 },
+			.num_planes = 1,
+		},
+	}
+};
+
+static struct mtk_dip_ctx_queue_desc
+	output_queues[MTK_DIP_CTX_P2_TOTAL_OUTPUT] = {
+	{
+		.id = MTK_DIP_CTX_P2_RAW_QUEUE_IN,
+		.name = "Raw Input",
+		.dynamic = 0,
+		.capture = 0,
+		.image = 1,
+		.smem_alloc = 0,
+		.fmts = in_fmts,
+		.num_fmts = ARRAY_SIZE(in_fmts),
+		.default_fmt_idx = 0,
+	},
+	{
+		.id = MTK_DIP_CTX_P2_TUNING_QUEUE_IN,
+		.name = "Tuning",
+		.dynamic = 0,
+		.capture = 0,
+		.image = 0,
+		.smem_alloc = 1,
+		.fmts = fw_param_fmts,
+		.num_fmts = 1,
+		.default_fmt_idx = 0,
+	},
+};
+
+static struct mtk_dip_ctx_queue_desc
+	reprocess_output_queues[MTK_DIP_CTX_P2_TOTAL_OUTPUT] = {
+	{
+		.id = MTK_DIP_CTX_P2_RAW_QUEUE_IN,
+		.name = "Raw Input",
+		.dynamic = 0,
+		.capture = 0,
+		.image = 1,
+		.smem_alloc = 0,
+		.fmts = in_fmts,
+		.num_fmts = ARRAY_SIZE(in_fmts),
+		.default_fmt_idx = 5,
+	},
+	{
+		.id = MTK_DIP_CTX_P2_TUNING_QUEUE_IN,
+		.name = "Tuning",
+		.dynamic = 0,
+		.capture = 0,
+		.image = 0,
+		.smem_alloc = 1,
+		.fmts = fw_param_fmts,
+		.num_fmts = 1,
+		.default_fmt_idx = 0,
+	},
+};
+
+static struct mtk_dip_ctx_queue_desc
+	capture_queues[MTK_DIP_CTX_P2_TOTAL_CAPTURE] = {
+	{
+		.id = MTK_DIP_CTX_P2_MDP0_QUEUE_OUT,
+		.name = "MDP0",
+		.dynamic = 1,
+		.capture = 1,
+		.image = 1,
+		.smem_alloc = 0,
+		.fmts = out_fmts,
+		.num_fmts = ARRAY_SIZE(out_fmts),
+		.default_fmt_idx = 1,
+	},
+	{
+		.id = MTK_DIP_CTX_P2_MDP1_QUEUE_OUT,
+		.name = "MDP1",
+		.dynamic = 1,
+		.capture = 1,
+		.image = 1,
+		.smem_alloc = 0,
+		.fmts = out_fmts,
+		.num_fmts = ARRAY_SIZE(out_fmts),
+		.default_fmt_idx = 1,
+	},
+};
+
+static struct mtk_dip_ctx_queues_setting preview_queues_setting = {
+	.master = MTK_DIP_CTX_P2_RAW_QUEUE_IN,
+	.output_queue_descs = output_queues,
+	.total_output_queues = MTK_DIP_CTX_P2_TOTAL_OUTPUT,
+	.capture_queue_descs = capture_queues,
+	.total_capture_queues = MTK_DIP_CTX_P2_TOTAL_CAPTURE,
+};
+
+static struct mtk_dip_ctx_queues_setting capture_queues_setting = {
+	.master = MTK_DIP_CTX_P2_RAW_QUEUE_IN,
+	.output_queue_descs = output_queues,
+	.total_output_queues = MTK_DIP_CTX_P2_TOTAL_OUTPUT,
+	.capture_queue_descs = capture_queues,
+	.total_capture_queues = MTK_DIP_CTX_P2_TOTAL_CAPTURE,
+};
+
+static struct mtk_dip_ctx_queues_setting reprocess_queues_setting = {
+	.master = MTK_DIP_CTX_P2_RAW_QUEUE_IN,
+	.output_queue_descs = reprocess_output_queues,
+	.total_output_queues = MTK_DIP_CTX_P2_TOTAL_OUTPUT,
+	.capture_queue_descs = capture_queues,
+	.total_capture_queues = MTK_DIP_CTX_P2_TOTAL_CAPTURE,
+};
+
+static struct mtk_dip_ctx_desc mtk_dip_ctx_desc_dip_preview = {
+	"proc_device_dip_preview", mtk_dip_ctx_dip_preview_init,};
+
+static struct mtk_dip_ctx_desc mtk_dip_ctx_desc_dip_capture = {
+	"proc_device_dip_capture", mtk_dip_ctx_dip_capture_init,};
+
+static struct mtk_dip_ctx_desc mtk_dip_ctx_desc_dip_reprocess = {
+	"proc_device_dip_reprocess", mtk_dip_ctx_dip_reprocess_init,};
+
+int mtk_dip_ctx_dip_v4l2_init(struct platform_device *pdev,
+			      struct mtk_dip_dev *isp_preview_dev,
+			      struct mtk_dip_dev *isp_capture_dev,
+			      struct mtk_dip_dev *isp_reprocess_dev)
+{
+	struct media_device *media_dev;
+	struct v4l2_device *v4l2_dev;
+	struct v4l2_ctrl_handler *ctrl_handler;
+	int ret = 0;
+
+	/* initialize the v4l2 common part */
+	dev_info(&pdev->dev, "init v4l2 common part: dev=%llx\n",
+		 (unsigned long long)&pdev->dev);
+
+	media_dev = &isp_preview_dev->media_dev;
+	v4l2_dev = &isp_preview_dev->v4l2_dev;
+	ctrl_handler = &isp_preview_dev->ctx.ctrl_handler;
+
+	ret = mtk_dip_media_register(&pdev->dev,
+				     media_dev,
+				     MTK_DIP_DEV_DIP_MEDIA_MODEL_NAME);
+
+	ret = mtk_dip_v4l2_register(&pdev->dev,
+				    media_dev,
+				    v4l2_dev,
+				    ctrl_handler);
+
+	dev_info(&pdev->dev, "init v4l2 preview part\n");
+	ret = mtk_dip_dev_core_init_ext(pdev,
+					isp_preview_dev,
+					&mtk_dip_ctx_desc_dip_preview,
+					media_dev, v4l2_dev);
+
+	if (ret)
+		dev_err(&pdev->dev, "Preview v4l2 part init failed: %d\n", ret);
+
+	dev_info(&pdev->dev, "init v4l2 capture part\n");
+
+	ret = mtk_dip_dev_core_init_ext(pdev,
+					isp_capture_dev,
+					&mtk_dip_ctx_desc_dip_capture,
+					media_dev, v4l2_dev);
+
+	if (ret)
+		dev_err(&pdev->dev, "Capture v4l2 part init failed: %d\n", ret);
+
+
+	ret = mtk_dip_dev_core_init_ext(pdev,
+					isp_reprocess_dev,
+					&mtk_dip_ctx_desc_dip_reprocess,
+					media_dev, v4l2_dev);
+
+	if (ret)
+		dev_err(&pdev->dev, "Reprocess v4l2 part init failed: %d\n", ret);
+
+	return ret;
+}
+
+/* MTK DIP context initialization */
+int mtk_dip_ctx_dip_preview_init(struct mtk_dip_ctx *preview_ctx)
+{
+	preview_ctx->ctx_id = MTK_DIP_CTX_P2_ID_PREVIEW;
+
+	/* Initialize main data structure */
+	mtk_dip_ctx_core_queue_setup(preview_ctx, &preview_queues_setting);
+
+	return mtk_dip_ctx_core_steup(preview_ctx,
+				      &mtk_dip_ctx_dip_preview_setting);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_dip_preview_init);
+
+int mtk_dip_ctx_dip_capture_init(struct mtk_dip_ctx *capture_ctx)
+{
+	capture_ctx->ctx_id =  MTK_DIP_CTX_P2_ID_CAPTURE;
+	/* Initialize main data structure */
+	mtk_dip_ctx_core_queue_setup(capture_ctx, &capture_queues_setting);
+
+	return mtk_dip_ctx_core_steup(capture_ctx,
+				      &mtk_dip_ctx_dip_capture_setting);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_dip_capture_init);
+
+int mtk_dip_ctx_dip_reprocess_init(struct mtk_dip_ctx *reprocess_ctx)
+{
+	reprocess_ctx->ctx_id =  MTK_DIP_CTX_P2_ID_REPROCESS;
+	/* Initialize main data structure */
+	mtk_dip_ctx_core_queue_setup(reprocess_ctx,
+				     &reprocess_queues_setting);
+
+	return mtk_dip_ctx_core_steup(reprocess_ctx,
+				      &mtk_dip_ctx_dip_reprocess_setting);
+}
+EXPORT_SYMBOL_GPL(mtk_dip_ctx_dip_reprocess_init);
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.h
new file mode 100644
index 000000000000..f66c599a8ad4
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip-v4l2.h
@@ -0,0 +1,64 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Frederic Chen <frederic.chen@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_V4L2__
+#define __MTK_DIP_V4L2__
+
+#include <linux/types.h>
+#include <linux/device.h>
+#include "mtk_dip-dev.h"
+#include "mtk_dip-core.h"
+
+#define MTK_DIP_CTX_P2_ID_PREVIEW (0)
+#define MTK_DIP_CTX_P2_ID_CAPTURE (1)
+#define MTK_DIP_CTX_P2_ID_REPROCESS (2)
+
+/* Input: RAW image */
+#define MTK_DIP_CTX_P2_RAW_QUEUE_IN		(0)
+/* Input: binary parameters */
+#define MTK_DIP_CTX_P2_TUNING_QUEUE_IN		(1)
+#define MTK_DIP_CTX_P2_TOTAL_OUTPUT (2)
+
+/* OUT: Main output for still or video */
+#define MTK_DIP_CTX_P2_MDP0_QUEUE_OUT		(2)
+/* OUT: Preview */
+#define MTK_DIP_CTX_P2_MDP1_QUEUE_OUT		(3)
+#define MTK_DIP_CTX_P2_TOTAL_CAPTURE (2)
+
+enum STREAM_TYPE_ENUM {
+		STREAM_UNKNOWN,
+		STREAM_BITBLT,
+		STREAM_GPU_BITBLT,
+		STREAM_DUAL_BITBLT,
+		STREAM_2ND_BITBLT,
+		STREAM_ISP_IC,
+		STREAM_ISP_VR,
+		STREAM_ISP_ZSD,
+		STREAM_ISP_IP,
+		STREAM_ISP_VSS,
+		STREAM_ISP_ZSD_SLOW,
+		STREAM_WPE,
+		STREAM_WPE2,
+};
+
+int mtk_dip_ctx_dip_preview_init(struct mtk_dip_ctx *preview_ctx);
+int mtk_dip_ctx_dip_capture_init(struct mtk_dip_ctx *capture_ctx);
+int mtk_dip_ctx_dip_reprocess_init(struct mtk_dip_ctx *reprocess_ctx);
+
+int mtk_dip_ctx_dip_v4l2_init(struct platform_device *pdev,
+			      struct mtk_dip_dev *isp_preview_dev,
+			      struct mtk_dip_dev *isp_capture_dev,
+			      struct mtk_dip_dev *isp_reprocess_dev);
+#endif /*__MTK_DIP_V4L2__*/
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.c b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.c
new file mode 100644
index 000000000000..975177051541
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.c
@@ -0,0 +1,1420 @@
+// SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Holmes Chiou <holmes.chiou@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/of_device.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/kthread.h> /* thread functions */
+#include <linux/pm_runtime.h>
+#include <linux/dma-iommu.h>
+#include <linux/spinlock.h>
+#include <linux/slab.h> /* kzalloc and kfree */
+
+#include <linux/remoteproc.h>
+#include <linux/platform_data/mtk_scp.h>
+#include "mtk-mdp3-cmdq.h"
+
+#include "mtk_dip-dev.h"
+#include "mtk_dip.h"
+#include "mtk_dip-core.h"
+#include "mtk_dip-v4l2.h"
+
+#define DIP_DEV_NAME		"camera-dip"
+
+#define DIP_COMPOSER_THREAD_TIMEOUT     (16U)
+#define DIP_COMPOSING_WQ_TIMEOUT	(16U)
+#define DIP_COMPOSING_MAX_NUM		(3)
+#define DIP_FLUSHING_WQ_TIMEOUT		(16U)
+
+#define DIP_MAX_ERR_COUNT		(188U)
+
+#define DIP_FRM_SZ		(76 * 1024)
+#define DIP_SUB_FRM_SZ		(16 * 1024)
+#define DIP_TUNING_SZ		(32 * 1024)
+#define DIP_COMP_SZ		(24 * 1024)
+#define DIP_FRAMEPARAM_SZ	(4 * 1024)
+
+#define DIP_TUNING_OFFSET	(DIP_SUB_FRM_SZ)
+#define DIP_COMP_OFFSET		(DIP_TUNING_OFFSET + DIP_TUNING_SZ)
+#define DIP_FRAMEPARAM_OFFSET	(DIP_COMP_OFFSET + DIP_COMP_SZ)
+
+#define DIP_SUB_FRM_DATA_NUM	(32)
+
+#define DIP_SCP_WORKINGBUF_OFFSET	(5 * 1024 * 1024)
+
+#define DIP_GET_ID(x)			(((x) & 0xffff0000) >> 16)
+
+static const struct of_device_id dip_of_ids[] = {
+	/* Remider: Add this device node manually in .dtsi */
+	{ .compatible = "mediatek,mt8183-dip", },
+	{}
+};
+
+static void call_mtk_dip_ctx_finish(struct dip_device *dip_dev,
+				    struct img_ipi_frameparam *iparam);
+
+static struct img_frameparam *dip_create_framejob(int sequence)
+{
+	struct dip_frame_job *fjob = NULL;
+
+	fjob = kzalloc(sizeof(*fjob), GFP_ATOMIC);
+
+	if (!fjob)
+		return NULL;
+
+	fjob->sequence = sequence;
+
+	return &fjob->fparam;
+}
+
+static void dip_free_framejob(struct img_frameparam *fparam)
+{
+	struct dip_frame_job *fjob = NULL;
+
+	fjob = mtk_dip_fparam_to_job(fparam);
+
+	/* to avoid use after free issue */
+	fjob->sequence = -1;
+
+	kfree(fjob);
+}
+
+static void dip_enable_ccf_clock(struct dip_device *dip_dev)
+{
+	int ret;
+
+	ret = pm_runtime_get_sync(dip_dev->larb_dev);
+	if (ret < 0)
+		dev_err(&dip_dev->pdev->dev, "cannot get smi larb clock\n");
+
+	ret = clk_prepare_enable(dip_dev->dip_clk.DIP_IMG_LARB5);
+	if (ret)
+		dev_err(&dip_dev->pdev->dev,
+			"cannot prepare and enable DIP_IMG_LARB5 clock\n");
+
+	ret = clk_prepare_enable(dip_dev->dip_clk.DIP_IMG_DIP);
+	if (ret)
+		dev_err(&dip_dev->pdev->dev,
+			"cannot prepare and enable DIP_IMG_DIP clock\n");
+}
+
+static void dip_disable_ccf_clock(struct dip_device *dip_dev)
+{
+	clk_disable_unprepare(dip_dev->dip_clk.DIP_IMG_DIP);
+	clk_disable_unprepare(dip_dev->dip_clk.DIP_IMG_LARB5);
+	pm_runtime_put_sync(dip_dev->larb_dev);
+}
+
+static int dip_send(struct platform_device *pdev, enum scp_ipi_id id,
+		    void *buf, unsigned int  len, unsigned int wait)
+{
+	return scp_ipi_send(pdev, id, buf, len, wait);
+}
+
+static void call_mtk_dip_ctx_finish(struct dip_device *dip_dev,
+				    struct img_ipi_frameparam *iparam)
+{
+	struct mtk_dip_ctx_finish_param fparam;
+	struct mtk_isp_dip_drv_data *drv_data;
+	struct mtk_dip_ctx *dev_ctx;
+	struct mtk_dip_dev *isp_dev;
+
+	int ctx_id = 0;
+	int r = 0;
+
+	if (!dip_dev) {
+		pr_err("Can't update buffer status, dip_dev can't be NULL\n");
+		return;
+	}
+
+	if (!iparam) {
+		dev_err(&dip_dev->pdev->dev,
+			"%s: iparam can't be NULL\n", __func__);
+		return;
+	}
+
+	drv_data = dip_dev_to_drv(dip_dev);
+
+	frame_param_ipi_to_ctx(iparam, &fparam);
+	ctx_id = MTK_DIP_GET_CTX_ID_FROM_SEQUENCE(fparam.frame_id);
+
+	if (ctx_id == MTK_DIP_CTX_P2_ID_PREVIEW) {
+		dev_ctx = &drv_data->isp_preview_dev.ctx;
+	} else if (ctx_id == MTK_DIP_CTX_P2_ID_CAPTURE) {
+		dev_ctx = &drv_data->isp_capture_dev.ctx;
+	} else if (ctx_id == MTK_DIP_CTX_P2_ID_REPROCESS) {
+		dev_ctx = &drv_data->isp_reprocess_dev.ctx;
+	} else {
+		dev_err(&dip_dev->pdev->dev,
+			"unknown ctx id: %d\n", ctx_id);
+		return;
+	}
+
+	isp_dev = mtk_dip_ctx_to_dev(dev_ctx);
+	mutex_lock(&isp_dev->lock);
+	r = mtk_dip_ctx_core_job_finish(dev_ctx, &fparam);
+	mutex_unlock(&isp_dev->lock);
+
+	if (r)
+		dev_err(&dip_dev->pdev->dev, "finish op failed: %d\n",
+			r);
+	dev_dbg(&dip_dev->pdev->dev, "Ready to return buffers: CTX(%d), Frame(%d)\n",
+		ctx_id, fparam.frame_id);
+}
+
+static void mtk_dip_notify(void *data)
+{
+	struct dip_device	*dip_dev;
+	struct mtk_dip_hw_ctx	*dip_ctx;
+	struct img_frameparam	*framejob;
+	struct dip_user_id	*user_id;
+	struct dip_subframe	*buf, *tmpbuf;
+	struct img_ipi_frameparam	*frameparam;
+    struct img_ipi_param ipi_param;
+	u32 num;
+	bool found = false;
+
+	frameparam = (struct img_ipi_frameparam *)data;
+	dip_ctx = (struct mtk_dip_hw_ctx *)frameparam->drv_data;
+	dip_dev = container_of(dip_ctx, struct dip_device, dip_ctx);
+	framejob = container_of(frameparam,
+				struct img_frameparam,
+				frameparam);
+
+	if (frameparam->state == FRAME_STATE_HW_TIMEOUT) {
+        ipi_param.usage = IMG_IPI_DEBUG;
+        dip_send(dip_ctx->vpu_pdev, SCP_IPI_DIP,
+            (void *)&ipi_param, sizeof(ipi_param), 0);
+        dev_err(&dip_dev->pdev->dev, "frame no(%d) HW timeout\n",
+			frameparam->frame_no);
+	}
+
+	mutex_lock(&dip_ctx->dip_usedbufferlist.queuelock);
+	list_for_each_entry_safe(buf, tmpbuf,
+				 &dip_ctx->dip_usedbufferlist.queue,
+				 list_entry) {
+		if (buf->buffer.pa == frameparam->subfrm_data.pa) {
+			list_del(&buf->list_entry);
+			dip_ctx->dip_usedbufferlist.queue_cnt--;
+			found = true;
+			dev_dbg(&dip_dev->pdev->dev,
+				"Find used buffer (%x)\n", buf->buffer.pa);
+			break;
+		}
+	}
+	mutex_unlock(&dip_ctx->dip_usedbufferlist.queuelock);
+
+	if (!found) {
+		dev_err(&dip_dev->pdev->dev,
+			"frame_no(%d) buffer(%x) used buffer count(%d)\n",
+			frameparam->frame_no, frameparam->subfrm_data.pa,
+			dip_ctx->dip_usedbufferlist.queue_cnt);
+
+		frameparam->state = FRAME_STATE_ERROR;
+
+	} else {
+		mutex_lock(&dip_ctx->dip_freebufferlist.queuelock);
+		list_add_tail(&buf->list_entry,
+			      &dip_ctx->dip_freebufferlist.queue);
+		dip_ctx->dip_freebufferlist.queue_cnt++;
+		mutex_unlock(&dip_ctx->dip_freebufferlist.queuelock);
+
+		frameparam->state = FRAME_STATE_DONE;
+	}
+
+	call_mtk_dip_ctx_finish(dip_dev, frameparam);
+
+	found = false;
+	mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+	list_for_each_entry(user_id,
+			    &dip_ctx->dip_useridlist.queue,
+			    list_entry) {
+		if (DIP_GET_ID(frameparam->index) == user_id->id) {
+			user_id->num--;
+			dev_dbg(&dip_dev->pdev->dev,
+				"user_id(%x) is found, and cnt: %d\n",
+				user_id->id, user_id->num);
+			found = true;
+			break;
+		}
+	}
+	mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+	wake_up(&dip_ctx->flushing_wq);
+	dev_dbg(&dip_dev->pdev->dev,
+		"frame_no(%d) is finished\n", framejob->frameparam.frame_no);
+	dip_free_framejob(framejob);
+
+	num = atomic_dec_return(&dip_ctx->num_running);
+	dev_dbg(&dip_dev->pdev->dev, "Running count: %d\n", num);
+}
+
+static void mdp_cb_worker(struct work_struct *work)
+{
+	struct mtk_mdpcb_work *mdpcb_work;
+
+	mdpcb_work = container_of(work, struct mtk_mdpcb_work, frame_work);
+	mtk_dip_notify(mdpcb_work->frameparams);
+	kfree(mdpcb_work);
+}
+
+static struct img_ipi_frameparam *convert_to_fparam(struct cmdq_cb_data *data)
+{
+	struct device *dev = NULL;
+	struct dip_device *dip_dev = NULL;
+	struct dip_frame_job *fjob = NULL;
+	struct img_ipi_frameparam *ipi_fparam = NULL;
+
+	if (!data) {
+		dev_err(dev, "DIP got NULL in cmdq_cb_data,%s\n",
+			__func__);
+		return NULL;
+	}
+
+	if (data->sta != CMDQ_CB_NORMAL) {
+		dev_warn(dev, "DIP got CMDQ CB (%d) without CMDQ_CB_NORMAL\n",
+			 data->sta);
+	}
+
+	if (!data->data) {
+		dev_err(dev, "DIP got NULL data in cmdq_cb_data,%s\n",
+			__func__);
+		return NULL;
+	}
+
+	fjob = mtk_dip_ipi_fparam_to_job(data->data);
+
+	if (fjob->sequence == -1) {
+		dev_err(dev, "Invalid cmdq_cb_data(%llx)\n",
+			(unsigned long long)data);
+		ipi_fparam = NULL;
+	} else {
+		ipi_fparam = &fjob->fparam.frameparam;
+		dip_dev = dip_hw_ctx_to_dev((void *)ipi_fparam->drv_data);
+		dev = &dip_dev->pdev->dev;
+	}
+
+	dev_dbg(dev, "framejob(0x%llx,seq:%d):\n",
+		(unsigned long long)fjob, fjob->sequence);
+	dev_dbg(dev, "idx(%d),no(%d),s(%d),n_in(%d),n_out(%d),drv(%llx)\n",
+		fjob->fparam.frameparam.index,
+		fjob->fparam.frameparam.frame_no,
+		fjob->fparam.frameparam.state,
+		fjob->fparam.frameparam.num_inputs,
+		fjob->fparam.frameparam.num_outputs,
+		(unsigned long long)fjob->fparam.frameparam.drv_data
+	);
+
+	return ipi_fparam;
+}
+
+/* Maybe in IRQ context of cmdq */
+void dip_mdp_cb_func(struct cmdq_cb_data data)
+{
+	struct img_ipi_frameparam *frameparam;
+	struct mtk_dip_hw_ctx *dip_ctx;
+	struct mtk_mdpcb_work *mdpcb_work;
+
+	frameparam = convert_to_fparam(&data);
+
+	if (!frameparam) {
+		dev_err(NULL, "%s return due to invalid cmdq_cb_data(%llx)",
+			__func__, &data);
+		return;
+	}
+
+	dip_ctx = (struct mtk_dip_hw_ctx *)frameparam->drv_data;
+
+	mdpcb_work = kzalloc(sizeof(*mdpcb_work), GFP_ATOMIC);
+	WARN_ONCE(!mdpcb_work, "frame_no(%d) is lost", frameparam->frame_no);
+	if (!mdpcb_work)
+		return;
+
+	INIT_WORK(&mdpcb_work->frame_work, mdp_cb_worker);
+	mdpcb_work->frameparams = frameparam;
+	if (data.sta != CMDQ_CB_NORMAL)
+		mdpcb_work->frameparams->state = FRAME_STATE_HW_TIMEOUT;
+
+	queue_work(dip_ctx->mdpcb_workqueue, &mdpcb_work->frame_work);
+}
+
+static void dip_vpu_handler(void *data, unsigned int len, void *priv)
+{
+	struct img_frameparam *framejob;
+	struct img_ipi_frameparam *frameparam;
+	struct mtk_dip_hw_ctx *dip_ctx;
+	struct dip_device *dip_dev;
+    struct img_ipi_param *ipi_param;
+	unsigned long flags;
+	u32 num;
+
+	WARN_ONCE(!data, "%s is failed due to NULL data\n", __func__);
+	if (!data)
+		return;
+
+    ipi_param = (struct img_ipi_param *)data;
+    frameparam = (struct img_ipi_frameparam *)ipi_param->frm_param.va;
+
+	framejob = dip_create_framejob(frameparam->index);
+	WARN_ONCE(!framejob, "frame_no(%d) is lost", frameparam->frame_no);
+	if (!framejob)
+		return;
+
+	dip_ctx = (struct mtk_dip_hw_ctx *)frameparam->drv_data;
+	dip_dev = container_of(dip_ctx, struct dip_device, dip_ctx);
+
+	wake_up(&dip_ctx->composing_wq);
+	memcpy(&framejob->frameparam, frameparam, sizeof(framejob->frameparam));
+	num = atomic_dec_return(&dip_ctx->num_composing);
+
+	spin_lock_irqsave(&dip_ctx->dip_gcejoblist.queuelock, flags);
+	list_add_tail(&framejob->list_entry, &dip_ctx->dip_gcejoblist.queue);
+	dip_ctx->dip_gcejoblist.queue_cnt++;
+	spin_unlock_irqrestore(&dip_ctx->dip_gcejoblist.queuelock, flags);
+
+	dev_dbg(&dip_dev->pdev->dev,
+		"frame_no(%d) is back, composing num: %d\n",
+		frameparam->frame_no, num);
+
+	wake_up(&dip_ctx->dip_runner_thread.wq);
+}
+
+static int dip_runner_func(void *data)
+{
+	struct img_frameparam	*framejob;
+	struct mtk_dip_hw_ctx	*dip_ctx;
+	struct dip_device	*dip_dev;
+	struct dip_user_id	*user_id;
+	unsigned long		flags;
+	bool			found;
+	u32			queuecnt, num;
+	int			ret;
+
+	dip_ctx = (struct mtk_dip_hw_ctx *)data;
+	dip_dev = container_of(dip_ctx, struct dip_device, dip_ctx);
+
+	while (1) {
+		spin_lock_irqsave(&dip_ctx->dip_gcejoblist.queuelock, flags);
+		queuecnt = dip_ctx->dip_gcejoblist.queue_cnt;
+		spin_unlock_irqrestore(&dip_ctx->dip_gcejoblist.queuelock,
+				       flags);
+
+		ret = wait_event_interruptible_timeout
+			(dip_ctx->dip_runner_thread.wq,
+			 queuecnt || kthread_should_stop(),
+			 msecs_to_jiffies(DIP_COMPOSER_THREAD_TIMEOUT));
+
+		if (kthread_should_stop())
+			break;
+
+		if (ret == 0) {
+			/* Timeout */
+			ret = -ETIME;
+		} else if (ret == -ERESTARTSYS) {
+			dev_err(&dip_dev->pdev->dev,
+				"interrupted by a signal!\n");
+		}
+
+		if (queuecnt > 0) {
+			spin_lock_irqsave(&dip_ctx->dip_gcejoblist.queuelock,
+					  flags);
+			framejob = list_first_entry
+				(&dip_ctx->dip_gcejoblist.queue,
+				 struct img_frameparam, list_entry);
+
+			dip_ctx->dip_gcejoblist.queue_cnt--;
+			list_del(&framejob->list_entry);
+			spin_unlock_irqrestore
+				(&dip_ctx->dip_gcejoblist.queuelock, flags);
+
+			found = false;
+			mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+			list_for_each_entry(user_id,
+					    &dip_ctx->dip_useridlist.queue,
+					    list_entry) {
+				if (DIP_GET_ID(framejob->frameparam.index) ==
+					user_id->id) {
+					found = true;
+					break;
+				}
+			}
+			mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+			if (!found) {
+				dev_err(&dip_dev->pdev->dev,
+					"frame_no(%d) index: %x is abnormal\n",
+					framejob->frameparam.frame_no,
+					framejob->frameparam.index);
+				/* Due to error index, DIP driver could NOT  */
+				/* notify the V4L2 common driver to  */
+				/* return buffer */
+				dip_free_framejob(framejob);
+				continue;
+			}
+
+			mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+			if (user_id->state == DIP_STATE_STREAMOFF) {
+				mutex_unlock
+					(&dip_ctx->dip_useridlist.queuelock);
+
+				framejob->frameparam.state =
+					FRAME_STATE_STREAMOFF;
+				call_mtk_dip_ctx_finish(dip_dev,
+							&framejob->frameparam);
+				mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+				user_id->num--;
+				mutex_unlock
+					(&dip_ctx->dip_useridlist.queuelock);
+
+				dev_dbg(&dip_dev->pdev->dev,
+					"user_id(%x) streamoff, current num:%d, frame_no(%d) flushed\n",
+					user_id->id, user_id->num,
+					framejob->frameparam.frame_no);
+
+				dip_free_framejob(framejob);
+				continue;
+			}
+			mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+			dev_dbg(&dip_dev->pdev->dev,
+				"MDP Run frame_no(%d) and the rest joblist count: %d\n",
+				framejob->frameparam.frame_no,
+				dip_ctx->dip_gcejoblist.queue_cnt);
+
+			/* Call MDP/GCE API to do HW excecution
+			 * Pass the framejob to MDP driver
+			 */
+			framejob->frameparam.state = FRAME_STATE_COMPOSING;
+
+			mdp_cmdq_sendtask
+				(dip_ctx->mdp_pdev,
+				 (struct img_config *)
+					framejob->frameparam.config_data.va,
+				 &framejob->frameparam, NULL, false,
+				 dip_mdp_cb_func,
+				 (void *)&framejob->frameparam);
+
+			num = atomic_inc_return(&dip_ctx->num_running);
+			dev_dbg(&dip_dev->pdev->dev,
+				"MDP Running num: %d\n", num);
+		}
+
+	};
+
+	return 0;
+}
+
+static void dip_submit_worker(struct work_struct *work)
+{
+	struct mtk_dip_submit_work *dip_submit_work =
+		container_of(work, struct mtk_dip_submit_work, frame_work);
+
+	struct mtk_dip_hw_ctx  *dip_ctx = dip_submit_work->dip_ctx;
+	struct mtk_dip_work *dip_work;
+	struct dip_device *dip_dev;
+	struct dip_subframe *buf;
+    struct img_ipi_param ipi_param;
+	u32 len, num;
+	int ret;
+
+	dip_dev = container_of(dip_ctx, struct dip_device, dip_ctx);
+	num  = atomic_read(&dip_ctx->num_composing);
+
+	mutex_lock(&dip_ctx->dip_worklist.queuelock);
+	dip_work = list_first_entry(&dip_ctx->dip_worklist.queue,
+				    struct mtk_dip_work, list_entry);
+	mutex_unlock(&dip_ctx->dip_worklist.queuelock);
+
+	mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+	if (dip_work->user_id->state == DIP_STATE_STREAMOFF) {
+		mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+		dip_work->frameparams.state = FRAME_STATE_STREAMOFF;
+		call_mtk_dip_ctx_finish(dip_dev, &dip_work->frameparams);
+
+		mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+		dip_work->user_id->num--;
+		dev_dbg(&dip_dev->pdev->dev,
+			"user_id(%x) is streamoff and num: %d, frame_no(%d) index: %x\n",
+			dip_work->user_id->id, dip_work->user_id->num,
+			dip_work->frameparams.frame_no,
+			dip_work->frameparams.index);
+		mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+		goto free_work_list;
+	}
+	mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+	while (num >= DIP_COMPOSING_MAX_NUM) {
+		ret = wait_event_interruptible_timeout
+			(dip_ctx->composing_wq,
+			 (num < DIP_COMPOSING_MAX_NUM),
+			 msecs_to_jiffies(DIP_COMPOSING_WQ_TIMEOUT));
+
+		if (ret == -ERESTARTSYS)
+			dev_err(&dip_dev->pdev->dev,
+				"interrupted by a signal!\n");
+		else if (ret == 0)
+			dev_dbg(&dip_dev->pdev->dev,
+				"timeout frame_no(%d), num: %d\n",
+				dip_work->frameparams.frame_no, num);
+		else
+			dev_dbg(&dip_dev->pdev->dev,
+				"wakeup frame_no(%d), num: %d\n",
+				dip_work->frameparams.frame_no, num);
+
+		num = atomic_read(&dip_ctx->num_composing);
+	};
+
+	mutex_lock(&dip_ctx->dip_freebufferlist.queuelock);
+	if (list_empty(&dip_ctx->dip_freebufferlist.queue)) {
+		mutex_unlock(&dip_ctx->dip_freebufferlist.queuelock);
+
+		dev_err(&dip_dev->pdev->dev,
+			"frame_no(%d) index: %x no free buffer: %d\n",
+			dip_work->frameparams.frame_no,
+			dip_work->frameparams.index,
+			dip_ctx->dip_freebufferlist.queue_cnt);
+
+		/* Call callback to notify V4L2 common framework
+		 * for failure of enqueue
+		 */
+		dip_work->frameparams.state = FRAME_STATE_ERROR;
+		call_mtk_dip_ctx_finish(dip_dev, &dip_work->frameparams);
+
+		mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+		dip_work->user_id->num--;
+		mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+		goto free_work_list;
+	}
+
+	buf = list_first_entry(&dip_ctx->dip_freebufferlist.queue,
+			       struct dip_subframe,
+			       list_entry);
+	list_del(&buf->list_entry);
+	dip_ctx->dip_freebufferlist.queue_cnt--;
+	mutex_unlock(&dip_ctx->dip_freebufferlist.queuelock);
+
+	mutex_lock(&dip_ctx->dip_usedbufferlist.queuelock);
+	list_add_tail(&buf->list_entry, &dip_ctx->dip_usedbufferlist.queue);
+	dip_ctx->dip_usedbufferlist.queue_cnt++;
+	mutex_unlock(&dip_ctx->dip_usedbufferlist.queuelock);
+
+	memcpy(&dip_work->frameparams.subfrm_data,
+	       &buf->buffer, sizeof(buf->buffer));
+
+	memset((char *)buf->buffer.va, 0, DIP_SUB_FRM_SZ);
+
+	memcpy(&dip_work->frameparams.config_data,
+	       &buf->config_data, sizeof(buf->config_data));
+
+	memset((char *)buf->config_data.va, 0, DIP_COMP_SZ);
+
+	if (dip_work->frameparams.tuning_data.pa == 0) {
+		dev_dbg(&dip_dev->pdev->dev,
+			"frame_no(%d) has no tuning_data\n",
+			dip_work->frameparams.frame_no);
+
+		memcpy(&dip_work->frameparams.tuning_data,
+		       &buf->tuning_buf, sizeof(buf->tuning_buf));
+
+		memset((char *)buf->tuning_buf.va, 0, DIP_TUNING_SZ);
+		/* When user enqueued without tuning buffer,
+		 * it would use driver internal buffer.
+		 * So, tuning_data.va should be 0
+		 */
+		dip_work->frameparams.tuning_data.va = 0;
+	}
+
+	dip_work->frameparams.drv_data = (u64)dip_ctx;
+	dip_work->frameparams.state = FRAME_STATE_COMPOSING;
+
+    dip_work->frameparams.self_data.va = buf->frameparam.va;
+    dip_work->frameparams.self_data.pa = buf->frameparam.pa;
+
+	memcpy((void *)buf->frameparam.va, &dip_work->frameparams,
+	       sizeof(dip_work->frameparams));
+
+    ipi_param.usage = IMG_IPI_FRAME;
+    ipi_param.frm_param.va = buf->frameparam.va;
+    ipi_param.frm_param.pa = buf->frameparam.pa;
+    dip_send(dip_ctx->vpu_pdev, SCP_IPI_DIP,(void *)&ipi_param, sizeof(ipi_param), 0);
+	num = atomic_inc_return(&dip_ctx->num_composing);
+
+free_work_list:
+
+	mutex_lock(&dip_ctx->dip_worklist.queuelock);
+	list_del(&dip_work->list_entry);
+	dip_ctx->dip_worklist.queue_cnt--;
+	len = dip_ctx->dip_worklist.queue_cnt;
+	mutex_unlock(&dip_ctx->dip_worklist.queuelock);
+
+	dev_dbg(&dip_dev->pdev->dev,
+		"frame_no(%d) index: %x, worklist count: %d, composing num: %d\n",
+		dip_work->frameparams.frame_no, dip_work->frameparams.index,
+		len, num);
+
+	kfree(dip_work);
+}
+
+static void dip_setclock(struct dip_device *dip_dev, bool enable)
+{
+	if (enable) {
+		dev_dbg(&dip_dev->pdev->dev, "CCF:prepare_enable clk\n");
+		dip_enable_ccf_clock(dip_dev);
+	} else {
+		dev_dbg(&dip_dev->pdev->dev, "CCF:disable_unprepare clk\n");
+		dip_disable_ccf_clock(dip_dev);
+	}
+}
+
+int dip_open_context(struct dip_device *dip_dev)
+{
+	u32 i;
+	phys_addr_t scp_mem_pa;
+	u64 scp_mem_va;
+	int ret = 0;
+	struct mtk_dip_hw_ctx *dip_ctx;
+
+	dip_ctx = &dip_dev->dip_ctx;
+
+	dip_ctx->mdp_pdev = mdp_get_plat_device(dip_dev->pdev);
+	if (!dip_ctx->mdp_pdev) {
+		dev_dbg(&dip_dev->pdev->dev, "Failed to get MDP device\n");
+		return -EINVAL;
+	}
+
+	init_waitqueue_head(&dip_ctx->dip_runner_thread.wq);
+
+	/*  All lists in DIP initialization */
+	INIT_LIST_HEAD(&dip_ctx->dip_gcejoblist.queue);
+	spin_lock_init(&dip_ctx->dip_gcejoblist.queuelock);
+	dip_ctx->dip_gcejoblist.queue_cnt = 0;
+
+	INIT_LIST_HEAD(&dip_ctx->dip_freebufferlist.queue);
+	mutex_init(&dip_ctx->dip_freebufferlist.queuelock);
+	dip_ctx->dip_freebufferlist.queue_cnt = 0;
+
+	INIT_LIST_HEAD(&dip_ctx->dip_usedbufferlist.queue);
+	mutex_init(&dip_ctx->dip_usedbufferlist.queuelock);
+	dip_ctx->dip_usedbufferlist.queue_cnt = 0;
+
+	dip_ctx->mdpcb_workqueue =
+		create_singlethread_workqueue("mdp_callback");
+	if (!dip_ctx->mdpcb_workqueue) {
+		dev_err(&dip_dev->pdev->dev,
+			"unable to alloc mdpcb workqueue\n");
+		ret = -ENOMEM;
+		goto err_alloc_mdpcb_wq;
+	}
+
+	dip_ctx->composer_wq =
+		create_singlethread_workqueue("dip_composer");
+	if (!dip_ctx->composer_wq) {
+		dev_err(&dip_dev->pdev->dev,
+			"unable to alloc composer workqueue\n");
+		ret = -ENOMEM;
+		goto err_alloc_composer_wq;
+	}
+	init_waitqueue_head(&dip_ctx->composing_wq);
+	init_waitqueue_head(&dip_ctx->flushing_wq);
+
+	dip_ctx->submit_work.dip_ctx = dip_ctx;
+	INIT_WORK(&dip_ctx->submit_work.frame_work, dip_submit_worker);
+
+	INIT_LIST_HEAD(&dip_ctx->dip_worklist.queue);
+	mutex_init(&dip_ctx->dip_worklist.queuelock);
+	dip_ctx->dip_worklist.queue_cnt = 0;
+
+	INIT_LIST_HEAD(&dip_ctx->dip_useridlist.queue);
+	mutex_init(&dip_ctx->dip_useridlist.queuelock);
+	dip_ctx->dip_useridlist.queue_cnt = 0;
+
+	dip_ctx->dip_runner_thread.thread =
+		kthread_run(dip_runner_func, (void *)dip_ctx, "dip_runner");
+
+	if (IS_ERR(dip_ctx->dip_runner_thread.thread)) {
+		dev_err(&dip_dev->pdev->dev, "unable to alloc workqueue\n");
+		ret = PTR_ERR(dip_ctx->dip_runner_thread.thread);
+		dip_ctx->dip_runner_thread.thread = NULL;
+		goto err_create_thread;
+	}
+
+	scp_mem_va = scp_get_reserve_mem_virt(SCP_DIP_MEM_ID);
+	scp_mem_pa = scp_get_reserve_mem_phys(SCP_DIP_MEM_ID);
+	dip_ctx->scp_workingbuf_addr = scp_mem_pa + DIP_SCP_WORKINGBUF_OFFSET;
+	dev_dbg(&dip_dev->pdev->dev,
+		"scp_mem_va: %llx, pa: %llx\n", scp_mem_va, (u64)scp_mem_pa);
+
+    scp_ipi_register(dip_ctx->vpu_pdev, SCP_IPI_DIP, dip_vpu_handler, NULL);
+
+	for (i = 0; i < DIP_SUB_FRM_DATA_NUM; i++) {
+		u32 size_align;
+		struct dip_subframe *buf;
+		struct sg_table *sgt;
+		struct page **pages;
+		u32 npages, j;
+
+		buf = kzalloc(sizeof(*buf), GFP_KERNEL);
+		if (!buf) {
+			ret = -ENOMEM;
+			goto err_create_thread;
+		}
+
+		/* Total: 0 ~ 72 KB
+		 * SubFrame: 0 ~ 16 KB
+		 */
+		buf->buffer.pa = scp_mem_pa + i * DIP_FRM_SZ;
+		buf->buffer.va = scp_mem_va + i * DIP_FRM_SZ;
+
+		/* Tuning: 16 ~ 48 KB */
+		buf->tuning_buf.pa = buf->buffer.pa + DIP_TUNING_OFFSET;
+		buf->tuning_buf.va = buf->buffer.va + DIP_TUNING_OFFSET;
+
+		/* Config_data: 48 ~ 72 KB */
+		buf->config_data.pa = buf->buffer.pa + DIP_COMP_OFFSET;
+		buf->config_data.va = buf->buffer.va + DIP_COMP_OFFSET;
+
+		/* Frame parameters: 72 ~ 76 KB */
+		buf->frameparam.pa = buf->buffer.pa + DIP_FRAMEPARAM_OFFSET;
+		buf->frameparam.va = buf->buffer.va + DIP_FRAMEPARAM_OFFSET;
+
+		/* get iova */
+		npages = (DIP_SUB_FRM_SZ + DIP_TUNING_SZ) >> PAGE_SHIFT;
+		pages = kmalloc_array(npages,
+				      sizeof(struct page *),
+				      GFP_KERNEL);
+		if (!pages) {
+			kfree(buf);
+			ret = -ENOMEM;
+			goto err_create_thread;
+		}
+
+		sgt = &buf->table;
+		for (j = 0; j < npages; j++)
+			pages[j] =
+				phys_to_page(buf->buffer.pa + j * PAGE_SIZE);
+
+		size_align = round_up(DIP_SUB_FRM_SZ + DIP_TUNING_SZ,
+				      PAGE_SIZE);
+		ret = sg_alloc_table_from_pages(sgt, pages, npages,
+						0, size_align, GFP_KERNEL);
+		if (ret < 0) {
+			dev_err(&dip_dev->pdev->dev,
+				"failed to get sgt from pages.\n");
+			ret = -ENOMEM;
+			kfree(pages);
+			kfree(buf);
+			goto err_create_thread;
+		}
+
+		dma_map_sg_attrs(&dip_dev->pdev->dev, sgt->sgl, sgt->nents,
+				 DMA_BIDIRECTIONAL, DMA_ATTR_SKIP_CPU_SYNC);
+		buf->buffer.iova = sg_dma_address(buf->table.sgl);
+		buf->tuning_buf.iova = buf->buffer.iova +
+			DIP_TUNING_OFFSET;
+
+		dev_dbg(&dip_dev->pdev->dev,
+			"buf pa (%d): %x, %x\n", i,
+			buf->buffer.pa,
+			buf->buffer.iova);
+
+		dev_dbg(&dip_dev->pdev->dev,
+			"config_data pa (%d): %x, %llx\n", i,
+			buf->config_data.pa,
+			buf->config_data.va);
+
+		dev_dbg(&dip_dev->pdev->dev,
+			"tuning_buf pa (%d): %x, %x\n", i,
+			buf->tuning_buf.pa,
+			buf->tuning_buf.iova);
+
+		dev_dbg(&dip_dev->pdev->dev,
+			"frameparam pa (%d): %x, %llx\n", i,
+			buf->frameparam.pa,
+			buf->frameparam.va);
+
+		list_add_tail(&buf->list_entry,
+			      &dip_ctx->dip_freebufferlist.queue);
+		dip_ctx->dip_freebufferlist.queue_cnt++;
+		kfree(pages);
+	}
+
+	return 0;
+
+err_create_thread:
+	mutex_destroy(&dip_ctx->dip_useridlist.queuelock);
+	mutex_destroy(&dip_ctx->dip_worklist.queuelock);
+	mutex_destroy(&dip_ctx->dip_usedbufferlist.queuelock);
+	mutex_destroy(&dip_ctx->dip_freebufferlist.queuelock);
+
+err_alloc_composer_wq:
+	destroy_workqueue(dip_ctx->composer_wq);
+
+err_alloc_mdpcb_wq:
+	destroy_workqueue(dip_ctx->mdpcb_workqueue);
+
+	return ret;
+}
+
+int dip_release_context(struct dip_device *dip_dev)
+{
+	u32 i = 0;
+	struct dip_subframe *buf, *tmpbuf;
+	struct mtk_dip_work *dip_work, *tmp_work;
+	struct dip_user_id  *dip_userid, *tmp_id;
+	struct mtk_dip_hw_ctx *dip_ctx;
+
+	dip_ctx = &dip_dev->dip_ctx;
+	dev_dbg(&dip_dev->pdev->dev, "composer work queue = %d\n",
+		dip_ctx->dip_worklist.queue_cnt);
+
+	list_for_each_entry_safe(dip_work, tmp_work,
+				 &dip_ctx->dip_worklist.queue,
+				 list_entry) {
+		list_del(&dip_work->list_entry);
+		dev_dbg(&dip_dev->pdev->dev, "dip work frame no: %d\n",
+			dip_work->frameparams.frame_no);
+		kfree(dip_work);
+		dip_ctx->dip_worklist.queue_cnt--;
+	}
+
+	if (dip_ctx->dip_worklist.queue_cnt != 0)
+		dev_dbg(&dip_dev->pdev->dev,
+			"dip_worklist is not empty (%d)\n",
+			dip_ctx->dip_worklist.queue_cnt);
+
+	list_for_each_entry_safe(dip_userid, tmp_id,
+				 &dip_ctx->dip_useridlist.queue,
+				 list_entry) {
+		list_del(&dip_userid->list_entry);
+		dev_dbg(&dip_dev->pdev->dev, "dip user id: %x\n",
+			dip_userid->id);
+		kfree(dip_userid);
+		dip_ctx->dip_useridlist.queue_cnt--;
+	}
+
+	if (dip_ctx->dip_useridlist.queue_cnt != 0)
+		dev_dbg(&dip_dev->pdev->dev,
+			"dip_useridlist is not empty (%d)\n",
+			dip_ctx->dip_useridlist.queue_cnt);
+
+	flush_workqueue(dip_ctx->mdpcb_workqueue);
+	destroy_workqueue(dip_ctx->mdpcb_workqueue);
+	dip_ctx->mdpcb_workqueue = NULL;
+
+	flush_workqueue(dip_ctx->composer_wq);
+	destroy_workqueue(dip_ctx->composer_wq);
+	dip_ctx->composer_wq = NULL;
+
+	atomic_set(&dip_ctx->num_composing, 0);
+	atomic_set(&dip_ctx->num_running, 0);
+
+	kthread_stop(dip_ctx->dip_runner_thread.thread);
+	dip_ctx->dip_runner_thread.thread = NULL;
+
+	atomic_set(&dip_ctx->dip_user_cnt, 0);
+	atomic_set(&dip_ctx->dip_stream_cnt, 0);
+	atomic_set(&dip_ctx->dip_enque_cnt, 0);
+
+	/* All the buffer should be in the freebufferlist when release */
+	list_for_each_entry_safe(buf, tmpbuf,
+				 &dip_ctx->dip_freebufferlist.queue,
+				 list_entry) {
+		struct sg_table *sgt = &buf->table;
+
+		dev_dbg(&dip_dev->pdev->dev,
+			"buf pa (%d): %x\n", i, buf->buffer.pa);
+		dip_ctx->dip_freebufferlist.queue_cnt--;
+		dma_unmap_sg_attrs(&dip_dev->pdev->dev, sgt->sgl,
+				   sgt->orig_nents,
+				   DMA_BIDIRECTIONAL, DMA_ATTR_SKIP_CPU_SYNC);
+		sg_free_table(sgt);
+		list_del(&buf->list_entry);
+		kfree(buf);
+		buf = NULL;
+		i++;
+	}
+
+	if (dip_ctx->dip_freebufferlist.queue_cnt != 0 &&
+	    i != DIP_SUB_FRM_DATA_NUM)
+		dev_err(&dip_dev->pdev->dev,
+			"dip_freebufferlist is not empty (%d/%d)\n",
+			dip_ctx->dip_freebufferlist.queue_cnt, i);
+
+	mutex_destroy(&dip_ctx->dip_useridlist.queuelock);
+	mutex_destroy(&dip_ctx->dip_worklist.queuelock);
+	mutex_destroy(&dip_ctx->dip_usedbufferlist.queuelock);
+	mutex_destroy(&dip_ctx->dip_freebufferlist.queuelock);
+
+	return 0;
+}
+
+static int mtk_dip_flush_by_id(struct platform_device *pdev,
+			       u16 id,
+			       struct dip_user_id *user_id)
+{
+	struct mtk_dip_hw_ctx	*dip_ctx;
+	struct dip_device	*dip_dev;
+
+	u32			num, err_cnt;
+	int			ret;
+
+	dip_dev = get_dip_device(&pdev->dev);
+	dip_ctx = &dip_dev->dip_ctx;
+
+	err_cnt = 0;
+	do {
+		mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+		num = user_id->num;
+		mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+		ret = wait_event_interruptible_timeout
+			(dip_ctx->flushing_wq,
+			 (num == 0),
+			 msecs_to_jiffies(DIP_FLUSHING_WQ_TIMEOUT));
+
+		if (ret == -ERESTARTSYS)
+			dev_err(&dip_dev->pdev->dev,
+				"interrupted by a signal! num: %d\n", num);
+		else if (ret == 0)
+			dev_dbg(&dip_dev->pdev->dev,
+				"timeout num: %d\n", num);
+		else
+			dev_dbg(&dip_dev->pdev->dev,
+				"wakeup  num: %d\n", num);
+
+		err_cnt++;
+
+		if (num > 0 && err_cnt >= DIP_MAX_ERR_COUNT) {
+			dev_err(&dip_dev->pdev->dev,
+				"Flushing is aborted num: %d, err_cnt: %d\n",
+				num, err_cnt);
+			return -EINVAL;
+		}
+
+	} while (num > 0);
+
+	dev_dbg(&dip_dev->pdev->dev, "Flushing is done num: %d\n", num);
+	return 0;
+}
+
+int mtk_dip_open(struct platform_device *pdev)
+{
+	int ret = 0;
+	s32 usercount;
+	struct dip_device *dip_dev;
+	struct mtk_dip_hw_ctx *dip_ctx;
+    struct img_ipi_param ipi_param;
+	phandle rproc_phandle;
+
+	if (!pdev) {
+		dev_err(&dip_dev->pdev->dev, "platform device is NULL\n");
+		return -EINVAL;
+	}
+
+	dip_dev = get_dip_device(&pdev->dev);
+	dip_ctx = &dip_dev->dip_ctx;
+	dev_dbg(&dip_dev->pdev->dev, "open dip_dev = 0x%p\n", dip_dev);
+
+	usercount = atomic_inc_return(&dip_dev->dip_ctx.dip_user_cnt);
+
+	if (usercount == 1) {
+		struct img_ipi_frameparam frameparam;
+
+		dip_ctx->vpu_pdev = scp_get_pdev(dip_dev->pdev);
+		if (!dip_ctx->vpu_pdev) {
+			dev_err(&dip_dev->pdev->dev,
+				"Failed to get VPU device\n");
+			return -EINVAL;
+		}
+
+		if (of_property_read_u32(pdev->dev.of_node, "mediatek,scp",
+					 &rproc_phandle)) {
+			dev_err(&dip_dev->pdev->dev,
+				"Could not get scp device\n");
+			return  -EINVAL;
+		}
+
+		dip_ctx->rproc_handle = rproc_get_by_phandle(rproc_phandle);
+
+		if (!dip_ctx->rproc_handle) {
+			dev_err(&dip_dev->pdev->dev,
+				"Could not get DIP's rproc_handle\n");
+			return  -EINVAL;
+		}
+
+		dev_info(&pdev->dev, "DIP rproc_phandle: %llx",
+			 (unsigned long long)dip_ctx->rproc_handle);
+
+		ret = rproc_boot(dip_ctx->rproc_handle);
+
+		if (ret < 0) {
+			/*
+			 * Return 0 if downloading firmware successfully,
+			 * otherwise it is failed
+			 */
+			dev_err(&dip_dev->pdev->dev,
+				"rproc_boot failed: %d", ret);
+			return -EINVAL;
+		}
+
+		/* Enable clock */
+		dip_setclock(dip_dev, true);
+
+		/* DIP HW INIT */
+		memset(&frameparam, 0, sizeof(frameparam));
+		/* SCP only support 32bits address */
+		frameparam.drv_data = (u64)dip_ctx;
+		frameparam.state = FRAME_STATE_INIT;
+        ipi_param.usage = IMG_IPI_INIT;
+		dip_send(dip_ctx->vpu_pdev, SCP_IPI_DIP,
+			 (void *)&ipi_param, sizeof(ipi_param), 0);
+		dip_open_context(dip_dev);
+	}
+
+	dev_dbg(&dip_dev->pdev->dev, "usercount = %d\n", usercount);
+	return ret;
+}
+EXPORT_SYMBOL(mtk_dip_open);
+
+int mtk_dip_release(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct dip_device *dip_dev;
+
+	if (!pdev) {
+		dev_err(&dip_dev->pdev->dev, "platform device is NULL\n");
+		return -EINVAL;
+	}
+
+	dip_dev = get_dip_device(&pdev->dev);
+
+	dev_dbg(&dip_dev->pdev->dev, "release dip_dev = 0x%p\n", dip_dev);
+
+	if (atomic_dec_and_test(&dip_dev->dip_ctx.dip_user_cnt)) {
+		dip_release_context(dip_dev);
+		dip_setclock(dip_dev, false);
+	}
+	dev_dbg(&dip_dev->pdev->dev, "usercount = %d\n",
+		atomic_read(&dip_dev->dip_ctx.dip_user_cnt));
+
+	return ret;
+}
+EXPORT_SYMBOL(mtk_dip_release);
+
+int mtk_dip_streamon(struct platform_device *pdev, u16 id)
+{
+	struct dip_device *dip_dev;
+	struct dip_user_id *user_id;
+	struct mtk_dip_hw_ctx *dip_ctx;
+	s32 count, len;
+
+	dip_dev = get_dip_device(&pdev->dev);
+	dip_ctx = &dip_dev->dip_ctx;
+	count = atomic_inc_return(&dip_ctx->dip_stream_cnt);
+
+	dev_dbg(&dip_dev->pdev->dev, "%s id: %x\n", __func__, id);
+
+	user_id = kzalloc(sizeof(*user_id), GFP_KERNEL);
+	if (!user_id)
+		return -ENOMEM;
+
+	user_id->id = id;
+	user_id->state = DIP_STATE_STREAMON;
+
+	mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+	list_add_tail(&user_id->list_entry, &dip_ctx->dip_useridlist.queue);
+	dip_ctx->dip_useridlist.queue_cnt++;
+	len = dip_ctx->dip_useridlist.queue_cnt;
+	mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+	dev_dbg(&dip_dev->pdev->dev,
+		"stream count = %d,  id: %x len: %d\n", count, id, len);
+
+	return 0;
+}
+EXPORT_SYMBOL(mtk_dip_streamon);
+
+int mtk_dip_streamoff(struct platform_device *pdev, u16 id)
+{
+	struct dip_device  *dip_dev;
+	struct dip_user_id *user_id;
+	struct mtk_dip_hw_ctx *dip_ctx;
+	s32 count = -1;
+	bool found = false;
+	int ret;
+
+	dip_dev = get_dip_device(&pdev->dev);
+	dip_ctx = &dip_dev->dip_ctx;
+	dev_dbg(&dip_dev->pdev->dev, "streamoff id (%x)\n", id);
+
+	mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+	list_for_each_entry(user_id,
+			    &dip_ctx->dip_useridlist.queue, list_entry) {
+		if (user_id->id == id) {
+			user_id->state = DIP_STATE_STREAMOFF;
+			found = true;
+			break;
+		}
+	}
+	mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+	if (found) {
+		ret = mtk_dip_flush_by_id(pdev, id, user_id);
+		if (ret != 0) {
+			dev_err(&dip_dev->pdev->dev,
+				"stream id(%x) streamoff error: %d\n",
+				id, ret);
+			WARN_ON(1);
+		}
+
+		mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+		list_del(&user_id->list_entry);
+		dip_ctx->dip_useridlist.queue_cnt--;
+		dev_dbg(&dip_dev->pdev->dev,
+			"stream id(%x) user_id count: %d\n",
+			id, dip_ctx->dip_useridlist.queue_cnt);
+		mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+		kfree(user_id);
+		user_id = NULL;
+		count = atomic_dec_return(&dip_ctx->dip_stream_cnt);
+
+		dev_dbg(&dip_dev->pdev->dev, "stream id(%x) count = %d\n",
+			id, count);
+	} else {
+		dev_dbg(&dip_dev->pdev->dev,
+			"stream id(%x) is not found\n", id);
+	}
+
+	if (count < 0)
+		return -EINVAL;
+
+	return 0;
+}
+EXPORT_SYMBOL(mtk_dip_streamoff);
+
+int mtk_dip_enqueue(struct platform_device *pdev,
+		    struct img_ipi_frameparam *frameparams)
+{
+	struct mtk_dip_work	*framework = NULL;
+	struct mtk_dip_hw_ctx	*dip_ctx = NULL;
+	struct dip_device	*dip_dev = NULL;
+	struct dip_user_id	*user_id = NULL;
+	bool	found = false;
+	u32	tmpcount;
+
+	dip_dev = get_dip_device(&pdev->dev);
+	dip_ctx = &dip_dev->dip_ctx;
+
+	dev_dbg(&dip_dev->pdev->dev, "%s index: %x",
+		__func__, frameparams->index);
+
+	mutex_lock(&dip_ctx->dip_useridlist.queuelock);
+	list_for_each_entry(user_id, &dip_ctx->dip_useridlist.queue,
+			    list_entry) {
+		if (DIP_GET_ID(frameparams->index) == user_id->id) {
+			user_id->num++;
+			dev_dbg(&dip_dev->pdev->dev,
+				"user_id(%x) is found and current num: %d\n",
+				user_id->id, user_id->num);
+			found = true;
+			break;
+		}
+	}
+	mutex_unlock(&dip_ctx->dip_useridlist.queuelock);
+
+	if (!found) {
+		dev_err(&dip_dev->pdev->dev,
+			"user_id(%x) can NOT be found, index: %x\n",
+			DIP_GET_ID(frameparams->index),
+			frameparams->index);
+		return -EINVAL;
+	}
+
+	framework = kzalloc(sizeof(*framework), GFP_KERNEL);
+	if (!framework)
+		return -ENOMEM;
+
+	memcpy(&framework->frameparams, frameparams, sizeof(*frameparams));
+	framework->frameparams.state = FRAME_STATE_INIT;
+	framework->frameparams.frame_no =
+		atomic_inc_return(&dip_ctx->dip_enque_cnt);
+	framework->user_id = user_id;
+
+	mutex_lock(&dip_dev->dip_ctx.dip_worklist.queuelock);
+	list_add_tail(&framework->list_entry, &dip_ctx->dip_worklist.queue);
+	dip_ctx->dip_worklist.queue_cnt++;
+	tmpcount = dip_ctx->dip_worklist.queue_cnt;
+	mutex_unlock(&dip_ctx->dip_worklist.queuelock);
+	dev_dbg(&dip_dev->pdev->dev, "frame_no(%d) into worklist count: %d\n",
+		framework->frameparams.frame_no, tmpcount);
+
+	queue_work(dip_ctx->composer_wq, &dip_ctx->submit_work.frame_work);
+	return 0;
+}
+EXPORT_SYMBOL(mtk_dip_enqueue);
+
+static int mtk_dip_probe(struct platform_device *pdev)
+{
+	struct mtk_isp_dip_drv_data *dip_drv;
+	struct dip_device *dip_dev;
+	struct mtk_dip_hw_ctx *dip_ctx;
+	struct device_node *node;
+	struct platform_device *larb_pdev;
+
+	int ret = 0;
+
+	dev_info(&pdev->dev, "E. DIP driver probe.\n");
+
+	dip_drv = devm_kzalloc(&pdev->dev, sizeof(*dip_drv), GFP_KERNEL);
+	dev_set_drvdata(&pdev->dev, dip_drv);
+	dip_dev = &dip_drv->dip_dev;
+
+	if (!dip_dev)
+		return -ENOMEM;
+
+	dev_info(&pdev->dev, "Created dip_dev = 0x%p\n", dip_dev);
+
+	dip_dev->pdev = pdev;
+	dip_ctx = &dip_dev->dip_ctx;
+
+	node = of_parse_phandle(pdev->dev.of_node, "mediatek,larb", 0);
+	if (!node) {
+		dev_err(&pdev->dev, "no mediatek,larb found");
+		return -EINVAL;
+	}
+	larb_pdev = of_find_device_by_node(node);
+	if (!larb_pdev) {
+		dev_err(&pdev->dev, "no mediatek,larb device found");
+		return -EINVAL;
+	}
+	dip_dev->larb_dev = &larb_pdev->dev;
+
+	/*CCF: Grab clock pointer (struct clk*) */
+	dip_dev->dip_clk.DIP_IMG_LARB5 = devm_clk_get(&pdev->dev,
+						      "DIP_CG_IMG_LARB5");
+	dip_dev->dip_clk.DIP_IMG_DIP = devm_clk_get(&pdev->dev,
+						    "DIP_CG_IMG_DIP");
+	if (IS_ERR(dip_dev->dip_clk.DIP_IMG_LARB5)) {
+		dev_err(&pdev->dev, "cannot get DIP_IMG_LARB5 clock\n");
+		return PTR_ERR(dip_dev->dip_clk.DIP_IMG_LARB5);
+	}
+	if (IS_ERR(dip_dev->dip_clk.DIP_IMG_DIP)) {
+		dev_err(&pdev->dev, "cannot get DIP_IMG_DIP clock\n");
+		return PTR_ERR(dip_dev->dip_clk.DIP_IMG_DIP);
+	}
+
+	pm_runtime_enable(&pdev->dev);
+
+	atomic_set(&dip_ctx->dip_user_cnt, 0);
+	atomic_set(&dip_ctx->dip_stream_cnt, 0);
+	atomic_set(&dip_ctx->dip_enque_cnt, 0);
+
+	atomic_set(&dip_ctx->num_composing, 0);
+	atomic_set(&dip_ctx->num_running, 0);
+
+	dip_ctx->dip_worklist.queue_cnt = 0;
+
+	ret = mtk_dip_ctx_dip_v4l2_init(pdev,
+					&dip_drv->isp_preview_dev,
+					&dip_drv->isp_capture_dev,
+					&dip_drv->isp_reprocess_dev);
+
+	if (ret)
+		dev_err(&pdev->dev, "v4l2 init failed: %d\n", ret);
+
+	dev_info(&pdev->dev, "X. DIP driver probe.\n");
+
+	return ret;
+}
+
+static int mtk_dip_remove(struct platform_device *pdev)
+{
+	struct mtk_isp_dip_drv_data *drv_data =
+		dev_get_drvdata(&pdev->dev);
+
+	if (drv_data) {
+		mtk_dip_dev_core_release(pdev, &drv_data->isp_preview_dev);
+		mtk_dip_dev_core_release(pdev, &drv_data->isp_capture_dev);
+		mtk_dip_dev_core_release(pdev, &drv_data->isp_reprocess_dev);
+	}
+
+	pm_runtime_disable(&pdev->dev);
+
+	return 0;
+}
+
+static int __maybe_unused mtk_dip_pm_suspend(struct device *dev)
+{
+	struct dip_device *dip = get_dip_device(dev);
+
+	if (atomic_read(&dip->dip_ctx.dip_user_cnt) > 0) {
+		dip_setclock(dip, false);
+		dev_dbg(&dip->pdev->dev, "Disable clock\n");
+	}
+
+	return 0;
+}
+
+static int __maybe_unused mtk_dip_pm_resume(struct device *dev)
+{
+	struct dip_device *dip = get_dip_device(dev);
+
+	if (atomic_read(&dip->dip_ctx.dip_user_cnt) > 0) {
+		dip_setclock(dip, true);
+		dev_dbg(&dip->pdev->dev, "Enable clock\n");
+	}
+
+	return 0;
+}
+
+static int __maybe_unused mtk_dip_suspend(struct device *dev)
+{
+	if (pm_runtime_suspended(dev))
+		return 0;
+
+	return mtk_dip_pm_suspend(dev);
+}
+
+static int __maybe_unused mtk_dip_resume(struct device *dev)
+{
+	if (pm_runtime_suspended(dev))
+		return 0;
+
+	return mtk_dip_pm_resume(dev);
+}
+
+static const struct dev_pm_ops mtk_dip_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(mtk_dip_suspend, mtk_dip_resume)
+	SET_RUNTIME_PM_OPS(mtk_dip_suspend, mtk_dip_resume, NULL)
+};
+
+static struct platform_driver mtk_dip_driver = {
+	.probe   = mtk_dip_probe,
+	.remove  = mtk_dip_remove,
+	.driver  = {
+		.name  = DIP_DEV_NAME,
+		.owner = THIS_MODULE,
+		.of_match_table = dip_of_ids,
+		.pm     = &mtk_dip_pm_ops,
+	}
+};
+
+module_platform_driver(mtk_dip_driver);
+
+MODULE_DESCRIPTION("Camera DIP driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.h b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.h
new file mode 100644
index 000000000000..6650c4ae98f6
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/dip/mtk_dip.h
@@ -0,0 +1,93 @@
+// SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note
+/*
+ * Copyright (C) 2018 MediaTek Inc.
+ * Author: Holmes Chiou <holmes.chiou@mediatek.com>
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_DIP_H
+#define __MTK_DIP_H
+
+#include "mtk-img-ipi.h"
+
+enum frame_state {
+	FRAME_STATE_INIT	= 0,
+	FRAME_STATE_COMPOSING,
+	FRAME_STATE_RUNNING,
+	FRAME_STATE_DONE,
+	FRAME_STATE_STREAMOFF,
+	FRAME_STATE_ERROR,
+	FRAME_STATE_HW_TIMEOUT
+};
+
+/**
+ * mtk_dip_enqueue - enqueue to dip driver
+ *
+ * @pdev:	DIP platform device
+ * @img_ipi_frameparam:	frame parameters
+ *
+ * Enqueue a frame to dip driver.
+ *
+ * Return: Return 0 if ipi registers successfully, otherwise it is failed.
+ */
+int	mtk_dip_enqueue(struct platform_device *pdev,
+			struct img_ipi_frameparam *frameparams);
+
+/**
+ * mtk_dip_open -
+ *
+ * @pdev:	DIP platform device
+ * @img_ipi_frameparam:	frame parameters
+ *
+ * Enqueue a frame to dip driver.
+ *
+ * Return: Return 0 if ipi registers successfully, otherwise it is failed.
+ */
+int mtk_dip_open(struct platform_device *pdev);
+
+/**
+ * mtk_dip_release -
+ *
+ * @pdev:	DIP platform device
+ * @img_ipi_frameparam:	frame parameters
+ *
+ * Enqueue a frame to dip driver.
+ *
+ * Return: Return 0 if ipi registers successfully, otherwise it is failed.
+ */
+int mtk_dip_release(struct platform_device *pdev);
+
+/**
+ * mtk_dip_streamon -
+ *
+ * @pdev:	DIP platform device
+ * @img_ipi_frameparam:	frame parameters
+ *
+ * Enqueue a frame to dip driver.
+ *
+ * Return: Return 0 if ipi registers successfully, otherwise it is failed.
+ */
+int mtk_dip_streamon(struct platform_device *pdev, u16 id);
+
+/**
+ * mtk_dip_streamoff -
+ *
+ * @pdev:	DIP platform device
+ * @img_ipi_frameparam:	frame parameters
+ *
+ * Enqueue a frame to dip driver.
+ *
+ * Return: Return 0 if ipi registers successfully, otherwise it is failed.
+ */
+int mtk_dip_streamoff(struct platform_device *pdev, u16 id);
+
+#endif /* __MTK_DIP_H */
+
diff --git a/drivers/media/platform/mtk-isp/isp_50/seninf/Makefile b/drivers/media/platform/mtk-isp/isp_50/seninf/Makefile
new file mode 100755
index 000000000000..f1b2e2d2be3b
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/seninf/Makefile
@@ -0,0 +1,4 @@
+MODULE		= mtk_seninf
+LIB_FILES	= mtk_seninf
+
+obj-$(CONFIG_MTK_SENINF) += mtk_seninf.o
diff --git a/drivers/media/platform/mtk-isp/isp_50/seninf/mtk_seninf.c b/drivers/media/platform/mtk-isp/isp_50/seninf/mtk_seninf.c
new file mode 100644
index 000000000000..7ac8a4a259c0
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/seninf/mtk_seninf.c
@@ -0,0 +1,1339 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2016 MediaTek Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See http://www.gnu.org/licenses/gpl-2.0.html for more details.
+ */
+
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/pm_runtime.h>
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include <linux/of_platform.h>
+#include <linux/of.h>
+#include <linux/of_graph.h>
+#include <linux/of_irq.h>
+#include <linux/of_address.h>
+#include <linux/vmalloc.h>
+#ifdef CONFIG_COMPAT
+#include <linux/compat.h>
+#endif
+#include <linux/videodev2.h>
+#include <media/v4l2-common.h>
+#include <media/v4l2-dev.h>
+#include <media/v4l2-device.h>
+#include <media/v4l2-subdev.h>
+#include <media/v4l2-fwnode.h>
+#include <media/v4l2-ctrls.h>
+#include <media/v4l2-async.h>
+#include <media/media-entity.h>
+#include "seninf_reg.h"
+#include "seninf_drv_def.h"
+
+#define IS_4D1C (csi_info->port < CFG_CSI_PORT_0A)
+#define IS_CDPHY_COMBO (csi_info->port == CFG_CSI_PORT_0A ||\
+	csi_info->port == CFG_CSI_PORT_0B ||\
+	csi_info->port == CFG_CSI_PORT_0)
+
+static struct seninf_csi_info SENINF_CSI_INFO[CFG_CSI_PORT_MAX_NUM] = {
+	{CFG_CSI_PORT_0,  SENINF_1},
+	{CFG_CSI_PORT_1,  SENINF_3},
+	{CFG_CSI_PORT_2,  SENINF_5},
+	{CFG_CSI_PORT_0A, SENINF_1},
+	{CFG_CSI_PORT_0B, SENINF_2},
+};
+
+static struct sensor_vc_info_struct SENSOR_VC_INFO[2] = {
+	/* Preview mode setting */
+	{
+		0x02, 0x0A, 0x00, 0x08, 0x40, 0x00,
+		0x00, 0x2B, 0x0500, 0x02D0, 0x00, 0x00, 0x0000, 0x0000,
+		0x00, 0x00, 0x0000, 0x0000, 0x00, 0x00, 0x0000, 0x0000
+	},
+	/* Capture mode setting */
+	{
+		0x02, 0x0A, 0x00, 0x08, 0x40, 0x00,
+		0x00, 0x2B, 0x1080, 0x0C40, 0x00, 0x00, 0x0000, 0x0000,
+		0x01, 0x2B, 0x0100, 0x0300, 0x00, 0x00, 0x0000, 0x0000
+	}
+};
+
+struct _seninf {
+	struct v4l2_subdev subdev;
+	struct device *dev;
+	struct v4l2_fwnode_endpoint ep[2];
+	struct v4l2_ctrl_handler ctrl_handler;
+	struct v4l2_ctrl *test_pattern;
+	struct media_pad pads[NUM_PADS];
+	struct clk *cam_clk, *top_mux_clk;
+	unsigned int port;
+	int format;
+	int dpcm;
+	int mux_select;
+	void __iomem *base_reg;
+	void __iomem *rx_reg;
+	unsigned char *seninf_hw;
+	unsigned char *seninf_ctrl[SENINF_NUM];
+	unsigned char *seninf_mux[SENINF_MUX_NUM];
+	unsigned char *csi2_rx[CFG_CSI_PORT_MAX_NUM];
+	unsigned char *csi_rx_conf[SENINF_NUM];
+};
+
+static int set_top_mux_ctrl(struct _seninf *priv,
+			    unsigned int mux_idx, unsigned int seninf_src
+)
+{
+	int ret = 0;
+	void *pseninf = priv->seninf_hw;
+
+	seninf_write_reg(pseninf, SENINF_TOP_MUX_CTRL,
+			 ((seninf_read_reg(pseninf, SENINF_TOP_MUX_CTRL) &
+			 (~(0xF << (mux_idx * 4)))) | ((seninf_src & 0xF)
+			 << (mux_idx * 4))));
+	return ret;
+}
+
+static int __attribute__((unused))
+	set_tg_mux_ctrl(struct _seninf *priv,
+			unsigned int target_tg, unsigned int mux_src
+)
+{
+	int ret = 0;
+	void *pseninf = priv->seninf_hw;
+
+	seninf_write_reg(pseninf, SENINF_TOP_CAM_MUX_CTRL,
+			 ((seninf_read_reg(pseninf,
+			 SENINF_TOP_CAM_MUX_CTRL) &
+			 (~(0xF << (target_tg * 4)))) | ((mux_src & 0xF)
+			 << (target_tg * 4))));
+	return ret;
+}
+
+static int set_virtual_channel(struct _seninf *priv, unsigned int seninf_sel,
+			       unsigned int vc0_id, unsigned int vc1_id,
+			       unsigned int vc2_id, unsigned int vc3_id,
+			       unsigned int vc4_id, unsigned int vc5_id)
+{
+	int ret = 0;
+	void *pseninf =  NULL;
+
+	return 0; /* todo: support virtual channel */
+
+	pseninf = priv->seninf_ctrl[seninf_sel];
+
+	/* General Long Packet Data Types: 0x10-0x17 */
+	if ((0x10 <= (vc0_id >> 2) && (vc0_id >> 2) <= 0x17) ||
+	    (0x10 <= (vc1_id >> 2) && (vc1_id >> 2) <= 0x17) ||
+	    (0x10 <= (vc2_id >> 2) && (vc2_id >> 2) <= 0x17) ||
+	    (0x10 <= (vc3_id >> 2) && (vc3_id >> 2) <= 0x17) ||
+	    (0x10 <= (vc4_id >> 2) && (vc4_id >> 2) <= 0x17) ||
+	    (0x10 <= (vc5_id >> 2) && (vc5_id >> 2) <= 0x17))
+		write_master(pseninf, SENINF1_CSI2_CTL,
+			     (1 << 12), 0x00001000);
+
+	pr_debug("VC Data set :0x%x 0x%x\n", ((vc3_id) << 24) | ((vc2_id) << 16)
+		 | ((vc1_id) << 8) | (vc0_id), (vc5_id << 8) | (vc4_id));
+
+	/* 0x1a04_0a3c for VC0~VC3 */
+	seninf_write_reg(pseninf, SENINF1_CSI2_DI, ((vc3_id) << 24) |
+			 ((vc2_id) << 16) | ((vc1_id) << 8) | (vc0_id));
+	/* 0x1a04_0af0 for VC4~VC5 */
+	seninf_write_reg(pseninf, SENINF1_CSI2_DI_EXT,
+			 (vc5_id << 8) | (vc4_id));
+	/* Clear */
+	seninf_write_reg(pseninf, SENINF1_CSI2_DI_CTRL, 0x00);
+	seninf_write_reg(pseninf, SENINF1_CSI2_DI_CTRL_EXT, 0x00);
+	if (vc0_id == 0 && vc1_id == 0 && vc2_id == 0 &&
+	    vc3_id == 0  && vc4_id == 0 && vc5_id == 0)
+		return ret;
+
+	if ((vc0_id & 0xfc) != 0)
+		write_master(pseninf, SENINF1_CSI2_DI_CTRL,
+			     ((1 << 0) | (1 << 1)), 0x00000007);
+	if ((vc1_id & 0xfc) != 0)
+		write_master(pseninf, SENINF1_CSI2_DI_CTRL,
+			     ((1 << 8) | (1 << 9)), 0x00000700);
+	if ((vc2_id & 0xfc) != 0)
+		write_master(pseninf, SENINF1_CSI2_DI_CTRL,
+			     ((1 << 16) | (1 << 17)), 0x00070000);
+	if ((vc3_id & 0xfc) != 0)
+		write_master(pseninf, SENINF1_CSI2_DI_CTRL,
+			     ((1 << 24) | (1 << 25)), 0x07000000);
+	if ((vc4_id & 0xfc) != 0)
+		write_master(pseninf, SENINF1_CSI2_DI_CTRL_EXT,
+			     ((1 << 0) | (1 << 1)), 0x00000007);
+	if ((vc5_id & 0xfc) != 0)
+		write_master(pseninf, SENINF1_CSI2_DI_CTRL_EXT,
+			     ((1 << 8) | (1 << 9)), 0x00000700);
+
+	pr_debug("VC Data(0x%x,0x%x), VC Ctrl(0x%x,0x%x)",
+		 seninf_read_reg(pseninf, SENINF1_CSI2_DI),
+		 seninf_read_reg(pseninf, SENINF1_CSI2_DI_EXT),
+		 seninf_read_reg(pseninf, SENINF1_CSI2_DI_CTRL),
+		 seninf_read_reg(pseninf, SENINF1_CSI2_DI_CTRL_EXT));
+	return ret;
+}
+
+static int set_mux_ctrl(struct _seninf *priv,
+			unsigned int mux, unsigned int hs_pol,
+			unsigned int vs_pol, unsigned int src_type_sel,
+			unsigned int input_data_type, unsigned int pixel_mode
+)
+{
+	int ret = 0;
+	void *pseninf = priv->seninf_mux[mux];
+
+	unsigned int temp = 0;
+
+	write_master(pseninf, SENINF1_MUX_CTRL,
+		     (src_type_sel << 12), 0x0000F000);
+	temp = (src_type_sel == TEST_MODEL) ? 0 : 1;
+	write_master(pseninf, SENINF1_MUX_CTRL_EXT,
+		     (temp << 0), 0x00000003);
+	if (pixel_mode == 1) { /*2 Pixel*/
+		write_master(pseninf, SENINF1_MUX_CTRL_EXT,
+			     (0 << 4), 0x00000010);
+		write_master(pseninf, SENINF1_MUX_CTRL,
+			     (1 << 8), 0x00000100);
+
+	} else if (pixel_mode == 2) { /* 4 Pixel*/
+		write_master(pseninf, SENINF1_MUX_CTRL_EXT,
+			     (1 << 4), 0x00000010);
+		write_master(pseninf, SENINF1_MUX_CTRL,
+			     (0 << 8), 0x00000100);
+	} else { /* 1 pixel*/
+		write_master(pseninf, SENINF1_MUX_CTRL_EXT,
+			     (0 << 4), 0x00000010);
+		write_master(pseninf, SENINF1_MUX_CTRL,
+			     (0 << 8), 0x00000100);
+	}
+
+	if (input_data_type != JPEG_FMT)
+		write_master(pseninf, SENINF1_MUX_CTRL,
+			     (2 << 28), 0x30000000);
+	else
+		write_master(pseninf, SENINF1_MUX_CTRL,
+			     (0 << 28), 0x30000000);
+
+	if (src_type_sel == CSI2 || src_type_sel >= MIPI_SENSOR) {
+		/*Need to use Default for New design*/
+		if (input_data_type != JPEG_FMT)
+			write_master(pseninf, SENINF1_MUX_CTRL,
+				     ((0x1B << 22) | (0x1F << 16)),
+				     0x0FFF0000);
+		else
+			write_master(pseninf, SENINF1_MUX_CTRL,
+				     ((0x18 << 22) | (0x1E << 16)),
+				     0x0FFF0000);
+	}
+
+	write_master(pseninf, SENINF1_MUX_CTRL,
+		     ((hs_pol << 10) | (vs_pol << 9)), 0x00000600);
+
+	temp = seninf_read_reg(pseninf, SENINF1_MUX_CTRL);
+	seninf_write_reg(pseninf, SENINF1_MUX_CTRL, temp | 0x3);
+	seninf_write_reg(pseninf, SENINF1_MUX_CTRL, temp & 0xFFFFFFFC);
+
+	return ret;
+}
+
+static int enable_mux(struct _seninf *priv, unsigned int mux)
+{
+	void *pseninf = priv->seninf_mux[mux];
+
+	write_master(pseninf, SENINF1_MUX_CTRL, (1 << 31), 0x80000000);
+	return 0;
+}
+
+static struct seninf_csi_info *get_csi_info(struct _seninf *priv,
+					    unsigned int mipi_port)
+{
+	int i;
+
+	for (i = 0; i < CFG_CSI_PORT_MAX_NUM; i++) {
+		if (SENINF_CSI_INFO[i].port == mipi_port)
+			return &SENINF_CSI_INFO[i];
+	}
+
+	return NULL;
+}
+
+static int set_csi_mipi(struct _seninf *priv,
+			struct seninf_csi_mipi *pcsi_mipi)
+{
+	int ret = 0;
+	void *pseninf = NULL;
+	void *seninf_base = priv->seninf_hw;
+	void *pmipi_rx = NULL;
+	void *pmipi_rx_base = priv->csi2_rx[CFG_CSI_PORT_0];
+	void *pmipi_rx_conf = NULL;
+	struct seninf_csi_info *csi_info = pcsi_mipi->csi_info;
+	unsigned int cal_sel;
+	unsigned int temp = 0;
+
+	pr_debug("IS_4D1C %d csi_type %d port %d enable %d\n",
+		 IS_4D1C, pcsi_mipi->csi_type, csi_info->port,
+		 pcsi_mipi->enable);
+
+	pmipi_rx = priv->csi2_rx[csi_info->port];
+	pseninf = priv->seninf_ctrl[csi_info->seninf];
+	pmipi_rx_conf = priv->csi_rx_conf[csi_info->seninf];
+
+	if (csi_info->port == CFG_CSI_PORT_1) {
+		write_master(seninf_base, SENINF_TOP_PHY_SENINF_CTL_CSI1,
+			     ((0 << 0) | (2 << 8) |
+			     (pcsi_mipi->enable << 31)), 0x80000701);
+		cal_sel = 1;
+	} else if (csi_info->port == CFG_CSI_PORT_2) {
+		write_master(seninf_base, SENINF_TOP_PHY_SENINF_CTL_CSI2,
+			     ((0 << 0) | (2 << 8) |
+			     (pcsi_mipi->enable << 31)), 0x80000701);
+		cal_sel = 2;
+	} else if (csi_info->port == CFG_CSI_PORT_0) {
+		cal_sel = 0;
+		write_master(seninf_base, SENINF_TOP_PHY_SENINF_CTL_CSI0,
+			     ((0 << 0) | (2 << 8) |
+			     (pcsi_mipi->enable << 31)), 0x80000701);
+	} else if (csi_info->port == CFG_CSI_PORT_0A) {
+		cal_sel = 0;
+		write_master(seninf_base, SENINF_TOP_PHY_SENINF_CTL_CSI0,
+			     ((0 << 1) | (1 << 8) | (1 << 12) |
+			     (pcsi_mipi->enable << 31)), 0x80003701);
+	} else if (csi_info->port == CFG_CSI_PORT_0B) {
+		cal_sel = 0;
+		write_master(seninf_base, SENINF_TOP_PHY_SENINF_CTL_CSI0,
+			     ((0 << 1) | (1 << 8) | (1 << 12) |
+			     (pcsi_mipi->enable << 31)), 0x80003701);
+	} else {
+		pr_err("unsupported CSI configuration\n");
+		cal_sel = 0;
+		write_master(seninf_base, SENINF_TOP_PHY_SENINF_CTL_CSI0,
+			     ((0 << 0) | (2 << 8) |
+			     (pcsi_mipi->enable << 31)), 0x80000701);
+	}
+
+	/*First Enable Sensor interface and select pad (0x1a04_0200)*/
+	write_master(pseninf, SENINF1_CTRL,
+		     pcsi_mipi->enable << 0, 0x00000001);
+	write_master(pseninf, SENINF1_CTRL,
+		     pcsi_mipi->pad_sel << 28, 0x70000000);
+
+	if (pcsi_mipi->csi_type == CSI2_1_5G ||
+	    pcsi_mipi->csi_type == CSI2_2_5G) {
+		write_master(pseninf, SENINF1_CTRL, 0 << 12, 0x0000F000);
+		write_master(pseninf, SENINF1_CTRL_EXT,
+			     (pcsi_mipi->enable << 6) | (0 << 5), 0x00000060);
+	}
+	if (!pcsi_mipi->enable) {
+		seninf_write_reg(pseninf, SENINF1_CSI2_CTL,
+				 seninf_read_reg(pseninf, SENINF1_CSI2_CTL) &
+				 0xFFFFFFE0);
+		/* disable mipi BG */
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (0 << 3) | (0 << 2), 0x0000000C);
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+			     (0 << 3) | (0 << 2), 0x0000000C);
+		return ret;
+	}
+
+	if (pcsi_mipi->csi_type != CSI2_2_5G_CPHY) { /* Dphy */
+		/* set analog phy mode to DPHY */
+		if (IS_CDPHY_COMBO)
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+				     (0 << 0), 0x00000001);
+
+		if (IS_4D1C) /* 4D1C (MIPIRX_ANALOG_A_BASE) = 0x00001A42 */
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+				     (0 << 5) | (1 << 6) | (0 << 8) |
+				     (1 << 9) | (1 << 11) | (1 << 12),
+				     0x00001B60);
+		else /*(MIPIRX_ANALOG_BASE) = 0x102;*/
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+				     (0 << 5) | (0 << 6) | (1 << 8) |
+				     (0 << 9) | (0 << 11) | (0 << 12),
+				     0x00001B60);
+
+		if (IS_CDPHY_COMBO)
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+				     (0 << 0), 0x00000001);
+
+		/*only 4d1c need set CSIB (MIPIRX_ANALOG_B_BASE) = 0x00001242*/
+		if (IS_4D1C)
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+				     (0 << 5) | (1 << 6) | (0 << 8) |
+				     (1 << 9) | (0 << 11) | (1 << 12),
+				     0x00001B60);
+		else /*(MIPIRX_ANALOG_BASE) = 0x102;*/
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+				     (0 << 6) | (1 << 8) | (1 << 9) |
+				     (0 << 11) | (0 << 12),
+				     0x00001B40);
+
+		/* byte clock invert*/
+		write_master(pmipi_rx, MIPI_RX_ANAA8_CSI0A,
+			     (1 << 0) | (1 << 1) | (1 << 2), 0x00000007);
+		if (IS_4D1C)
+			write_master(pmipi_rx, MIPI_RX_ANAA8_CSI0B,
+				     (1 << 0) | (1 << 1) | (1 << 2),
+				     0x00000007);
+
+		/*start ANA EQ tuning*/
+		if (IS_CDPHY_COMBO) {
+			write_master(pmipi_rx, MIPI_RX_ANA18_CSI0A,
+				     (1 << 4) | (1 << 6), 0x000000F0);
+			write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0A,
+				     (1 << 20) | (1 << 22), 0x00F00000);
+			write_master(pmipi_rx, MIPI_RX_ANA20_CSI0A,
+				     (1 << 20) | (1 << 22), 0x00F00000);
+
+			if (IS_4D1C) { /* 4d1c */
+				write_master(pmipi_rx, MIPI_RX_ANA18_CSI0B,
+					     (1 << 4) | (1 << 6), 0x000000F0);
+				write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0B,
+					     (1 << 20) | (1 << 22),
+					     0x00F00000);
+				write_master(pmipi_rx, MIPI_RX_ANA20_CSI0B,
+					     (1 << 20) | (1 << 22),
+					     0x00F00000);
+			}
+		} else {
+			void *pdhy_ana_base = pmipi_rx;
+
+			write_master(pdhy_ana_base, MIPI_RX_ANA18_CSI1A,
+				     (1 << 4) | (1 << 6) | (1 << 20) |
+				     (1 << 22), 0x00F000F0);
+			write_master(pdhy_ana_base, MIPI_RX_ANA1C_CSI1A,
+				     (1 << 4) | (1 << 6), 0x000000F0);
+
+			if (IS_4D1C) { /* 4d1c */
+				write_master(pdhy_ana_base,
+					     MIPI_RX_ANA18_CSI1B, (1 << 4) |
+					     (1 << 6) | (1 << 20) |
+					     (1 << 22), 0x00F000F0);
+				write_master(pdhy_ana_base,
+					     MIPI_RX_ANA1C_CSI1B, (1 << 4) |
+					     (1 << 6), 0x000000F0);
+			}
+		}
+		/*end ANA EQ tuning*/
+		seninf_write_reg(pmipi_rx_base, MIPI_RX_ANA40_CSI0A, 0x90);
+		write_master(pmipi_rx, MIPI_RX_ANA24_CSI0A,
+			     (0x40 << 24), 0xFF000000);
+		if (IS_4D1C)
+			write_master(pmipi_rx, MIPI_RX_ANA24_CSI0B,
+				     (0x40 << 24), 0xFF000000);
+		write_master(pmipi_rx, MIPI_RX_WRAPPER80_CSI0A,
+			     (0 << 16), 0x00030000);
+		if (IS_4D1C)
+			write_master(pmipi_rx, MIPI_RX_WRAPPER80_CSI0B,
+				     (0 << 16), 0x00030000);
+		/*ANA power on*/
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (1 << 3), 0x00000008);
+		if (IS_4D1C)
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+				     (1 << 3), 0x00000008);
+		usleep_range(20, 40);
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (1 << 3), 0x00000008);
+		if (IS_4D1C)
+			write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+				     (1 << 2), 0x00000004);
+		udelay(1);
+#ifdef CSI2_SW_OFFSET_CAL
+		pr_debug("CSI offset calibration start");
+		if (IS_CDPHY_COMBO) {
+			write_master(pmipi_rx, MIPI_RX_ANA18_CSI0A,
+				     (1 << 0), 0x00000001);
+			write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0A,
+				     (1 << 0), 0x00000001);
+			write_master(pmipi_rx, MIPI_RX_ANA20_CSI0A,
+				     (1 << 0), 0x00000001);
+
+			if (IS_4D1C) {
+				write_master(pmipi_rx, MIPI_RX_ANA18_CSI0B,
+					     (1 << 0), 0x00000001);
+				write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0B,
+					     (1 << 0), 0x00000001);
+				write_master(pmipi_rx, MIPI_RX_ANA20_CSI0B,
+					     (1 << 0), 0x00000001);
+			}
+		} else {
+			void *pdhy_ana_base = pmipi_rx;
+
+			write_master(pdhy_ana_base, MIPI_RX_ANA18_CSI1A,
+				     (1 << 0) | (1 << 16), 0x00010001);
+			write_master(pdhy_ana_base, MIPI_RX_ANA1C_CSI1A,
+				     (1 << 0), 0x00000001);
+			if (IS_4D1C) {
+				write_master(pdhy_ana_base, MIPI_RX_ANA18_CSI1B,
+					     (1 << 0) | (1 << 16), 0x00010001);
+				write_master(pdhy_ana_base, MIPI_RX_ANA1C_CSI1B,
+					     (1 << 0), 0x00000001);
+			}
+		}
+		udelay(1);
+		int status = 0;
+		int i = 0;
+
+		while (1) {
+			status = seninf_read_reg(pmipi_rx, MIPI_RX_ANA48_CSI0A);
+			if ((IS_CDPHY_COMBO) && (status & (1 << 0)) &&
+			    (status & (1 << 3)) && (status & (1 << 5)))
+				break;
+			else if ((status & (1 << 3)) && (status & (1 << 4)) &&
+				 (status & (1 << 5)))
+				break;
+
+			pr_debug("CSIA offset calibration ongoing");
+			i++;
+			if (i > 100) {
+				pr_debug("CSIA offset calibration timeout");
+				break;
+			}
+			usleep_range(20, 40);
+		}
+		if (IS_4D1C) {
+			i = 0;
+			status = 0;
+
+			while (1) {
+				status = seninf_read_reg(pmipi_rx,
+							 MIPI_RX_ANA48_CSI0B);
+				if ((IS_CDPHY_COMBO) && (status & (1 << 0)) &&
+				    (status & (1 << 3)) && (status & (1 << 5)))
+					break;
+				else if ((status & (1 << 3)) && (status &
+					 (1 << 4)) && (status & (1 << 5)))
+					break;
+
+				pr_debug("CSIB offset calibration ongoing");
+				i++;
+				if (i > 100) {
+					pr_debug("offset calibration timeout");
+					break;
+				}
+				usleep_range(20, 40);
+			}
+		}
+		pr_debug("CSI offset calibration end 0x%x, 0x%x",
+			 seninf_read_reg(pmipi_rx, MIPI_RX_ANA48_CSI0A),
+			 seninf_read_reg(pmipi_rx, MIPI_RX_ANA48_CSI0B));
+#endif
+		if (IS_4D1C) { /* 4d1c (MIPIRX_CONFIG_CSI_BASE) =0xC9000000; */
+			write_master(pmipi_rx_conf, MIPI_RX_CON24_CSI0,
+				     (1 << 24) | (2 << 26) | (0 << 28) |
+				     (3 << 30), 0xFF000000);
+		} else { /* 2d1c (MIPIRX_CONFIG_CSI_BASE) =0xE4000000; */
+			write_master(pmipi_rx_conf, MIPI_RX_CON24_CSI0,
+				     (0 << 24) | (1 << 26) | (2 << 28) |
+				     (3 << 30), 0xFF000000);
+		}
+		pr_debug("pcsi_mipi->CSI2_IP %d, MIPI_RX_CON24_CSI0 0x%x",
+			 csi_info->port,
+			 seninf_read_reg(pmipi_rx_conf, MIPI_RX_CON24_CSI0));
+		usleep_range(20, 40);
+		/*D-PHY SW Delay Line calibration*/
+	} else { /*Cphy  setting for CSI0 */
+		/* byte clock invert*/
+		int status = 0;
+		int i = 0;
+
+		write_master(pmipi_rx, MIPI_RX_ANAA8_CSI0A,
+			     (1 << 0) | (1 << 2), 0x00000005);
+		write_master(pmipi_rx, MIPI_RX_ANAA8_CSI0B,
+			     (1 << 0) | (1 << 2), 0x00000005);
+		/*EQ Power to Enhance Speed*/
+		write_master(pmipi_rx, MIPI_RX_ANA18_CSI0A,
+			     (1 << 6) | (1 << 22), 0x00C000C0);
+		write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0A,
+			     (1 << 6) | (1 << 22), 0x00C000C0);
+		write_master(pmipi_rx, MIPI_RX_ANA20_CSI0A,
+			     (1 << 6) | (1 << 22), 0x00C000C0);
+		write_master(pmipi_rx, MIPI_RX_ANA18_CSI0B,
+			     (1 << 6) | (1 << 22), 0x00C000C0);
+		write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0B,
+			     (1 << 6) | (1 << 22), 0x00C000C0);
+		write_master(pmipi_rx, MIPI_RX_ANA20_CSI0B,
+			     (1 << 6) | (1 << 22), 0x00C000C0);
+
+		/*CDR register setting*/
+
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x30)) = 0x06040404;
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x3c)) = 0x06040404;
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x34)) = 0x1;
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x28)) = 0x1;
+
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x1030)) =
+			0x06040404;
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x103c)) =
+			0x06040404;
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x1034)) = 0x1;
+		*((int *)(priv->csi2_rx[csi_info->port] + 0x1028)) = 0x1;
+
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (1 << 0) | (0 << 5) | (0 << 6) | (0 << 8) |
+			     (0 << 9) | (0 < 11) | (0 < 12), 0x00001B61);
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+			     (1 << 0) | (0 << 5) | (0 << 6) | (0 << 8) |
+			     (0 << 9) | (0 < 11) | (0 < 12), 0x00001B61);
+		/*Power on DPHY*/
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (1 << 3), 0x00000008);
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+			     (1 << 3), 0x00000008);
+		usleep_range(20, 40);
+		/*Enable LPF*/
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (1 << 2), 0x00000004);
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+			     (1 << 2), 0x00000004);
+		udelay(1);
+		/*offset calibration*/
+		write_master(pmipi_rx, MIPI_RX_ANA18_CSI0A,
+			     (1 << 0) | (1 << 16), 0x00010001);
+		write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0A,
+			     (1 << 0) | (1 << 16), 0x00010001);
+		write_master(pmipi_rx, MIPI_RX_ANA20_CSI0A,
+			     (1 << 0) | (1 << 16), 0x00010001);
+		write_master(pmipi_rx, MIPI_RX_ANA18_CSI0B,
+			     (1 << 0) | (1 << 16), 0x00010001);
+		write_master(pmipi_rx, MIPI_RX_ANA1C_CSI0B,
+			     (1 << 0) | (1 << 16), 0x00010001);
+		write_master(pmipi_rx, MIPI_RX_ANA20_CSI0B,
+			     (1 << 0) | (1 << 16), 0x00010001);
+		udelay(1);
+		while (1) {
+			status = seninf_read_reg(pmipi_rx,
+						 MIPI_RX_ANA48_CSI0A);
+			if ((status & 0x3f) == 0x3f)
+				break;
+			i++;
+			if (i > 100) {
+				pr_debug("CSIA offset calibration timeout");
+				break;
+			}
+			usleep_range(20, 40);
+		}
+
+		i = 0;
+		status = 0;
+		while (1) {
+			status = seninf_read_reg(pmipi_rx,
+						 MIPI_RX_ANA48_CSI0B);
+			if ((status & 0x3f) == 0x3f)
+				break;
+			i++;
+			if (i > 100) {
+				pr_debug("CSIB offset calibration timeout");
+				break;
+			}
+			usleep_range(20, 40);
+		}
+	}
+	/* End of CSI MIPI */
+	/* DPCM Enable */
+	seninf_write_reg(pseninf, SENINF1_CSI2_DPCM,
+			 1 << ((pcsi_mipi->dpcm == 0x2a)
+			 ? 15 : ((pcsi_mipi->dpcm & 0xF) + 7)));
+
+	pr_debug("CSI2-%d cnt:%d LaneNum:%d CSI2_EN:%d HeadOrder:%d dpcm:%d\n",
+		 cal_sel, SENINF_SETTLE_DELAY,
+		 (int)(pcsi_mipi->data_lane_num + 1), (int)pcsi_mipi->enable,
+		 (int)pcsi_mipi->data_header_order, (int)pcsi_mipi->dpcm);
+
+	/*Settle delay*/
+	write_master(pseninf, SENINF1_CSI2_LNRD_TIMING,
+		     (SENINF_SETTLE_DELAY << 8), 0x0000FF00);
+	/*CSI2 control*/
+	if (pcsi_mipi->csi_type != CSI2_2_5G_CPHY) { /*DPhy*/
+		seninf_write_reg(pseninf, SENINF1_CSI2_CTL,
+				 (seninf_read_reg(pseninf, SENINF1_CSI2_CTL) |
+				 (pcsi_mipi->data_header_order << 16) |
+				 (pcsi_mipi->enable << 4) |
+				 (((1 << (pcsi_mipi->data_lane_num + 1)) - 1)
+				 )));
+		write_master(pseninf, SENINF1_CSI2_RESYNC_MERGE_CTL,
+			     (0 << 10) | (0 << 11) | (3 << 0), 0x00000C07);
+		write_master(pseninf, SENINF1_CSI2_MODE,
+			     (0 << 0) | (0 << 8), 0x000007FF);
+		write_master(pseninf, SENINF1_CSI2_DPHY_SYNC,
+			     (0xff00 << 0) | (0x001d << 16), 0xFFFFFFFF);
+		seninf_write_reg(pseninf, SENINF1_CSI2_SPARE0,
+				 seninf_read_reg(pseninf, SENINF1_CSI2_SPARE0)
+				 & 0xFFFFFFFE);
+	} else { /*CPhy*/
+		write_master(pseninf, SENINF1_CSI2_LNRD_TIMING,
+			     (0 << 0), 0x000000FF);
+		seninf_write_reg(pseninf, SENINF1_CSI2_CTL,
+				 (seninf_read_reg(pseninf, SENINF1_CSI2_CTL) |
+				 pcsi_mipi->data_header_order << 16));
+		temp = (pcsi_mipi->data_lane_num == SENSOR_MIPI_1_LANE) ? 1 :
+			(pcsi_mipi->data_lane_num == SENSOR_MIPI_2_LANE) ? 2 :
+			(pcsi_mipi->data_lane_num == SENSOR_MIPI_3_LANE) ?
+			4 : 5;
+		write_master(pseninf, SENINF1_CSI2_MODE,
+			     (temp << 8), 0x00000700);
+		temp = pcsi_mipi->data_lane_num >= SENSOR_MIPI_1_LANE;
+		write_master(pseninf, SENINF1_CSI2_CTRL_TRIO_CON,
+			     (temp << 0), 0x00000001);
+		temp = pcsi_mipi->data_lane_num >= SENSOR_MIPI_2_LANE;
+		write_master(pseninf, SENINF1_CSI2_CTRL_TRIO_CON,
+			     (temp << 2), 0x00000004);
+		temp = pcsi_mipi->data_lane_num >= SENSOR_MIPI_3_LANE;
+		write_master(pseninf, SENINF1_CSI2_CTRL_TRIO_CON,
+			     (temp << 4), 0x00000010);
+		temp = pcsi_mipi->data_lane_num >= SENSOR_MIPI_4_LANE;
+		write_master(pseninf, SENINF1_CSI2_CTRL_TRIO_CON,
+			     (temp << 6), 0x00000040);
+		write_master(pseninf, SENINF1_CSI2_MODE,
+			     (0x2 << 0), 0x000000FF);
+		write_master(pseninf, SENINF1_CSI2_RESYNC_MERGE_CTL,
+			     (3 << 0) | (0 << 10) | (1 << 11), 0x00000C07);
+		write_master(pseninf, SENINF1_SYNC_RESYNC_CTL,
+			     (1 << 0), 0x00000007);
+		write_master(pseninf, SENINF1_POST_DETECT_CTL,
+			     (1 << 1), 0x00000002);
+
+		seninf_write_reg(pseninf, SENINF1_CSI2_SPARE0,
+				 seninf_read_reg(pseninf, SENINF1_CSI2_SPARE0)
+				 | 0x1);
+	}
+
+	write_master(pseninf, SENINF1_CSI2_CTL, (0 << 27) | (0 << 7) |
+		     (1 << 25), 0x0A000080);
+	write_master(pseninf, SENINF1_CSI2_HS_TRAIL,
+		     (SENINF_HS_TRAIL_PARAMETER << 0), 0x000000FF);
+
+	/* set debug port to output packet number */
+	seninf_write_reg(pseninf, SENINF1_CSI2_DGB_SEL, 0x8000001A);
+	/*Enable CSI2 IRQ mask*/
+	/* turn on all interrupt */
+	seninf_write_reg(pseninf, SENINF1_CSI2_INT_EN, 0xFFFFFFFF);
+	/*write clear CSI2 IRQ*/
+	seninf_write_reg(pseninf, SENINF1_CSI2_INT_STATUS, 0xFFFFFFFF);
+	/*Enable CSI2 Extend IRQ mask*/
+	/* turn on all interrupt */
+	seninf_write_reg(pseninf, SENINF1_CSI2_INT_EN_EXT, 0x0000001f);
+
+	write_master(pseninf, SENINF1_CTRL, (1 << 7), 0x00000080);
+	udelay(1);
+	write_master(pseninf, SENINF1_CTRL, (0 << 7), 0x00000080);
+
+	return ret;
+}
+
+static int power_off(struct _seninf *priv, void *pcsi)
+{
+	int ret = 0;
+	struct seninf_csi_mipi *pcsi_mipi = (struct seninf_csi_mipi *)pcsi;
+	struct seninf_csi_info *csi_info = pcsi_mipi->csi_info;
+	void *pmipi_rx = priv->csi2_rx[csi_info->port];
+	void *pseninf = priv->seninf_ctrl[csi_info->seninf];
+
+	/* disable CSI2(2.5G) first*/
+	seninf_write_reg(pseninf, SENINF1_CSI2_CTL,
+			 seninf_read_reg(pseninf, SENINF1_CSI2_CTL)
+			 & 0xFFFFFFE0);
+	/* disable mipi BG */
+	switch (csi_info->port) {
+	case CFG_CSI_PORT_0A:
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (0 << 3) | (0 << 2), 0x0000000C);
+		break;
+	case CFG_CSI_PORT_0B:
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+			     (0 << 3) | (0 << 2), 0x0000000C);
+		break;
+	default:
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0A,
+			     (0 << 3) | (0 << 2), 0x0000000C);
+		write_master(pmipi_rx, MIPI_RX_ANA00_CSI0B,
+			     (0 << 3) | (0 << 2), 0x0000000C);
+		break;
+	}
+
+	return ret;
+}
+
+static int map_fmt(struct _seninf *priv)
+{
+	int fmtidx = 0;
+
+	switch (priv->format) {
+	case MEDIA_BUS_FMT_SBGGR8_1X8:
+	case MEDIA_BUS_FMT_SGBRG8_1X8:
+	case MEDIA_BUS_FMT_SGRBG8_1X8:
+	case MEDIA_BUS_FMT_SRGGB8_1X8:
+		fmtidx = 0;
+		priv->dpcm = 0;
+		break;
+	case MEDIA_BUS_FMT_SGRBG10_1X10:
+	case MEDIA_BUS_FMT_SRGGB10_1X10:
+	case MEDIA_BUS_FMT_SBGGR10_1X10:
+	case MEDIA_BUS_FMT_SGBRG10_1X10:
+		fmtidx = 1;
+		priv->dpcm = 0;
+		break;
+	case MEDIA_BUS_FMT_SGRBG10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SRGGB10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SBGGR10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SGBRG10_DPCM8_1X8:
+		fmtidx = 1;
+		priv->dpcm = 1;
+		break;
+	case MEDIA_BUS_FMT_SBGGR12_1X12:
+	case MEDIA_BUS_FMT_SGBRG12_1X12:
+	case MEDIA_BUS_FMT_SGRBG12_1X12:
+	case MEDIA_BUS_FMT_SRGGB12_1X12:
+		fmtidx = 2;
+		priv->dpcm = 0;
+		break;
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+	case MEDIA_BUS_FMT_VYUY8_1X16:
+	case MEDIA_BUS_FMT_YUYV8_1X16:
+	case MEDIA_BUS_FMT_YVYU8_1X16:
+		fmtidx = 3;
+		priv->dpcm = 0;
+		break;
+	default:
+		WARN(1, "CSI2: pixel format %08x unsupported!\n",
+		     priv->format);
+	}
+	return fmtidx;
+}
+
+static int seninf_set_fmt(struct v4l2_subdev *sd,
+			  struct v4l2_subdev_pad_config *cfg,
+			  struct v4l2_subdev_format *fmt)
+{
+	struct _seninf *priv = container_of(sd, struct _seninf, subdev);
+
+	priv->format = fmt->format.code;
+	pr_debug("priv->format 0x%x", priv->format);
+	return 0;
+}
+
+static int seninf_s_stream(struct v4l2_subdev *sd, int on)
+{
+	struct _seninf *priv = container_of(sd, struct _seninf, subdev);
+	int ret = 0;
+	struct seninf_csi_mipi csi_mipi;
+	unsigned int input_data_type = RAW_10BIT_FMT;
+	struct sensor_vc_info_struct vc_info;
+	unsigned int mux_select = 0;
+	unsigned int pixel_mode = ONE_PIXEL_MODE;
+	struct seninf_csi_info *csi_info;
+	unsigned int port;
+	unsigned int seninf_src;
+
+	unsigned char sensor_hsync_polarity = SENSOR_CLOCK_POLARITY_LOW;
+	unsigned char sensor_vsync_polarity = SENSOR_CLOCK_POLARITY_LOW;
+	unsigned char sensor_packet_ecc_order = 1;
+	unsigned char sensor_mipi_lane_num =
+		priv->ep[priv->port].bus.mipi_csi2.num_data_lanes;
+	unsigned int mipi_sensor_type = MIPI_OPHY_NCSI2;
+	void *pseninf = priv->seninf_hw;
+
+	priv->mux_select = mux_select; /* seninfMUXArbitration */
+	port = priv->port;
+	csi_info = get_csi_info(priv, port);
+	seninf_src = csi_info->seninf;
+
+	pr_debug("seninf csi_info->seninf(%d) port(%d)\n",
+		 csi_info->seninf, csi_info->port);
+
+	/*configureMipi*/
+	csi_mipi.enable = 1;
+	csi_mipi.data_header_order = sensor_packet_ecc_order;
+	csi_mipi.data_lane_num = sensor_mipi_lane_num - 1;
+	csi_mipi.csi_type = (mipi_sensor_type == MIPI_CPHY)
+		? CSI2_2_5G_CPHY : CSI2_2_5G;
+	csi_mipi.csi_info = csi_info;
+
+	csi_mipi.pad_sel = PAD_10BIT;
+	csi_mipi.dpcm = 0;
+	input_data_type = (unsigned int)map_fmt(priv);
+	csi_mipi.dpcm = priv->dpcm;
+
+	if (on) {
+		/* Configure timestamp */
+		write_master(pseninf, SENINF1_CTRL, (1 << 0), 0x00000001);
+		write_master(pseninf, SENINF1_CTRL_EXT, (1 << 6), 0x00000040);
+		seninf_write_reg(pseninf, SENINF_TG1_TM_STP,
+				 SENINF_TIMESTAMP_STEP);
+		memcpy((void *)&vc_info, (void *)&SENSOR_VC_INFO[0],
+		       sizeof(struct sensor_vc_info_struct));
+
+		ret = set_virtual_channel(priv, csi_info->seninf,
+					  (vc_info.vc0_data_type << 2) |
+					  (vc_info.VC0_ID & 0x03),
+					  (vc_info.vc1_data_type << 2) |
+					  (vc_info.VC1_ID & 0x03),
+					  (vc_info.vc2_data_type << 2) |
+					  (vc_info.VC2_ID & 0x03),
+					  (vc_info.vc3_data_type << 2) |
+					  (vc_info.VC3_ID & 0x03),
+					  (vc_info.vc4_data_type << 2) |
+					  (vc_info.VC4_ID & 0x03),
+					  (vc_info.vc5_data_type << 2) |
+					  (vc_info.VC5_ID & 0x03));
+
+		set_csi_mipi(priv, (struct seninf_csi_mipi *)&csi_mipi);
+
+		enable_mux(priv, mux_select);
+		set_mux_ctrl(priv, mux_select, sensor_hsync_polarity ? 0 : 1,
+			     sensor_vsync_polarity ? 0 : 1,
+			     MIPI_SENSOR, input_data_type, pixel_mode);
+
+		set_top_mux_ctrl(priv, mux_select, seninf_src);
+		seninf_write_reg(pseninf, SENINF_TOP_CAM_MUX_CTRL, 0x0);
+	} else {
+		power_off(priv, &csi_mipi);
+	}
+	return 0;
+};
+
+static const struct v4l2_subdev_pad_ops seninf_subdev_pad_ops = {
+	.set_fmt = seninf_set_fmt,
+};
+
+static const struct v4l2_subdev_video_ops seninf_subdev_video_ops = {
+	.s_stream = seninf_s_stream,
+};
+
+static struct v4l2_subdev_ops seninf_subdev_ops = {
+	.video	= &seninf_subdev_video_ops,
+	.pad	= &seninf_subdev_pad_ops,
+};
+
+static int seninf_link_setup(struct media_entity *entity,
+			     const struct media_pad *local,
+			     const struct media_pad *remote, u32 flags)
+{
+	struct v4l2_subdev *sd;
+	struct _seninf *priv;
+
+	sd = media_entity_to_v4l2_subdev(entity);
+	priv = v4l2_get_subdevdata(sd);
+	pr_debug("mtk_seninf: remote %d-%d, local %d-%d",
+		 remote->entity->graph_obj.id, remote->index,
+		 local->entity->graph_obj.id, local->index);
+	pr_debug("local->flags %d flags %d", local->flags, flags);
+	//link seninf-p1
+	if ((local->flags & MEDIA_PAD_FL_SOURCE) &&
+	    (flags & MEDIA_LNK_FL_ENABLED)) {
+		pr_debug("set seninf port %d", local->index);
+		priv->mux_select = local->index;
+		//switch(local->index)	//select TG Mux
+	}
+
+	if ((local->flags & MEDIA_PAD_FL_SINK) &&
+	    (flags & MEDIA_LNK_FL_ENABLED)) {
+		pr_debug("link sensor-seninf");
+		priv->port = local->index;
+	}
+	//seninf internal use force enable create link
+
+	return 0;
+}
+
+static const struct media_entity_operations seninf_media_ops = {
+	.link_setup = seninf_link_setup,
+	.link_validate = v4l2_subdev_link_validate,
+};
+
+#ifdef CONFIG_VIDEO_V4L2_SUBDEV_API
+static int seninf_open(struct v4l2_subdev *sd, struct v4l2_subdev_fh *fh)
+{
+	struct _seninf *priv = container_of(sd, struct _seninf, subdev);
+	int ret = 0;
+
+	ret = pm_runtime_get_sync(priv->dev);
+	if (ret < 0)
+		dev_err(priv->dev, "Failed to pm_runtime_get_sync: %d\n", ret);
+
+	clk_prepare_enable(priv->cam_clk);
+	clk_prepare_enable(priv->top_mux_clk);
+	return 0;
+}
+
+static int seninf_close(struct v4l2_subdev *sd, struct v4l2_subdev_fh *fh)
+{
+	struct _seninf *priv = container_of(sd, struct _seninf, subdev);
+
+	clk_disable_unprepare(priv->top_mux_clk);
+	clk_disable_unprepare(priv->cam_clk);
+	pm_runtime_put(priv->dev);
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_VIDEO_V4L2_SUBDEV_API
+static const struct v4l2_subdev_internal_ops seninf_internal_ops = {
+	.open = seninf_open,
+	.close = seninf_close,
+};
+#endif
+
+static irqreturn_t seninf_irq(int irq, void *device_id)
+{
+	return IRQ_HANDLED;
+}
+
+static int seninf_enable_test_pattern(struct _seninf *priv, u32 pattern)
+{
+	void *pseninf = priv->seninf_hw;
+
+	switch (pattern) {
+	case TEST_DISABLED:
+	case TEST_PATTERN_MODE:
+		break;
+	case TEST_DEBUG_MODE:
+		/*Sensor Interface Control */
+		pr_debug("SENINF_CSI2_CTL SENINF1:0x%x, 2:0x%x, 3:0x%x, 5:0x%x\n",
+			 seninf_read_reg(pseninf, SENINF1_CSI2_CTL),
+			 seninf_read_reg(pseninf, SENINF2_CSI2_CTL),
+			 seninf_read_reg(pseninf, SENINF3_CSI2_CTL),
+			 seninf_read_reg(pseninf, SENINF5_CSI2_CTL));
+		/*read width/height*/
+		/*read interrupt status*/
+		pr_debug("SENINF1_IRQ:0x%x, 2:0x%x, 3:0x%x, 5:0x%x\n",
+			 seninf_read_reg(pseninf, SENINF1_CSI2_INT_STATUS),
+			 seninf_read_reg(pseninf, SENINF2_CSI2_INT_STATUS),
+			 seninf_read_reg(pseninf, SENINF3_CSI2_INT_STATUS),
+			 seninf_read_reg(pseninf, SENINF5_CSI2_INT_STATUS));
+		/*Mux1 */
+		pr_debug("SENINF1_MUX_CTRL:0x%x, INTSTA:0x%x, DEBUG_2(0x%x)\n",
+			 seninf_read_reg(pseninf, SENINF1_MUX_CTRL),
+			 seninf_read_reg(pseninf, SENINF1_MUX_INTSTA),
+			 seninf_read_reg(pseninf, SENINF1_MUX_DEBUG_2));
+		if (seninf_read_reg(pseninf, SENINF1_MUX_INTSTA) & 0x1) {
+			seninf_write_reg(pseninf, SENINF1_MUX_INTSTA,
+					 0xffffffff);
+			udelay(SENINF_DRV_DEBUG_DELAY);
+			pr_debug("overrun CTRL:%x INTSTA:%x DEBUG_2:%x\n",
+				 seninf_read_reg(pseninf, SENINF1_MUX_CTRL),
+				 seninf_read_reg(pseninf, SENINF1_MUX_INTSTA),
+				 seninf_read_reg(pseninf, SENINF1_MUX_DEBUG_2));
+		}
+		break;
+	default:
+		dev_warn(priv->dev, "%s Unhandled testcase:%d\n",
+			 __func__, pattern);
+		break;
+	}
+
+	return 0;
+}
+
+static int seninf_set_ctrl(struct v4l2_ctrl *ctrl)
+{
+	struct _seninf *priv = container_of(ctrl->handler,
+					     struct _seninf, ctrl_handler);
+	int ret = 0;
+
+	switch (ctrl->id) {
+	case V4L2_CID_TEST_PATTERN:
+		ret = seninf_enable_test_pattern(priv, ctrl->val);
+		break;
+	default:
+		dev_warn(priv->dev, "%s Unhandled id:0x%x, val:0x%x\n",
+			 __func__, ctrl->id, ctrl->val);
+		break;
+	}
+	return ret;
+}
+
+static const struct v4l2_ctrl_ops seninf_ctrl_ops = {
+	.s_ctrl = seninf_set_ctrl,
+};
+
+static const char * const seninf_test_pattern_menu[] = {
+	"Disabled",
+	"test_pattern_mode",
+	"test_debug_mode",
+};
+
+static int seninf_initialize_controls(struct _seninf *priv)
+{
+	struct v4l2_ctrl_handler *handler;
+	int ret = 0;
+
+	handler = &priv->ctrl_handler;
+	ret = v4l2_ctrl_handler_init(handler, 2);
+	if (ret)
+		return ret;
+	priv->test_pattern =
+	v4l2_ctrl_new_std_menu_items(handler, &seninf_ctrl_ops,
+				     V4L2_CID_TEST_PATTERN,
+				     ARRAY_SIZE(seninf_test_pattern_menu) - 1,
+				     0, 0, seninf_test_pattern_menu);
+
+	if (handler->error) {
+		ret = handler->error;
+		dev_err(priv->dev,
+			"Failed to init controls(%d)\n", ret);
+		goto err_free_handler;
+	}
+
+	priv->subdev.ctrl_handler = handler;
+
+	return 0;
+
+err_free_handler:
+	v4l2_ctrl_handler_free(handler);
+
+	return ret;
+}
+
+static int seninf_probe(struct platform_device *pdev)
+{
+	struct resource *res;
+	unsigned int irq;
+	int i = 0;
+	int ret = 0;
+	struct _seninf *priv;
+	struct v4l2_subdev *sd;
+	struct device_node *endpoint = NULL;
+	struct device *dev = &pdev->dev;
+	struct media_pad *pads;
+	unsigned int irq_info[3];
+
+	dev_dbg(dev, "seninf probe +\n");
+	priv = devm_kzalloc(&pdev->dev, sizeof(struct _seninf), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+	memset(priv, 0, sizeof(struct _seninf));
+	priv->dev = &pdev->dev;
+	sd = &priv->subdev;
+	pads = priv->pads;
+	/* cam0 <reg 0> */
+	/* cam1 <reg 1> */
+	for (i = 0; i < 2; i++) { /* support upto 2 senosrs */
+		endpoint = of_graph_get_endpoint_by_regs(dev->of_node, i, i);
+		if (!endpoint) {
+			dev_err(dev, "endpoint node not found\n");
+			return -EINVAL;
+		}
+		ret = v4l2_fwnode_endpoint_parse(of_fwnode_handle(endpoint),
+						 &priv->ep[i]);
+		of_node_put(endpoint);
+
+		if (ret < 0) {
+			pr_err("parsing endpoint node failed\n");
+			return ret;
+		}
+		if (priv->ep[i].bus_type != V4L2_MBUS_CSI2) {
+			pr_err("invalid bus type, must be CSI2\n");
+			return -EINVAL;
+		}
+		pr_debug("bus.mipi_csi2.num_data_lanes %d\n",
+			 priv->ep[i].bus.mipi_csi2.num_data_lanes);
+	}
+	/* get IRQ ID and request IRQ */
+	irq = irq_of_parse_and_map(pdev->dev.of_node, 0);
+
+	if (irq > 0) {
+		/* Get IRQ Flag from device node */
+		if (of_property_read_u32_array(pdev->dev.of_node,
+					       "interrupts", irq_info,
+					       ARRAY_SIZE(irq_info))) {
+			dev_err(dev, "get irq flags from DTS fail!!\n");
+			return -ENODEV;
+		}
+		ret = request_irq(irq, (irq_handler_t)seninf_irq,
+				  irq_info[2], "SENINF", NULL);
+		if (ret) {
+			dev_err(dev, "request_irq fail\n");
+			return ret;
+		}
+		pr_debug("seninf devnode:%s, irq=%d\n",
+			 pdev->dev.of_node->name, irq);
+	} else {
+		pr_debug("No IRQ!!\n");
+	}
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "base_reg");
+	priv->base_reg = devm_ioremap_resource(dev, res);
+	if (IS_ERR(priv->base_reg))
+		return PTR_ERR(priv->base_reg);
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "rx_reg");
+	priv->rx_reg = devm_ioremap_resource(dev, res);
+	if (IS_ERR(priv->rx_reg))
+		return PTR_ERR(priv->rx_reg);
+
+	priv->csi2_rx[CFG_CSI_PORT_0]  = priv->rx_reg;
+	priv->csi2_rx[CFG_CSI_PORT_0A] = priv->rx_reg;
+	priv->csi2_rx[CFG_CSI_PORT_0B] = priv->rx_reg + 0x1000;
+	priv->csi2_rx[CFG_CSI_PORT_1]  = priv->rx_reg + 0x2000;
+	priv->csi2_rx[CFG_CSI_PORT_2]  = priv->rx_reg + 0x4000;
+
+	priv->seninf_hw = priv->base_reg;
+	for (i = 0; i < SENINF_NUM; i++)
+		priv->seninf_ctrl[i] =  priv->base_reg + 0x1000 * i;
+	for (i = 0; i < SENINF_MUX_NUM; i++)
+		priv->seninf_mux[i] =  priv->base_reg + 0x1000 * i;
+	for (i = 0; i < SENINF_NUM; i++)
+		priv->csi_rx_conf[i] =  priv->base_reg + 0x1000 * i;
+
+	priv->cam_clk = devm_clk_get(dev, "CLK_CAM_SENINF");
+	if (IS_ERR(priv->cam_clk)) {
+		dev_err(dev, "Failed to get cam_clk\n");
+		return -EINVAL;
+	}
+
+	priv->top_mux_clk = devm_clk_get(dev, "CLK_TOP_MUX_SENINF");
+	if (IS_ERR(priv->top_mux_clk)) {
+		dev_err(dev, "Failed to get top_mux_clk\n");
+		return -EINVAL;
+	}
+
+	v4l2_subdev_init(sd, &seninf_subdev_ops);
+
+	ret = seninf_initialize_controls(priv);
+	if (ret) {
+		dev_err(dev, "Failed to initialize controls\n");
+		return ret;
+	}
+#ifdef CONFIG_VIDEO_V4L2_SUBDEV_API
+	sd->internal_ops = &seninf_internal_ops;
+	sd->flags |= V4L2_SUBDEV_FL_HAS_DEVNODE;
+#endif
+	priv->subdev.dev = &pdev->dev;
+	snprintf(sd->name, V4L2_SUBDEV_NAME_SIZE, "%s.mipi-csi",
+		 dev_name(&pdev->dev));
+	v4l2_set_subdevdata(sd, priv);
+#if defined(CONFIG_MEDIA_CONTROLLER)
+	sd->entity.function = MEDIA_ENT_F_CAM_SENSOR;
+	sd->entity.ops = &seninf_media_ops;
+	for (i = 0; i < 4; i++)
+		pads[i].flags = MEDIA_PAD_FL_SINK;
+	for (i = 4; i < NUM_PADS; i++)
+		pads[i].flags = MEDIA_PAD_FL_SOURCE;
+	ret = media_entity_pads_init(&sd->entity, NUM_PADS, pads);
+	if (ret < 0)
+		goto err_free_handler;
+#endif
+	ret = v4l2_async_register_subdev(sd);
+	if (ret < 0) {
+		dev_err(dev, "v4l2 async register subdev failed\n");
+		goto err_clean_entity;
+	}
+	pm_runtime_set_active(dev);
+	pm_runtime_enable(dev);
+	pm_runtime_idle(dev);
+	dev_dbg(dev, "seninf probe -\n");
+	return 0;
+
+err_clean_entity:
+#if defined(CONFIG_MEDIA_CONTROLLER)
+	media_entity_cleanup(&sd->entity);
+#endif
+err_free_handler:
+	v4l2_ctrl_handler_free(&priv->ctrl_handler);
+
+	return ret;
+}
+
+static int seninf_pm_suspend(struct device *dev)
+{
+	pr_debug("seninf_runtime_suspend\n");
+	return 0;
+}
+
+static int seninf_pm_resume(struct device *dev)
+{
+	pr_debug("seninf_runtime_resume\n");
+	return 0;
+}
+
+static const struct dev_pm_ops runtime_pm_ops = {
+	SET_RUNTIME_PM_OPS(seninf_pm_suspend,
+			   seninf_pm_resume,
+			   NULL)
+};
+
+static int seninf_remove(struct platform_device *pdev)
+{
+	struct v4l2_subdev *subdev = platform_get_drvdata(pdev);
+	struct _seninf *priv = container_of(subdev, struct _seninf, subdev);
+
+	v4l2_async_unregister_subdev(&priv->subdev);
+	pm_runtime_disable(priv->dev);
+	return 0;
+}
+
+#ifdef CONFIG_OF
+static const struct of_device_id mtk_seninf_of_match[] = {
+	{.compatible = "mediatek,mt8183-seninf"},
+	{},
+};
+MODULE_DEVICE_TABLE(of, mtk_seninf_of_match);
+#endif
+
+static int seninf_suspend(struct platform_device *pdev, pm_message_t mesg)
+{
+	return 0;
+}
+
+static int seninf_resume(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static struct platform_driver seninf_pdrv = {
+	.probe	= seninf_probe,
+	.remove	= seninf_remove,
+	.suspend = seninf_suspend,
+	.resume = seninf_resume,
+	.driver	= {
+		.name	= "seninf_0",
+		.owner  = THIS_MODULE,
+#ifdef CONFIG_OF
+		.of_match_table = mtk_seninf_of_match,
+#endif
+		.pm  = &runtime_pm_ops,
+	},
+};
+
+static int __init mtk_seninf_init(void)
+{
+	int ret;
+
+	pr_debug("seninf Init\n");
+	ret = platform_driver_register(&seninf_pdrv);
+	if (ret) {
+		pr_err("Failed to register platform driver\n");
+		return ret;
+	}
+	return 0;
+}
+
+static void __exit mtk_seninf_exit(void)
+{
+	pr_debug("seninf Exit\n");
+	platform_driver_unregister(&seninf_pdrv);
+}
+
+late_initcall(mtk_seninf_init);
+module_exit(mtk_seninf_exit);
+
+MODULE_DESCRIPTION("MTK seninf driver");
+MODULE_AUTHOR("Louis Kuo <louis.kuo@mediatek.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("MTK:mtk_seninf");
diff --git a/drivers/media/platform/mtk-isp/isp_50/seninf/seninf_drv_def.h b/drivers/media/platform/mtk-isp/isp_50/seninf/seninf_drv_def.h
new file mode 100644
index 000000000000..6280ae49a97d
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/seninf/seninf_drv_def.h
@@ -0,0 +1,201 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015 MediaTek Inc.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __SENINF_DRV_DEF_H__
+#define __SENINF_DRV_DEF_H__
+
+#if defined(SENINF_CLK_208M)
+#define SENINF_TIMESTAMP_STEP     0x67
+#define SENINF_SETTLE_DELAY       0x15
+#define SENINF_HS_TRAIL_PARAMETER 0x8
+#elif defined(SENINF_CLK_312M)
+#define SENINF_TIMESTAMP_STEP     0x9b
+#define SENINF_SETTLE_DELAY       0x20
+#define SENINF_HS_TRAIL_PARAMETER 0xa
+#else
+#define SENINF_TIMESTAMP_STEP     0x67
+#define SENINF_SETTLE_DELAY       0x15
+#define SENINF_HS_TRAIL_PARAMETER 0x8
+#endif
+
+#define SENINF_DRV_DEBUG_DELAY 1000
+
+#define SENSOR_CLOCK_POLARITY_HIGH     0
+#define SENSOR_CLOCK_POLARITY_LOW      1
+#define NUM_PADS	12
+
+enum {
+	MIPI_OPHY_NCSI2 = 0,
+	MIPI_OPHY_CSI2  = 1,
+	MIPI_CPHY       = 2,
+};
+
+struct sensor_vc_info_struct {
+	unsigned short vc_num;
+	unsigned short vc_pixel_num;
+	unsigned short mode_select;   /* 0: auto mode, 1:direct mode  */
+	unsigned short expo_ratio;   /* 1/1, 1/2, 1/4, 1/8 */
+	unsigned short od_value;      /* OD Value */
+	unsigned short RG_STATSMODE; /* 0: 16x16, 1:8x8, 2:4x4, 3:1x1*/
+	unsigned short VC0_ID;
+	unsigned short vc0_data_type;
+	unsigned short VC0_SIZEH;
+	unsigned short VC0_SIZEV;
+	unsigned short VC1_ID;
+	unsigned short vc1_data_type;
+	unsigned short VC1_SIZEH;
+	unsigned short VC1_SIZEV;
+	unsigned short VC2_ID;
+	unsigned short vc2_data_type;
+	unsigned short VC2_SIZEH;
+	unsigned short VC2_SIZEV;
+	unsigned short VC3_ID;
+	unsigned short vc3_data_type;
+	unsigned short VC3_SIZEH;
+	unsigned short VC3_SIZEV;
+	unsigned short VC4_ID;
+	unsigned short vc4_data_type;
+	unsigned short VC4_SIZEH;
+	unsigned short VC4_SIZEV;
+	unsigned short VC5_ID;
+	unsigned short vc5_data_type;
+	unsigned short VC5_SIZEH;
+	unsigned short VC5_SIZEV;
+};
+
+enum {
+	TEST_DISABLED = 0X0,
+	TEST_PATTERN_MODE,
+	TEST_DEBUG_MODE,
+};
+
+enum {
+	CFG_CSI_PORT_0 = 0x0,/* 4D1C */
+	CFG_CSI_PORT_1,      /* 4D1C */
+	CFG_CSI_PORT_2,      /* 4D1C */
+	CFG_CSI_PORT_0A,     /* 2D1C */
+	CFG_CSI_PORT_0B,     /* 2D1C */
+	CFG_CSI_PORT_MAX_NUM,
+	CFG_CSI_PORT_NONE    /*for non-MIPI sensor */
+};
+
+enum {
+	ONE_PIXEL_MODE  = 0x0,
+	TWO_PIXEL_MODE  = 0x1,
+	FOUR_PIXEL_MODE = 0x2,
+};
+
+#define SENINF_CAM_MUX_MIN      SENINF_MUX1
+#define SENINF_CAM_MUX_MAX      SENINF_MUX3
+#define SENINF_CAMSV_MUX_MIN    SENINF_MUX3
+#define SENINF_CAMSV_MUX_MAX    SENINF_MUX_NUM
+
+#define SENINF_PIXEL_MODE_CAM   TWO_PIXEL_MODE
+#define SENINF_PIXEL_MODE_CAMSV FOUR_PIXEL_MODE
+
+#define SENINF_TIMESTAMP_CLK    1000
+
+enum {
+	SENSOR_MIPI_1_LANE = 0,
+	SENSOR_MIPI_2_LANE,
+	SENSOR_MIPI_3_LANE,
+	SENSOR_MIPI_4_LANE
+};
+
+enum {
+	SENINF_MUX1 = 0x0,
+	SENINF_MUX2 = 0x1,
+	SENINF_MUX3 = 0x2,
+	SENINF_MUX4 = 0x3,
+	SENINF_MUX5 = 0x4,
+	SENINF_MUX6 = 0x5,
+	SENINF_MUX_NUM,
+	SENINF_MUX_ERROR = -1,
+};
+
+enum {
+	SENINF_1 = 0x0,
+	SENINF_2 = 0x1,
+	SENINF_3 = 0x2,
+	SENINF_4 = 0x3,
+	SENINF_5 = 0x4,
+	SENINF_NUM,
+};
+
+enum {
+	PAD_10BIT       = 0x0,
+	PAD_8BIT_7_0    = 0x3,
+	PAD_8BIT_9_2    = 0x4,
+};
+
+enum { /* 0:CSI2(2.5G), 3: parallel, 8:NCSI2(1.5G) */
+	CSI2            = 0x0, /* 2.5G support */
+	TEST_MODEL      = 0x1,
+	CCIR656         = 0x2,
+	PARALLEL_SENSOR = 0x3,
+	SERIAL_SENSOR   = 0x4,
+	HD_TV           = 0x5,
+	EXT_CSI2_OUT1   = 0x6,
+	EXT_CSI2_OUT2   = 0x7,
+	MIPI_SENSOR     = 0x8,/* 1.5G support */
+	VIRTUAL_CHANNEL_1  = 0x9,
+	VIRTUAL_CHANNEL_2  = 0xA,
+	VIRTUAL_CHANNEL_3  = 0xB,
+	VIRTUAL_CHANNEL_4  = 0xC,
+	VIRTUAL_CHANNEL_5  = 0xD,
+	VIRTUAL_CHANNEL_6  = 0xE,
+};
+
+enum { /* 0:CSI2(2.5G), 1:NCSI2(1.5G) */
+	CSI2_1_5G           = 0x0, /* 1.5G support */
+	CSI2_2_5G           = 0x1, /* 2.5G support*/
+	CSI2_2_5G_CPHY      = 0x2, /* 2.5G support*/
+};
+
+enum {
+	RAW_8BIT_FMT        = 0x0,
+	RAW_10BIT_FMT       = 0x1,
+	RAW_12BIT_FMT       = 0x2,
+	YUV422_FMT          = 0x3,
+	RAW_14BIT_FMT       = 0x4,
+	RGB565_MIPI_FMT     = 0x5,
+	RGB888_MIPI_FMT     = 0x6,
+	JPEG_FMT            = 0x7
+};
+
+enum {
+	CMD_SENINF_GET_SENINF_ADDR,
+	CMD_SENINF_DEBUG_TASK,
+	CMD_SENINF_DEBUG_TASK_CAMSV,
+	CMD_SENINF_DEBUG_PIXEL_METER,
+	CMD_SENINF_MAX
+};
+
+/* MIPI sensor pad usage */
+struct seninf_csi_info {
+	unsigned int port;
+	unsigned int         seninf;
+};
+
+struct seninf_csi_mipi {
+	unsigned int     enable;
+	struct seninf_csi_info  *csi_info;
+	unsigned int csi_type;
+	unsigned int     data_lane_num;
+	unsigned int     dpcm;
+	unsigned int     data_header_order;
+	unsigned int     pad_sel;
+};
+
+#endif /*__SENINF_DRV_DEF_H__ */
diff --git a/drivers/media/platform/mtk-isp/isp_50/seninf/seninf_reg.h b/drivers/media/platform/mtk-isp/isp_50/seninf/seninf_reg.h
new file mode 100644
index 000000000000..7402630ab7b6
--- /dev/null
+++ b/drivers/media/platform/mtk-isp/isp_50/seninf/seninf_reg.h
@@ -0,0 +1,992 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015 MediaTek Inc.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _SENINF_REG_H_
+#define _SENINF_REG_H_
+
+#define mt_reg_sync_writel(v, a) \
+	do {	\
+		__raw_writel((v), (void __force __iomem *)((a)));	\
+		/* add memory barrier */ \
+		mb();  \
+	} while (0)
+
+#define seninf_read_reg(reg_base, reg_name) \
+	((unsigned int)ioread32((reg_base) + (reg_name)))
+#define seninf_write_reg(reg_base, reg_name, value) \
+	mt_reg_sync_writel(value, (reg_base) + (reg_name))
+#define write_master(reg_base, reg_name, value, mask)	\
+	mt_reg_sync_writel(ioread32((reg_base) + (reg_name)) \
+			   & (~(mask)) | (value), (reg_base) + (reg_name))
+
+/* 0x11C80000..0x11C850AC */
+#define MIPI_RX_ANA00_CSI0A           0x0000
+#define MIPI_RX_ANA04_CSI0A           0x0004
+#define MIPI_RX_ANA08_CSI0A           0x0008
+#define MIPI_RX_ANA0C_CSI0A           0x000C
+#define MIPI_RX_ANA10_CSI0A           0x0010
+#define MIPI_RX_ANA14_CSI0A           0x0014
+#define MIPI_RX_ANA18_CSI0A           0x0018
+#define MIPI_RX_ANA1C_CSI0A           0x001C
+#define MIPI_RX_ANA20_CSI0A           0x0020
+#define MIPI_RX_ANA24_CSI0A           0x0024
+#define MIPI_RX_ANA28_CSI0A           0x0028
+#define MIPI_RX_ANA2C_CSI0A           0x002C
+#define rsv_0030                      0x0030
+#define MIPI_RX_ANA34_CSI0A           0x0034
+#define MIPI_RX_ANA38_CSI0A           0x0038
+#define rsv_003C                      0x003C
+#define MIPI_RX_ANA40_CSI0A           0x0040
+#define rsv_0044                      0x0044
+#define MIPI_RX_ANA48_CSI0A           0x0048
+#define rsv_004C_13                   0x004C
+#define MIPI_RX_WRAPPER80_CSI0A       0x0080
+#define MIPI_RX_WRAPPER84_CSI0A       0x0084
+#define MIPI_RX_WRAPPER88_CSI0A       0x0088
+#define MIPI_RX_WRAPPER8C_CSI0A       0x008C
+#define MIPI_RX_WRAPPER90_CSI0A       0x0090
+#define MIPI_RX_WRAPPER94_CSI0A       0x0094
+#define MIPI_RX_WRAPPER98_CSI0A       0x0098
+#define MIPI_RX_WRAPPER9C_CSI0A       0x009C
+#define rsv_00A0                      0x00A0
+#define MIPI_RX_ANAA4_CSI0A           0x00A4
+#define MIPI_RX_ANAA8_CSI0A           0x00A8
+#define rsv_00AC_981                  0x00AC
+#define MIPI_RX_ANA00_CSI0B           0x1000
+#define MIPI_RX_ANA04_CSI0B           0x1004
+#define MIPI_RX_ANA08_CSI0B           0x1008
+#define MIPI_RX_ANA0C_CSI0B           0x100C
+#define MIPI_RX_ANA10_CSI0B           0x1010
+#define MIPI_RX_ANA14_CSI0B           0x1014
+#define MIPI_RX_ANA18_CSI0B           0x1018
+#define MIPI_RX_ANA1C_CSI0B           0x101C
+#define MIPI_RX_ANA20_CSI0B           0x1020
+#define MIPI_RX_ANA24_CSI0B           0x1024
+#define MIPI_RX_ANA28_CSI0B           0x1028
+#define MIPI_RX_ANA2C_CSI0B           0x102C
+#define rsv_1030                      0x1030
+#define MIPI_RX_ANA34_CSI0B           0x1034
+#define MIPI_RX_ANA38_CSI0B           0x1038
+#define rsv_103C_3                    0x103C
+#define MIPI_RX_ANA48_CSI0B           0x1048
+#define rsv_104C_13                   0x104C
+#define MIPI_RX_WRAPPER80_CSI0B       0x1080
+#define MIPI_RX_WRAPPER84_CSI0B       0x1084
+#define MIPI_RX_WRAPPER88_CSI0B       0x1088
+#define MIPI_RX_WRAPPER8C_CSI0B       0x108C
+#define MIPI_RX_WRAPPER90_CSI0B       0x1090
+#define MIPI_RX_WRAPPER94_CSI0B       0x1094
+#define MIPI_RX_WRAPPER98_CSI0B       0x1098
+#define MIPI_RX_WRAPPER9C_CSI0B       0x109C
+#define rsv_10A0                      0x10A0
+#define MIPI_RX_ANAA4_CSI0B           0x10A4
+#define MIPI_RX_ANAA8_CSI0B           0x10A8
+#define rsv_10AC_981                  0x10AC
+#define MIPI_RX_ANA00_CSI1A           0x2000
+#define MIPI_RX_ANA04_CSI1A           0x2004
+#define MIPI_RX_ANA08_CSI1A           0x2008
+#define MIPI_RX_ANA0C_CSI1A           0x200C
+#define MIPI_RX_ANA10_CSI1A           0x2010
+#define rsv_2014                      0x2014
+#define MIPI_RX_ANA18_CSI1A           0x2018
+#define MIPI_RX_ANA1C_CSI1A           0x201C
+#define rsv_2020                      0x2020
+#define MIPI_RX_ANA24_CSI1A           0x2024
+#define rsv_2028_8                    0x2028
+#define MIPI_RX_ANA48_CSI1A           0x2048
+#define rsv_204C_13                   0x204C
+#define MIPI_RX_WRAPPER80_CSI1A       0x2080
+#define MIPI_RX_WRAPPER84_CSI1A       0x2084
+#define MIPI_RX_WRAPPER88_CSI1A       0x2088
+#define MIPI_RX_WRAPPER8C_CSI1A       0x208C
+#define MIPI_RX_WRAPPER90_CSI1A       0x2090
+#define MIPI_RX_WRAPPER94_CSI1A       0x2094
+#define MIPI_RX_WRAPPER98_CSI1A       0x2098
+#define MIPI_RX_WRAPPER9C_CSI1A       0x209C
+#define rsv_20A0                      0x20A0
+#define MIPI_RX_ANAA4_CSI1A           0x20A4
+#define MIPI_RX_ANAA8_CSI1A           0x20A8
+#define rsv_20AC_981                  0x20AC
+#define MIPI_RX_ANA00_CSI1B           0x3000
+#define MIPI_RX_ANA04_CSI1B           0x3004
+#define MIPI_RX_ANA08_CSI1B           0x3008
+#define MIPI_RX_ANA0C_CSI1B           0x300C
+#define MIPI_RX_ANA10_CSI1B           0x3010
+#define rsv_3014                      0x3014
+#define MIPI_RX_ANA18_CSI1B           0x3018
+#define MIPI_RX_ANA1C_CSI1B           0x301C
+#define rsv_3020                      0x3020
+#define MIPI_RX_ANA24_CSI1B           0x3024
+#define rsv_3028_8                    0x3028
+#define MIPI_RX_ANA48_CSI1B           0x3048
+#define rsv_304C_13                   0x304C
+#define MIPI_RX_WRAPPER80_CSI1B       0x3080
+#define MIPI_RX_WRAPPER84_CSI1B       0x3084
+#define MIPI_RX_WRAPPER88_CSI1B       0x3088
+#define MIPI_RX_WRAPPER8C_CSI1B       0x308C
+#define MIPI_RX_WRAPPER90_CSI1B       0x3090
+#define MIPI_RX_WRAPPER94_CSI1B       0x3094
+#define MIPI_RX_WRAPPER98_CSI1B       0x3098
+#define MIPI_RX_WRAPPER9C_CSI1B       0x309C
+#define rsv_30A0                      0x30A0
+#define MIPI_RX_ANAA4_CSI1B           0x30A4
+#define MIPI_RX_ANAA8_CSI1B           0x30A8
+#define rsv_30AC_981                  0x30AC
+#define MIPI_RX_ANA00_CSI2A           0x4000
+#define MIPI_RX_ANA04_CSI2A           0x4004
+#define MIPI_RX_ANA08_CSI2A           0x4008
+#define MIPI_RX_ANA0C_CSI2A           0x400C
+#define MIPI_RX_ANA10_CSI2A           0x4010
+#define rsv_4014                      0x4014
+#define MIPI_RX_ANA18_CSI2A           0x4018
+#define MIPI_RX_ANA1C_CSI2A           0x401C
+#define rsv_4020                      0x4020
+#define MIPI_RX_ANA24_CSI2A           0x4024
+#define rsv_4028_8                    0x4028
+#define MIPI_RX_ANA48_CSI2A           0x4048
+#define rsv_404C_13                   0x404C
+#define MIPI_RX_WRAPPER80_CSI2A       0x4080
+#define MIPI_RX_WRAPPER84_CSI2A       0x4084
+#define MIPI_RX_WRAPPER88_CSI2A       0x4088
+#define MIPI_RX_WRAPPER8C_CSI2A       0x408C
+#define MIPI_RX_WRAPPER90_CSI2A       0x4090
+#define MIPI_RX_WRAPPER94_CSI2A       0x4094
+#define MIPI_RX_WRAPPER98_CSI2A       0x4098
+#define MIPI_RX_WRAPPER9C_CSI2A       0x409C
+#define rsv_40A0                      0x40A0
+#define MIPI_RX_ANAA4_CSI2A           0x40A4
+#define MIPI_RX_ANAA8_CSI2A           0x40A8
+#define rsv_40AC_981                  0x40AC
+#define MIPI_RX_ANA00_CSI2B           0x5000
+#define MIPI_RX_ANA04_CSI2B           0x5004
+#define MIPI_RX_ANA08_CSI2B           0x5008
+#define MIPI_RX_ANA0C_CSI2B           0x500C
+#define MIPI_RX_ANA10_CSI2B           0x5010
+#define rsv_5014                      0x5014
+#define MIPI_RX_ANA18_CSI2B           0x5018
+#define MIPI_RX_ANA1C_CSI2B           0x501C
+#define rsv_5020                      0x5020
+#define MIPI_RX_ANA24_CSI2B           0x5024
+#define rsv_5028_8                    0x5028
+#define MIPI_RX_ANA48_CSI2B           0x5048
+#define rsv_504C_13                   0x504C
+#define MIPI_RX_WRAPPER80_CSI2B       0x5080
+#define MIPI_RX_WRAPPER84_CSI2B       0x5084
+#define MIPI_RX_WRAPPER88_CSI2B       0x5088
+#define MIPI_RX_WRAPPER8C_CSI2B       0x508C
+#define MIPI_RX_WRAPPER90_CSI2B       0x5090
+#define MIPI_RX_WRAPPER94_CSI2B       0x5094
+#define MIPI_RX_WRAPPER98_CSI2B       0x5098
+#define MIPI_RX_WRAPPER9C_CSI2B       0x509C
+#define rsv_50A0                      0x50A0
+#define MIPI_RX_ANAA4_CSI2B           0x50A4
+#define MIPI_RX_ANAA8_CSI2B           0x50A8
+#define rsv_50AC_20                   0x50AC
+
+/* 0x1A040000..0x1A047D40 */
+#define SENINF_TOP_CTRL                        0x0000
+#define SENINF_TOP_CMODEL_PAR                  0x0004
+#define SENINF_TOP_MUX_CTRL                    0x0008
+#define rsv_000C                               0x000C
+#define SENINF_TOP_CAM_MUX_CTRL                0x0010
+#define SENINF_TOP_N3D_A_CTL                   0x0014
+#define SENINF_TOP_N3D_B_CTL                   0x0018
+#define SENINF_TOP_PHY_SENINF_CTL_CSI0         0x001C
+#define SENINF_TOP_PHY_SENINF_CTL_CSI1         0x0020
+#define SENINF_TOP_PHY_SENINF_CTL_CSI2         0x0024
+#define rsv_0028_54                            0x0028
+#define SENINF_N3D_A_CTL                       0x0100
+#define SENINF_N3D_A_POS                       0x0104
+#define SENINF_N3D_A_TRIG                      0x0108
+#define SENINF_N3D_A_INT                       0x010C
+#define SENINF_N3D_A_CNT0                      0x0110
+#define SENINF_N3D_A_CNT1                      0x0114
+#define SENINF_N3D_A_DBG                       0x0118
+#define SENINF_N3D_A_DIFF_THR                  0x011C
+#define SENINF_N3D_A_DIFF_CNT                  0x0120
+#define SENINF_N3D_A_DBG_1                     0x0124
+#define SENINF_N3D_A_VALID_TG_CNT              0x0128
+#define SENINF_N3D_A_SYNC_A_PERIOD             0x012C
+#define SENINF_N3D_A_SYNC_B_PERIOD             0x0130
+#define SENINF_N3D_A_SYNC_A_PULSE_LEN          0x0134
+#define SENINF_N3D_A_SYNC_B_PULSE_LEN          0x0138
+#define SENINF_N3D_A_SUB_CNT                   0x013C
+#define SENINF_N3D_A_VSYNC_CNT                 0x0140
+#define rsv_0144_47                            0x0144
+#define SENINF1_CTRL                           0x0200
+#define SENINF1_CTRL_EXT                       0x0204
+#define SENINF1_ASYNC_CTRL                     0x0208
+#define rsv_020C_253                           0x020C
+#define SENINF_TG1_PH_CNT                      0x0600
+#define SENINF_TG1_SEN_CK                      0x0604
+#define SENINF_TG1_TM_CTL                      0x0608
+#define SENINF_TG1_TM_SIZE                     0x060C
+#define SENINF_TG1_TM_CLK                      0x0610
+#define SENINF_TG1_TM_STP                      0x0614
+#define rsv_0618_131                           0x0618
+#define MIPI_RX_CON24_CSI0                     0x0824
+#define MIPI_RX_CON28_CSI0                     0x0828
+#define rsv_082C_2                             0x082C
+#define MIPI_RX_CON34_CSI0                     0x0834
+#define MIPI_RX_CON38_CSI0                     0x0838
+#define MIPI_RX_CON3C_CSI0                     0x083C
+#define rsv_0840_15                            0x0840
+#define MIPI_RX_CON7C_CSI0                     0x087C
+#define MIPI_RX_CON80_CSI0                     0x0880
+#define MIPI_RX_CON84_CSI0                     0x0884
+#define MIPI_RX_CON88_CSI0                     0x0888
+#define MIPI_RX_CON8C_CSI0                     0x088C
+#define MIPI_RX_CON90_CSI0                     0x0890
+#define MIPI_RX_CON94_CSI0                     0x0894
+#define MIPI_RX_CON98_CSI0                     0x0898
+#define rsv_089C                               0x089C
+#define MIPI_RX_CONA0_CSI0                     0x08A0
+#define rsv_08A4_3                             0x08A4
+#define MIPI_RX_CONB0_CSI0                     0x08B0
+#define MIPI_RX_CONB4_CSI0                     0x08B4
+#define MIPI_RX_CONB8_CSI0                     0x08B8
+#define MIPI_RX_CONBC_CSI0                     0x08BC
+#define MIPI_RX_CONC0_CSI0                     0x08C0
+#define MIPI_RX_CONC4_CSI0                     0x08C4
+#define MIPI_RX_CONC8_CSI0                     0x08C8
+#define MIPI_RX_CONCC_CSI0                     0x08CC
+#define MIPI_RX_COND0_CSI0                     0x08D0
+#define rsv_08D4_75                            0x08D4
+#define SENINF1_CSI2_CTL                       0x0A00
+#define SENINF1_CSI2_LNRC_TIMING               0x0A04
+#define SENINF1_CSI2_LNRD_TIMING               0x0A08
+#define SENINF1_CSI2_DPCM                      0x0A0C
+#define SENINF1_CSI2_INT_EN                    0x0A10
+#define SENINF1_CSI2_INT_STATUS                0x0A14
+#define SENINF1_CSI2_DGB_SEL                   0x0A18
+#define SENINF1_CSI2_DBG_PORT                  0x0A1C
+#define SENINF1_CSI2_SPARE0                    0x0A20
+#define SENINF1_CSI2_SPARE1                    0x0A24
+#define SENINF1_CSI2_LNRC_FSM                  0x0A28
+#define SENINF1_CSI2_LNRD_FSM                  0x0A2C
+#define SENINF1_CSI2_FRAME_LINE_NUM            0x0A30
+#define SENINF1_CSI2_GENERIC_SHORT             0x0A34
+#define SENINF1_CSI2_HSRX_DBG                  0x0A38
+#define SENINF1_CSI2_DI                        0x0A3C
+#define SENINF1_CSI2_HS_TRAIL                  0x0A40
+#define SENINF1_CSI2_DI_CTRL                   0x0A44
+#define rsv_0A48                               0x0A48
+#define SENINF1_CSI2_DETECT_CON1               0x0A4C
+#define SENINF1_CSI2_DETECT_CON2               0x0A50
+#define SENINF1_CSI2_DETECT_CON3               0x0A54
+#define SENINF1_CSI2_RLR0_CON0                 0x0A58
+#define SENINF1_CSI2_RLR1_CON0                 0x0A5C
+#define SENINF1_CSI2_RLR2_CON0                 0x0A60
+#define SENINF1_CSI2_RLR_CON0                  0x0A64
+#define SENINF1_CSI2_MUX_CON                   0x0A68
+#define SENINF1_CSI2_DETECT_DBG0               0x0A6C
+#define SENINF1_CSI2_DETECT_DBG1               0x0A70
+#define SENINF1_CSI2_RESYNC_MERGE_CTL          0x0A74
+#define SENINF1_CSI2_CTRL_TRIO_MUX             0x0A78
+#define SENINF1_CSI2_CTRL_TRIO_CON             0x0A7C
+#define SENINF1_FIX_ADDR_CPHY0_DBG             0x0A80
+#define SENINF1_FIX_ADDR_CPHY1_DBG             0x0A84
+#define SENINF1_FIX_ADDR_CPHY2_DBG             0x0A88
+#define SENINF1_FIX_ADDR_DBG                   0x0A8C
+#define SENINF1_WIRE_STATE_DECODE_CPHY0_DBG0   0x0A90
+#define SENINF1_WIRE_STATE_DECODE_CPHY0_DBG1   0x0A94
+#define SENINF1_WIRE_STATE_DECODE_CPHY1_DBG0   0x0A98
+#define SENINF1_WIRE_STATE_DECODE_CPHY1_DBG1   0x0A9C
+#define SENINF1_WIRE_STATE_DECODE_CPHY2_DBG0   0x0AA0
+#define SENINF1_WIRE_STATE_DECODE_CPHY2_DBG1   0x0AA4
+#define SENINF1_SYNC_RESYNC_CTL                0x0AA8
+#define SENINF1_POST_DETECT_CTL                0x0AAC
+#define SENINF1_WIRE_STATE_DECODE_CONFIG       0x0AB0
+#define SENINF1_CSI2_CPHY_LNRD_FSM             0x0AB4
+#define SENINF1_FIX_ADDR_CPHY0_DBG0            0x0AB8
+#define SENINF1_FIX_ADDR_CPHY0_DBG1            0x0ABC
+#define SENINF1_FIX_ADDR_CPHY0_DBG2            0x0AC0
+#define SENINF1_FIX_ADDR_CPHY1_DBG0            0x0AC4
+#define SENINF1_FIX_ADDR_CPHY1_DBG1            0x0AC8
+#define SENINF1_FIX_ADDR_CPHY1_DBG2            0x0ACC
+#define SENINF1_FIX_ADDR_CPHY2_DBG0            0x0AD0
+#define SENINF1_FIX_ADDR_CPHY2_DBG1            0x0AD4
+#define SENINF1_FIX_ADDR_CPHY2_DBG2            0x0AD8
+#define SENINF1_FIX_ADDR_DBG0                  0x0ADC
+#define SENINF1_FIX_ADDR_DBG1                  0x0AE0
+#define SENINF1_FIX_ADDR_DBG2                  0x0AE4
+#define SENINF1_CSI2_MODE                      0x0AE8
+#define rsv_0AEC                               0x0AEC
+#define SENINF1_CSI2_DI_EXT                    0x0AF0
+#define SENINF1_CSI2_DI_CTRL_EXT               0x0AF4
+#define SENINF1_CSI2_CPHY_LOOPBACK             0x0AF8
+#define rsv_0AFC                               0x0AFC
+#define SENINF1_CSI2_PROGSEQ_0                 0x0B00
+#define SENINF1_CSI2_PROGSEQ_1                 0x0B04
+#define rsv_0B08_2                             0x0B08
+#define SENINF1_CSI2_INT_EN_EXT                0x0B10
+#define SENINF1_CSI2_INT_STATUS_EXT            0x0B14
+#define SENINF1_CSI2_CPHY_FIX_POINT_RST        0x0B18
+#define SENINF1_CSI2_RLR3_CON0                 0x0B1C
+#define SENINF1_CSI2_DPHY_SYNC                 0x0B20
+#define SENINF1_CSI2_DESKEW_SYNC               0x0B24
+#define SENINF1_CSI2_DETECT_DBG2               0x0B28
+#define rsv_0B2C                               0x0B2C
+#define SENINF1_FIX_ADDR_CPHY3_DBG0            0x0B30
+#define SENINF1_FIX_ADDR_CPHY3_DBG1            0x0B34
+#define SENINF1_FIX_ADDR_CPHY3_DBG2            0x0B38
+#define SENINF1_CSI2_DI_EXT_2                  0x0B3C
+#define SENINF1_CSI2_DI_CTRL_EXT_2             0x0B40
+#define SENINF1_WIRE_STATE_DECODE_CPHY3_DBG0   0x0B44
+#define SENINF1_WIRE_STATE_DECODE_CPHY3_DBG1   0x0B48
+#define rsv_0B4C_109                           0x0B4C
+#define SENINF1_MUX_CTRL                       0x0D00
+#define SENINF1_MUX_INTEN                      0x0D04
+#define SENINF1_MUX_INTSTA                     0x0D08
+#define SENINF1_MUX_SIZE                       0x0D0C
+#define SENINF1_MUX_DEBUG_1                    0x0D10
+#define SENINF1_MUX_DEBUG_2                    0x0D14
+#define SENINF1_MUX_DEBUG_3                    0x0D18
+#define SENINF1_MUX_DEBUG_4                    0x0D1C
+#define SENINF1_MUX_DEBUG_5                    0x0D20
+#define SENINF1_MUX_DEBUG_6                    0x0D24
+#define SENINF1_MUX_DEBUG_7                    0x0D28
+#define SENINF1_MUX_SPARE                      0x0D2C
+#define SENINF1_MUX_DATA                       0x0D30
+#define SENINF1_MUX_DATA_CNT                   0x0D34
+#define SENINF1_MUX_CROP                       0x0D38
+#define SENINF1_MUX_CTRL_EXT                   0x0D3C
+#define rsv_0D40_240                           0x0D40
+#define SENINF_N3D_B_CTL                       0x1100
+#define SENINF_N3D_B_POS                       0x1104
+#define SENINF_N3D_B_TRIG                      0x1108
+#define SENINF_N3D_B_INT                       0x110C
+#define SENINF_N3D_B_CNT0                      0x1110
+#define SENINF_N3D_B_CNT1                      0x1114
+#define SENINF_N3D_B_DBG                       0x1118
+#define SENINF_N3D_B_DIFF_THR                  0x111C
+#define SENINF_N3D_B_DIFF_CNT                  0x1120
+#define SENINF_N3D_B_DBG_1                     0x1124
+#define SENINF_N3D_B_VALID_TG_CNT              0x1128
+#define SENINF_N3D_B_SYNC_A_PERIOD             0x112C
+#define SENINF_N3D_B_SYNC_B_PERIOD             0x1130
+#define SENINF_N3D_B_SYNC_A_PULSE_LEN          0x1134
+#define SENINF_N3D_B_SYNC_B_PULSE_LEN          0x1138
+#define SENINF_N3D_B_SUB_CNT                   0x113C
+#define SENINF_N3D_B_VSYNC_CNT                 0x1140
+#define rsv_1144_47                            0x1144
+#define SENINF2_CTRL                           0x1200
+#define SENINF2_CTRL_EXT                       0x1204
+#define SENINF2_ASYNC_CTRL                     0x1208
+#define rsv_120C_253                           0x120C
+#define SENINF_TG2_PH_CNT                      0x1600
+#define SENINF_TG2_SEN_CK                      0x1604
+#define SENINF_TG2_TM_CTL                      0x1608
+#define SENINF_TG2_TM_SIZE                     0x160C
+#define SENINF_TG2_TM_CLK                      0x1610
+#define SENINF_TG2_TM_STP                      0x1614
+#define rsv_1618_131                           0x1618
+#define MIPI_RX_CON24_CSI1                     0x1824
+#define MIPI_RX_CON28_CSI1                     0x1828
+#define rsv_182C_2                             0x182C
+#define MIPI_RX_CON34_CSI1                     0x1834
+#define MIPI_RX_CON38_CSI1                     0x1838
+#define MIPI_RX_CON3C_CSI1                     0x183C
+#define rsv_1840_15                            0x1840
+#define MIPI_RX_CON7C_CSI1                     0x187C
+#define MIPI_RX_CON80_CSI1                     0x1880
+#define MIPI_RX_CON84_CSI1                     0x1884
+#define MIPI_RX_CON88_CSI1                     0x1888
+#define MIPI_RX_CON8C_CSI1                     0x188C
+#define MIPI_RX_CON90_CSI1                     0x1890
+#define MIPI_RX_CON94_CSI1                     0x1894
+#define MIPI_RX_CON98_CSI1                     0x1898
+#define rsv_189C                               0x189C
+#define MIPI_RX_CONA0_CSI1                     0x18A0
+#define rsv_18A4_3                             0x18A4
+#define MIPI_RX_CONB0_CSI1                     0x18B0
+#define MIPI_RX_CONB4_CSI1                     0x18B4
+#define MIPI_RX_CONB8_CSI1                     0x18B8
+#define MIPI_RX_CONBC_CSI1                     0x18BC
+#define MIPI_RX_CONC0_CSI1                     0x18C0
+#define MIPI_RX_CONC4_CSI1                     0x18C4
+#define MIPI_RX_CONC8_CSI1                     0x18C8
+#define MIPI_RX_CONCC_CSI1                     0x18CC
+#define MIPI_RX_COND0_CSI1                     0x18D0
+#define rsv_18D4_75                            0x18D4
+#define SENINF2_CSI2_CTL                       0x1A00
+#define SENINF2_CSI2_LNRC_TIMING               0x1A04
+#define SENINF2_CSI2_LNRD_TIMING               0x1A08
+#define SENINF2_CSI2_DPCM                      0x1A0C
+#define SENINF2_CSI2_INT_EN                    0x1A10
+#define SENINF2_CSI2_INT_STATUS                0x1A14
+#define SENINF2_CSI2_DGB_SEL                   0x1A18
+#define SENINF2_CSI2_DBG_PORT                  0x1A1C
+#define SENINF2_CSI2_SPARE0                    0x1A20
+#define SENINF2_CSI2_SPARE1                    0x1A24
+#define SENINF2_CSI2_LNRC_FSM                  0x1A28
+#define SENINF2_CSI2_LNRD_FSM                  0x1A2C
+#define SENINF2_CSI2_FRAME_LINE_NUM            0x1A30
+#define SENINF2_CSI2_GENERIC_SHORT             0x1A34
+#define SENINF2_CSI2_HSRX_DBG                  0x1A38
+#define SENINF2_CSI2_DI                        0x1A3C
+#define SENINF2_CSI2_HS_TRAIL                  0x1A40
+#define SENINF2_CSI2_DI_CTRL                   0x1A44
+#define rsv_1A48                               0x1A48
+#define SENINF2_CSI2_DETECT_CON1               0x1A4C
+#define SENINF2_CSI2_DETECT_CON2               0x1A50
+#define SENINF2_CSI2_DETECT_CON3               0x1A54
+#define SENINF2_CSI2_RLR0_CON0                 0x1A58
+#define SENINF2_CSI2_RLR1_CON0                 0x1A5C
+#define SENINF2_CSI2_RLR2_CON0                 0x1A60
+#define SENINF2_CSI2_RLR_CON0                  0x1A64
+#define SENINF2_CSI2_MUX_CON                   0x1A68
+#define SENINF2_CSI2_DETECT_DBG0               0x1A6C
+#define SENINF2_CSI2_DETECT_DBG1               0x1A70
+#define SENINF2_CSI2_RESYNC_MERGE_CTL          0x1A74
+#define SENINF2_CSI2_CTRL_TRIO_MUX             0x1A78
+#define SENINF2_CSI2_CTRL_TRIO_CON             0x1A7C
+#define SENINF2_FIX_ADDR_CPHY0_DBG             0x1A80
+#define SENINF2_FIX_ADDR_CPHY1_DBG             0x1A84
+#define SENINF2_FIX_ADDR_CPHY2_DBG             0x1A88
+#define SENINF2_FIX_ADDR_DBG                   0x1A8C
+#define SENINF2_WIRE_STATE_DECODE_CPHY0_DBG0   0x1A90
+#define SENINF2_WIRE_STATE_DECODE_CPHY0_DBG1   0x1A94
+#define SENINF2_WIRE_STATE_DECODE_CPHY1_DBG0   0x1A98
+#define SENINF2_WIRE_STATE_DECODE_CPHY1_DBG1   0x1A9C
+#define SENINF2_WIRE_STATE_DECODE_CPHY2_DBG0   0x1AA0
+#define SENINF2_WIRE_STATE_DECODE_CPHY2_DBG1   0x1AA4
+#define SENINF2_SYNC_RESYNC_CTL                0x1AA8
+#define SENINF2_POST_DETECT_CTL                0x1AAC
+#define SENINF2_WIRE_STATE_DECODE_CONFIG       0x1AB0
+#define SENINF2_CSI2_CPHY_LNRD_FSM             0x1AB4
+#define SENINF2_FIX_ADDR_CPHY0_DBG0            0x1AB8
+#define SENINF2_FIX_ADDR_CPHY0_DBG1            0x1ABC
+#define SENINF2_FIX_ADDR_CPHY0_DBG2            0x1AC0
+#define SENINF2_FIX_ADDR_CPHY1_DBG0            0x1AC4
+#define SENINF2_FIX_ADDR_CPHY1_DBG1            0x1AC8
+#define SENINF2_FIX_ADDR_CPHY1_DBG2            0x1ACC
+#define SENINF2_FIX_ADDR_CPHY2_DBG0            0x1AD0
+#define SENINF2_FIX_ADDR_CPHY2_DBG1            0x1AD4
+#define SENINF2_FIX_ADDR_CPHY2_DBG2            0x1AD8
+#define SENINF2_FIX_ADDR_DBG0                  0x1ADC
+#define SENINF2_FIX_ADDR_DBG1                  0x1AE0
+#define SENINF2_FIX_ADDR_DBG2                  0x1AE4
+#define SENINF2_CSI2_MODE                      0x1AE8
+#define rsv_1AEC                               0x1AEC
+#define SENINF2_CSI2_DI_EXT                    0x1AF0
+#define SENINF2_CSI2_DI_CTRL_EXT               0x1AF4
+#define SENINF2_CSI2_CPHY_LOOPBACK             0x1AF8
+#define rsv_1AFC                               0x1AFC
+#define SENINF2_CSI2_PROGSEQ_0                 0x1B00
+#define SENINF2_CSI2_PROGSEQ_1                 0x1B04
+#define rsv_1B08_2                             0x1B08
+#define SENINF2_CSI2_INT_EN_EXT                0x1B10
+#define SENINF2_CSI2_INT_STATUS_EXT            0x1B14
+#define SENINF2_CSI2_CPHY_FIX_POINT_RST        0x1B18
+#define SENINF2_CSI2_RLR3_CON0                 0x1B1C
+#define SENINF2_CSI2_DPHY_SYNC                 0x1B20
+#define SENINF2_CSI2_DESKEW_SYNC               0x1B24
+#define SENINF2_CSI2_DETECT_DBG2               0x1B28
+#define rsv_1B2C                               0x1B2C
+#define SENINF2_FIX_ADDR_CPHY3_DBG0            0x1B30
+#define SENINF2_FIX_ADDR_CPHY3_DBG1            0x1B34
+#define SENINF2_FIX_ADDR_CPHY3_DBG2            0x1B38
+#define SENINF2_CSI2_DI_EXT_2                  0x1B3C
+#define SENINF2_CSI2_DI_CTRL_EXT_2             0x1B40
+#define SENINF2_WIRE_STATE_DECODE_CPHY3_DBG0   0x1B44
+#define SENINF2_WIRE_STATE_DECODE_CPHY3_DBG1   0x1B48
+#define rsv_1B4C_109                           0x1B4C
+#define SENINF2_MUX_CTRL                       0x1D00
+#define SENINF2_MUX_INTEN                      0x1D04
+#define SENINF2_MUX_INTSTA                     0x1D08
+#define SENINF2_MUX_SIZE                       0x1D0C
+#define SENINF2_MUX_DEBUG_1                    0x1D10
+#define SENINF2_MUX_DEBUG_2                    0x1D14
+#define SENINF2_MUX_DEBUG_3                    0x1D18
+#define SENINF2_MUX_DEBUG_4                    0x1D1C
+#define SENINF2_MUX_DEBUG_5                    0x1D20
+#define SENINF2_MUX_DEBUG_6                    0x1D24
+#define SENINF2_MUX_DEBUG_7                    0x1D28
+#define SENINF2_MUX_SPARE                      0x1D2C
+#define SENINF2_MUX_DATA                       0x1D30
+#define SENINF2_MUX_DATA_CNT                   0x1D34
+#define SENINF2_MUX_CROP                       0x1D38
+#define SENINF2_MUX_CTRL_EXT                   0x1D3C
+#define rsv_1D40_304                           0x1D40
+#define SENINF3_CTRL                           0x2200
+#define SENINF3_CTRL_EXT                       0x2204
+#define SENINF3_ASYNC_CTRL                     0x2208
+#define rsv_220C_253                           0x220C
+#define SENINF_TG3_PH_CNT                      0x2600
+#define SENINF_TG3_SEN_CK                      0x2604
+#define SENINF_TG3_TM_CTL                      0x2608
+#define SENINF_TG3_TM_SIZE                     0x260C
+#define SENINF_TG3_TM_CLK                      0x2610
+#define SENINF_TG3_TM_STP                      0x2614
+#define rsv_2618_131                           0x2618
+#define MIPI_RX_CON24_CSI2                     0x2824
+#define MIPI_RX_CON28_CSI2                     0x2828
+#define rsv_282C_2                             0x282C
+#define MIPI_RX_CON34_CSI2                     0x2834
+#define MIPI_RX_CON38_CSI2                     0x2838
+#define MIPI_RX_CON3C_CSI2                     0x283C
+#define rsv_2840_15                            0x2840
+#define MIPI_RX_CON7C_CSI2                     0x287C
+#define MIPI_RX_CON80_CSI2                     0x2880
+#define MIPI_RX_CON84_CSI2                     0x2884
+#define MIPI_RX_CON88_CSI2                     0x2888
+#define MIPI_RX_CON8C_CSI2                     0x288C
+#define MIPI_RX_CON90_CSI2                     0x2890
+#define MIPI_RX_CON94_CSI2                     0x2894
+#define MIPI_RX_CON98_CSI2                     0x2898
+#define rsv_289C                               0x289C
+#define MIPI_RX_CONA0_CSI2                     0x28A0
+#define rsv_28A4_3                             0x28A4
+#define MIPI_RX_CONB0_CSI2                     0x28B0
+#define MIPI_RX_CONB4_CSI2                     0x28B4
+#define MIPI_RX_CONB8_CSI2                     0x28B8
+#define MIPI_RX_CONBC_CSI2                     0x28BC
+#define MIPI_RX_CONC0_CSI2                     0x28C0
+#define MIPI_RX_CONC4_CSI2                     0x28C4
+#define MIPI_RX_CONC8_CSI2                     0x28C8
+#define MIPI_RX_CONCC_CSI2                     0x28CC
+#define MIPI_RX_COND0_CSI2                     0x28D0
+#define rsv_28D4_75                            0x28D4
+#define SENINF3_CSI2_CTL                       0x2A00
+#define SENINF3_CSI2_LNRC_TIMING               0x2A04
+#define SENINF3_CSI2_LNRD_TIMING               0x2A08
+#define SENINF3_CSI2_DPCM                      0x2A0C
+#define SENINF3_CSI2_INT_EN                    0x2A10
+#define SENINF3_CSI2_INT_STATUS                0x2A14
+#define SENINF3_CSI2_DGB_SEL                   0x2A18
+#define SENINF3_CSI2_DBG_PORT                  0x2A1C
+#define SENINF3_CSI2_SPARE0                    0x2A20
+#define SENINF3_CSI2_SPARE1                    0x2A24
+#define SENINF3_CSI2_LNRC_FSM                  0x2A28
+#define SENINF3_CSI2_LNRD_FSM                  0x2A2C
+#define SENINF3_CSI2_FRAME_LINE_NUM            0x2A30
+#define SENINF3_CSI2_GENERIC_SHORT             0x2A34
+#define SENINF3_CSI2_HSRX_DBG                  0x2A38
+#define SENINF3_CSI2_DI                        0x2A3C
+#define SENINF3_CSI2_HS_TRAIL                  0x2A40
+#define SENINF3_CSI2_DI_CTRL                   0x2A44
+#define rsv_2A48                               0x2A48
+#define SENINF3_CSI2_DETECT_CON1               0x2A4C
+#define SENINF3_CSI2_DETECT_CON2               0x2A50
+#define SENINF3_CSI2_DETECT_CON3               0x2A54
+#define SENINF3_CSI2_RLR0_CON0                 0x2A58
+#define SENINF3_CSI2_RLR1_CON0                 0x2A5C
+#define SENINF3_CSI2_RLR2_CON0                 0x2A60
+#define SENINF3_CSI2_RLR_CON0                  0x2A64
+#define SENINF3_CSI2_MUX_CON                   0x2A68
+#define SENINF3_CSI2_DETECT_DBG0               0x2A6C
+#define SENINF3_CSI2_DETECT_DBG1               0x2A70
+#define SENINF3_CSI2_RESYNC_MERGE_CTL          0x2A74
+#define SENINF3_CSI2_CTRL_TRIO_MUX             0x2A78
+#define SENINF3_CSI2_CTRL_TRIO_CON             0x2A7C
+#define SENINF3_FIX_ADDR_CPHY0_DBG             0x2A80
+#define SENINF3_FIX_ADDR_CPHY1_DBG             0x2A84
+#define SENINF3_FIX_ADDR_CPHY2_DBG             0x2A88
+#define SENINF3_FIX_ADDR_DBG                   0x2A8C
+#define SENINF3_WIRE_STATE_DECODE_CPHY0_DBG0   0x2A90
+#define SENINF3_WIRE_STATE_DECODE_CPHY0_DBG1   0x2A94
+#define SENINF3_WIRE_STATE_DECODE_CPHY1_DBG0   0x2A98
+#define SENINF3_WIRE_STATE_DECODE_CPHY1_DBG1   0x2A9C
+#define SENINF3_WIRE_STATE_DECODE_CPHY2_DBG0   0x2AA0
+#define SENINF3_WIRE_STATE_DECODE_CPHY2_DBG1   0x2AA4
+#define SENINF3_SYNC_RESYNC_CTL                0x2AA8
+#define SENINF3_POST_DETECT_CTL                0x2AAC
+#define SENINF3_WIRE_STATE_DECODE_CONFIG       0x2AB0
+#define SENINF3_CSI2_CPHY_LNRD_FSM             0x2AB4
+#define SENINF3_FIX_ADDR_CPHY0_DBG0            0x2AB8
+#define SENINF3_FIX_ADDR_CPHY0_DBG1            0x2ABC
+#define SENINF3_FIX_ADDR_CPHY0_DBG2            0x2AC0
+#define SENINF3_FIX_ADDR_CPHY1_DBG0            0x2AC4
+#define SENINF3_FIX_ADDR_CPHY1_DBG1            0x2AC8
+#define SENINF3_FIX_ADDR_CPHY1_DBG2            0x2ACC
+#define SENINF3_FIX_ADDR_CPHY2_DBG0            0x2AD0
+#define SENINF3_FIX_ADDR_CPHY2_DBG1            0x2AD4
+#define SENINF3_FIX_ADDR_CPHY2_DBG2            0x2AD8
+#define SENINF3_FIX_ADDR_DBG0                  0x2ADC
+#define SENINF3_FIX_ADDR_DBG1                  0x2AE0
+#define SENINF3_FIX_ADDR_DBG2                  0x2AE4
+#define SENINF3_CSI2_MODE                      0x2AE8
+#define rsv_2AEC                               0x2AEC
+#define SENINF3_CSI2_DI_EXT                    0x2AF0
+#define SENINF3_CSI2_DI_CTRL_EXT               0x2AF4
+#define SENINF3_CSI2_CPHY_LOOPBACK             0x2AF8
+#define rsv_2AFC                               0x2AFC
+#define SENINF3_CSI2_PROGSEQ_0                 0x2B00
+#define SENINF3_CSI2_PROGSEQ_1                 0x2B04
+#define rsv_2B08_2                             0x2B08
+#define SENINF3_CSI2_INT_EN_EXT                0x2B10
+#define SENINF3_CSI2_INT_STATUS_EXT            0x2B14
+#define SENINF3_CSI2_CPHY_FIX_POINT_RST        0x2B18
+#define SENINF3_CSI2_RLR3_CON0                 0x2B1C
+#define SENINF3_CSI2_DPHY_SYNC                 0x2B20
+#define SENINF3_CSI2_DESKEW_SYNC               0x2B24
+#define SENINF3_CSI2_DETECT_DBG2               0x2B28
+#define rsv_2B2C                               0x2B2C
+#define SENINF3_FIX_ADDR_CPHY3_DBG0            0x2B30
+#define SENINF3_FIX_ADDR_CPHY3_DBG1            0x2B34
+#define SENINF3_FIX_ADDR_CPHY3_DBG2            0x2B38
+#define SENINF3_CSI2_DI_EXT_2                  0x2B3C
+#define SENINF3_CSI2_DI_CTRL_EXT_2             0x2B40
+#define SENINF3_WIRE_STATE_DECODE_CPHY3_DBG0   0x2B44
+#define SENINF3_WIRE_STATE_DECODE_CPHY3_DBG1   0x2B48
+#define rsv_2B4C_109                           0x2B4C
+#define SENINF3_MUX_CTRL                       0x2D00
+#define SENINF3_MUX_INTEN                      0x2D04
+#define SENINF3_MUX_INTSTA                     0x2D08
+#define SENINF3_MUX_SIZE                       0x2D0C
+#define SENINF3_MUX_DEBUG_1                    0x2D10
+#define SENINF3_MUX_DEBUG_2                    0x2D14
+#define SENINF3_MUX_DEBUG_3                    0x2D18
+#define SENINF3_MUX_DEBUG_4                    0x2D1C
+#define SENINF3_MUX_DEBUG_5                    0x2D20
+#define SENINF3_MUX_DEBUG_6                    0x2D24
+#define SENINF3_MUX_DEBUG_7                    0x2D28
+#define SENINF3_MUX_SPARE                      0x2D2C
+#define SENINF3_MUX_DATA                       0x2D30
+#define SENINF3_MUX_DATA_CNT                   0x2D34
+#define SENINF3_MUX_CROP                       0x2D38
+#define SENINF3_MUX_CTRL_EXT                   0x2D3C
+#define rsv_2D40_304                           0x2D40
+#define SENINF4_CTRL                           0x3200
+#define SENINF4_CTRL_EXT                       0x3204
+#define SENINF4_ASYNC_CTRL                     0x3208
+#define rsv_320C_253                           0x320C
+#define SENINF_TG4_PH_CNT                      0x3600
+#define SENINF_TG4_SEN_CK                      0x3604
+#define SENINF_TG4_TM_CTL                      0x3608
+#define SENINF_TG4_TM_SIZE                     0x360C
+#define SENINF_TG4_TM_CLK                      0x3610
+#define SENINF_TG4_TM_STP                      0x3614
+#define rsv_3618_131                           0x3618
+#define MIPI_RX_CON24_CSI3                     0x3824
+#define MIPI_RX_CON28_CSI3                     0x3828
+#define rsv_382C_2                             0x382C
+#define MIPI_RX_CON34_CSI3                     0x3834
+#define MIPI_RX_CON38_CSI3                     0x3838
+#define MIPI_RX_CON3C_CSI3                     0x383C
+#define rsv_3840_15                            0x3840
+#define MIPI_RX_CON7C_CSI3                     0x387C
+#define MIPI_RX_CON80_CSI3                     0x3880
+#define MIPI_RX_CON84_CSI3                     0x3884
+#define MIPI_RX_CON88_CSI3                     0x3888
+#define MIPI_RX_CON8C_CSI3                     0x388C
+#define MIPI_RX_CON90_CSI3                     0x3890
+#define MIPI_RX_CON94_CSI3                     0x3894
+#define MIPI_RX_CON98_CSI3                     0x3898
+#define rsv_389C                               0x389C
+#define MIPI_RX_CONA0_CSI3                     0x38A0
+#define rsv_38A4_3                             0x38A4
+#define MIPI_RX_CONB0_CSI3                     0x38B0
+#define MIPI_RX_CONB4_CSI3                     0x38B4
+#define MIPI_RX_CONB8_CSI3                     0x38B8
+#define MIPI_RX_CONBC_CSI3                     0x38BC
+#define MIPI_RX_CONC0_CSI3                     0x38C0
+#define MIPI_RX_CONC4_CSI3                     0x38C4
+#define MIPI_RX_CONC8_CSI3                     0x38C8
+#define MIPI_RX_CONCC_CSI3                     0x38CC
+#define MIPI_RX_COND0_CSI3                     0x38D0
+#define rsv_38D4_75                            0x38D4
+#define SENINF4_CSI2_CTL                       0x3A00
+#define SENINF4_CSI2_LNRC_TIMING               0x3A04
+#define SENINF4_CSI2_LNRD_TIMING               0x3A08
+#define SENINF4_CSI2_DPCM                      0x3A0C
+#define SENINF4_CSI2_INT_EN                    0x3A10
+#define SENINF4_CSI2_INT_STATUS                0x3A14
+#define SENINF4_CSI2_DGB_SEL                   0x3A18
+#define SENINF4_CSI2_DBG_PORT                  0x3A1C
+#define SENINF4_CSI2_SPARE0                    0x3A20
+#define SENINF4_CSI2_SPARE1                    0x3A24
+#define SENINF4_CSI2_LNRC_FSM                  0x3A28
+#define SENINF4_CSI2_LNRD_FSM                  0x3A2C
+#define SENINF4_CSI2_FRAME_LINE_NUM            0x3A30
+#define SENINF4_CSI2_GENERIC_SHORT             0x3A34
+#define SENINF4_CSI2_HSRX_DBG                  0x3A38
+#define SENINF4_CSI2_DI                        0x3A3C
+#define SENINF4_CSI2_HS_TRAIL                  0x3A40
+#define SENINF4_CSI2_DI_CTRL                   0x3A44
+#define rsv_3A48                               0x3A48
+#define SENINF4_CSI2_DETECT_CON1               0x3A4C
+#define SENINF4_CSI2_DETECT_CON2               0x3A50
+#define SENINF4_CSI2_DETECT_CON3               0x3A54
+#define SENINF4_CSI2_RLR0_CON0                 0x3A58
+#define SENINF4_CSI2_RLR1_CON0                 0x3A5C
+#define SENINF4_CSI2_RLR2_CON0                 0x3A60
+#define SENINF4_CSI2_RLR_CON0                  0x3A64
+#define SENINF4_CSI2_MUX_CON                   0x3A68
+#define SENINF4_CSI2_DETECT_DBG0               0x3A6C
+#define SENINF4_CSI2_DETECT_DBG1               0x3A70
+#define SENINF4_CSI2_RESYNC_MERGE_CTL          0x3A74
+#define SENINF4_CSI2_CTRL_TRIO_MUX             0x3A78
+#define SENINF4_CSI2_CTRL_TRIO_CON             0x3A7C
+#define SENINF4_FIX_ADDR_CPHY0_DBG             0x3A80
+#define SENINF4_FIX_ADDR_CPHY1_DBG             0x3A84
+#define SENINF4_FIX_ADDR_CPHY2_DBG             0x3A88
+#define SENINF4_FIX_ADDR_DBG                   0x3A8C
+#define SENINF4_WIRE_STATE_DECODE_CPHY0_DBG0   0x3A90
+#define SENINF4_WIRE_STATE_DECODE_CPHY0_DBG1   0x3A94
+#define SENINF4_WIRE_STATE_DECODE_CPHY1_DBG0   0x3A98
+#define SENINF4_WIRE_STATE_DECODE_CPHY1_DBG1   0x3A9C
+#define SENINF4_WIRE_STATE_DECODE_CPHY2_DBG0   0x3AA0
+#define SENINF4_WIRE_STATE_DECODE_CPHY2_DBG1   0x3AA4
+#define SENINF4_SYNC_RESYNC_CTL                0x3AA8
+#define SENINF4_POST_DETECT_CTL                0x3AAC
+#define SENINF4_WIRE_STATE_DECODE_CONFIG       0x3AB0
+#define SENINF4_CSI2_CPHY_LNRD_FSM             0x3AB4
+#define SENINF4_FIX_ADDR_CPHY0_DBG0            0x3AB8
+#define SENINF4_FIX_ADDR_CPHY0_DBG1            0x3ABC
+#define SENINF4_FIX_ADDR_CPHY0_DBG2            0x3AC0
+#define SENINF4_FIX_ADDR_CPHY1_DBG0            0x3AC4
+#define SENINF4_FIX_ADDR_CPHY1_DBG1            0x3AC8
+#define SENINF4_FIX_ADDR_CPHY1_DBG2            0x3ACC
+#define SENINF4_FIX_ADDR_CPHY2_DBG0            0x3AD0
+#define SENINF4_FIX_ADDR_CPHY2_DBG1            0x3AD4
+#define SENINF4_FIX_ADDR_CPHY2_DBG2            0x3AD8
+#define SENINF4_FIX_ADDR_DBG0                  0x3ADC
+#define SENINF4_FIX_ADDR_DBG1                  0x3AE0
+#define SENINF4_FIX_ADDR_DBG2                  0x3AE4
+#define SENINF4_CSI2_MODE                      0x3AE8
+#define rsv_3AEC                               0x3AEC
+#define SENINF4_CSI2_DI_EXT                    0x3AF0
+#define SENINF4_CSI2_DI_CTRL_EXT               0x3AF4
+#define SENINF4_CSI2_CPHY_LOOPBACK             0x3AF8
+#define rsv_3AFC                               0x3AFC
+#define SENINF4_CSI2_PROGSEQ_0                 0x3B00
+#define SENINF4_CSI2_PROGSEQ_1                 0x3B04
+#define rsv_3B08_2                             0x3B08
+#define SENINF4_CSI2_INT_EN_EXT                0x3B10
+#define SENINF4_CSI2_INT_STATUS_EXT            0x3B14
+#define SENINF4_CSI2_CPHY_FIX_POINT_RST        0x3B18
+#define SENINF4_CSI2_RLR3_CON0                 0x3B1C
+#define SENINF4_CSI2_DPHY_SYNC                 0x3B20
+#define SENINF4_CSI2_DESKEW_SYNC               0x3B24
+#define SENINF4_CSI2_DETECT_DBG2               0x3B28
+#define rsv_3B2C                               0x3B2C
+#define SENINF4_FIX_ADDR_CPHY3_DBG0            0x3B30
+#define SENINF4_FIX_ADDR_CPHY3_DBG1            0x3B34
+#define SENINF4_FIX_ADDR_CPHY3_DBG2            0x3B38
+#define SENINF4_CSI2_DI_EXT_2                  0x3B3C
+#define SENINF4_CSI2_DI_CTRL_EXT_2             0x3B40
+#define SENINF4_WIRE_STATE_DECODE_CPHY3_DBG0   0x3B44
+#define SENINF4_WIRE_STATE_DECODE_CPHY3_DBG1   0x3B48
+#define rsv_3B4C_109                           0x3B4C
+#define SENINF4_MUX_CTRL                       0x3D00
+#define SENINF4_MUX_INTEN                      0x3D04
+#define SENINF4_MUX_INTSTA                     0x3D08
+#define SENINF4_MUX_SIZE                       0x3D0C
+#define SENINF4_MUX_DEBUG_1                    0x3D10
+#define SENINF4_MUX_DEBUG_2                    0x3D14
+#define SENINF4_MUX_DEBUG_3                    0x3D18
+#define SENINF4_MUX_DEBUG_4                    0x3D1C
+#define SENINF4_MUX_DEBUG_5                    0x3D20
+#define SENINF4_MUX_DEBUG_6                    0x3D24
+#define SENINF4_MUX_DEBUG_7                    0x3D28
+#define SENINF4_MUX_SPARE                      0x3D2C
+#define SENINF4_MUX_DATA                       0x3D30
+#define SENINF4_MUX_DATA_CNT                   0x3D34
+#define SENINF4_MUX_CROP                       0x3D38
+#define SENINF4_MUX_CTRL_EXT                   0x3D3C
+#define rsv_3D40_304                           0x3D40
+#define SENINF5_CTRL                           0x4200
+#define SENINF5_CTRL_EXT                       0x4204
+#define SENINF5_ASYNC_CTRL                     0x4208
+#define rsv_420C_253                           0x420C
+#define SENINF_TG5_PH_CNT                      0x4600
+#define SENINF_TG5_SEN_CK                      0x4604
+#define SENINF_TG5_TM_CTL                      0x4608
+#define SENINF_TG5_TM_SIZE                     0x460C
+#define SENINF_TG5_TM_CLK                      0x4610
+#define SENINF_TG5_TM_STP                      0x4614
+#define rsv_4618_131                           0x4618
+#define MIPI_RX_CON24_CSI4                     0x4824
+#define MIPI_RX_CON28_CSI4                     0x4828
+#define rsv_482C_2                             0x482C
+#define MIPI_RX_CON34_CSI4                     0x4834
+#define MIPI_RX_CON38_CSI4                     0x4838
+#define MIPI_RX_CON3C_CSI4                     0x483C
+#define rsv_4840_15                            0x4840
+#define MIPI_RX_CON7C_CSI4                     0x487C
+#define MIPI_RX_CON80_CSI4                     0x4880
+#define MIPI_RX_CON84_CSI4                     0x4884
+#define MIPI_RX_CON88_CSI4                     0x4888
+#define MIPI_RX_CON8C_CSI4                     0x488C
+#define MIPI_RX_CON90_CSI4                     0x4890
+#define MIPI_RX_CON94_CSI4                     0x4894
+#define MIPI_RX_CON98_CSI4                     0x4898
+#define rsv_489C                               0x489C
+#define MIPI_RX_CONA0_CSI4                     0x48A0
+#define rsv_48A4_3                             0x48A4
+#define MIPI_RX_CONB0_CSI4                     0x48B0
+#define MIPI_RX_CONB4_CSI4                     0x48B4
+#define MIPI_RX_CONB8_CSI4                     0x48B8
+#define MIPI_RX_CONBC_CSI4                     0x48BC
+#define MIPI_RX_CONC0_CSI4                     0x48C0
+#define MIPI_RX_CONC4_CSI4                     0x48C4
+#define MIPI_RX_CONC8_CSI4                     0x48C8
+#define MIPI_RX_CONCC_CSI4                     0x48CC
+#define MIPI_RX_COND0_CSI4                     0x48D0
+#define rsv_48D4_75                            0x48D4
+#define SENINF5_CSI2_CTL                       0x4A00
+#define SENINF5_CSI2_LNRC_TIMING               0x4A04
+#define SENINF5_CSI2_LNRD_TIMING               0x4A08
+#define SENINF5_CSI2_DPCM                      0x4A0C
+#define SENINF5_CSI2_INT_EN                    0x4A10
+#define SENINF5_CSI2_INT_STATUS                0x4A14
+#define SENINF5_CSI2_DGB_SEL                   0x4A18
+#define SENINF5_CSI2_DBG_PORT                  0x4A1C
+#define SENINF5_CSI2_SPARE0                    0x4A20
+#define SENINF5_CSI2_SPARE1                    0x4A24
+#define SENINF5_CSI2_LNRC_FSM                  0x4A28
+#define SENINF5_CSI2_LNRD_FSM                  0x4A2C
+#define SENINF5_CSI2_FRAME_LINE_NUM            0x4A30
+#define SENINF5_CSI2_GENERIC_SHORT             0x4A34
+#define SENINF5_CSI2_HSRX_DBG                  0x4A38
+#define SENINF5_CSI2_DI                        0x4A3C
+#define SENINF5_CSI2_HS_TRAIL                  0x4A40
+#define SENINF5_CSI2_DI_CTRL                   0x4A44
+#define rsv_4A48                               0x4A48
+#define SENINF5_CSI2_DETECT_CON1               0x4A4C
+#define SENINF5_CSI2_DETECT_CON2               0x4A50
+#define SENINF5_CSI2_DETECT_CON3               0x4A54
+#define SENINF5_CSI2_RLR0_CON0                 0x4A58
+#define SENINF5_CSI2_RLR1_CON0                 0x4A5C
+#define SENINF5_CSI2_RLR2_CON0                 0x4A60
+#define SENINF5_CSI2_RLR_CON0                  0x4A64
+#define SENINF5_CSI2_MUX_CON                   0x4A68
+#define SENINF5_CSI2_DETECT_DBG0               0x4A6C
+#define SENINF5_CSI2_DETECT_DBG1               0x4A70
+#define SENINF5_CSI2_RESYNC_MERGE_CTL          0x4A74
+#define SENINF5_CSI2_CTRL_TRIO_MUX             0x4A78
+#define SENINF5_CSI2_CTRL_TRIO_CON             0x4A7C
+#define SENINF5_FIX_ADDR_CPHY0_DBG             0x4A80
+#define SENINF5_FIX_ADDR_CPHY1_DBG             0x4A84
+#define SENINF5_FIX_ADDR_CPHY2_DBG             0x4A88
+#define SENINF5_FIX_ADDR_DBG                   0x4A8C
+#define SENINF5_WIRE_STATE_DECODE_CPHY0_DBG0   0x4A90
+#define SENINF5_WIRE_STATE_DECODE_CPHY0_DBG1   0x4A94
+#define SENINF5_WIRE_STATE_DECODE_CPHY1_DBG0   0x4A98
+#define SENINF5_WIRE_STATE_DECODE_CPHY1_DBG1   0x4A9C
+#define SENINF5_WIRE_STATE_DECODE_CPHY2_DBG0   0x4AA0
+#define SENINF5_WIRE_STATE_DECODE_CPHY2_DBG1   0x4AA4
+#define SENINF5_SYNC_RESYNC_CTL                0x4AA8
+#define SENINF5_POST_DETECT_CTL                0x4AAC
+#define SENINF5_WIRE_STATE_DECODE_CONFIG       0x4AB0
+#define SENINF5_CSI2_CPHY_LNRD_FSM             0x4AB4
+#define SENINF5_FIX_ADDR_CPHY0_DBG0            0x4AB8
+#define SENINF5_FIX_ADDR_CPHY0_DBG1            0x4ABC
+#define SENINF5_FIX_ADDR_CPHY0_DBG2            0x4AC0
+#define SENINF5_FIX_ADDR_CPHY1_DBG0            0x4AC4
+#define SENINF5_FIX_ADDR_CPHY1_DBG1            0x4AC8
+#define SENINF5_FIX_ADDR_CPHY1_DBG2            0x4ACC
+#define SENINF5_FIX_ADDR_CPHY2_DBG0            0x4AD0
+#define SENINF5_FIX_ADDR_CPHY2_DBG1            0x4AD4
+#define SENINF5_FIX_ADDR_CPHY2_DBG2            0x4AD8
+#define SENINF5_FIX_ADDR_DBG0                  0x4ADC
+#define SENINF5_FIX_ADDR_DBG1                  0x4AE0
+#define SENINF5_FIX_ADDR_DBG2                  0x4AE4
+#define SENINF5_CSI2_MODE                      0x4AE8
+#define rsv_4AEC                               0x4AEC
+#define SENINF5_CSI2_DI_EXT                    0x4AF0
+#define SENINF5_CSI2_DI_CTRL_EXT               0x4AF4
+#define SENINF5_CSI2_CPHY_LOOPBACK             0x4AF8
+#define rsv_4AFC                               0x4AFC
+#define SENINF5_CSI2_PROGSEQ_0                 0x4B00
+#define SENINF5_CSI2_PROGSEQ_1                 0x4B04
+#define rsv_4B08_2                             0x4B08
+#define SENINF5_CSI2_INT_EN_EXT                0x4B10
+#define SENINF5_CSI2_INT_STATUS_EXT            0x4B14
+#define SENINF5_CSI2_CPHY_FIX_POINT_RST        0x4B18
+#define SENINF5_CSI2_RLR3_CON0                 0x4B1C
+#define SENINF5_CSI2_DPHY_SYNC                 0x4B20
+#define SENINF5_CSI2_DESKEW_SYNC               0x4B24
+#define SENINF5_CSI2_DETECT_DBG2               0x4B28
+#define rsv_4B2C                               0x4B2C
+#define SENINF5_FIX_ADDR_CPHY3_DBG0            0x4B30
+#define SENINF5_FIX_ADDR_CPHY3_DBG1            0x4B34
+#define SENINF5_FIX_ADDR_CPHY3_DBG2            0x4B38
+#define SENINF5_CSI2_DI_EXT_2                  0x4B3C
+#define SENINF5_CSI2_DI_CTRL_EXT_2             0x4B40
+#define SENINF5_WIRE_STATE_DECODE_CPHY3_DBG0   0x4B44
+#define SENINF5_WIRE_STATE_DECODE_CPHY3_DBG1   0x4B48
+#define rsv_4B4C_109                           0x4B4C
+#define SENINF5_MUX_CTRL                       0x4D00
+#define SENINF5_MUX_INTEN                      0x4D04
+#define SENINF5_MUX_INTSTA                     0x4D08
+#define SENINF5_MUX_SIZE                       0x4D0C
+#define SENINF5_MUX_DEBUG_1                    0x4D10
+#define SENINF5_MUX_DEBUG_2                    0x4D14
+#define SENINF5_MUX_DEBUG_3                    0x4D18
+#define SENINF5_MUX_DEBUG_4                    0x4D1C
+#define SENINF5_MUX_DEBUG_5                    0x4D20
+#define SENINF5_MUX_DEBUG_6                    0x4D24
+#define SENINF5_MUX_DEBUG_7                    0x4D28
+#define SENINF5_MUX_SPARE                      0x4D2C
+#define SENINF5_MUX_DATA                       0x4D30
+#define SENINF5_MUX_DATA_CNT                   0x4D34
+#define SENINF5_MUX_CROP                       0x4D38
+#define SENINF5_MUX_CTRL_EXT                   0x4D3C
+#define rsv_4D40_1008                          0x4D40
+#define SENINF6_MUX_CTRL                       0x5D00
+#define SENINF6_MUX_INTEN                      0x5D04
+#define SENINF6_MUX_INTSTA                     0x5D08
+#define SENINF6_MUX_SIZE                       0x5D0C
+#define SENINF6_MUX_DEBUG_1                    0x5D10
+#define SENINF6_MUX_DEBUG_2                    0x5D14
+#define SENINF6_MUX_DEBUG_3                    0x5D18
+#define SENINF6_MUX_DEBUG_4                    0x5D1C
+#define SENINF6_MUX_DEBUG_5                    0x5D20
+#define SENINF6_MUX_DEBUG_6                    0x5D24
+#define SENINF6_MUX_DEBUG_7                    0x5D28
+#define SENINF6_MUX_SPARE                      0x5D2C
+#define SENINF6_MUX_DATA                       0x5D30
+#define SENINF6_MUX_DATA_CNT                   0x5D34
+#define SENINF6_MUX_CROP                       0x5D38
+#define SENINF6_MUX_CTRL_EXT                   0x5D3C
+#define rsv_5D40_1008                          0x5D40
+#define SENINF7_MUX_CTRL                       0x6D00
+#define SENINF7_MUX_INTEN                      0x6D04
+#define SENINF7_MUX_INTSTA                     0x6D08
+#define SENINF7_MUX_SIZE                       0x6D0C
+#define SENINF7_MUX_DEBUG_1                    0x6D10
+#define SENINF7_MUX_DEBUG_2                    0x6D14
+#define SENINF7_MUX_DEBUG_3                    0x6D18
+#define SENINF7_MUX_DEBUG_4                    0x6D1C
+#define SENINF7_MUX_DEBUG_5                    0x6D20
+#define SENINF7_MUX_DEBUG_6                    0x6D24
+#define SENINF7_MUX_DEBUG_7                    0x6D28
+#define SENINF7_MUX_SPARE                      0x6D2C
+#define SENINF7_MUX_DATA                       0x6D30
+#define SENINF7_MUX_DATA_CNT                   0x6D34
+#define SENINF7_MUX_CROP                       0x6D38
+#define SENINF7_MUX_CTRL_EXT                   0x6D3C
+#define rsv_6D40_1008                          0x6D40
+#define SENINF8_MUX_CTRL                       0x7D00
+#define SENINF8_MUX_INTEN                      0x7D04
+#define SENINF8_MUX_INTSTA                     0x7D08
+#define SENINF8_MUX_SIZE                       0x7D0C
+#define SENINF8_MUX_DEBUG_1                    0x7D10
+#define SENINF8_MUX_DEBUG_2                    0x7D14
+#define SENINF8_MUX_DEBUG_3                    0x7D18
+#define SENINF8_MUX_DEBUG_4                    0x7D1C
+#define SENINF8_MUX_DEBUG_5                    0x7D20
+#define SENINF8_MUX_DEBUG_6                    0x7D24
+#define SENINF8_MUX_DEBUG_7                    0x7D28
+#define SENINF8_MUX_SPARE                      0x7D2C
+#define SENINF8_MUX_DATA                       0x7D30
+#define SENINF8_MUX_DATA_CNT                   0x7D34
+#define SENINF8_MUX_CROP                       0x7D38
+#define SENINF8_MUX_CTRL_EXT                   0x7D3C
+#define rsv_7D40_20                            0x7D40
+
+#endif /* _SENINF_REG_H_ */
diff --git a/drivers/media/platform/mtk-mdp3/Makefile b/drivers/media/platform/mtk-mdp3/Makefile
new file mode 100644
index 000000000000..cd1de4ef7f42
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/Makefile
@@ -0,0 +1,15 @@
+# SPDX-License-Identifier: GPL-2.0
+mtk-mdp3-y += mtk-mdp3-core.o mtk-mdp3-vpu.o mtk-mdp3-regs.o
+mtk-mdp3-y += mtk-mdp3-m2m.o
+mtk-mdp3-y += mtk-mdp3-comp.o mtk-mdp3-cmdq.o
+
+ccflags-y += -DMDP_DEBUG
+mtk-mdp3-y += mtk-mdp3-debug.o
+
+ccflags-y += -DMDP_UT
+mtk-mdp3-y += mtk-mdp3-ut.o
+
+obj-$(CONFIG_VIDEO_MEDIATEK_MDP3) += mtk-mdp3.o
+
+ccflags-y += -I$(srctree)/drivers/media/platform/mtk-vpu
+
diff --git a/drivers/media/platform/mtk-mdp3/isp_reg.h b/drivers/media/platform/mtk-mdp3/isp_reg.h
new file mode 100644
index 000000000000..93552943c323
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/isp_reg.h
@@ -0,0 +1,38 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __ISP_REG_H__
+#define __ISP_REG_H__
+
+enum ISP_DIP_CQ {
+	ISP_DRV_DIP_CQ_THRE0 = 0,
+	ISP_DRV_DIP_CQ_THRE1,
+	ISP_DRV_DIP_CQ_THRE2,
+	ISP_DRV_DIP_CQ_THRE3,
+	ISP_DRV_DIP_CQ_THRE4,
+	ISP_DRV_DIP_CQ_THRE5,
+	ISP_DRV_DIP_CQ_THRE6,
+	ISP_DRV_DIP_CQ_THRE7,
+	ISP_DRV_DIP_CQ_THRE8,
+	ISP_DRV_DIP_CQ_THRE9,
+	ISP_DRV_DIP_CQ_THRE10,
+	ISP_DRV_DIP_CQ_THRE11,
+	ISP_DRV_DIP_CQ_NUM,
+	ISP_DRV_DIP_CQ_NONE,
+	/* we only need 12 CQ threads in this chip,
+	 *so we move the following enum behind ISP_DRV_DIP_CQ_NUM
+	 */
+	ISP_DRV_DIP_CQ_THRE12,
+	ISP_DRV_DIP_CQ_THRE13,
+	ISP_DRV_DIP_CQ_THRE14,
+	ISP_DRV_DIP_CQ_THRE15,	/* CQ_THREAD15 does not connect to GCE */
+	ISP_DRV_DIP_CQ_THRE16,	/* CQ_THREAD16 does not connect to GCE */
+	ISP_DRV_DIP_CQ_THRE17,	/* CQ_THREAD17 does not connect to GCE */
+	ISP_DRV_DIP_CQ_THRE18,	/* CQ_THREAD18 does not connect to GCE */
+};
+
+#endif  // __ISP_REG_H__
diff --git a/drivers/media/platform/mtk-mdp3/mdp-platform.h b/drivers/media/platform/mtk-mdp3/mdp-platform.h
new file mode 100644
index 000000000000..6926c3a754fa
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mdp-platform.h
@@ -0,0 +1,67 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MDP_PLATFORM_H__
+#define __MDP_PLATFORM_H__
+
+#include "mtk-mdp3-comp.h"
+
+/* CAM */
+#define MDP_WPEI           MDP_COMP_WPEI
+#define MDP_WPEO           MDP_COMP_WPEO
+#define MDP_WPEI2          MDP_COMP_WPEI2
+#define MDP_WPEO2          MDP_COMP_WPEO2
+#define MDP_IMGI           MDP_COMP_ISP_IMGI
+#define MDP_IMGO           MDP_COMP_ISP_IMGO
+#define MDP_IMG2O          MDP_COMP_ISP_IMG2O
+
+/* IPU */
+#define MDP_IPUI           MDP_COMP_NONE
+#define MDP_IPUO           MDP_COMP_NONE
+
+/* MDP */
+#define MDP_CAMIN          MDP_COMP_CAMIN
+#define MDP_CAMIN2         MDP_COMP_CAMIN2
+#define MDP_RDMA0          MDP_COMP_RDMA0
+#define MDP_RDMA1          MDP_COMP_NONE
+#define MDP_AAL0           MDP_COMP_AAL0
+#define MDP_CCORR0         MDP_COMP_CCORR0
+#define MDP_SCL0           MDP_COMP_RSZ0
+#define MDP_SCL1           MDP_COMP_RSZ1
+#define MDP_SCL2           MDP_COMP_NONE
+#define MDP_TDSHP0         MDP_COMP_TDSHP0
+#define MDP_COLOR0         MDP_COMP_COLOR0
+#define MDP_WROT0          MDP_COMP_WROT0
+#define MDP_WROT1          MDP_COMP_NONE
+#define MDP_WDMA           MDP_COMP_WDMA
+#define MDP_PATH0_SOUT     MDP_COMP_PATH0_SOUT
+#define MDP_PATH1_SOUT     MDP_COMP_PATH1_SOUT
+
+#define MDP_TOTAL          (MDP_COMP_WDMA + 1)
+
+/* Platform options */
+#define ESL_SETTING			1
+#define RDMA_SUPPORT_10BIT		1
+#define RDMA0_RSZ1_SRAM_SHARING		1
+#define RDMA_UPSAMPLE_REPEAT_ONLY	1
+#define RSZ_DISABLE_DCM_SMALL_TILE	0
+#define WROT_FILTER_CONSTRAINT		0
+#define WROT0_DISP_SRAM_SHARING		0
+
+#define MM_MUTEX_MOD_OFFSET	0x30
+#define MM_MUTEX_SOF_OFFSET	0x2c
+
+#endif  /* __MDP_PLATFORM_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mdp_reg_ccorr.h b/drivers/media/platform/mtk-mdp3/mdp_reg_ccorr.h
new file mode 100644
index 000000000000..e3340726e6d4
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mdp_reg_ccorr.h
@@ -0,0 +1,76 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MDP_REG_CCORR_H__
+#define __MDP_REG_CCORR_H__
+
+#include "mmsys_reg_base.h"
+
+#define MDP_CCORR_EN                0x000
+#define MDP_CCORR_RESET             0x004
+#define MDP_CCORR_INTEN             0x008
+#define MDP_CCORR_INTSTA            0x00c
+#define MDP_CCORR_STATUS            0x010
+#define MDP_CCORR_CFG               0x020
+#define MDP_CCORR_INPUT_COUNT       0x024
+#define MDP_CCORR_OUTPUT_COUNT      0x028
+#define MDP_CCORR_CHKSUM            0x02c
+#define MDP_CCORR_SIZE              0x030
+#define MDP_CCORR_Y2R_00            0x034
+#define MDP_CCORR_Y2R_01            0x038
+#define MDP_CCORR_Y2R_02            0x03c
+#define MDP_CCORR_Y2R_03            0x040
+#define MDP_CCORR_Y2R_04            0x044
+#define MDP_CCORR_Y2R_05            0x048
+#define MDP_CCORR_R2Y_00            0x04c
+#define MDP_CCORR_R2Y_01            0x050
+#define MDP_CCORR_R2Y_02            0x054
+#define MDP_CCORR_R2Y_03            0x058
+#define MDP_CCORR_R2Y_04            0x05c
+#define MDP_CCORR_R2Y_05            0x060
+#define MDP_CCORR_COEF_0            0x080
+#define MDP_CCORR_COEF_1            0x084
+#define MDP_CCORR_COEF_2            0x088
+#define MDP_CCORR_COEF_3            0x08c
+#define MDP_CCORR_COEF_4            0x090
+#define MDP_CCORR_SHADOW            0x0a0
+#define MDP_CCORR_DUMMY_REG         0x0c0
+#define MDP_CCORR_ATPG              0x0fc
+
+/* MASK */
+#define MDP_CCORR_EN_MASK           0x00000001
+#define MDP_CCORR_RESET_MASK        0x00000001
+#define MDP_CCORR_INTEN_MASK        0x00000003
+#define MDP_CCORR_INTSTA_MASK       0x00000003
+#define MDP_CCORR_STATUS_MASK       0xfffffff3
+#define MDP_CCORR_CFG_MASK          0x70001317
+#define MDP_CCORR_INPUT_COUNT_MASK  0x1fff1fff
+#define MDP_CCORR_OUTPUT_COUNT_MASK 0x1fff1fff
+#define MDP_CCORR_CHKSUM_MASK       0xffffffff
+#define MDP_CCORR_SIZE_MASK         0x1fff1fff
+#define MDP_CCORR_Y2R_00_MASK       0x01ff01ff
+#define MDP_CCORR_Y2R_01_MASK       0x1fff01ff
+#define MDP_CCORR_Y2R_02_MASK       0x1fff1fff
+#define MDP_CCORR_Y2R_03_MASK       0x1fff1fff
+#define MDP_CCORR_Y2R_04_MASK       0x1fff1fff
+#define MDP_CCORR_Y2R_05_MASK       0x1fff1fff
+#define MDP_CCORR_R2Y_00_MASK       0x01ff01ff
+#define MDP_CCORR_R2Y_01_MASK       0x07ff01ff
+#define MDP_CCORR_R2Y_02_MASK       0x07ff07ff
+#define MDP_CCORR_R2Y_03_MASK       0x07ff07ff
+#define MDP_CCORR_R2Y_04_MASK       0x07ff07ff
+#define MDP_CCORR_R2Y_05_MASK       0x07ff07ff
+#define MDP_CCORR_COEF_0_MASK       0x1fff1fff
+#define MDP_CCORR_COEF_1_MASK       0x1fff1fff
+#define MDP_CCORR_COEF_2_MASK       0x1fff1fff
+#define MDP_CCORR_COEF_3_MASK       0x1fff1fff
+#define MDP_CCORR_COEF_4_MASK       0x1fff1fff
+#define MDP_CCORR_SHADOW_MASK       0x00000007
+#define MDP_CCORR_DUMMY_REG_MASK    0xffffffff
+#define MDP_CCORR_ATPG_MASK         0x00000003
+
+#endif  // __MDP_REG_CCORR_H__
diff --git a/drivers/media/platform/mtk-mdp3/mdp_reg_rdma.h b/drivers/media/platform/mtk-mdp3/mdp_reg_rdma.h
new file mode 100644
index 000000000000..5625d9f7810d
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mdp_reg_rdma.h
@@ -0,0 +1,207 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MDP_REG_RDMA_H__
+#define __MDP_REG_RDMA_H__
+
+#include "mmsys_reg_base.h"
+
+#define MDP_RDMA_EN                     0x000
+#define MDP_RDMA_RESET                  0x008
+#define MDP_RDMA_INTERRUPT_ENABLE       0x010
+#define MDP_RDMA_INTERRUPT_STATUS       0x018
+#define MDP_RDMA_CON                    0x020
+#define MDP_RDMA_GMCIF_CON              0x028
+#define MDP_RDMA_SRC_CON                0x030
+#define MDP_RDMA_SRC_BASE_0             0xf00
+#define MDP_RDMA_SRC_BASE_1             0xf08
+#define MDP_RDMA_SRC_BASE_2             0xf10
+#define MDP_RDMA_UFO_DEC_LENGTH_BASE_Y  0xf20
+#define MDP_RDMA_UFO_DEC_LENGTH_BASE_C  0xf28
+#define MDP_RDMA_MF_BKGD_SIZE_IN_BYTE   0x060
+#define MDP_RDMA_MF_BKGD_SIZE_IN_PXL    0x068
+#define MDP_RDMA_MF_SRC_SIZE            0x070
+#define MDP_RDMA_MF_CLIP_SIZE           0x078
+#define MDP_RDMA_MF_OFFSET_1            0x080
+#define MDP_RDMA_MF_PAR                 0x088
+#define MDP_RDMA_SF_BKGD_SIZE_IN_BYTE   0x090
+#define MDP_RDMA_SF_PAR                 0x0b8
+#define MDP_RDMA_MB_DEPTH               0x0c0
+#define MDP_RDMA_MB_BASE                0x0c8
+#define MDP_RDMA_MB_CON                 0x0d0
+#define MDP_RDMA_SB_DEPTH               0x0d8
+#define MDP_RDMA_SB_BASE                0x0e0
+#define MDP_RDMA_SB_CON                 0x0e8
+#define MDP_RDMA_VC1_RANGE              0x0f0
+#define MDP_RDMA_SRC_END_0              0x100
+#define MDP_RDMA_SRC_END_1              0x108
+#define MDP_RDMA_SRC_END_2              0x110
+#define MDP_RDMA_SRC_OFFSET_0           0x118
+#define MDP_RDMA_SRC_OFFSET_1           0x120
+#define MDP_RDMA_SRC_OFFSET_2           0x128
+#define MDP_RDMA_SRC_OFFSET_W_0         0x130
+#define MDP_RDMA_SRC_OFFSET_W_1         0x138
+#define MDP_RDMA_SRC_OFFSET_W_2         0x140
+#define MDP_RDMA_SRC_OFFSET_0_P         0x148
+#define MDP_RDMA_TRANSFORM_0            0x200
+#define MDP_RDMA_TRANSFORM_1            0x208
+#define MDP_RDMA_TRANSFORM_2            0x210
+#define MDP_RDMA_TRANSFORM_3            0x218
+#define MDP_RDMA_TRANSFORM_4            0x220
+#define MDP_RDMA_TRANSFORM_5            0x228
+#define MDP_RDMA_TRANSFORM_6            0x230
+#define MDP_RDMA_TRANSFORM_7            0x238
+#define MDP_RDMA_DMABUF_CON_0           0x240
+#define MDP_RDMA_DMAULTRA_CON_0         0x248
+#define MDP_RDMA_DMABUF_CON_1           0x250
+#define MDP_RDMA_DMAULTRA_CON_1         0x258
+#define MDP_RDMA_DMABUF_CON_2           0x260
+#define MDP_RDMA_DMAULTRA_CON_2         0x268
+#define MDP_RDMA_DITHER_CON             0x288
+#define MDP_RDMA_RESV_DUMMY_0           0x2a0
+#define MDP_RDMA_CHKS_EXTR              0x300
+#define MDP_RDMA_CHKS_INTW              0x308
+#define MDP_RDMA_CHKS_INTR              0x310
+#define MDP_RDMA_CHKS_ROTO              0x318
+#define MDP_RDMA_CHKS_SRIY              0x320
+#define MDP_RDMA_CHKS_SRIU              0x328
+#define MDP_RDMA_CHKS_SRIV              0x330
+#define MDP_RDMA_CHKS_SROY              0x338
+#define MDP_RDMA_CHKS_SROU              0x340
+#define MDP_RDMA_CHKS_SROV              0x348
+#define MDP_RDMA_CHKS_VUPI              0x350
+#define MDP_RDMA_CHKS_VUPO              0x358
+#define MDP_RDMA_DEBUG_CON              0x380
+#define MDP_RDMA_MON_STA_0              0x400
+#define MDP_RDMA_MON_STA_1              0x408
+#define MDP_RDMA_MON_STA_2              0x410
+#define MDP_RDMA_MON_STA_3              0x418
+#define MDP_RDMA_MON_STA_4              0x420
+#define MDP_RDMA_MON_STA_5              0x428
+#define MDP_RDMA_MON_STA_6              0x430
+#define MDP_RDMA_MON_STA_7              0x438
+#define MDP_RDMA_MON_STA_8              0x440
+#define MDP_RDMA_MON_STA_9              0x448
+#define MDP_RDMA_MON_STA_10             0x450
+#define MDP_RDMA_MON_STA_11             0x458
+#define MDP_RDMA_MON_STA_12             0x460
+#define MDP_RDMA_MON_STA_13             0x468
+#define MDP_RDMA_MON_STA_14             0x470
+#define MDP_RDMA_MON_STA_15             0x478
+#define MDP_RDMA_MON_STA_16             0x480
+#define MDP_RDMA_MON_STA_17             0x488
+#define MDP_RDMA_MON_STA_18             0x490
+#define MDP_RDMA_MON_STA_19             0x498
+#define MDP_RDMA_MON_STA_20             0x4a0
+#define MDP_RDMA_MON_STA_21             0x4a8
+#define MDP_RDMA_MON_STA_22             0x4b0
+#define MDP_RDMA_MON_STA_23             0x4b8
+#define MDP_RDMA_MON_STA_24             0x4c0
+#define MDP_RDMA_MON_STA_25             0x4c8
+#define MDP_RDMA_MON_STA_26             0x4d0
+#define MDP_RDMA_MON_STA_27             0x4d8
+#define MDP_RDMA_MON_STA_28             0x4e0
+
+/* MASK */
+#define MDP_RDMA_EN_MASK                    0x00000001
+#define MDP_RDMA_RESET_MASK                 0x00000001
+#define MDP_RDMA_INTERRUPT_ENABLE_MASK      0x00000007
+#define MDP_RDMA_INTERRUPT_STATUS_MASK      0x00000007
+#define MDP_RDMA_CON_MASK                   0x00001110
+#define MDP_RDMA_GMCIF_CON_MASK             0xfffb3771
+#define MDP_RDMA_SRC_CON_MASK               0xf3ffffff
+#define MDP_RDMA_SRC_BASE_0_MASK            0xffffffff
+#define MDP_RDMA_SRC_BASE_1_MASK            0xffffffff
+#define MDP_RDMA_SRC_BASE_2_MASK            0xffffffff
+#define MDP_RDMA_UFO_DEC_LENGTH_BASE_Y_MASK 0xffffffff
+#define MDP_RDMA_UFO_DEC_LENGTH_BASE_C_MASK 0xffffffff
+#define MDP_RDMA_MF_BKGD_SIZE_IN_BYTE_MASK  0x001fffff
+#define MDP_RDMA_MF_BKGD_SIZE_IN_PXL_MASK   0x001fffff
+#define MDP_RDMA_MF_SRC_SIZE_MASK           0x1fff1fff
+#define MDP_RDMA_MF_CLIP_SIZE_MASK          0x1fff1fff
+#define MDP_RDMA_MF_OFFSET_1_MASK           0x003f001f
+#define MDP_RDMA_MF_PAR_MASK                0x1ffff3ff
+#define MDP_RDMA_SF_BKGD_SIZE_IN_BYTE_MASK  0x001fffff
+#define MDP_RDMA_SF_PAR_MASK                0x1ffff3ff
+#define MDP_RDMA_MB_DEPTH_MASK              0x0000007f
+#define MDP_RDMA_MB_BASE_MASK               0x0000ffff
+#define MDP_RDMA_MB_CON_MASK                0x3fff1fff
+#define MDP_RDMA_SB_DEPTH_MASK              0x0000007f
+#define MDP_RDMA_SB_BASE_MASK               0x0000ffff
+#define MDP_RDMA_SB_CON_MASK                0x3fff1fff
+#define MDP_RDMA_VC1_RANGE_MASK             0x001f1f11
+#define MDP_RDMA_SRC_END_0_MASK             0xffffffff
+#define MDP_RDMA_SRC_END_1_MASK             0xffffffff
+#define MDP_RDMA_SRC_END_2_MASK             0xffffffff
+#define MDP_RDMA_SRC_OFFSET_0_MASK          0xffffffff
+#define MDP_RDMA_SRC_OFFSET_1_MASK          0xffffffff
+#define MDP_RDMA_SRC_OFFSET_2_MASK          0xffffffff
+#define MDP_RDMA_SRC_OFFSET_W_0_MASK        0x0000ffff
+#define MDP_RDMA_SRC_OFFSET_W_1_MASK        0x0000ffff
+#define MDP_RDMA_SRC_OFFSET_W_2_MASK        0x0000ffff
+#define MDP_RDMA_SRC_OFFSET_0_P_MASK        0xffffffff
+#define MDP_RDMA_TRANSFORM_0_MASK           0xff110777
+#define MDP_RDMA_TRANSFORM_1_MASK           0x1ff7fdff
+#define MDP_RDMA_TRANSFORM_2_MASK           0x1ff7fdff
+#define MDP_RDMA_TRANSFORM_3_MASK           0x1fff1fff
+#define MDP_RDMA_TRANSFORM_4_MASK           0x1fff1fff
+#define MDP_RDMA_TRANSFORM_5_MASK           0x1fff1fff
+#define MDP_RDMA_TRANSFORM_6_MASK           0x1fff1fff
+#define MDP_RDMA_TRANSFORM_7_MASK           0x00001fff
+#define MDP_RDMA_DMABUF_CON_0_MASK          0x077f007f
+#define MDP_RDMA_DMAULTRA_CON_0_MASK        0x7f7f7f7f
+#define MDP_RDMA_DMABUF_CON_1_MASK          0x073f003f
+#define MDP_RDMA_DMAULTRA_CON_1_MASK        0x3f3f3f3f
+#define MDP_RDMA_DMABUF_CON_2_MASK          0x071f001f
+#define MDP_RDMA_DMAULTRA_CON_2_MASK        0x1f1f1f1f
+
+#define MDP_RDMA_DITHER_CON_MASK            0xffffffff
+#define MDP_RDMA_RESV_DUMMY_0_MASK          0xffffffff
+#define MDP_RDMA_CHKS_EXTR_MASK             0xffffff01
+#define MDP_RDMA_CHKS_INTW_MASK             0xffffff01
+#define MDP_RDMA_CHKS_INTR_MASK             0xffffff01
+#define MDP_RDMA_CHKS_ROTO_MASK             0xffffff01
+#define MDP_RDMA_CHKS_SRIY_MASK             0xffffff01
+#define MDP_RDMA_CHKS_SRIU_MASK             0xffffff01
+#define MDP_RDMA_CHKS_SRIV_MASK             0xffffff01
+#define MDP_RDMA_CHKS_SROY_MASK             0xffffff01
+#define MDP_RDMA_CHKS_SROU_MASK             0xffffff01
+#define MDP_RDMA_CHKS_SROV_MASK             0xffffff01
+#define MDP_RDMA_CHKS_VUPI_MASK             0xffffff01
+#define MDP_RDMA_CHKS_VUPO_MASK             0xffffff01
+#define MDP_RDMA_DEBUG_CON_MASK             0x00001f11
+#define MDP_RDMA_MON_STA_0_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_1_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_2_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_3_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_4_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_5_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_6_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_7_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_8_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_9_MASK             0xffffffff
+#define MDP_RDMA_MON_STA_10_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_11_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_12_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_13_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_14_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_15_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_16_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_17_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_18_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_19_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_20_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_21_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_22_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_23_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_24_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_25_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_26_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_27_MASK            0xffffffff
+#define MDP_RDMA_MON_STA_28_MASK            0xffffffff
+
+#endif  // __MDP_REG_RDMA_H__
diff --git a/drivers/media/platform/mtk-mdp3/mdp_reg_rsz.h b/drivers/media/platform/mtk-mdp3/mdp_reg_rsz.h
new file mode 100644
index 000000000000..407b7691e9d1
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mdp_reg_rsz.h
@@ -0,0 +1,110 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MDP_REG_RSZ_H__
+#define __MDP_REG_RSZ_H__
+
+#include "mmsys_reg_base.h"
+
+#define PRZ_ENABLE                                        0x000
+#define PRZ_CONTROL_1                                     0x004
+#define PRZ_CONTROL_2                                     0x008
+#define PRZ_INT_FLAG                                      0x00c
+#define PRZ_INPUT_IMAGE                                   0x010
+#define PRZ_OUTPUT_IMAGE                                  0x014
+#define PRZ_HORIZONTAL_COEFF_STEP                         0x018
+#define PRZ_VERTICAL_COEFF_STEP                           0x01c
+#define PRZ_LUMA_HORIZONTAL_INTEGER_OFFSET                0x020
+#define PRZ_LUMA_HORIZONTAL_SUBPIXEL_OFFSET               0x024
+#define PRZ_LUMA_VERTICAL_INTEGER_OFFSET                  0x028
+#define PRZ_LUMA_VERTICAL_SUBPIXEL_OFFSET                 0x02c
+#define PRZ_CHROMA_HORIZONTAL_INTEGER_OFFSET              0x030
+#define PRZ_CHROMA_HORIZONTAL_SUBPIXEL_OFFSET             0x034
+#define PRZ_RSV                                           0x040
+#define PRZ_DEBUG_SEL                                     0x044
+#define PRZ_DEBUG                                         0x048
+#define PRZ_TAP_ADAPT                                     0x04c
+#define PRZ_IBSE_SOFTCLIP                                 0x050
+#define PRZ_IBSE_YLEVEL_1                                 0x054
+#define PRZ_IBSE_YLEVEL_2                                 0x058
+#define PRZ_IBSE_YLEVEL_3                                 0x05c
+#define PRZ_IBSE_YLEVEL_4                                 0x060
+#define PRZ_IBSE_YLEVEL_5                                 0x064
+#define PRZ_IBSE_GAINCONTROL_1                            0x068
+#define PRZ_IBSE_GAINCONTROL_2                            0x06c
+#define PRZ_DEMO_IN_HMASK                                 0x070
+#define PRZ_DEMO_IN_VMASK                                 0x074
+#define PRZ_DEMO_OUT_HMASK                                0x078
+#define PRZ_DEMO_OUT_VMASK                                0x07c
+#define PRZ_ATPG                                          0x0fc
+#define PRZ_PAT1_GEN_SET                                  0x100
+#define PRZ_PAT1_GEN_FRM_SIZE                             0x104
+#define PRZ_PAT1_GEN_COLOR0                               0x108
+#define PRZ_PAT1_GEN_COLOR1                               0x10c
+#define PRZ_PAT1_GEN_COLOR2                               0x110
+#define PRZ_PAT1_GEN_POS                                  0x114
+#define PRZ_PAT1_GEN_TILE_POS                             0x124
+#define PRZ_PAT1_GEN_TILE_OV                              0x128
+#define PRZ_PAT2_GEN_SET                                  0x200
+#define PRZ_PAT2_GEN_COLOR0                               0x208
+#define PRZ_PAT2_GEN_COLOR1                               0x20c
+#define PRZ_PAT2_GEN_POS                                  0x214
+#define PRZ_PAT2_GEN_CURSOR_RB0                           0x218
+#define PRZ_PAT2_GEN_CURSOR_RB1                           0x21c
+#define PRZ_PAT2_GEN_TILE_POS                             0x224
+#define PRZ_PAT2_GEN_TILE_OV                              0x228
+
+/* MASK */
+#define PRZ_ENABLE_MASK                                   0x00010001
+#define PRZ_CONTROL_1_MASK                                0xfffffff3
+#define PRZ_CONTROL_2_MASK                                0x0ffffaff
+#define PRZ_INT_FLAG_MASK                                 0x00000033
+#define PRZ_INPUT_IMAGE_MASK                              0xffffffff
+#define PRZ_OUTPUT_IMAGE_MASK                             0xffffffff
+#define PRZ_HORIZONTAL_COEFF_STEP_MASK                    0x007fffff
+#define PRZ_VERTICAL_COEFF_STEP_MASK                      0x007fffff
+#define PRZ_LUMA_HORIZONTAL_INTEGER_OFFSET_MASK           0x0000ffff
+#define PRZ_LUMA_HORIZONTAL_SUBPIXEL_OFFSET_MASK          0x001fffff
+#define PRZ_LUMA_VERTICAL_INTEGER_OFFSET_MASK             0x0000ffff
+#define PRZ_LUMA_VERTICAL_SUBPIXEL_OFFSET_MASK            0x001fffff
+#define PRZ_CHROMA_HORIZONTAL_INTEGER_OFFSET_MASK         0x0000ffff
+#define PRZ_CHROMA_HORIZONTAL_SUBPIXEL_OFFSET_MASK        0x001fffff
+#define PRZ_RSV_MASK                                      0xffffffff
+#define PRZ_DEBUG_SEL_MASK                                0x0000000f
+#define PRZ_DEBUG_MASK                                    0xffffffff
+#define PRZ_TAP_ADAPT_MASK                                0x03ffffff
+#define PRZ_IBSE_SOFTCLIP_MASK                            0x000fffff
+#define PRZ_IBSE_YLEVEL_1_MASK                            0xffffffff
+#define PRZ_IBSE_YLEVEL_2_MASK                            0xffffffff
+#define PRZ_IBSE_YLEVEL_3_MASK                            0xffffffff
+#define PRZ_IBSE_YLEVEL_4_MASK                            0xffffffff
+#define PRZ_IBSE_YLEVEL_5_MASK                            0x0000ff3f
+#define PRZ_IBSE_GAINCONTROL_1_MASK                       0xffffffff
+#define PRZ_IBSE_GAINCONTROL_2_MASK                       0x0fffff0f
+#define PRZ_DEMO_IN_HMASK_MASK                            0xffffffff
+#define PRZ_DEMO_IN_VMASK_MASK                            0xffffffff
+#define PRZ_DEMO_OUT_HMASK_MASK                           0xffffffff
+#define PRZ_DEMO_OUT_VMASK_MASK                           0xffffffff
+#define PRZ_ATPG_MASK                                     0x00000003
+#define PRZ_PAT1_GEN_SET_MASK                             0x00ff00fd
+#define PRZ_PAT1_GEN_FRM_SIZE_MASK                        0x1fff1fff
+#define PRZ_PAT1_GEN_COLOR0_MASK                          0x00ff00ff
+#define PRZ_PAT1_GEN_COLOR1_MASK                          0x00ff00ff
+#define PRZ_PAT1_GEN_COLOR2_MASK                          0x00ff00ff
+#define PRZ_PAT1_GEN_POS_MASK                             0x1fff1fff
+#define PRZ_PAT1_GEN_TILE_POS_MASK                        0x1fff1fff
+#define PRZ_PAT1_GEN_TILE_OV_MASK                         0x0000ffff
+#define PRZ_PAT2_GEN_SET_MASK                             0x00ff0003
+#define PRZ_PAT2_GEN_COLOR0_MASK                          0x00ff00ff
+#define PRZ_PAT2_GEN_COLOR1_MASK                          0x000000ff
+#define PRZ_PAT2_GEN_POS_MASK                             0x1fff1fff
+#define PRZ_PAT2_GEN_CURSOR_RB0_MASK                      0x00ff00ff
+#define PRZ_PAT2_GEN_CURSOR_RB1_MASK                      0x000000ff
+#define PRZ_PAT2_GEN_TILE_POS_MASK                        0x1fff1fff
+#define PRZ_PAT2_GEN_TILE_OV_MASK                         0x0000ffff
+
+#endif // __MDP_REG_RSZ_H__
diff --git a/drivers/media/platform/mtk-mdp3/mdp_reg_wdma.h b/drivers/media/platform/mtk-mdp3/mdp_reg_wdma.h
new file mode 100644
index 000000000000..7a3b857953e2
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mdp_reg_wdma.h
@@ -0,0 +1,126 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MDP_REG_WDMA_H__
+#define __MDP_REG_WDMA_H__
+
+#include "mmsys_reg_base.h"
+
+#define WDMA_INTEN              0x000
+#define WDMA_INTSTA             0x004
+#define WDMA_EN                 0x008
+#define WDMA_RST                0x00c
+#define WDMA_SMI_CON            0x010
+#define WDMA_CFG                0x014
+#define WDMA_SRC_SIZE           0x018
+#define WDMA_CLIP_SIZE          0x01c
+#define WDMA_CLIP_COORD         0x020
+#define WDMA_DST_ADDR           0xf00
+#define WDMA_DST_W_IN_BYTE      0x028
+#define WDMA_ALPHA              0x02c
+#define WDMA_BUF_CON1           0x038
+#define WDMA_BUF_CON2           0x03c
+#define WDMA_C00                0x040
+#define WDMA_C02                0x044
+#define WDMA_C10                0x048
+#define WDMA_C12                0x04c
+#define WDMA_C20                0x050
+#define WDMA_C22                0x054
+#define WDMA_PRE_ADD0           0x058
+#define WDMA_PRE_ADD2           0x05c
+#define WDMA_POST_ADD0          0x060
+#define WDMA_POST_ADD2          0x064
+#define WDMA_DST_U_ADDR         0xf04
+#define WDMA_DST_V_ADDR         0xf08
+#define WDMA_DST_UV_PITCH       0x078
+#define WDMA_DST_ADDR_OFFSET    0x080
+#define WDMA_DST_U_ADDR_OFFSET  0x084
+#define WDMA_DST_V_ADDR_OFFSET  0x088
+#define PROC_TRACK_CON_0        0x090
+#define PROC_TRACK_CON_1        0x094
+#define PROC_TRACK_CON_2        0x098
+#define WDMA_FLOW_CTRL_DBG      0x0a0
+#define WDMA_EXEC_DBG           0x0a4
+#define WDMA_CT_DBG             0x0a8
+#define WDMA_SMI_TRAFFIC_DBG    0x0ac
+#define WDMA_PROC_TRACK_DBG_0   0x0b0
+#define WDMA_PROC_TRACK_DBG_1   0x0b4
+#define WDMA_DEBUG              0x0b8
+#define WDMA_DUMMY              0x100
+#define WDMA_DITHER_0           0xe00
+#define WDMA_DITHER_5           0xe14
+#define WDMA_DITHER_6           0xe18
+#define WDMA_DITHER_7           0xe1c
+#define WDMA_DITHER_8           0xe20
+#define WDMA_DITHER_9           0xe24
+#define WDMA_DITHER_10          0xe28
+#define WDMA_DITHER_11          0xe2c
+#define WDMA_DITHER_12          0xe30
+#define WDMA_DITHER_13          0xe34
+#define WDMA_DITHER_14          0xe38
+#define WDMA_DITHER_15          0xe3c
+#define WDMA_DITHER_16          0xe40
+#define WDMA_DITHER_17          0xe44
+
+/* MASK */
+#define WDMA_INTEN_MASK             0x00000003
+#define WDMA_INTSTA_MASK            0x00000003
+#define WDMA_EN_MASK                0x00000001
+#define WDMA_RST_MASK               0x00000001
+#define WDMA_SMI_CON_MASK           0x0fffffff
+#define WDMA_CFG_MASK               0xff03bff0
+#define WDMA_SRC_SIZE_MASK          0x3fff3fff
+#define WDMA_CLIP_SIZE_MASK         0x3fff3fff
+#define WDMA_CLIP_COORD_MASK        0x3fff3fff
+#define WDMA_DST_ADDR_MASK          0xffffffff
+#define WDMA_DST_W_IN_BYTE_MASK     0x0000ffff
+#define WDMA_ALPHA_MASK             0x800000ff
+#define WDMA_BUF_CON1_MASK          0xd1ff01ff
+#define WDMA_BUF_CON2_MASK          0xffffffff
+#define WDMA_C00_MASK               0x1fff1fff
+#define WDMA_C02_MASK               0x00001fff
+#define WDMA_C10_MASK               0x1fff1fff
+#define WDMA_C12_MASK               0x00001fff
+#define WDMA_C20_MASK               0x1fff1fff
+#define WDMA_C22_MASK               0x00001fff
+#define WDMA_PRE_ADD0_MASK          0x01ff01ff
+#define WDMA_PRE_ADD2_MASK          0x000001ff
+#define WDMA_POST_ADD0_MASK         0x01ff01ff
+#define WDMA_POST_ADD2_MASK         0x000001ff
+#define WDMA_DST_U_ADDR_MASK        0xffffffff
+#define WDMA_DST_V_ADDR_MASK        0xffffffff
+#define WDMA_DST_UV_PITCH_MASK      0x0000ffff
+#define WDMA_DST_ADDR_OFFSET_MASK   0x0fffffff
+#define WDMA_DST_U_ADDR_OFFSET_MASK 0x0fffffff
+#define WDMA_DST_V_ADDR_OFFSET_MASK 0x0fffffff
+#define PROC_TRACK_CON_0_MASK       0x70000fff
+#define PROC_TRACK_CON_1_MASK       0x00ffffff
+#define PROC_TRACK_CON_2_MASK       0x00ffffff
+#define WDMA_FLOW_CTRL_DBG_MASK     0x0000f3ff
+#define WDMA_EXEC_DBG_MASK          0x003f003f
+#define WDMA_CT_DBG_MASK            0x3fff3fff
+#define WDMA_SMI_TRAFFIC_DBG_MASK   0xffffffff
+#define WDMA_PROC_TRACK_DBG_0_MASK  0xffffffff
+#define WDMA_PROC_TRACK_DBG_1_MASK  0xffffffff
+#define WDMA_DEBUG_MASK             0xffffffff
+#define WDMA_DUMMY_MASK             0xffffffff
+#define WDMA_DITHER_0_MASK          0x0111ff11
+#define WDMA_DITHER_5_MASK          0x0000ffff
+#define WDMA_DITHER_6_MASK          0x0001f3ff
+#define WDMA_DITHER_7_MASK          0x00000333
+#define WDMA_DITHER_8_MASK          0x03ff0001
+#define WDMA_DITHER_9_MASK          0x03ff03ff
+#define WDMA_DITHER_10_MASK         0x00000733
+#define WDMA_DITHER_11_MASK         0x00003331
+#define WDMA_DITHER_12_MASK         0xffff0031
+#define WDMA_DITHER_13_MASK         0x00000777
+#define WDMA_DITHER_14_MASK         0x00000371
+#define WDMA_DITHER_15_MASK         0x77770001
+#define WDMA_DITHER_16_MASK         0x77777777
+#define WDMA_DITHER_17_MASK         0x0001ffff
+
+#endif  // __MDP_REG_WDMA_H__
diff --git a/drivers/media/platform/mtk-mdp3/mdp_reg_wrot.h b/drivers/media/platform/mtk-mdp3/mdp_reg_wrot.h
new file mode 100644
index 000000000000..376bc85c7703
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mdp_reg_wrot.h
@@ -0,0 +1,116 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MDP_REG_WROT_H__
+#define __MDP_REG_WROT_H__
+
+#include "mmsys_reg_base.h"
+
+#define VIDO_CTRL                   0x000
+#define VIDO_DMA_PERF               0x004
+#define VIDO_MAIN_BUF_SIZE          0x008
+#define VIDO_SOFT_RST               0x010
+#define VIDO_SOFT_RST_STAT          0x014
+#define VIDO_INT_EN                 0x018
+#define VIDO_INT                    0x01c
+#define VIDO_CROP_OFST              0x020
+#define VIDO_TAR_SIZE               0x024
+#define VIDO_BASE_ADDR              0xf00
+#define VIDO_OFST_ADDR              0x02c
+#define VIDO_STRIDE                 0x030
+#define VIDO_BASE_ADDR_C            0xf04
+#define VIDO_OFST_ADDR_C            0x038
+#define VIDO_STRIDE_C               0x03c
+#define VIDO_DITHER                 0x054
+#define VIDO_BASE_ADDR_V            0xf08
+#define VIDO_OFST_ADDR_V            0x068
+#define VIDO_STRIDE_V               0x06c
+#define VIDO_RSV_1                  0x070
+#define VIDO_DMA_PREULTRA           0x074
+#define VIDO_IN_SIZE                0x078
+#define VIDO_ROT_EN                 0x07c
+#define VIDO_FIFO_TEST              0x080
+#define VIDO_MAT_CTRL               0x084
+#define VIDO_MAT_RMY                0x088
+#define VIDO_MAT_RMV                0x08c
+#define VIDO_MAT_GMY                0x090
+#define VIDO_MAT_BMY                0x094
+#define VIDO_MAT_BMV                0x098
+#define VIDO_MAT_PREADD             0x09c
+#define VIDO_MAT_POSTADD            0x0a0
+#define VIDO_DITHER_00              0x0a4
+#define VIDO_DITHER_02              0x0ac
+#define VIDO_DITHER_03              0x0b0
+#define VIDO_DITHER_04              0x0b4
+#define VIDO_DITHER_05              0x0b8
+#define VIDO_DITHER_06              0x0bc
+#define VIDO_DITHER_07              0x0c0
+#define VIDO_DITHER_08              0x0c4
+#define VIDO_DITHER_09              0x0c8
+#define VIDO_DITHER_10              0x0cc
+#define VIDO_DEBUG                  0x0d0
+#define VIDO_ARB_SW_CTL             0x0d4
+#define MDP_WROT_TRACK_CTL          0x0e0
+#define MDP_WROT_TRACK_WINDOW       0x0e4
+#define MDP_WROT_TRACK_TARGET       0x0e8
+#define MDP_WROT_TRACK_STOP         0x0ec
+#define MDP_WROT_TRACK_PROC_CNT0    0x0f0
+#define MDP_WROT_TRACK_PROC_CNT1    0x0f4
+
+/* MASK */
+#define VIDO_CTRL_MASK                  0xf530711f
+#define VIDO_DMA_PERF_MASK              0x3fffffff
+#define VIDO_MAIN_BUF_SIZE_MASK         0x1fff7f77
+#define VIDO_SOFT_RST_MASK              0x00000001
+#define VIDO_SOFT_RST_STAT_MASK         0x00000001
+#define VIDO_INT_EN_MASK                0x00003f07
+#define VIDO_INT_MASK                   0x00000007
+#define VIDO_CROP_OFST_MASK             0x1fff1fff
+#define VIDO_TAR_SIZE_MASK              0x1fff1fff
+#define VIDO_BASE_ADDR_MASK             0xffffffff
+#define VIDO_OFST_ADDR_MASK             0x0fffffff
+#define VIDO_STRIDE_MASK                0x0000ffff
+#define VIDO_BASE_ADDR_C_MASK           0xffffffff
+#define VIDO_OFST_ADDR_C_MASK           0x0fffffff
+#define VIDO_STRIDE_C_MASK              0x0000ffff
+#define VIDO_DITHER_MASK                0xff000001
+#define VIDO_BASE_ADDR_V_MASK           0xffffffff
+#define VIDO_OFST_ADDR_V_MASK           0x0fffffff
+#define VIDO_STRIDE_V_MASK              0x0000ffff
+#define VIDO_RSV_1_MASK                 0xffffffff
+#define VIDO_DMA_PREULTRA_MASK          0x00ffffff
+#define VIDO_IN_SIZE_MASK               0x1fff1fff
+#define VIDO_ROT_EN_MASK                0x00000001
+#define VIDO_FIFO_TEST_MASK             0x00000fff
+#define VIDO_MAT_CTRL_MASK              0x000000f3
+#define VIDO_MAT_RMY_MASK               0x1fff1fff
+#define VIDO_MAT_RMV_MASK               0x1fff1fff
+#define VIDO_MAT_GMY_MASK               0x1fff1fff
+#define VIDO_MAT_BMY_MASK               0x1fff1fff
+#define VIDO_MAT_BMV_MASK               0x00001fff
+#define VIDO_MAT_PREADD_MASK            0x1ff7fdff
+#define VIDO_MAT_POSTADD_MASK           0x1ff7fdff
+#define VIDO_DITHER_00_MASK             0x0000ff3f
+#define VIDO_DITHER_02_MASK             0xffff3fff
+#define VIDO_DITHER_03_MASK             0x0000003f
+#define VIDO_DITHER_04_MASK             0xbfffffff
+#define VIDO_DITHER_05_MASK             0xffff7fff
+#define VIDO_DITHER_06_MASK             0x003ff773
+#define VIDO_DITHER_07_MASK             0x00007777
+#define VIDO_DITHER_08_MASK             0x00007777
+#define VIDO_DITHER_09_MASK             0x00007777
+#define VIDO_DITHER_10_MASK             0x0001ffff
+#define VIDO_DEBUG_MASK                 0xffffffff
+#define VIDO_ARB_SW_CTL_MASK            0x00000007
+#define MDP_WROT_TRACK_CTL_MASK         0x0000001f
+#define MDP_WROT_TRACK_WINDOW_MASK      0x00000fff
+#define MDP_WROT_TRACK_TARGET_MASK      0x00ffffff
+#define MDP_WROT_TRACK_STOP_MASK        0x00ffffff
+#define MDP_WROT_TRACK_PROC_CNT0_MASK   0xffffffff
+#define MDP_WROT_TRACK_PROC_CNT1_MASK   0x00000001
+
+#endif  // __MDP_REG_WROT_H__
diff --git a/drivers/media/platform/mtk-mdp3/mmsys_config.h b/drivers/media/platform/mtk-mdp3/mmsys_config.h
new file mode 100644
index 000000000000..d1328840bbf2
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mmsys_config.h
@@ -0,0 +1,189 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MMSYS_CONFIG_H__
+#define __MMSYS_CONFIG_H__
+
+#include "mmsys_reg_base.h"
+
+#define MMSYS_INTEN                   0x000
+#define MMSYS_INTSTA                  0x004
+#define MJC_APB_TX_CON                0x00c
+
+#define ISP_MOUT_EN                   0xf80
+#define MDP_RDMA0_MOUT_EN             0xf84
+#define MDP_RDMA1_MOUT_EN             0xf88
+#define MDP_PRZ0_MOUT_EN              0xf8c
+#define MDP_PRZ1_MOUT_EN              0xf90
+#define MDP_COLOR_MOUT_EN             0xf94
+#define IPU_MOUT_EN                   0xf98
+#define DISP_TO_WROT_SOUT_SEL         0xfa0
+#define MDP_COLOR_IN_SOUT_SEL         0xfa4
+#define MDP_PATH0_SOUT_SEL            0xfa8
+#define MDP_PATH1_SOUT_SEL            0xfac
+#define MDP_TDSHP_SOUT_SEL            0xfb0
+
+#define DISP_OVL0_MOUT_EN             0xf00
+#define DISP_OVL0_2L_MOUT_EN          0xf04
+#define DISP_OVL1_2L_MOUT_EN          0xf08
+#define DISP_DITHER0_MOUT_EN          0xf0c
+#define DISP_RSZ_MOUT_EN              0xf10
+
+#define MMSYS_MOUT_RST                0x048
+#define MDP_PRZ0_SEL_IN               0xfc0
+#define MDP_PRZ1_SEL_IN               0xfc4
+#define MDP_TDSHP_SEL_IN              0xfc8
+#define DISP_WDMA0_SEL_IN             0xfcc
+#define MDP_WROT0_SEL_IN              0xfd0
+#define MDP_WDMA_SEL_IN               0xfd4
+#define MDP_COLOR_OUT_SEL_IN          0xfd8
+#define MDP_COLOR_SEL_IN              0xfdc
+#define MDP_PATH0_SEL_IN              0xfe0
+#define MDP_PATH1_SEL_IN              0xfe4
+
+#define DISP_COLOR_OUT_SEL_IN         0xf20
+#define DISP_PATH0_SEL_IN             0xf24
+#define DISP_WDMA0_PRE_SEL_IN         0xf28
+#define DSI0_SEL_IN                   0xf2c
+#define DSI1_SEL_IN                   0xf30
+#define DISP_OVL0_SEL_IN              0xf34
+#define DISP_OVL0_2L_SEL_IN           0xf38
+#define OVL_TO_RSZ_SEL_IN             0xf3c
+#define OVL_TO_WDMA_SEL_IN            0xf40
+#define OVL_TO_WROT_SEL_IN            0xf44
+#define DISP_RSZ_SEL_IN               0xf48
+#define DISP_RDMA0_SOUT_SEL_IN        0xf50
+#define DISP_RDMA1_SOUT_SEL_IN        0xf54
+#define MDP_TO_DISP0_SOUT_SEL_IN      0xf58
+#define MDP_TO_DISP1_SOUT_SEL_IN      0xf5c
+#define DISP_RDMA0_RSZ_IN_SOUT_SEL_IN 0xf60
+#define DISP_RDMA0_RSZ_OUT_SEL_IN     0xf64
+#define MDP_AAL_MOUT_EN               0xfe8
+#define MDP_AAL_SEL_IN                0xfec
+#define MDP_CCORR_SEL_IN              0xff0
+#define MDP_CCORR_SOUT_SEL            0xff4
+
+#define MMSYS_MISC                    0x0f0
+#define MMSYS_SMI_LARB_SEL            0x0f4
+#define MMSYS_SODI_REQ_MASK           0x0f8
+#define MMSYS_CG_CON0                 0x100
+#define MMSYS_CG_SET0                 0x104
+#define MMSYS_CG_CLR0                 0x108
+#define MMSYS_CG_CON1                 0x110
+#define MMSYS_CG_SET1                 0x114
+#define MMSYS_CG_CLR1                 0x118
+#define MMSYS_HW_DCM_DIS0             0x120
+#define MMSYS_HW_DCM_DIS_SET0         0x124
+#define MMSYS_HW_DCM_DIS_CLR0         0x128
+#define MMSYS_HW_DCM_DIS1             0x130
+#define MMSYS_HW_DCM_DIS_SET1         0x134
+#define MMSYS_HW_DCM_DIS_CLR1         0x138
+#define MMSYS_HW_DCM_EVENT_CTL1       0x13c
+#define MMSYS_SW0_RST_B               0x140
+#define MMSYS_SW1_RST_B               0x144
+#define MMSYS_LCM_RST_B               0x150
+#define LARB6_AXI_ASIF_CFG_WD         0x180
+#define LARB6_AXI_ASIF_CFG_RD         0x184
+#define PROC_TRACK_EMI_BUSY_CON       0x190
+#define DISP_FAKE_ENG_EN              0x200
+#define DISP_FAKE_ENG_RST             0x204
+#define DISP_FAKE_ENG_CON0            0x208
+#define DISP_FAKE_ENG_CON1            0x20c
+#define DISP_FAKE_ENG_RD_ADDR         0x210
+#define DISP_FAKE_ENG_WR_ADDR         0x214
+#define DISP_FAKE_ENG_STATE           0x218
+#define DISP_FAKE_ENG2_EN             0x220
+#define DISP_FAKE_ENG2_RST            0x224
+#define DISP_FAKE_ENG2_CON0           0x228
+#define DISP_FAKE_ENG2_CON1           0x22c
+#define DISP_FAKE_ENG2_RD_ADDR        0x230
+#define DISP_FAKE_ENG2_WR_ADDR        0x234
+#define DISP_FAKE_ENG2_STATE          0x238
+#define MMSYS_MBIST_CON               0x800
+#define MMSYS_MBIST_DONE              0x804
+#define MMSYS_MBIST_HOLDB             0x808
+#define MMSYS_MBIST_MODE              0x80c
+#define MMSYS_MBIST_FAIL0             0x810
+#define MMSYS_MBIST_FAIL1             0x814
+#define MMSYS_MBIST_FAIL2             0x818
+#define MMSYS_MBIST_DEBUG             0x820
+#define MMSYS_MBIST_DIAG_SCANOUT      0x824
+#define MMSYS_MBIST_PRE_FUSE          0x828
+#define MMSYS_MBIST_BSEL0             0x82c
+#define MMSYS_MBIST_BSEL1             0x830
+#define MMSYS_MBIST_BSEL2             0x834
+#define MMSYS_MBIST_BSEL3             0x838
+#define MMSYS_MBIST_HDEN              0x83c
+#define MDP_RDMA0_MEM_DELSEL          0x840
+#define MDP_RDMA1_MEM_DELSEL          0x844
+#define MDP_RSZ_MEM_DELSEL            0x848
+#define MDP_TDSHP_MEM_DELSEL          0x84c
+#define MDP_AAL_MEM_DELSEL            0x850
+
+#define MDP_WROT0_MEM_DELSEL          0x854
+#define MDP_WDMA_MEM_DELSEL           0x858
+#define DISP_OVL_MEM_DELSEL           0x85c
+#define DISP_OVL_2L_MEM_DELSEL        0x860
+#define DISP_RDMA_MEM_DELSEL          0x864
+#define DISP_WDMA0_MEM_DELSEL         0x868
+#define DISP_GAMMA_MEM_DELSEL         0x870
+#define DSI_MEM_DELSEL                0x874
+#define DISP_SPLIT_MEM_DELSEL         0x878
+#define DISP_DSC_MEM_DELSEL           0x87c
+#define MMSYS_DEBUG_OUT_SEL           0x88c
+#define MMSYS_MBIST_RP_RST_B          0x890
+#define MMSYS_MBIST_RP_FAIL0          0x894
+#define MMSYS_MBIST_RP_FAIL1          0x898
+#define MMSYS_MBIST_RP_OK0            0x89c
+#define MMSYS_MBIST_RP_OK1            0x8a0
+#define MMSYS_DUMMY0                  0x8a4
+#define MMSYS_DUMMY1                  0x8a8
+#define MMSYS_DUMMY2                  0x8ac
+#define MMSYS_DUMMY3                  0x8b0
+#define DISP_DL_VALID_0               0x8b4
+#define DISP_DL_VALID_1               0x8b8
+#define DISP_DL_VALID_2               0x8bc
+#define DISP_DL_READY_0               0x8c0
+#define DISP_DL_READY_1               0x8c4
+#define DISP_DL_READY_2               0x8C8
+#define MDP_DL_VALID_0                0x8cc
+#define MDP_DL_VALID_1                0x8d0
+#define MDP_DL_READY_0                0x8d4
+#define MDP_DL_READY_1                0x8d8
+#define SMI_LARB0_GREQ                0x8dc
+#define DISP_MOUT_MASK                0x8e0
+#define DISP_MOUT_MASK1               0x8e4
+#define MDP_MOUT_MASK                 0x8e8
+#define MMSYS_POWER_READ              0x8ec
+#define TOP_RELAY_FSM_RD              0x960
+#define MDP_ASYNC_CFG_WD              0x934
+#define MDP_ASYNC_CFG_RD              0x938
+#define MDP_ASYNC_IPU_CFG_WD          0x93C
+#define MDP_ASYNC_CFG_IPU_RD          0x940
+#define MDP_ASYNC_CFG_OUT_RD          0x958
+#define MDP_ASYNC_IPU_CFG_OUT_RD      0x95C
+#define ISP_RELAY_CFG_WD              0x994
+#define ISP_RELAY_CNT_RD              0x998
+#define ISP_RELAY_CNT_LATCH_RD        0x99c
+#define IPU_RELAY_CFG_WD              0x9a0
+#define IPU_RELAY_CNT_RD              0x9a4
+#define IPU_RELAY_CNT_LATCH_RD        0x9a8
+
+/* MASK */
+#define MMSYS_SW0_RST_B_MASK          0xffffffff
+#define MMSYS_SW1_RST_B_MASK          0xffffffff
+#define MDP_COLOR_IN_SOUT_SEL_MASK    0x0000000f
+#define DISP_COLOR_OUT_SEL_IN_MASK    0xffffffff
+#define MDP_ASYNC_CFG_WD_MASK         0xffffffff
+#define MDP_ASYNC_IPU_CFG_WD_MASK     0xffffffff
+#define MMSYS_HW_DCM_DIS0_MASK        0xffffffff
+#define MMSYS_HW_DCM_DIS1_MASK        0xffffffff
+#define MDP_ASYNC_CFG_WD_MASK         0xffffffff
+#define ISP_RELAY_CFG_WD_MASK         0xffffffff
+#define IPU_RELAY_CFG_WD_MASK         0xffffffff
+
+#endif  // __MMSYS_CONFIG_H__
diff --git a/drivers/media/platform/mtk-mdp3/mmsys_mutex.h b/drivers/media/platform/mtk-mdp3/mmsys_mutex.h
new file mode 100644
index 000000000000..9ff382cc37c8
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mmsys_mutex.h
@@ -0,0 +1,36 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MMSYS_MUTEX_H__
+#define __MMSYS_MUTEX_H__
+
+#include "mmsys_reg_base.h"
+#include "mdp-platform.h"
+
+#define MM_MUTEX_INTEN              0x00
+#define MM_MUTEX_INTSTA             0x04
+#define MM_MUTEX_CFG                0x08
+
+#define MM_MUTEX_EN                 (0x20 + mutex_id * 0x20)
+#define MM_MUTEX_GET                (0x24 + mutex_id * 0x20)
+#define MM_MUTEX_RST                (0x28 + mutex_id * 0x20)
+#define MM_MUTEX_MOD                (MM_MUTEX_MOD_OFFSET + mutex_id * 0x20)
+#define MM_MUTEX_SOF                (MM_MUTEX_SOF_OFFSET + mutex_id * 0x20)
+
+// MASK
+#define MM_MUTEX_INTEN_MASK         0x0fff
+#define MM_MUTEX_INTSTA_MASK        0x0fff
+#define MM_MUTEX_DEBUG_OUT_SEL_MASK 0x03
+#define MM_MUTEX_CFG_MASK           0x01
+
+#define MM_MUTEX_EN_MASK            0x01
+#define MM_MUTEX_GET_MASK           0x03
+#define MM_MUTEX_RST_MASK           0x01
+#define MM_MUTEX_MOD_MASK           0x07ffffff
+#define MM_MUTEX_SOF_MASK           0x0f
+
+#endif  // __MMSYS_MUTEX_H__
diff --git a/drivers/media/platform/mtk-mdp3/mmsys_reg_base.h b/drivers/media/platform/mtk-mdp3/mmsys_reg_base.h
new file mode 100644
index 000000000000..441cb56fcbba
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mmsys_reg_base.h
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ */
+
+#ifndef __MMSYS_REG_BASE_H__
+#define __MMSYS_REG_BASE_H__
+
+#define MM_REG_WRITE_MASK(cmd, id, base, ofst, val, mask, ...) \
+	cmdq_pkt_write_mask(cmd->pkt, id, \
+		(base) + (ofst), (val), (mask), ##__VA_ARGS__)
+#define MM_REG_WRITE(cmd, id, base, ofst, val, mask, ...) \
+	MM_REG_WRITE_MASK(cmd, id, base, ofst, val, \
+		(((mask) & (ofst##_MASK)) == (ofst##_MASK)) ? \
+			(0xffffffff) : (mask), ##__VA_ARGS__)
+
+#define MM_REG_WAIT(cmd, evt) \
+	cmdq_pkt_wfe(cmd->pkt, cmd->event[(evt)])
+
+#define MM_REG_WAIT_NO_CLEAR(cmd, evt) \
+	cmdq_pkt_wait_no_clear(cmd->pkt, cmd->event[(evt)])
+
+#define MM_REG_CLEAR(cmd, evt) \
+	cmdq_pkt_clear_event(cmd->pkt, cmd->event[(evt)])
+
+#define MM_REG_SET_EVENT(cmd, evt) \
+	cmdq_pkt_set_event(cmd->pkt, cmd->event[(evt)])
+
+#define MM_REG_POLL_MASK(cmd, id, base, ofst, val, mask, ...) \
+	cmdq_pkt_poll(cmd->pkt, id, \
+		(base) + (ofst), (val), (mask), ##__VA_ARGS__)
+#define MM_REG_POLL(cmd, id, base, ofst, val, mask, ...) \
+	MM_REG_POLL_MASK(cmd, id, base, ofst, val, \
+		(((mask) & (ofst##_MASK)) == (ofst##_MASK)) ? \
+			(0xffffffff) : (mask), ##__VA_ARGS__)
+
+#endif  // __MM_REG_BASE_H__
diff --git a/drivers/media/platform/mtk-mdp3/mtk-img-ipi.h b/drivers/media/platform/mtk-mdp3/mtk-img-ipi.h
new file mode 100644
index 000000000000..681732b2316a
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-img-ipi.h
@@ -0,0 +1,282 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Holmes Chiou <holmes.chiou@mediatek.com>
+ *         Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_IMG_IPI_H__
+#define __MTK_IMG_IPI_H__
+
+#include <linux/types.h>
+
+/* ISP-MDP generic input information */
+
+#define IMG_MAX_HW_INPUTS	1
+
+#define IMG_MAX_HW_OUTPUTS	4
+
+#define IMG_MAX_PLANES		3
+
+#define IMG_IPI_INIT    1
+#define IMG_IPI_DEINIT  2
+#define IMG_IPI_FRAME   3
+#define IMG_IPI_DEBUG   4
+
+struct img_addr {
+	u64	va;	/* Used by Linux OS access */
+	u32	pa;	/* Used by CM4 access */
+	u32	iova;	/* Used by IOMMU HW access */
+} __attribute__ ((__packed__));
+
+struct img_sw_addr {
+	u64	va;	/* Used by APMCU access */
+	u32	pa;	/* Used by CM4 access */
+} __attribute__ ((__packed__));
+
+struct img_plane_format {
+	u32	size;
+	u16	stride;
+} __attribute__ ((__packed__));
+
+struct img_pix_format {
+	u16		width;
+	u16		height;
+	u32		colorformat;	/* enum mdp_color */
+	u16		ycbcr_prof;	/* enum mdp_ycbcr_profile */
+	struct img_plane_format	plane_fmt[IMG_MAX_PLANES];
+} __attribute__ ((__packed__));
+
+struct img_image_buffer {
+	struct img_pix_format	format;
+	u32		iova[IMG_MAX_PLANES];
+	/* enum mdp_buffer_usage, FD or advanced ISP usages */
+	u32		usage;
+} __attribute__ ((__packed__));
+
+#define IMG_SUBPIXEL_SHIFT	20
+
+struct img_crop {
+	s16		left;
+	s16		top;
+	u16	width;
+	u16	height;
+	u32	left_subpix;
+	u32	top_subpix;
+	u32	width_subpix;
+	u32	height_subpix;
+} __attribute__ ((__packed__));
+
+#define IMG_CTRL_FLAG_HFLIP	BIT(0)
+#define IMG_CTRL_FLAG_DITHER	BIT(1)
+#define IMG_CTRL_FLAG_SHARPNESS	BIT(4)
+#define IMG_CTRL_FLAG_HDR	BIT(5)
+#define IMG_CTRL_FLAG_DRE	BIT(6)
+
+struct img_input {
+	struct img_image_buffer	buffer;
+	u16		flags;	/* HDR, DRE, dither */
+} __attribute__ ((__packed__));
+
+struct img_output {
+	struct img_image_buffer	buffer;
+	struct img_crop		crop;
+	s16			rotation;
+	u16		flags;	/* H-flip, sharpness, dither */
+} __attribute__ ((__packed__));
+
+struct img_ipi_frameparam {
+	u32		index;
+	u32		frame_no;
+	u64		timestamp;
+	u8			type;	/* enum mdp_stream_type */
+	u8			state;
+	u8			num_inputs;
+	u8			num_outputs;
+	u64		drv_data;
+	struct img_input	inputs[IMG_MAX_HW_INPUTS];
+	struct img_output	outputs[IMG_MAX_HW_OUTPUTS];
+	struct img_addr		tuning_data;
+	struct img_addr		subfrm_data;
+	struct img_sw_addr	config_data;
+    struct img_sw_addr  self_data;
+	/* u8		pq_data[]; */
+} __attribute__ ((__packed__));
+
+struct img_ipi_param {
+    uint8_t usage;
+    struct img_sw_addr frm_param;
+} __attribute__ ((__packed__));
+
+struct img_frameparam {
+	struct list_head	list_entry;
+	struct img_ipi_frameparam frameparam;
+};
+
+/* ISP-MDP generic output information */
+
+struct img_comp_frame {
+	u32	output_disable:1;
+	u32	bypass:1;
+	u16	in_width;
+	u16	in_height;
+	u16	out_width;
+	u16	out_height;
+	struct img_crop	crop;
+	u16	in_total_width;
+	u16	out_total_width;
+} __attribute__ ((__packed__));
+
+struct img_region {
+	s16	left;
+	s16	right;
+	s16	top;
+	s16	bottom;
+} __attribute__ ((__packed__));
+
+struct img_offset {
+	s16		left;
+	s16		top;
+	u32	left_subpix;
+	u32	top_subpix;
+} __attribute__ ((__packed__));
+
+struct img_comp_subfrm {
+	u32		tile_disable:1;
+	struct img_region	in;
+	struct img_region	out;
+	struct img_offset	luma;
+	struct img_offset	chroma;
+	s16			out_vertical;	/* Output vertical index */
+	s16			out_horizontal;	/* Output horizontal index */
+} __attribute__ ((__packed__));
+
+#define IMG_MAX_SUBFRAMES	12
+
+struct mdp_rdma_subfrm {
+	u32	offset[IMG_MAX_PLANES];
+	u32	offset_0_p;
+	u32	src;
+	u32	clip;
+	u32	clip_ofst;
+} __attribute__ ((__packed__));
+
+struct mdp_rdma_data {
+	u32		src_ctrl;
+	u32		control;
+	u32		iova[IMG_MAX_PLANES];
+	u32		iova_end[IMG_MAX_PLANES];
+	u32		mf_bkgd;
+	u32		mf_bkgd_in_pxl;
+	u32		sf_bkgd;
+	u32		ufo_dec_y;
+	u32		ufo_dec_c;
+	u32		transform;
+	struct mdp_rdma_subfrm	subfrms[IMG_MAX_SUBFRAMES];
+} __attribute__ ((__packed__));
+
+struct mdp_rsz_subfrm {
+	u32	control2;
+	u32	src;
+	u32	clip;
+} __attribute__ ((__packed__));
+
+struct mdp_rsz_data {
+	u32		coeff_step_x;
+	u32		coeff_step_y;
+	u32		control1;
+	u32		control2;
+	struct mdp_rsz_subfrm	subfrms[IMG_MAX_SUBFRAMES];
+} __attribute__ ((__packed__));
+
+struct mdp_wrot_subfrm {
+	u32	offset[IMG_MAX_PLANES];
+	u32	src;
+	u32	clip;
+	u32	clip_ofst;
+	u32	main_buf;
+} __attribute__ ((__packed__));
+
+struct mdp_wrot_data {
+	u32		iova[IMG_MAX_PLANES];
+	u32		control;
+	u32		stride[IMG_MAX_PLANES];
+	u32		mat_ctrl;
+	u32		fifo_test;
+	u32		filter;
+	struct mdp_wrot_subfrm	subfrms[IMG_MAX_SUBFRAMES];
+} __attribute__ ((__packed__));
+
+struct mdp_wdma_subfrm {
+	u32	offset[IMG_MAX_PLANES];
+	u32	src;
+	u32	clip;
+	u32	clip_ofst;
+} __attribute__ ((__packed__));
+
+struct mdp_wdma_data {
+	u32		wdma_cfg;
+	u32		iova[IMG_MAX_PLANES];
+	u32		w_in_byte;
+	u32		uv_stride;
+	struct mdp_wdma_subfrm	subfrms[IMG_MAX_SUBFRAMES];
+} __attribute__ ((__packed__));
+
+struct isp_data {
+	u64	dl_flags;	/* 1 << (enum mdp_comp_type) */
+	u32	smxi_iova[4];
+	u32	cq_idx;
+	u32	cq_iova;
+	u32	tpipe_iova[IMG_MAX_SUBFRAMES];
+} __attribute__ ((__packed__));
+
+struct img_compparam {
+	u16		type;	/* enum mdp_comp_type */
+	u16		id;	/* enum mdp_comp_id */
+	u32		input;
+	u32		outputs[IMG_MAX_HW_OUTPUTS];
+	u32		num_outputs;
+	struct img_comp_frame	frame;
+	struct img_comp_subfrm	subfrms[IMG_MAX_SUBFRAMES];
+	u32		num_subfrms;
+	union {
+		struct mdp_rdma_data	rdma;
+		struct mdp_rsz_data	rsz;
+		struct mdp_wrot_data	wrot;
+		struct mdp_wdma_data	wdma;
+		/* struct mdp_hdr_data	hdr; */
+		struct isp_data		isp;
+		/* struct wpe_data	wpe; */
+	};
+} __attribute__ ((__packed__));
+
+#define IMG_MAX_COMPONENTS	20
+
+struct img_mux {
+	u32	reg;
+	u32	value;
+};
+
+struct img_mmsys_ctrl {
+	struct img_mux	sets[IMG_MAX_COMPONENTS * 2];
+	u32	num_sets;
+};
+
+struct img_config {
+	struct img_compparam	components[IMG_MAX_COMPONENTS];
+	u32		num_components;
+	struct img_mmsys_ctrl	ctrls[IMG_MAX_SUBFRAMES];
+	u32		num_subfrms;
+} __attribute__ ((__packed__));
+
+#endif  /* __MTK_IMG_IPI_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.c
new file mode 100644
index 000000000000..707f967efa91
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.c
@@ -0,0 +1,458 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/platform_device.h>
+#include "mtk-mdp3-cmdq.h"
+#include "mtk-mdp3-comp.h"
+#include "mtk-mdp3-core.h"
+#ifdef MDP_DEBUG
+#include "mtk-mdp3-debug.h"
+#endif
+
+#include "mdp-platform.h"
+#include "mmsys_mutex.h"
+
+#define DISP_MUTEX_MDP_FIRST	(5)
+#define DISP_MUTEX_MDP_COUNT	(5)
+
+#define MDP_PATH_MAX_COMPS	IMG_MAX_COMPONENTS
+
+struct mdp_path {
+	struct mdp_dev		*mdp_dev;
+	struct mdp_comp_ctx	comps[MDP_PATH_MAX_COMPS];
+	u32			num_comps;
+	const struct img_config	*config;
+	const struct img_ipi_frameparam *param;
+	const struct v4l2_rect	*composes[IMG_MAX_HW_OUTPUTS];
+	struct v4l2_rect	bounds[IMG_MAX_HW_OUTPUTS];
+};
+
+#define has_op(ctx, op) \
+	(ctx->comp->ops && ctx->comp->ops->op)
+#define call_op(ctx, op, ...) \
+	(has_op(ctx, op) ? ctx->comp->ops->op(ctx, ##__VA_ARGS__) : 0)
+
+struct mdp_path_subfrm {
+	s32	mutex_id;
+	u32	mutex_mod;
+	s32	sofs[MDP_PATH_MAX_COMPS];
+	u32	num_sofs;
+};
+
+bool is_output_disable(const struct img_compparam *param, u32 count)
+{
+	return (count < param->num_subfrms) ?
+		(param->frame.output_disable ||
+		param->subfrms[count].tile_disable) :
+		true;
+}
+
+int mdp_path_subfrm_require(struct mdp_path_subfrm *subfrm,
+			    const struct mdp_path *path, struct mdp_cmd *cmd,
+			    u32 count)
+{
+	const struct img_config *config = path->config;
+	const struct mdp_comp_ctx *ctx;
+	phys_addr_t mm_mutex = path->mdp_dev->mm_mutex.reg_base;
+	s32 mutex_id = -1;
+	u32 mutex_sof = 0;
+	int mdp_color = 0;
+	int index;
+	u8 subsys_id = path->mdp_dev->mm_mutex.subsys_id;
+
+	/* Default value */
+	memset(subfrm, 0, sizeof(*subfrm));
+
+	for (index = 0; index < config->num_components; index++) {
+		ctx = &path->comps[index];
+		if (is_output_disable(ctx->param, count))
+			continue;
+		switch (ctx->comp->id) {
+		/**********************************************
+		 * Name            MSB LSB
+		 * DISP_MUTEX_MOD   23   0
+		 *
+		 * Specifies which modules are in this mutex.
+		 * Every bit denotes a module. Bit definition:
+		 *  2 mdp_rdma0
+		 *  4 mdp_rsz0
+		 *  5 mdp_rsz1
+		 *  6 mdp_tdshp
+		 *  7 mdp_wrot0
+		 *  8 mdp_wdma
+		 *  13 mdp_color
+		 *  23 mdp_aal
+		 *  24 mdp_ccorr
+		 **********************************************/
+		case MDP_AAL0:
+			subfrm->mutex_mod |= 1 << 23;
+			break;
+		case MDP_CCORR0:
+			subfrm->mutex_mod |= 1 << 24;
+			break;
+		case MDP_COLOR0:
+			if (mdp_color)
+				subfrm->mutex_mod |= 1 << 13;
+			break;
+		case MDP_WDMA:
+			subfrm->mutex_mod |= 1 << 8;
+			subfrm->sofs[subfrm->num_sofs++] = MDP_WDMA;
+			break;
+		case MDP_WROT0:
+			subfrm->mutex_mod |= 1 << 7;
+			subfrm->sofs[subfrm->num_sofs++] = MDP_WROT0;
+			break;
+		case MDP_TDSHP0:
+			subfrm->mutex_mod |= 1 << 6;
+			subfrm->sofs[subfrm->num_sofs++] = MDP_TDSHP0;
+			break;
+		case MDP_SCL1:
+			subfrm->mutex_mod |= 1 << 5;
+			subfrm->sofs[subfrm->num_sofs++] = MDP_SCL1;
+			break;
+		case MDP_SCL0:
+			subfrm->mutex_mod |= 1 << 4;
+			subfrm->sofs[subfrm->num_sofs++] = MDP_SCL0;
+			break;
+		case MDP_RDMA0:
+			mutex_id = DISP_MUTEX_MDP_FIRST + 1;
+			subfrm->mutex_mod |= 1 << 2;
+			subfrm->sofs[subfrm->num_sofs++] = MDP_RDMA0;
+			break;
+		case MDP_IMGI:
+			mutex_id = DISP_MUTEX_MDP_FIRST;
+			break;
+		case MDP_WPEI:
+			mutex_id = DISP_MUTEX_MDP_FIRST + 3;
+			break;
+		case MDP_WPEI2:
+			mutex_id = DISP_MUTEX_MDP_FIRST + 4;
+			break;
+		default:
+			break;
+		}
+	}
+
+	subfrm->mutex_id = mutex_id;
+	if (-1 == mutex_id) {
+		mdp_err("No mutex assigned");
+		return -EINVAL;
+	}
+
+	if (subfrm->mutex_mod) {
+		/* Set mutex modules */
+		MM_REG_WRITE(cmd, subsys_id, mm_mutex, MM_MUTEX_MOD,
+			     subfrm->mutex_mod, 0x07FFFFFF);
+		MM_REG_WRITE(cmd, subsys_id, mm_mutex, MM_MUTEX_SOF,
+			     mutex_sof, 0x00000007);
+	}
+	return 0;
+}
+
+int mdp_path_subfrm_run(const struct mdp_path_subfrm *subfrm,
+			const struct mdp_path *path, struct mdp_cmd *cmd)
+{
+	phys_addr_t mm_mutex = path->mdp_dev->mm_mutex.reg_base;
+	s32 mutex_id = subfrm->mutex_id;
+	u8 subsys_id = path->mdp_dev->mm_mutex.subsys_id;
+
+	if (-1 == mutex_id) {
+		mdp_err("Incorrect mutex id");
+		return -EINVAL;
+	}
+
+	if (subfrm->mutex_mod) {
+		int index;
+
+		/* Wait WROT SRAM shared to DISP RDMA */
+		/* Clear SOF event for each engine */
+		for (index = 0; index < subfrm->num_sofs; index++) {
+			switch (subfrm->sofs[index]) {
+			case MDP_RDMA0:
+				MM_REG_CLEAR(cmd, RDMA0_SOF);
+				MM_REG_CLEAR(cmd, RDMA0_DONE);
+				break;
+			case MDP_TDSHP0:
+				MM_REG_CLEAR(cmd, TDSHP0_SOF);
+				break;
+			case MDP_SCL0:
+				MM_REG_CLEAR(cmd, RSZ0_SOF);
+				break;
+			case MDP_SCL1:
+				MM_REG_CLEAR(cmd, RSZ1_SOF);
+				break;
+			case MDP_WDMA:
+				MM_REG_CLEAR(cmd, WDMA0_SOF);
+				MM_REG_CLEAR(cmd, WDMA0_DONE);
+				break;
+			case MDP_WROT0:
+#if WROT0_DISP_SRAM_SHARING
+				MM_REG_WAIT_NO_CLEAR(cmd, WROT0_SRAM_READY);
+#endif
+				MM_REG_CLEAR(cmd, WROT0_SOF);
+				MM_REG_CLEAR(cmd, WROT0_DONE);
+				break;
+			default:
+				break;
+			}
+		}
+
+		/* Enable the mutex */
+		MM_REG_WRITE(cmd, subsys_id, mm_mutex, MM_MUTEX_EN, 0x1,
+			     0x00000001);
+
+		/* Wait SOF events and clear mutex modules (optional) */
+		for (index = 0; index < subfrm->num_sofs; index++) {
+			switch (subfrm->sofs[index]) {
+			case MDP_RDMA0:
+				MM_REG_WAIT(cmd, RDMA0_SOF);
+				break;
+			case MDP_TDSHP0:
+				MM_REG_WAIT(cmd, TDSHP0_SOF);
+				break;
+			case MDP_SCL0:
+				MM_REG_WAIT(cmd, RSZ0_SOF);
+				break;
+			case MDP_SCL1:
+				MM_REG_WAIT(cmd, RSZ1_SOF);
+				break;
+			case MDP_WDMA:
+				MM_REG_WAIT(cmd, WDMA0_SOF);
+				break;
+			case MDP_WROT0:
+				MM_REG_WAIT(cmd, WROT0_SOF);
+				break;
+			default:
+				break;
+			}
+		}
+	}
+	return 0;
+}
+
+static int mdp_path_config_subfrm(struct mdp_cmd *cmd, struct mdp_path *path,
+				  u32 count)
+{
+	struct mdp_path_subfrm subfrm;
+	const struct img_config *config = path->config;
+	const struct img_mmsys_ctrl *ctrl = &config->ctrls[count];
+	const struct img_mux *set;
+	struct mdp_comp_ctx *ctx;
+	phys_addr_t mmsys = path->mdp_dev->mmsys.reg_base;
+	int index, ret;
+	u8 subsys_id = path->mdp_dev->mmsys.subsys_id;
+
+	/* Acquire components */
+	ret = mdp_path_subfrm_require(&subfrm, path, cmd, count);
+	if (ret)
+		return ret;
+	/* Enable mux settings */
+	for (index = 0; index < ctrl->num_sets; index++) {
+		set = &ctrl->sets[index];
+		MM_REG_WRITE_MASK(cmd, subsys_id, mmsys, set->reg, set->value,
+				  0xFFFFFFFF);
+	}
+	/* Config sub-frame information */
+	for (index = (config->num_components - 1); index >= 0; index--) {
+		ctx = &path->comps[index];
+		if (is_output_disable(ctx->param, count))
+			continue;
+		ret = call_op(ctx, config_subfrm, cmd, count);
+		if (ret)
+			return ret;
+	}
+	/* Run components */
+	ret = mdp_path_subfrm_run(&subfrm, path, cmd);
+	if (ret)
+		return ret;
+	/* Wait components done */
+	for (index = 0; index < config->num_components; index++) {
+		ctx = &path->comps[index];
+		if (is_output_disable(ctx->param, count))
+			continue;
+		ret = call_op(ctx, wait_comp_event, cmd);
+		if (ret)
+			return ret;
+	}
+	/* Advance to the next sub-frame */
+	for (index = 0; index < config->num_components; index++) {
+		ctx = &path->comps[index];
+		ret = call_op(ctx, advance_subfrm, cmd, count);
+		if (ret)
+			return ret;
+	}
+	/* Disable mux settings */
+	for (index = 0; index < ctrl->num_sets; index++) {
+		set = &ctrl->sets[index];
+		MM_REG_WRITE_MASK(cmd, subsys_id, mmsys, set->reg, 0,
+				  0xFFFFFFFF);
+	}
+	return 0;
+}
+
+static int mdp_path_config(struct mdp_dev *mdp, struct mdp_cmd *cmd,
+			   struct mdp_path *path)
+{
+	const struct img_config *config = path->config;
+	struct mdp_comp_ctx *ctx;
+	int index, count, ret;
+
+	for (index = 0; index < config->num_components; index++) {
+		ret = mdp_comp_ctx_init(mdp, &path->comps[index],
+					&config->components[index],
+					path->param);
+		if (ret)
+			return ret;
+	}
+
+	/* Config path frame */
+	/* Reset components */
+	for (index = 0; index < config->num_components; index++) {
+		ctx = &path->comps[index];
+		ret = call_op(ctx, init_comp, cmd);
+		if (ret)
+			return ret;
+	}
+	/* Config frame mode */
+	for (index = 0; index < config->num_components; index++) {
+		const struct v4l2_rect *compose =
+			path->composes[ctx->param->outputs[0]];
+
+		ctx = &path->comps[index];
+		ret = call_op(ctx, config_frame, cmd, compose);
+		if (ret)
+			return ret;
+	}
+
+	/* Config path sub-frames */
+	for (count = 0; count < config->num_subfrms; count++) {
+		ret = mdp_path_config_subfrm(cmd, path, count);
+		if (ret)
+			return ret;
+	}
+	/* Post processing information */
+	for (index = 0; index < config->num_components; index++) {
+		ctx = &path->comps[index];
+		ret = call_op(ctx, post_process, cmd);
+		if (ret)
+			return ret;
+	}
+	return 0;
+}
+
+void mdp_handle_cmdq_callback(struct cmdq_cb_data data)
+{
+	struct mdp_cmdq_cb_param *cb_param;
+
+	if (!data.data) {
+		mdp_err("%s:no callback data\n", __func__);
+		return;
+	}
+
+	cb_param = (struct mdp_cmdq_cb_param *)data.data;
+#ifdef MDP_DEBUG
+	if (data.sta == CMDQ_CB_ERROR) {
+		struct mdp_func_struct *pFunc = mdp_get_func();
+		pFunc->mdp_dump_mmsys_config();
+		mdp_dump_info(~0, 1);
+	}
+#endif
+	if (cb_param->user_cmdq_cb) {
+		struct cmdq_cb_data user_cb_data;
+
+		user_cb_data.sta = data.sta;
+		user_cb_data.data = cb_param->user_cb_data;
+		cb_param->user_cmdq_cb(user_cb_data);
+	}
+
+	cmdq_pkt_destroy(cb_param->pkt);
+	kfree(cb_param);
+}
+
+int mdp_cmdq_send(struct mdp_dev *mdp, struct mdp_cmdq_param *param)
+{
+	struct mdp_cmd cmd;
+	struct mdp_path path;
+	int i, ret;
+
+	cmd.pkt = cmdq_pkt_create(mdp->cmdq_clt, SZ_16K);
+	if (IS_ERR(cmd.pkt))
+		return PTR_ERR(cmd.pkt);
+	cmd.event = &mdp->event[0];
+
+	path.mdp_dev = mdp;
+	path.config = param->config;
+	path.param = param->param;
+	for (i = 0; i < param->param->num_outputs; i++) {
+		path.bounds[i].left = 0;
+		path.bounds[i].top = 0;
+		path.bounds[i].width =
+			param->param->outputs[i].buffer.format.width;
+		path.bounds[i].height =
+			param->param->outputs[i].buffer.format.height;
+		path.composes[i] = param->composes[i] ?
+			param->composes[i] : &path.bounds[i];
+	}
+	ret = mdp_path_config(mdp, &cmd, &path);
+	if (ret)
+		return ret;
+#ifdef MDP_UT
+	/* cmdq_pkt_dump_buf(cmd.pkt, 0); */
+#endif
+
+	// TODO: engine conflict dispatch
+	for (i = 0; i < param->config->num_components; i++)
+		mdp_comp_clock_on(&mdp->pdev->dev, path.comps[i].comp);
+
+	if (param->wait) {
+		ret = cmdq_pkt_flush(cmd.pkt);
+		cmdq_pkt_destroy(cmd.pkt);
+		for (i = 0; i < param->config->num_components; i++)
+			mdp_comp_clock_off(&mdp->pdev->dev, path.comps[i].comp);
+	} else {
+		struct mdp_cmdq_cb_param *cb_param =
+		kzalloc(sizeof(struct mdp_cmdq_cb_param), GFP_KERNEL);
+
+		cb_param->user_cmdq_cb = param->cmdq_cb;
+		cb_param->user_cb_data = param->cb_data;
+		cb_param->pkt = cmd.pkt;
+
+		ret = cmdq_pkt_flush_async(cmd.pkt,
+					   mdp_handle_cmdq_callback,
+					   (void *)cb_param);
+		// TODO: destroy & clock-off after callback
+	}
+	return ret;
+}
+
+int mdp_cmdq_sendtask(struct platform_device *pdev, struct img_config *config,
+		      struct img_ipi_frameparam *param,
+		      struct v4l2_rect *compose, unsigned int wait,
+		      void (*cmdq_cb)(struct cmdq_cb_data data), void *cb_data)
+{
+	struct mdp_dev *mdp = platform_get_drvdata(pdev);
+	struct mdp_cmdq_param task = {
+		.config = config,
+		.param = param,
+		.composes[0] = compose,
+		.wait = wait,
+		.cmdq_cb = cmdq_cb,
+		.cb_data = cb_data,
+	};
+
+	return mdp_cmdq_send(mdp, &task);
+}
+EXPORT_SYMBOL_GPL(mdp_cmdq_sendtask);
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.h
new file mode 100644
index 000000000000..b61ab1ac4325
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-cmdq.h
@@ -0,0 +1,57 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_CMDQ_H__
+#define __MTK_MDP3_CMDQ_H__
+
+#include <linux/platform_device.h>
+#include <linux/videodev2.h>
+#include <linux/soc/mediatek/mtk-cmdq.h>
+#include "mtk-img-ipi.h"
+
+struct platform_device *mdp_get_plat_device(struct platform_device *pdev);
+
+int mdp_cmdq_sendtask(struct platform_device *pdev, struct img_config *config,
+		      struct img_ipi_frameparam *param,
+		      struct v4l2_rect *compose, unsigned int wait,
+		      void (*cmdq_cb)(struct cmdq_cb_data data), void *cb_data);
+
+struct mdp_cmd {
+	struct cmdq_pkt *pkt;
+	s32 *event;
+};
+
+struct mdp_cmdq_param {
+	struct img_config	*config;
+	struct img_ipi_frameparam *param;
+	const struct v4l2_rect	*composes[IMG_MAX_HW_OUTPUTS];
+	unsigned int		wait;
+
+	void (*cmdq_cb)(struct cmdq_cb_data data);
+	void *cb_data;
+};
+
+struct mdp_cmdq_cb_param {
+	void (*user_cmdq_cb)(struct cmdq_cb_data data);
+	void *user_cb_data;
+	struct cmdq_pkt *pkt;
+};
+
+struct mdp_dev;
+
+int mdp_cmdq_send(struct mdp_dev *mdp, struct mdp_cmdq_param *param);
+
+#endif  /* __MTK_MDP3_CMDQ_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.c
new file mode 100644
index 000000000000..0d172f6b5f2b
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.c
@@ -0,0 +1,1325 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/of_platform.h>
+#include <linux/of_address.h>
+#include <linux/pm_runtime.h>
+#include "mtk-mdp3-comp.h"
+#include "mtk-mdp3-core.h"
+#include "mtk-mdp3-regs.h"
+
+#include "mdp-platform.h"
+#include "mmsys_config.h"
+#include "mdp_reg_rdma.h"
+#include "mdp_reg_ccorr.h"
+#include "mdp_reg_rsz.h"
+#include "mdp_reg_wrot.h"
+#include "mdp_reg_wdma.h"
+#include "isp_reg.h"
+
+static s64 get_comp_flag(const struct mdp_comp_ctx *ctx)
+{
+#if RDMA0_RSZ1_SRAM_SHARING
+	if (ctx->comp->id == MDP_RDMA0)
+		return (1 << MDP_RDMA0) | (1 << MDP_SCL1);
+#endif
+	return 1 << ctx->comp->id;
+}
+
+static int init_rdma(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+#if RDMA0_RSZ1_SRAM_SHARING
+	struct mdp_comp *prz1 = ctx->comp->mdp_dev->comp[MDP_SCL1];
+
+	/* Disable RSZ1 */
+	if (ctx->comp->id == MDP_RDMA0 && prz1)
+		MM_REG_WRITE(cmd, subsys_id, prz1->reg_base, PRZ_ENABLE,
+			     0x00000000, 0x00000001);
+#endif
+	/* Reset RDMA */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_RESET, 0x00000001,
+		     0x00000001);
+	MM_REG_POLL(cmd, subsys_id, base, MDP_RDMA_MON_STA_1, 0x00000100,
+		    0x00000100);
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_RESET, 0x00000000,
+		     0x00000001);
+	return 0;
+}
+
+static int config_rdma_frame(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			     const struct v4l2_rect *compose)
+{
+	const struct mdp_rdma_data *rdma = &ctx->param->rdma;
+	u32 colorformat = ctx->input->buffer.format.colorformat;
+	bool block10bit = MDP_COLOR_IS_10BIT_PACKED(colorformat);
+	bool en_ufo = MDP_COLOR_IS_UFP(colorformat);
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+#if RDMA_SUPPORT_10BIT
+	if (block10bit)
+		MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_RESV_DUMMY_0,
+			     0x00000007, 0x00000007);
+	else
+		MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_RESV_DUMMY_0,
+			     0x00000000, 0x00000007);
+#endif
+
+	/* Setup smi control */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_GMCIF_CON,
+		     (1 <<  0) +
+		     (7 <<  4) + //burst type to 8
+		     (1 << 16),  //enable pre-ultra
+		     0x00030071);
+
+	/* Setup source frame info */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_CON, rdma->src_ctrl,
+		     0x03C8FE0F);
+#if RDMA_SUPPORT_10BIT
+	if (en_ufo) {
+		/* Setup source buffer base */
+		MM_REG_WRITE(cmd, subsys_id,
+			     base, MDP_RDMA_UFO_DEC_LENGTH_BASE_Y,
+			     rdma->ufo_dec_y, 0xFFFFFFFF);
+		MM_REG_WRITE(cmd, subsys_id,
+			     base, MDP_RDMA_UFO_DEC_LENGTH_BASE_C,
+			     rdma->ufo_dec_c, 0xFFFFFFFF);
+		/* Set 10bit source frame pitch */
+		if (block10bit)
+			MM_REG_WRITE(cmd, subsys_id,
+				     base, MDP_RDMA_MF_BKGD_SIZE_IN_PXL,
+				     rdma->mf_bkgd_in_pxl, 0x001FFFFF);
+	}
+#endif
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_CON, rdma->control,
+		     0x00001110);
+	/* Setup source buffer base */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_BASE_0, rdma->iova[0],
+		     0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_BASE_1, rdma->iova[1],
+		     0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_BASE_2, rdma->iova[2],
+		     0xFFFFFFFF);
+	/* Setup source buffer end */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_END_0,
+		     rdma->iova_end[0], 0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_END_1,
+		     rdma->iova_end[1], 0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_END_2,
+		     rdma->iova_end[2], 0xFFFFFFFF);
+	/* Setup source frame pitch */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_MF_BKGD_SIZE_IN_BYTE,
+		     rdma->mf_bkgd, 0x001FFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SF_BKGD_SIZE_IN_BYTE,
+		     rdma->sf_bkgd, 0x001FFFFF);
+	/* Setup color transform */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_TRANSFORM_0,
+		     rdma->transform, 0x0F110000);
+
+	return 0;
+}
+
+static int config_rdma_subfrm(struct mdp_comp_ctx *ctx,
+			      struct mdp_cmd *cmd, u32 index)
+{
+	const struct mdp_rdma_subfrm *subfrm = &ctx->param->rdma.subfrms[index];
+	const struct img_comp_subfrm *csf = &ctx->param->subfrms[index];
+	u32 colorformat = ctx->input->buffer.format.colorformat;
+	bool block10bit = MDP_COLOR_IS_10BIT_PACKED(colorformat);
+	bool en_ufo = MDP_COLOR_IS_UFP(colorformat);
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Enable RDMA */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_EN, 0x00000001,
+		     0x00000001);
+
+	/* Set Y pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_OFFSET_0,
+		     subfrm->offset[0], 0xFFFFFFFF);
+#if RDMA_SUPPORT_10BIT
+	/* Set 10bit UFO mode */
+	if (block10bit && en_ufo)
+		MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_OFFSET_0_P,
+			     subfrm->offset_0_p, 0xFFFFFFFF);
+#endif
+	/* Set U pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_OFFSET_1,
+		     subfrm->offset[1], 0xFFFFFFFF);
+	/* Set V pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_SRC_OFFSET_2,
+		     subfrm->offset[2], 0xFFFFFFFF);
+	/* Set source size */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_MF_SRC_SIZE, subfrm->src,
+		     0x1FFF1FFF);
+	/* Set target size */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_MF_CLIP_SIZE,
+		     subfrm->clip, 0x1FFF1FFF);
+	/* Set crop offset */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_MF_OFFSET_1,
+		     subfrm->clip_ofst, 0x003F001F);
+
+#if RDMA_UPSAMPLE_REPEAT_ONLY
+	if ((csf->in.right - csf->in.left + 1) > 320)
+		MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_RESV_DUMMY_0,
+			     0x00000004, 0x00000004);
+#endif
+
+	return 0;
+}
+
+static int wait_rdma_event(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	if (ctx->comp->alias_id == 0)
+		MM_REG_WAIT(cmd, RDMA0_DONE);
+	else
+		MM_REG_WAIT(cmd, RDMA1_DONE);
+	/* Disable RDMA */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_RDMA_EN, 0x00000000,
+		     0x00000001);
+	return 0;
+}
+
+static const struct mdp_comp_ops rdma_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = init_rdma,
+	.config_frame = config_rdma_frame,
+	.config_subfrm = config_rdma_subfrm,
+	/* .reconfig_frame = reconfig_rdma_frame, */
+	/* .reconfig_subfrms = reconfig_rdma_subfrms, */
+	.wait_comp_event = wait_rdma_event,
+	.advance_subfrm = NULL,
+	.post_process = NULL,
+};
+
+static int init_rsz(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Reset RSZ */
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_ENABLE, 0x00010000,
+		     0x00010000);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_ENABLE, 0x00000000,
+		     0x00010000);
+	/* Enable RSZ */
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_ENABLE, 0x00000001,
+		     0x00000001);
+	return 0;
+}
+
+static int config_rsz_frame(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			    const struct v4l2_rect *compose)
+{
+	const struct mdp_rsz_data *rsz = &ctx->param->rsz;
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	if (ctx->param->frame.bypass) {
+		/* Disable RSZ */
+		MM_REG_WRITE(cmd, subsys_id, base, PRZ_ENABLE, 0x00000000,
+			     0x00000001);
+		return 0;
+	}
+
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_CONTROL_1, rsz->control1,
+		     0x03FFFDF3);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_CONTROL_2, rsz->control2,
+		     0x0FFFC290);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_HORIZONTAL_COEFF_STEP,
+		     rsz->coeff_step_x, 0x007FFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_VERTICAL_COEFF_STEP,
+		     rsz->coeff_step_y, 0x007FFFFF);
+	return 0;
+}
+
+static int config_rsz_subfrm(struct mdp_comp_ctx *ctx,
+			     struct mdp_cmd *cmd, u32 index)
+{
+	const struct mdp_rsz_subfrm *subfrm = &ctx->param->rsz.subfrms[index];
+	const struct img_comp_subfrm *csf = &ctx->param->subfrms[index];
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_CONTROL_2, subfrm->control2,
+		     0x00003800);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_INPUT_IMAGE, subfrm->src,
+		     0xFFFFFFFF);
+#if RSZ_DISABLE_DCM_SMALL_TILE
+	if ((csf->in.right - csf->in.left + 1) <= 16)
+		MM_REG_WRITE(cmd, subsys_id, base, PRZ_CONTROL_1, 1 << 27,
+			     1 << 27);
+#endif
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_LUMA_HORIZONTAL_INTEGER_OFFSET,
+		     csf->luma.left, 0x0000FFFF);
+	MM_REG_WRITE(cmd, subsys_id,
+		     base, PRZ_LUMA_HORIZONTAL_SUBPIXEL_OFFSET,
+		     csf->luma.left_subpix, 0x001FFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_LUMA_VERTICAL_INTEGER_OFFSET,
+		     csf->luma.top, 0x0000FFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_LUMA_VERTICAL_SUBPIXEL_OFFSET,
+		     csf->luma.top_subpix, 0x001FFFFF);
+	MM_REG_WRITE(cmd, subsys_id,
+		     base, PRZ_CHROMA_HORIZONTAL_INTEGER_OFFSET,
+		     csf->chroma.left, 0x0000FFFF);
+	MM_REG_WRITE(cmd, subsys_id,
+		     base, PRZ_CHROMA_HORIZONTAL_SUBPIXEL_OFFSET,
+		     csf->chroma.left_subpix, 0x001FFFFF);
+
+	MM_REG_WRITE(cmd, subsys_id, base, PRZ_OUTPUT_IMAGE, subfrm->clip,
+		     0xFFFFFFFF);
+
+	return 0;
+}
+
+static int advance_rsz_subfrm(struct mdp_comp_ctx *ctx,
+			      struct mdp_cmd *cmd, u32 index)
+{
+#if RSZ_DISABLE_DCM_SMALL_TILE
+	const struct img_comp_subfrm *csf = &ctx->param->subfrms[index];
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	if ((csf->in.right - csf->in.left + 1) <= 16)
+		MM_REG_WRITE(cmd, subsys_id, base, PRZ_CONTROL_1, 0, 1 << 27);
+#endif
+	return 0;
+}
+
+static const struct mdp_comp_ops rsz_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = init_rsz,
+	.config_frame = config_rsz_frame,
+	.config_subfrm = config_rsz_subfrm,
+	/* .reconfig_frame = NULL, */
+	/* .reconfig_subfrms = NULL, */
+	.wait_comp_event = NULL,
+	.advance_subfrm = advance_rsz_subfrm,
+	.post_process = NULL,
+};
+
+static int init_wrot(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+#if WROT_FILTER_CONSTRAINT
+	/* Wait WROT SRAM shared to DISP RDMA */
+	if (ctx->comp->alias_id == 0)
+		MM_REG_WAIT_NO_CLEAR(cmd, WROT0_SRAM_READY);
+	else
+		MM_REG_WAIT_NO_CLEAR(cmd, WROT1_SRAM_READY);
+#endif
+	/* Reset WROT */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_SOFT_RST, 0x01, 0x00000001);
+	MM_REG_POLL(cmd, subsys_id, base, VIDO_SOFT_RST_STAT, 0x01,
+		    0x00000001);
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_SOFT_RST, 0x00, 0x00000001);
+	MM_REG_POLL(cmd, subsys_id, base, VIDO_SOFT_RST_STAT, 0x00,
+		    0x00000001);
+	return 0;
+}
+
+static int config_wrot_frame(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			     const struct v4l2_rect *compose)
+{
+	const struct mdp_wrot_data *wrot = &ctx->param->wrot;
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Write frame base address */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_BASE_ADDR, wrot->iova[0],
+		     0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_BASE_ADDR_C, wrot->iova[1],
+		     0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_BASE_ADDR_V, wrot->iova[2],
+		     0xFFFFFFFF);
+	/* Write frame related registers */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_CTRL, wrot->control,
+		     0xF131510F);
+	/* Write frame Y pitch */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_STRIDE, wrot->stride[0],
+		     0x0000FFFF);
+	/* Write frame UV pitch */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_STRIDE_C, wrot->stride[1],
+		     0x0000FFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_STRIDE_V, wrot->stride[2],
+		     0x0000FFFF);
+	/* Write matrix control */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_MAT_CTRL, wrot->mat_ctrl,
+		     0x000000F3);
+
+	/* Set the fixed ALPHA as 0xFF */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_DITHER, 0xFF000000,
+		     0xFF000000);
+	/* Set VIDO_EOL_SEL */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_RSV_1, 0x80000000,
+		     0x80000000);
+	/* Set VIDO_FIFO_TEST */
+	if (wrot->fifo_test != 0)
+		MM_REG_WRITE(cmd, subsys_id, base, VIDO_FIFO_TEST,
+			     wrot->fifo_test, 0x00000FFF);
+
+#if WROT_FILTER_CONSTRAINT
+	/* Filter enable */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_MAIN_BUF_SIZE, wrot->filter,
+		     0x00000077);
+#endif
+
+	return 0;
+}
+
+static int config_wrot_subfrm(struct mdp_comp_ctx *ctx,
+			      struct mdp_cmd *cmd, u32 index)
+{
+	const struct mdp_wrot_subfrm *subfrm = &ctx->param->wrot.subfrms[index];
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Write Y pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_OFST_ADDR,
+		     subfrm->offset[0], 0x0FFFFFFF);
+	/* Write U pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_OFST_ADDR_C,
+		     subfrm->offset[1], 0x0FFFFFFF);
+	/* Write V pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_OFST_ADDR_V,
+		     subfrm->offset[2], 0x0FFFFFFF);
+	/* Write source size */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_IN_SIZE, subfrm->src,
+		     0x1FFF1FFF);
+	/* Write target size */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_TAR_SIZE, subfrm->clip,
+		     0x1FFF1FFF);
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_CROP_OFST, subfrm->clip_ofst,
+		     0x1FFF1FFF);
+
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_MAIN_BUF_SIZE,
+		     subfrm->main_buf, 0x1FFF7F00);
+
+	/* Enable WROT */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_ROT_EN, 0x01, 0x00000001);
+
+	return 0;
+}
+
+static int wait_wrot_event(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	if (ctx->comp->alias_id == 0)
+		MM_REG_WAIT(cmd, WROT0_DONE);
+	else
+		MM_REG_WAIT(cmd, WROT1_DONE);
+#if WROT_FILTER_CONSTRAINT
+	/* Filter disable */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_MAIN_BUF_SIZE,
+		     (0 << 4) +
+		(0 << 0),
+		0x00000077);
+#endif
+	/* Disable WROT */
+	MM_REG_WRITE(cmd, subsys_id, base, VIDO_ROT_EN, 0x00, 0x00000001);
+
+	return 0;
+}
+
+static const struct mdp_comp_ops wrot_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = init_wrot,
+	.config_frame = config_wrot_frame,
+	.config_subfrm = config_wrot_subfrm,
+	/* .reconfig_frame = reconfig_wrot_frame, */
+	/* .reconfig_subfrms = reconfig_wrot_subfrms, */
+	.wait_comp_event = wait_wrot_event,
+	.advance_subfrm = NULL,
+	.post_process = NULL,
+};
+
+static int init_wdma(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Reset WDMA */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_RST, 0x1, 0x00000001);
+	MM_REG_POLL(cmd, subsys_id, base, WDMA_FLOW_CTRL_DBG, 0x01,
+		    0x00000001);
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_RST, 0x0, 0x00000001);
+	return 0;
+}
+
+static int config_wdma_frame(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			     const struct v4l2_rect *compose)
+{
+	const struct mdp_wdma_data *wdma = &ctx->param->wdma;
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_BUF_CON2, 0x10101050,
+		     0xFFFFFFFF);
+
+	/* Setup frame information */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_CFG, wdma->wdma_cfg,
+		     0x0F01B8F0);
+	/* Setup frame base address */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_ADDR,   wdma->iova[0],
+		     0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_U_ADDR, wdma->iova[1],
+		     0xFFFFFFFF);
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_V_ADDR, wdma->iova[2],
+		     0xFFFFFFFF);
+	/* Setup Y pitch */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_W_IN_BYTE,
+		     wdma->w_in_byte, 0x0000FFFF);
+	/* Setup UV pitch */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_UV_PITCH,
+		     wdma->uv_stride, 0x0000FFFF);
+	/* Set the fixed ALPHA as 0xFF */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_ALPHA, 0x800000FF,
+		     0x800000FF);
+
+	return 0;
+}
+
+static int config_wdma_subfrm(struct mdp_comp_ctx *ctx,
+			      struct mdp_cmd *cmd, u32 index)
+{
+	const struct mdp_wdma_subfrm *subfrm = &ctx->param->wdma.subfrms[index];
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Write Y pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_ADDR_OFFSET,
+		     subfrm->offset[0], 0x0FFFFFFF);
+	/* Write U pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_U_ADDR_OFFSET,
+		     subfrm->offset[1], 0x0FFFFFFF);
+	/* Write V pixel offset */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_DST_V_ADDR_OFFSET,
+		     subfrm->offset[2], 0x0FFFFFFF);
+	/* Write source size */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_SRC_SIZE, subfrm->src,
+		     0x3FFF3FFF);
+	/* Write target size */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_CLIP_SIZE, subfrm->clip,
+		     0x3FFF3FFF);
+	/* Write clip offset */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_CLIP_COORD, subfrm->clip_ofst,
+		     0x3FFF3FFF);
+
+	/* Enable WDMA */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_EN, 0x01, 0x00000001);
+
+	return 0;
+}
+
+static int wait_wdma_event(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	MM_REG_WAIT(cmd, WDMA0_DONE);
+	/* Disable WDMA */
+	MM_REG_WRITE(cmd, subsys_id, base, WDMA_EN, 0x00, 0x00000001);
+	return 0;
+}
+
+static const struct mdp_comp_ops wdma_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = init_wdma,
+	.config_frame = config_wdma_frame,
+	.config_subfrm = config_wdma_subfrm,
+	/* .reconfig_frame = reconfig_wdma_frame, */
+	/* .reconfig_subfrms = reconfig_wdma_subfrms, */
+	.wait_comp_event = wait_wdma_event,
+	.advance_subfrm = NULL,
+	.post_process = NULL,
+};
+
+static int init_ccorr(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* CCORR enable */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_CCORR_EN, 0x1, 0x1);
+	/* Relay mode */
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_CCORR_CFG, 0x1, 0x1);
+	return 0;
+}
+
+static int config_ccorr_frame(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			      const struct v4l2_rect *compose)
+{
+	/* Disabled function */
+	return 0;
+}
+
+static int config_ccorr_subfrm(struct mdp_comp_ctx *ctx,
+			       struct mdp_cmd *cmd, u32 index)
+{
+	const struct img_comp_subfrm *csf = &ctx->param->subfrms[index];
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+	u32 hsize, vsize;
+
+	hsize = csf->in.right - csf->in.left + 1;
+	vsize = csf->in.bottom - csf->in.top + 1;
+	MM_REG_WRITE(cmd, subsys_id, base, MDP_CCORR_SIZE,
+		     (hsize << 16) + (vsize <<  0), 0x1FFF1FFF);
+	return 0;
+}
+
+static const struct mdp_comp_ops ccorr_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = init_ccorr,
+	.config_frame = config_ccorr_frame,
+	.config_subfrm = config_ccorr_subfrm,
+	/* .reconfig_frame = NULL, */
+	/* .reconfig_subfrms = NULL, */
+	.wait_comp_event = NULL,
+	.advance_subfrm = NULL,
+	.post_process = NULL,
+};
+
+static int init_isp(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	const struct isp_data *isp = &ctx->param->isp;
+	phys_addr_t mmsys = ctx->comp->mdp_dev->mmsys.reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* Direct link */
+	if (isp->dl_flags & (1 << MDP_CAMIN)) {
+		mdp_dbg(2, "SW_RST ASYNC");
+		/* Reset MDP_DL_ASYNC_TX */
+		/* Bit  3: MDP_DL_ASYNC_TX / MDP_RELAY */
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW0_RST_B, 0x0,
+			     0x00000008);
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW0_RST_B, 1 << 3,
+			     0x00000008);
+		/* Reset MDP_DL_ASYNC_RX */
+		/* Bit  10: MDP_DL_ASYNC_RX */
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW1_RST_B, 0x0,
+			     0x00000400);
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW1_RST_B, 1 << 10,
+			     0x00000400);
+
+		/* Enable sof mode */
+		MM_REG_WRITE(cmd, subsys_id, mmsys, ISP_RELAY_CFG_WD, 0 << 31,
+			     0x80000000);
+	}
+
+	if (isp->dl_flags & (1 << MDP_CAMIN2)) {
+		mdp_dbg(2, "SW_RST ASYNC2");
+		/* Reset MDP_DL_ASYNC2_TX */
+		/* Bit  4: MDP_DL_ASYNC2_TX / MDP_RELAY2 */
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW0_RST_B, 0x0,
+			     0x00000010);
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW0_RST_B, 1 << 4,
+			     0x00000010);
+		/* Reset MDP_DL_ASYNC2_RX */
+		/* Bit  11: MDP_DL_ASYNC2_RX */
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW1_RST_B, 0x0,
+			     0x00000800);
+		MM_REG_WRITE(cmd, subsys_id, mmsys, MMSYS_SW1_RST_B, 1 << 11,
+			     0x00000800);
+
+		/* Enable sof mode */
+		MM_REG_WRITE(cmd, subsys_id, mmsys, IPU_RELAY_CFG_WD, 0 << 31,
+			     0x80000000);
+	}
+
+	return 0;
+}
+
+static int config_isp_frame(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			    const struct v4l2_rect *compose)
+{
+	const struct isp_data *isp = &ctx->param->isp;
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* DIP_X_SMX1I_BASE_ADDR, DIP_X_SMX1O_BASE_ADDR */
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2890, isp->smxi_iova[0],
+			  0xFFFFFFFF);
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x27D0, isp->smxi_iova[0],
+			  0xFFFFFFFF);
+	/* DIP_X_SMX2I_BASE_ADDR, DIP_X_SMX2O_BASE_ADDR */
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x28C0, isp->smxi_iova[1],
+			  0xFFFFFFFF);
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2800, isp->smxi_iova[1],
+			  0xFFFFFFFF);
+	/* DIP_X_SMX3I_BASE_ADDR, DIP_X_SMX3O_BASE_ADDR */
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x28F0, isp->smxi_iova[2],
+			  0xFFFFFFFF);
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2830, isp->smxi_iova[2],
+			  0xFFFFFFFF);
+	/* DIP_X_SMX4I_BASE_ADDR, DIP_X_SMX4O_BASE_ADDR */
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2920, isp->smxi_iova[3],
+			  0xFFFFFFFF);
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2860, isp->smxi_iova[3],
+			  0xFFFFFFFF);
+
+	switch (isp->cq_idx) {
+	case ISP_DRV_DIP_CQ_THRE0:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2208,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE1:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2214,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE2:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2220,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE3:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x222C,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE4:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2238,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE5:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2244,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE6:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2250,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE7:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x225C,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE8:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2268,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE9:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2274,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE10:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2280,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE11:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x228C,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE12:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2298,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE13:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x22A4,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	case ISP_DRV_DIP_CQ_THRE14:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x22B0,
+				  isp->cq_iova, 0xFFFFFFFF);
+		break;
+	/* From CQ15 to CQ18, these do not connect to GCE */
+	default:
+		mdp_err("Do not support this cq (%d)", isp->cq_idx);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int config_isp_subfrm(struct mdp_comp_ctx *ctx,
+			     struct mdp_cmd *cmd, u32 index)
+{
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2304,
+			  ctx->param->isp.tpipe_iova[index], 0xFFFFFFFF);
+	return 0;
+}
+
+static int wait_isp_event(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd)
+{
+	const struct isp_data *isp = &ctx->param->isp;
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+
+	/* MDP_DL_SEL: select MDP_CROP */
+	if (isp->dl_flags & (1 << MDP_CAMIN))
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x0030, 0x00000000,
+				  0x00000200);
+	/* MDP2_DL_SEL: select MDP_CROP2 */
+	if (isp->dl_flags & (1 << MDP_CAMIN2))
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x0030, 0x00000000,
+				  0x00000C00);
+
+	switch (isp->cq_idx) {
+	case ISP_DRV_DIP_CQ_THRE0:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0001,
+				  0x00000001);
+		MM_REG_WAIT(cmd, ISP_P2_0_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE1:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0002,
+				  0x00000002);
+		MM_REG_WAIT(cmd, ISP_P2_1_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE2:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0004,
+				  0x00000004);
+		MM_REG_WAIT(cmd, ISP_P2_2_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE3:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0008,
+				  0x00000008);
+		MM_REG_WAIT(cmd, ISP_P2_3_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE4:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0010,
+				  0x00000010);
+		MM_REG_WAIT(cmd, ISP_P2_4_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE5:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0020,
+				  0x00000020);
+		MM_REG_WAIT(cmd, ISP_P2_5_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE6:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0040,
+				  0x00000040);
+		MM_REG_WAIT(cmd, ISP_P2_6_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE7:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0080,
+				  0x00000080);
+		MM_REG_WAIT(cmd, ISP_P2_7_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE8:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0100,
+				  0x00000100);
+		MM_REG_WAIT(cmd, ISP_P2_8_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE9:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0200,
+				  0x00000200);
+		MM_REG_WAIT(cmd, ISP_P2_9_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE10:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0400,
+				  0x00000400);
+		MM_REG_WAIT(cmd, ISP_P2_10_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE11:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x0800,
+				  0x00000800);
+		MM_REG_WAIT(cmd, ISP_P2_11_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE12:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x1000,
+				  0x00001000);
+		MM_REG_WAIT(cmd, ISP_P2_12_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE13:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x2000,
+				  0x00002000);
+		MM_REG_WAIT(cmd, ISP_P2_13_DONE);
+		break;
+	case ISP_DRV_DIP_CQ_THRE14:
+		MM_REG_WRITE_MASK(cmd, subsys_id, base, 0x2000, 0x4000,
+				  0x00004000);
+		MM_REG_WAIT(cmd, ISP_P2_14_DONE);
+		break;
+	/* From CQ15 to CQ18, these do not connect to GCE */
+	default:
+		mdp_err("Do not support this cq (%d)", isp->cq_idx);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static const struct mdp_comp_ops imgi_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = init_isp,
+	.config_frame = config_isp_frame,
+	.config_subfrm = config_isp_subfrm,
+	/* .reconfig_frame = reconfig_isp_frame, */
+	/* .reconfig_subfrms = reconfig_isp_subfrms, */
+	.wait_comp_event = wait_isp_event,
+	.advance_subfrm = NULL,
+	.post_process = NULL,
+};
+
+static int config_camin_subfrm(struct mdp_comp_ctx *ctx,
+			       struct mdp_cmd *cmd, u32 index)
+{
+	const struct img_comp_subfrm *csf = &ctx->param->subfrms[index];
+	phys_addr_t base = ctx->comp->reg_base;
+	u8 subsys_id = ctx->comp->subsys_id;
+	u32 isp_dl_w, isp_dl_h;
+
+	isp_dl_w = csf->in.right - csf->in.left + 1;
+	isp_dl_h = csf->in.bottom - csf->in.top + 1;
+
+	/* Config for direct link */
+	if (ctx->comp->alias_id == 0) {
+#ifdef MDP_ASYNC_CFG_WD
+		MM_REG_WRITE(cmd, subsys_id, base, MDP_ASYNC_CFG_WD,
+			     (isp_dl_h << 16) + isp_dl_w, 0x3FFF3FFF);
+#endif
+#ifdef ISP_RELAY_CFG_WD
+		MM_REG_WRITE(cmd, subsys_id, base, ISP_RELAY_CFG_WD,
+			     (isp_dl_h << 16) + isp_dl_w, 0x3FFF3FFF);
+#endif
+	} else {
+#ifdef MDP_ASYNC_IPU_CFG_WD
+		MM_REG_WRITE(cmd, subsys_id, base, MDP_ASYNC_IPU_CFG_WD,
+			     (isp_dl_h << 16) + isp_dl_w, 0x3FFF3FFF);
+#endif
+#ifdef IPU_RELAY_CFG_WD
+		MM_REG_WRITE(cmd, subsys_id, base, IPU_RELAY_CFG_WD,
+			     (isp_dl_h << 16) + isp_dl_w, 0x3FFF3FFF);
+#endif
+	}
+
+	return 0;
+}
+
+static const struct mdp_comp_ops camin_ops = {
+	.get_comp_flag = get_comp_flag,
+	.init_comp = NULL,
+	.config_frame = NULL,
+	.config_subfrm = config_camin_subfrm,
+	/* .reconfig_frame = NULL, */
+	/* .reconfig_subfrms = NULL, */
+	.wait_comp_event = NULL,
+	.advance_subfrm = NULL,
+	.post_process = NULL,
+};
+
+static const struct mdp_comp_ops *mdp_comp_ops[MDP_COMP_TYPE_COUNT] = {
+	[MDP_COMP_TYPE_RDMA] =		&rdma_ops,
+	[MDP_COMP_TYPE_RSZ] =		&rsz_ops,
+	[MDP_COMP_TYPE_WROT] =		&wrot_ops,
+	[MDP_COMP_TYPE_WDMA] =		&wdma_ops,
+	[MDP_COMP_TYPE_PATH] =		NULL,
+
+	[MDP_COMP_TYPE_CCORR] =		&ccorr_ops,
+
+	[MDP_COMP_TYPE_IMGI] =		&imgi_ops,
+	[MDP_COMP_TYPE_EXTO] =		NULL,
+	[MDP_COMP_TYPE_DL_PATH] =	&camin_ops,
+};
+
+struct mdp_comp_match {
+	enum mdp_comp_type	type;
+	u32			alias_id;
+};
+
+static const struct mdp_comp_match mdp_comp_matches[MDP_MAX_COMP_COUNT] = {
+	[MDP_COMP_WPEI] =	{ MDP_COMP_TYPE_WPEI, 0 },
+	[MDP_COMP_WPEO] =	{ MDP_COMP_TYPE_EXTO, 2 },
+	[MDP_COMP_WPEI2] =	{ MDP_COMP_TYPE_WPEI, 1 },
+	[MDP_COMP_WPEO2] =	{ MDP_COMP_TYPE_EXTO, 3 },
+	[MDP_COMP_ISP_IMGI] =	{ MDP_COMP_TYPE_IMGI, 0 },
+	[MDP_COMP_ISP_IMGO] =	{ MDP_COMP_TYPE_EXTO, 0 },
+	[MDP_COMP_ISP_IMG2O] =	{ MDP_COMP_TYPE_EXTO, 1 },
+
+	[MDP_COMP_CAMIN] =	{ MDP_COMP_TYPE_DL_PATH, 0 },
+	[MDP_COMP_CAMIN2] =	{ MDP_COMP_TYPE_DL_PATH, 1 },
+	[MDP_COMP_RDMA0] =	{ MDP_COMP_TYPE_RDMA, 0 },
+	[MDP_COMP_CCORR0] =	{ MDP_COMP_TYPE_CCORR, 0 },
+	[MDP_COMP_RSZ0] =	{ MDP_COMP_TYPE_RSZ, 0 },
+	[MDP_COMP_RSZ1] =	{ MDP_COMP_TYPE_RSZ, 1 },
+	[MDP_COMP_PATH0_SOUT] =	{ MDP_COMP_TYPE_PATH, 0 },
+	[MDP_COMP_PATH1_SOUT] =	{ MDP_COMP_TYPE_PATH, 1 },
+	[MDP_COMP_WROT0] =	{ MDP_COMP_TYPE_WROT, 0 },
+	[MDP_COMP_WDMA] =	{ MDP_COMP_TYPE_WDMA, 0 },
+};
+
+static const char * const gce_event_names[MDP_MAX_EVENT_COUNT] = {
+	[RDMA0_SOF] = "rdma0_sof",
+	[RDMA0_DONE] = "rdma0_done",
+	[RDMA1_SOF] = "rdma1_sof",
+	[RDMA1_DONE] = "rdma1_done",
+	[RSZ0_SOF] = "rsz0_sof",
+	[RSZ1_SOF] = "rsz1_sof",
+	[TDSHP0_SOF] = "tdshp0_sof",
+	[WROT0_SOF] = "wrot0_sof",
+	[WROT0_DONE] = "wrot0_done",
+	[WROT1_SOF] = "wrot1_sof",
+	[WROT1_DONE] = "wrot1_done",
+	[WDMA0_SOF] = "wdma0_sof",
+	[WDMA0_DONE] = "wdma0_done",
+	[IMG_DL_SOF] = "img_dl_sof",
+
+	[ISP_P2_0_DONE] = "isp_p2_0_done",
+	[ISP_P2_1_DONE] = "isp_p2_1_done",
+	[ISP_P2_2_DONE] = "isp_p2_2_done",
+	[ISP_P2_3_DONE] = "isp_p2_3_done",
+	[ISP_P2_4_DONE] = "isp_p2_4_done",
+	[ISP_P2_5_DONE] = "isp_p2_5_done",
+	[ISP_P2_6_DONE] = "isp_p2_6_done",
+	[ISP_P2_7_DONE] = "isp_p2_7_done",
+	[ISP_P2_8_DONE] = "isp_p2_8_done",
+	[ISP_P2_9_DONE] = "isp_p2_9_done",
+	[ISP_P2_10_DONE] = "isp_p2_10_done",
+	[ISP_P2_11_DONE] = "isp_p2_11_done",
+	[ISP_P2_12_DONE] = "isp_p2_12_done",
+	[ISP_P2_13_DONE] = "isp_p2_13_done",
+	[ISP_P2_14_DONE] = "isp_p2_14_done",
+
+	[WPE_DONE] = "wpe_done",
+	[WPE_B_DONE] = "wpe_b_done",
+	[WROT0_SRAM_READY] = "wrot0_sram_ready",
+	[WROT1_SRAM_READY] = "wrot1_sram_ready",
+};
+
+static const struct of_device_id mdp_comp_dt_ids[] = {
+	{
+		.compatible = "mediatek,mt8183-mdp-rdma",
+		.data = (void *)MDP_COMP_TYPE_RDMA,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-ccorr",
+		.data = (void *)MDP_COMP_TYPE_CCORR,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-rsz",
+		.data = (void *)MDP_COMP_TYPE_RSZ,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-wrot",
+		.data = (void *)MDP_COMP_TYPE_WROT,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-wdma",
+		.data = (void *)MDP_COMP_TYPE_WDMA,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-path",
+		.data = (void *)MDP_COMP_TYPE_PATH,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-imgi",
+		.data = (void *)MDP_COMP_TYPE_IMGI,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-exto",
+		.data = (void *)MDP_COMP_TYPE_EXTO,
+	}, {
+		.compatible = "mediatek,mt8183-mdp-dl",
+		.data = (void *)MDP_COMP_TYPE_DL_PATH,
+	},
+};
+
+static int mdp_comp_get_id(struct device *dev, struct device_node *node,
+			   enum mdp_comp_type type)
+{
+	u32 alias_id;
+	int i, ret;
+
+	ret = of_property_read_u32(node, "mediatek,mdp-id", &alias_id);
+	if (ret)
+		return ret;
+
+	for (i = 0; i < ARRAY_SIZE(mdp_comp_matches); i++)
+		if (mdp_comp_matches[i].type == type &&
+		    mdp_comp_matches[i].alias_id == alias_id)
+			return i;
+
+	dev_err(dev, "Failed to get id. type: %d, alias: %d\n", type, alias_id);
+	return -EINVAL;
+}
+
+void mdp_comp_clock_on(struct device *dev, struct mdp_comp *comp)
+{
+	int i, err;
+
+	if (comp->larb_dev) {
+		err = pm_runtime_get_sync(comp->larb_dev);
+		if (err < 0)
+			dev_err(dev,
+				"Failed to get larb, err %d. type:%d id:%d\n",
+				err, comp->type, comp->id);
+	}
+
+	for (i = 0; i < ARRAY_SIZE(comp->clks); i++) {
+		if (IS_ERR(comp->clks[i]))
+			break;
+		err = clk_prepare_enable(comp->clks[i]);
+		if (err)
+			dev_err(dev,
+				"Failed to enable clock %d, err %d. type:%d id:%d\n",
+				i, err, comp->type, comp->id);
+	}
+}
+
+void mdp_comp_clock_off(struct device *dev, struct mdp_comp *comp)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(comp->clks); i++) {
+		if (IS_ERR(comp->clks[i]))
+			break;
+		clk_disable_unprepare(comp->clks[i]);
+	}
+
+	if (comp->larb_dev)
+		pm_runtime_put_sync(comp->larb_dev);
+}
+
+static int mdp_get_subsys_id(struct device *dev, struct device_node *node,
+			     struct mdp_comp *comp)
+{
+	struct platform_device *comp_pdev;
+
+	if (!dev || !node || !comp)
+		return -EINVAL;
+
+	comp_pdev = of_find_device_by_node(node);
+
+	if (!comp_pdev) {
+		dev_err(dev, "get comp_pdev fail! comp id=%d type=%d\n",
+			comp->id, comp->type);
+		return -ENODEV;
+	} else {
+		struct cmdq_subsys *subsys;
+
+		subsys = cmdq_dev_get_subsys(&comp_pdev->dev, 0);
+		if (IS_ERR(subsys)) {
+			dev_err(&comp_pdev->dev,
+				"cmdq_dev_get_subsys fail!\n");
+			return (int)subsys;
+		} else {
+			comp->subsys_id = subsys->id;
+			dev_err(&comp_pdev->dev, "subsys id=%d\n", subsys->id);
+		}
+	}
+
+	return 0;
+}
+
+static void __mdp_comp_init(struct mdp_dev *mdp, struct device_node *node,
+			    struct mdp_comp *comp)
+{
+	struct resource res;
+	phys_addr_t base;
+
+	if (of_address_to_resource(node, 0, &res) < 0)
+		base = 0L;
+	else
+		base = 0L | res.start;
+
+	comp->mdp_dev = mdp;
+	/* comp->dev_node = of_node_get(node); */
+	comp->regs = of_iomap(node, 0);
+	comp->reg_base = base;
+}
+
+static int mdp_mm_init(struct device *dev, struct mdp_dev *mdp,
+		       struct mdp_comp *comp, const char *ref_name)
+{
+	struct device_node *node;
+
+	node = of_parse_phandle(dev->of_node, ref_name, 0);
+	if (!node) {
+		dev_err(dev, "Failed to parse dt %s\n", ref_name);
+		return -EINVAL;
+	}
+
+	__mdp_comp_init(mdp, node, comp);
+	mdp_get_subsys_id(dev, node, comp);
+	of_node_put(node);
+	if (!comp->reg_base) {
+		dev_err(dev, "Failed to init %s base\n", ref_name);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static int mdp_comp_init(struct device *dev, struct mdp_dev *mdp,
+			 struct device_node *node, struct mdp_comp *comp,
+			 enum mdp_comp_id id)
+{
+	struct device_node *larb_node;
+	struct platform_device *larb_pdev;
+	int i;
+
+	if (id < 0 || id >= MDP_MAX_COMP_COUNT) {
+		dev_err(dev, "Invalid component id %d\n", id);
+		return -EINVAL;
+	}
+
+	__mdp_comp_init(mdp, node, comp);
+	comp->type = mdp_comp_matches[id].type;
+	comp->id = id;
+	comp->alias_id = mdp_comp_matches[id].alias_id;
+	comp->ops = mdp_comp_ops[comp->type];
+
+	for (i = 0; i < ARRAY_SIZE(comp->clks); i++) {
+		comp->clks[i] = of_clk_get(node, i);
+		if (IS_ERR(comp->clks[i]))
+			break;
+	}
+
+	mdp_get_subsys_id(dev, node, comp);
+
+	/* Only DMA capable components need the LARB property */
+	comp->larb_dev = NULL;
+	if (comp->type != MDP_COMP_TYPE_RDMA &&
+	    comp->type != MDP_COMP_TYPE_WROT &&
+		comp->type != MDP_COMP_TYPE_WDMA)
+		return 0;
+
+	larb_node = of_parse_phandle(node, "mediatek,larb", 0);
+	if (!larb_node) {
+		dev_err(dev, "Missing mediatek,larb phandle in %pOF node\n",
+			node);
+		return -EINVAL;
+	}
+
+	larb_pdev = of_find_device_by_node(larb_node);
+	if (!larb_pdev) {
+		dev_warn(dev, "Waiting for larb device %pOF\n", larb_node);
+		of_node_put(larb_node);
+		return -EPROBE_DEFER;
+	}
+	of_node_put(larb_node);
+
+	comp->larb_dev = &larb_pdev->dev;
+
+	return 0;
+}
+
+static void mdp_comp_deinit(struct device *dev, struct mdp_comp *comp)
+{
+	iounmap(comp->regs);
+	/* of_node_put(comp->dev_node); */
+}
+
+void mdp_component_deinit(struct device *dev, struct mdp_dev *mdp)
+{
+	int i;
+
+	mdp_comp_deinit(dev, &mdp->mmsys);
+	mdp_comp_deinit(dev, &mdp->mm_mutex);
+	for (i = 0; i < ARRAY_SIZE(mdp->comp); i++) {
+		if (mdp->comp[i]) {
+			mdp_comp_deinit(dev, mdp->comp[i]);
+			kfree(mdp->comp[i]);
+		}
+	}
+}
+
+int mdp_component_init(struct device *dev, struct mdp_dev *mdp)
+{
+	struct device_node *node, *parent;
+	int i, ret;
+
+	for (i = 0; i < ARRAY_SIZE(gce_event_names); i++) {
+		s32 event_id;
+
+		event_id = cmdq_dev_get_event(dev, gce_event_names[i]);
+		mdp->event[i] = (event_id < 0) ? -i : event_id;
+		dev_info(dev, "Get event %s id:%d\n",
+			 gce_event_names[i], mdp->event[i]);
+	}
+
+	ret = mdp_mm_init(dev, mdp, &mdp->mmsys, "mediatek,mmsys");
+	if (ret)
+		goto err_init_mm;
+
+	ret = mdp_mm_init(dev, mdp, &mdp->mm_mutex, "mediatek,mm-mutex");
+	if (ret)
+		goto err_init_mm;
+
+	parent = dev->of_node->parent;
+	/* Iterate over sibling MDP function blocks */
+	for_each_child_of_node(parent, node) {
+		const struct of_device_id *of_id;
+		enum mdp_comp_type type;
+		int id;
+		struct mdp_comp *comp;
+
+		of_id = of_match_node(mdp_comp_dt_ids, node);
+		if (!of_id)
+			continue;
+
+		if (!of_device_is_available(node)) {
+			dev_err(dev, "Skipping disabled component %pOF\n",
+				node);
+			continue;
+		}
+
+		type = (enum mdp_comp_type)of_id->data;
+		id = mdp_comp_get_id(dev, node, type);
+		if (id < 0) {
+			dev_warn(dev, "Skipping unknown component %pOF\n",
+				 node);
+			continue;
+		}
+
+		comp = devm_kzalloc(dev, sizeof(*comp), GFP_KERNEL);
+		if (!comp) {
+			ret = -ENOMEM;
+			goto err_init_comps;
+		}
+		mdp->comp[id] = comp;
+
+		ret = mdp_comp_init(dev, mdp, node, comp, id);
+		if (ret)
+			goto err_init_comps;
+
+		dev_info(dev, "%s type:%d alias:%d id:%d base:%#x regs:%p\n",
+			 of_id->compatible, type, comp->alias_id, id,
+			(u32)comp->reg_base, comp->regs);
+	}
+	return 0;
+
+err_init_comps:
+	mdp_component_deinit(dev, mdp);
+err_init_mm:
+	return ret;
+}
+
+int mdp_comp_ctx_init(struct mdp_dev *mdp, struct mdp_comp_ctx *ctx,
+		      const struct img_compparam *param,
+	const struct img_ipi_frameparam *frame)
+{
+	int i;
+
+	if (param->type < 0 || param->type >= MDP_MAX_COMP_COUNT) {
+		mdp_err("Invalid component id %d", param->type);
+		return -EINVAL;
+	}
+
+	ctx->comp = mdp->comp[param->type];
+	if (!ctx->comp) {
+		mdp_err("Uninit component id %d", param->type);
+		return -EINVAL;
+	}
+
+	ctx->param = param;
+	ctx->input = &frame->inputs[param->input];
+	for (i = 0; i < param->num_outputs; i++)
+		ctx->outputs[i] = &frame->outputs[param->outputs[i]];
+	return 0;
+}
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.h
new file mode 100644
index 000000000000..0c65214ef695
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-comp.h
@@ -0,0 +1,177 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_COMP_H__
+#define __MTK_MDP3_COMP_H__
+
+#include "mtk-mdp3-cmdq.h"
+
+enum mdp_comp_type {
+	MDP_COMP_TYPE_INVALID = 0,
+
+	MDP_COMP_TYPE_RDMA,
+	MDP_COMP_TYPE_RSZ,
+	MDP_COMP_TYPE_WROT,
+	MDP_COMP_TYPE_WDMA,
+	MDP_COMP_TYPE_PATH,
+
+	MDP_COMP_TYPE_TDSHP,
+	MDP_COMP_TYPE_COLOR,
+	MDP_COMP_TYPE_DRE,
+	MDP_COMP_TYPE_CCORR,
+	MDP_COMP_TYPE_HDR,
+
+	MDP_COMP_TYPE_IMGI,
+	MDP_COMP_TYPE_WPEI,
+	MDP_COMP_TYPE_EXTO,	/* External path */
+	MDP_COMP_TYPE_DL_PATH,	/* Direct-link path */
+
+	MDP_COMP_TYPE_COUNT	/* ALWAYS keep at the end */
+};
+
+enum mdp_comp_id {
+	MDP_COMP_NONE = -1,	/* Invalid engine */
+
+	/* ISP */
+	MDP_COMP_WPEI = 0,
+	MDP_COMP_WPEO,		/* 1 */
+	MDP_COMP_WPEI2,		/* 2 */
+	MDP_COMP_WPEO2,		/* 3 */
+	MDP_COMP_ISP_IMGI,	/* 4 */
+	MDP_COMP_ISP_IMGO,	/* 5 */
+	MDP_COMP_ISP_IMG2O,	/* 6 */
+
+	/* IPU */
+	MDP_COMP_IPUI,		/* 7 */
+	MDP_COMP_IPUO,		/* 8 */
+
+	/* MDP */
+	MDP_COMP_CAMIN,		/* 9 */
+	MDP_COMP_CAMIN2,	/* 10 */
+	MDP_COMP_RDMA0,		/* 11 */
+	MDP_COMP_AAL0,		/* 12 */
+	MDP_COMP_CCORR0,	/* 13 */
+	MDP_COMP_RSZ0,		/* 14 */
+	MDP_COMP_RSZ1,		/* 15 */
+	MDP_COMP_TDSHP0,	/* 16 */
+	MDP_COMP_COLOR0,	/* 17 */
+	MDP_COMP_PATH0_SOUT,	/* 18 */
+	MDP_COMP_PATH1_SOUT,	/* 19 */
+	MDP_COMP_WROT0,		/* 20 */
+	MDP_COMP_WDMA,		/* 21 */
+
+	/* Dummy Engine */
+	MDP_COMP_RDMA1,		/* 22 */
+	MDP_COMP_RSZ2,		/* 23 */
+	MDP_COMP_TDSHP1,	/* 24 */
+	MDP_COMP_WROT1,		/* 25 */
+
+	MDP_MAX_COMP_COUNT	/* ALWAYS keep at the end */
+};
+
+enum mdp_comp_event {
+	RDMA0_SOF,
+	RDMA0_DONE,
+	RDMA1_SOF,
+	RDMA1_DONE,
+	RSZ0_SOF,
+	RSZ1_SOF,
+	TDSHP0_SOF,
+	WROT0_SOF,
+	WROT0_DONE,
+	WROT1_SOF,
+	WROT1_DONE,
+	WDMA0_SOF,
+	WDMA0_DONE,
+	IMG_DL_SOF,
+
+	ISP_P2_0_DONE,
+	ISP_P2_1_DONE,
+	ISP_P2_2_DONE,
+	ISP_P2_3_DONE,
+	ISP_P2_4_DONE,
+	ISP_P2_5_DONE,
+	ISP_P2_6_DONE,
+	ISP_P2_7_DONE,
+	ISP_P2_8_DONE,
+	ISP_P2_9_DONE,
+	ISP_P2_10_DONE,
+	ISP_P2_11_DONE,
+	ISP_P2_12_DONE,
+	ISP_P2_13_DONE,
+	ISP_P2_14_DONE,
+
+	WPE_DONE,
+	WPE_B_DONE,
+	WROT0_SRAM_READY,
+	WROT1_SRAM_READY,
+
+	MDP_MAX_EVENT_COUNT	/* ALWAYS keep at the end */
+};
+
+struct mdp_comp_ops;
+
+struct mdp_comp {
+	struct mdp_dev		*mdp_dev;
+	/* struct device_node	*dev_node; */
+	void __iomem		*regs;
+	phys_addr_t		reg_base;
+	u8			subsys_id;
+	struct clk		*clks[2];
+	struct device		*larb_dev;
+	enum mdp_comp_type	type;
+	enum mdp_comp_id	id;
+	u32			alias_id;
+	const struct mdp_comp_ops *ops;
+};
+
+struct mdp_comp_ctx {
+	struct mdp_comp			*comp;
+	const struct img_compparam	*param;
+	const struct img_input		*input;
+	const struct img_output		*outputs[IMG_MAX_HW_OUTPUTS];
+};
+
+struct mdp_comp_ops {
+	s64 (*get_comp_flag)(const struct mdp_comp_ctx *ctx);
+	/* s64 (*query_feature)(void); */
+	int (*init_comp)(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd);
+	int (*config_frame)(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd,
+			    const struct v4l2_rect *compose);
+	/* int (*config_frame_end)(struct mdp_comp_ctx *ctx,
+	 *      struct mdp_cmd *cmd);
+	 */
+	int (*config_subfrm)(struct mdp_comp_ctx *ctx,
+			     struct mdp_cmd *cmd, u32 index);
+	int (*wait_comp_event)(struct mdp_comp_ctx *ctx,
+			       struct mdp_cmd *cmd);
+	int (*advance_subfrm)(struct mdp_comp_ctx *ctx,
+			      struct mdp_cmd *cmd, u32 index);
+	int (*post_process)(struct mdp_comp_ctx *ctx, struct mdp_cmd *cmd);
+	/* void (*release)(struct mdp_comp_ctx *ctx); */
+};
+
+struct mdp_dev;
+
+int mdp_component_init(struct device *dev, struct mdp_dev *mdp);
+void mdp_component_deinit(struct device *dev, struct mdp_dev *mdp);
+void mdp_comp_clock_on(struct device *dev, struct mdp_comp *comp);
+void mdp_comp_clock_off(struct device *dev, struct mdp_comp *comp);
+int mdp_comp_ctx_init(struct mdp_dev *mdp, struct mdp_comp_ctx *ctx,
+		      const struct img_compparam *param,
+	const struct img_ipi_frameparam *frame);
+
+#endif  /* __MTK_MDP3_COMP_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-core.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-core.c
new file mode 100644
index 000000000000..426f1a3aa94a
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-core.c
@@ -0,0 +1,283 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/remoteproc.h>
+#include <linux/platform_data/mtk_scp.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk-mdp3-core.h"
+#ifdef MDP_DEBUG
+#include "mtk-mdp3-debug.h"
+#endif
+#include "mtk-mdp3-m2m.h"
+
+
+/* MDP debug log level (0-3). 3 shows all the logs. */
+int mtk_mdp_debug;
+EXPORT_SYMBOL(mtk_mdp_debug);
+module_param_named(debug, mtk_mdp_debug, int, 0644);
+
+static const struct of_device_id mdp_of_ids[] = {
+	{ .compatible = "mediatek,mt8183-mdp3", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, mdp_of_ids);
+
+#ifdef MDP_UT
+extern ssize_t mdp_ut_run(struct device *dev, struct device_attribute *attr,
+			  char *buf);
+
+ssize_t ut_show(struct device *dev, struct device_attribute *attr,
+			  char *buf)
+{
+	return mdp_ut_run(dev, attr, buf);
+}
+
+static DEVICE_ATTR_RO(ut);
+#endif
+
+struct platform_device *mdp_get_plat_device(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *mdp_node;
+	struct platform_device *mdp_pdev;
+
+	mdp_node = of_parse_phandle(dev->of_node, "mediatek,mdp3", 0);
+	if (!mdp_node) {
+		dev_err(dev, "can't get mdp node\n");
+		return NULL;
+	}
+
+	mdp_pdev = of_find_device_by_node(mdp_node);
+	if (WARN_ON(!mdp_pdev)) {
+		dev_err(dev, "mdp pdev failed\n");
+		of_node_put(mdp_node);
+		return NULL;
+	}
+
+	return mdp_pdev;
+}
+EXPORT_SYMBOL_GPL(mdp_get_plat_device);
+
+int mdp_vpu_get_locked(struct mdp_dev *mdp)
+{
+	int ret = 0;
+
+	if (mdp->vpu_count++ == 0) {
+		ret = rproc_boot(mdp->rproc_handle);
+		if (ret < 0) {
+			dev_err(&mdp->pdev->dev,
+				"vpu_load_firmware failed %d\n", ret);
+			goto err_load_vpu;
+		}
+		ret = mdp_vpu_register(mdp->vpu_dev);
+		if (ret < 0) {
+			dev_err(&mdp->pdev->dev,
+				"mdp_vpu register failed %d\n", ret);
+			goto err_reg_vpu;
+		}
+		ret = mdp_vpu_dev_init(&mdp->vpu, mdp->vpu_dev, &mdp->vpu_lock);
+		if (ret) {
+			dev_err(&mdp->pdev->dev,
+				"mdp_vpu device init failed %d\n", ret);
+			goto err_init_vpu;
+		}
+	}
+	return 0;
+
+err_init_vpu:
+	mdp_vpu_unregister(mdp->vpu_dev);
+err_reg_vpu:
+err_load_vpu:
+	mdp->vpu_count--;
+	return ret;
+}
+
+void mdp_vpu_put_locked(struct mdp_dev *mdp)
+{
+	if (--mdp->vpu_count == 0) {
+		mdp_vpu_dev_deinit(&mdp->vpu);
+		mdp_vpu_unregister(mdp->vpu_dev);
+	}
+}
+
+static int mdp_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct mdp_dev *mdp;
+	phandle rproc_phandle;
+	int ret;
+
+	mdp = devm_kzalloc(dev, sizeof(*mdp), GFP_KERNEL);
+	if (!mdp)
+		return -ENOMEM;
+
+	mdp->pdev = pdev;
+	ret = mdp_component_init(dev, mdp);
+	if (ret) {
+		dev_err(dev, "Failed to initialize mdp components\n");
+		goto err_init_comp;
+	}
+
+	mdp->job_wq = create_singlethread_workqueue(MDP_MODULE_NAME);
+	if (!mdp->job_wq) {
+		dev_err(dev, "Unable to create job workqueue\n");
+		ret = -ENOMEM;
+		goto err_create_job_wq;
+	}
+
+	mdp->vpu_dev = scp_get_pdev(pdev);
+
+	if (of_property_read_u32(pdev->dev.of_node, "mediatek,scp",
+				 &rproc_phandle))
+		dev_err(&pdev->dev, "Could not get scp device\n");
+	else
+		dev_info(&pdev->dev, "Find mediatek,scp phandle:%llx\n",
+			 (unsigned long long)rproc_phandle);
+
+	mdp->rproc_handle = rproc_get_by_phandle(rproc_phandle);
+
+	dev_info(&pdev->dev, "MDP rproc_handle: %llx",
+		 (unsigned long long)mdp->rproc_handle);
+
+	if (!mdp->rproc_handle)
+		dev_err(&pdev->dev, "Could not get MDP's rproc_handle\n");
+
+	/* vpu_wdt_reg_handler(mdp->vpu_dev, mdp_reset_handler, mdp,
+	 *		       VPU_RST_MDP);
+	 */
+	mutex_init(&mdp->vpu_lock);
+	mdp->vpu_count = 0;
+	mdp->id_count = 0;
+
+	mdp->cmdq_clt = cmdq_mbox_create(dev, 0, 1200);
+	if (IS_ERR(mdp->cmdq_clt))
+		goto err_mbox_create;
+
+	ret = v4l2_device_register(dev, &mdp->v4l2_dev);
+	if (ret) {
+		dev_err(dev, "Failed to register v4l2 device\n");
+		ret = -EINVAL;
+		goto err_v4l2_register;
+	}
+
+	ret = mdp_m2m_device_register(mdp);
+	if (ret) {
+		v4l2_err(&mdp->v4l2_dev, "Failed to register m2m device\n");
+		goto err_m2m_register;
+	}
+	mutex_init(&mdp->m2m_lock);
+
+	platform_set_drvdata(pdev, mdp);
+
+#ifdef MDP_DEBUG
+	mdp_debug_init(pdev);
+#endif
+
+	vb2_dma_contig_set_max_seg_size(&pdev->dev, DMA_BIT_MASK(32));
+	pm_runtime_enable(dev);
+	dev_dbg(dev, "mdp-%d registered successfully\n", pdev->id);
+#ifdef MDP_UT
+	device_create_file(&pdev->dev, &dev_attr_ut);
+#endif
+	return 0;
+
+err_m2m_register:
+	v4l2_device_unregister(&mdp->v4l2_dev);
+err_v4l2_register:
+err_mbox_create:
+	destroy_workqueue(mdp->job_wq);
+err_create_job_wq:
+err_init_comp:
+	kfree(mdp);
+
+	dev_dbg(dev, "Errno %d\n", ret);
+	return ret;
+}
+
+static int mdp_remove(struct platform_device *pdev)
+{
+	struct mdp_dev *mdp = platform_get_drvdata(pdev);
+
+	pm_runtime_disable(&pdev->dev);
+	vb2_dma_contig_clear_max_seg_size(&pdev->dev);
+	mdp_m2m_device_unregister(mdp);
+	v4l2_device_unregister(&mdp->v4l2_dev);
+
+	flush_workqueue(mdp->job_wq);
+	destroy_workqueue(mdp->job_wq);
+
+	mdp_component_deinit(&pdev->dev, mdp);
+	kfree(mdp);
+
+	dev_dbg(&pdev->dev, "%s driver unloaded\n", pdev->name);
+#ifdef MDP_UT
+	device_remove_file(&pdev->dev, &dev_attr_ut);
+#endif
+	return 0;
+}
+
+static int __maybe_unused mdp_pm_suspend(struct device *dev)
+{
+	// TODO: mdp clock off
+	return 0;
+}
+
+static int __maybe_unused mdp_pm_resume(struct device *dev)
+{
+	// TODO: mdp clock on
+	return 0;
+}
+
+static int __maybe_unused mdp_suspend(struct device *dev)
+{
+	if (pm_runtime_suspended(dev))
+		return 0;
+
+	return mdp_pm_suspend(dev);
+}
+
+static int __maybe_unused mdp_resume(struct device *dev)
+{
+	if (pm_runtime_suspended(dev))
+		return 0;
+
+	return mdp_pm_resume(dev);
+}
+
+static const struct dev_pm_ops mdp_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(mdp_suspend, mdp_resume)
+	SET_RUNTIME_PM_OPS(mdp_pm_suspend, mdp_pm_resume, NULL)
+};
+
+static struct platform_driver mdp_driver = {
+	.probe		= mdp_probe,
+	.remove		= mdp_remove,
+	.driver = {
+		.name	= MDP_MODULE_NAME,
+		.pm	= &mdp_pm_ops,
+		.of_match_table = mdp_of_ids,
+	},
+};
+
+module_platform_driver(mdp_driver);
+
+MODULE_AUTHOR("Ping-Hsun Wu <ping-hsun.wu@mediatek.com>");
+MODULE_DESCRIPTION("Mediatek image processor 3 driver");
+MODULE_LICENSE("GPL v2");
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-core.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-core.h
new file mode 100644
index 000000000000..bc3b168a4d5a
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-core.h
@@ -0,0 +1,88 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_CORE_H__
+#define __MTK_MDP3_CORE_H__
+
+#include <media/v4l2-device.h>
+#include <media/v4l2-mem2mem.h>
+#include "mtk-mdp3-comp.h"
+#include "mtk-mdp3-vpu.h"
+
+#define MDP_MODULE_NAME	"mtk-mdp3"
+
+enum mdp_buffer_usage {
+	MDP_BUFFER_USAGE_HW_READ,
+	MDP_BUFFER_USAGE_MDP,
+	MDP_BUFFER_USAGE_MDP2,
+	MDP_BUFFER_USAGE_ISP,
+	MDP_BUFFER_USAGE_WPE,
+};
+
+struct mdp_dev {
+	struct platform_device	*pdev;
+	struct mdp_comp		mmsys;
+	struct mdp_comp		mm_mutex;
+	struct mdp_comp		*comp[MDP_MAX_COMP_COUNT];
+	s32			event[MDP_MAX_EVENT_COUNT];
+
+	struct workqueue_struct	*job_wq;
+	struct mdp_vpu_dev	vpu;
+	struct platform_device	*vpu_dev;
+	struct rproc *rproc_handle;
+
+	struct mutex		vpu_lock;
+	s32			vpu_count;
+	u32			id_count;
+	struct cmdq_client	*cmdq_clt;
+
+	struct v4l2_device	v4l2_dev;
+	struct video_device	*m2m_vdev;
+	struct v4l2_m2m_dev	*m2m_dev;
+	/* synchronization protect for m2m device operation */
+	struct mutex		m2m_lock;
+};
+
+int mdp_vpu_get_locked(struct mdp_dev *mdp);
+void mdp_vpu_put_locked(struct mdp_dev *mdp);
+
+extern int mtk_mdp_debug;
+
+#define DEBUG
+#if defined(DEBUG)
+
+#define mdp_dbg(level, fmt, ...)\
+	do {\
+		if (mtk_mdp_debug >= (level))\
+			pr_info("[MTK-MDP3] %d %s:%d: " fmt "\n",\
+				level, __func__, __LINE__, ##__VA_ARGS__);\
+	} while (0)
+
+#define mdp_err(fmt, ...)\
+	pr_err("[MTK-MDP3][ERR] %s:%d: " fmt "\n", __func__, __LINE__,\
+		##__VA_ARGS__)
+
+#else
+
+#define mdp_dbg(level, fmt, ...)	do {} while (0)
+#define mdp_err(fmt, ...)		do {} while (0)
+
+#endif
+
+#define mdp_dbg_enter() mdp_dbg(3, "+")
+#define mdp_dbg_leave() mdp_dbg(3, "-")
+
+#endif  /* __MTK_MDP3_CORE_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.c
new file mode 100644
index 000000000000..0a97836aa71a
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.c
@@ -0,0 +1,1102 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Daoyuan Huang <daoyuan.huang@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/compiler_types.h>
+#include <linux/of_address.h>
+
+#include "mmsys_reg_base.h"
+#include "mtk-mdp3-core.h"
+#include "mtk-mdp3-debug.h"
+#include "mtk-mdp3-regs.h"
+
+struct mdp_module_base_va {
+	void __iomem *MDP_RDMA0;
+	void __iomem *MDP_RSZ0;
+	void __iomem *MDP_RSZ1;
+	void __iomem *MDP_TDSHP;
+	void __iomem *MDP_COLOR;
+	void __iomem *MDP_AAL;
+	void __iomem *MDP_CCORR;
+	void __iomem *MDP_WROT0;
+	void __iomem *MDP_WDMA;
+	void __iomem *VENC;
+	void __iomem *SMI_LARB0;
+};
+
+struct RegDef {
+	int offset;
+	const char *name;
+};
+
+struct mdp_debug_context {
+	struct platform_device *mdp_device;
+	struct mdp_func_struct mdp_func_pointer;
+	struct mdp_module_base_va mdp_mod_base_va;
+	void __iomem *mdp_mmsys_base_va;
+};
+
+#define MMSYS_CONFIG_BASE	mdp_get_module_base_VA_MMSYS_CONFIG()
+#define MDP_RDMA0_BASE		mdp_get_module_base_VA_MDP_RDMA0()
+#define MDP_RSZ0_BASE		mdp_get_module_base_VA_MDP_RSZ0()
+#define MDP_RSZ1_BASE		mdp_get_module_base_VA_MDP_RSZ1()
+#define MDP_TDSHP_BASE		mdp_get_module_base_VA_MDP_TDSHP()
+#define MDP_COLOR_BASE		mdp_get_module_base_VA_MDP_COLOR()
+#define MDP_AAL_BASE		mdp_get_module_base_VA_MDP_AAL()
+#define MDP_CCORR_BASE		mdp_get_module_base_VA_MDP_CCORR()
+#define MDP_WROT0_BASE		mdp_get_module_base_VA_MDP_WROT0()
+#define MDP_WDMA_BASE		mdp_get_module_base_VA_MDP_WDMA()
+#define VENC_BASE		mdp_get_module_base_VA_VENC()
+
+
+static struct mdp_debug_context g_mdp_debug;
+
+struct mdp_debug_context *mdp_get_mdp_debug(void)
+{
+	return &g_mdp_debug;
+}
+
+void __iomem *mdp_get_module_base_VA_MMSYS_CONFIG(void)
+{
+	return g_mdp_debug.mdp_mmsys_base_va;
+}
+
+void __iomem *mdp_get_module_base_VA_MDP_RDMA0(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_RDMA0;
+}
+void __iomem *mdp_get_module_base_VA_MDP_RSZ0(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_RSZ0;
+}
+void __iomem *mdp_get_module_base_VA_MDP_RSZ1(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_RSZ1;
+}
+void __iomem *mdp_get_module_base_VA_MDP_TDSHP(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_TDSHP;
+}
+void __iomem *mdp_get_module_base_VA_MDP_COLOR(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_COLOR;
+}
+void __iomem *mdp_get_module_base_VA_MDP_AAL(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_AAL;
+}
+void __iomem *mdp_get_module_base_VA_MDP_CCORR(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_CCORR;
+}
+void __iomem *mdp_get_module_base_VA_MDP_WROT0(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_WROT0;
+}
+void __iomem *mdp_get_module_base_VA_MDP_WDMA(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.MDP_WDMA;
+}
+void __iomem *mdp_get_module_base_VA_VENC(void)
+{
+	return g_mdp_debug.mdp_mod_base_va.VENC;
+}
+
+
+struct mdp_func_struct *mdp_get_func(void)
+{
+	return &g_mdp_debug.mdp_func_pointer;
+}
+
+void __iomem *mdp_alloc_reference_VA_by_name(const char *ref_name)
+{
+	struct device_node *node = NULL;
+	struct device *dev = &(g_mdp_debug.mdp_device->dev);
+	void __iomem *VA = 0L;
+
+	node = of_parse_phandle(dev->of_node, ref_name, 0);
+	if (node) {
+		VA = of_iomap(node, 0);
+		of_node_put(node);
+		mdp_dbg(2, "DEV: VA ref(%s): 0x%lx\n", ref_name, VA);
+	} else {
+		mdp_err("DEV: cannot parse node name:%s\n", ref_name);
+	}
+	return VA;
+}
+
+void mdp_free_module_base_VA(void __iomem *VA)
+{
+	iounmap(VA);
+}
+
+void mdp_init_module_base_VA(void)
+{
+	struct mdp_module_base_va *mod_base_va = &(g_mdp_debug.mdp_mod_base_va);
+	struct device_node *rdma_node = g_mdp_debug.mdp_device->dev.of_node;
+	void __iomem *va = 0L;
+
+	memset(mod_base_va, 0, sizeof(struct mdp_module_base_va));
+
+	//mod_base_va->MDP_RDMA0 = mdp_alloc_reference_VA_by_name("mdp_rdma0");
+	if (rdma_node) {
+		va = of_iomap(rdma_node, 0);
+		of_node_put(rdma_node);
+		mod_base_va->MDP_RDMA0 = va;
+		mdp_dbg(2, "MDP_RDMA va: 0x%lx\n", va);
+	} else
+		mdp_err("%s:MDP_RDMA node missing!\n", __func__);
+
+	mod_base_va->MDP_RSZ0 = mdp_alloc_reference_VA_by_name("mdp_rsz0");
+	mod_base_va->MDP_RSZ1 = mdp_alloc_reference_VA_by_name("mdp_rsz1");
+	mod_base_va->MDP_WROT0 = mdp_alloc_reference_VA_by_name("mdp_wrot0");
+	mod_base_va->MDP_WDMA = mdp_alloc_reference_VA_by_name("mdp_wdma0");
+	mod_base_va->MDP_TDSHP = mdp_alloc_reference_VA_by_name("mdp_tdshp0");
+	mod_base_va->MDP_COLOR = mdp_alloc_reference_VA_by_name("mdp_color0");
+	mod_base_va->MDP_AAL = mdp_alloc_reference_VA_by_name("mdp_aal0");
+	mod_base_va->MDP_CCORR = mdp_alloc_reference_VA_by_name("mdp_ccorr0");
+	mod_base_va->VENC = mdp_alloc_reference_VA_by_name("venc");
+	mod_base_va->SMI_LARB0 =
+		mdp_alloc_reference_VA_by_name("mediatek,larb");
+}
+
+void mdp_deinit_module_base_VA(void)
+{
+	struct mdp_module_base_va *mod_base_va = &(g_mdp_debug.mdp_mod_base_va);
+
+	mdp_free_module_base_VA(mod_base_va->MDP_RDMA0);
+	mdp_free_module_base_VA(mod_base_va->MDP_RSZ0);
+	mdp_free_module_base_VA(mod_base_va->MDP_RSZ1);
+	mdp_free_module_base_VA(mod_base_va->MDP_WROT0);
+	mdp_free_module_base_VA(mod_base_va->MDP_WDMA);
+	mdp_free_module_base_VA(mod_base_va->MDP_TDSHP);
+	mdp_free_module_base_VA(mod_base_va->MDP_COLOR);
+	mdp_free_module_base_VA(mod_base_va->MDP_AAL);
+	mdp_free_module_base_VA(mod_base_va->MDP_CCORR);
+	mdp_free_module_base_VA(mod_base_va->VENC);
+	mdp_free_module_base_VA(mod_base_va->SMI_LARB0);
+	memset(mod_base_va, 0, sizeof(struct mdp_module_base_va));
+}
+
+void mdp_map_mmsys_VA(void)
+{
+	g_mdp_debug.mdp_mmsys_base_va =
+		mdp_alloc_reference_VA_by_name("mediatek,mmsys");
+}
+
+void mdp_unmap_mmsys_VA(void)
+{
+	mdp_free_module_base_VA(g_mdp_debug.mdp_mmsys_base_va);
+}
+
+uint32_t mdp_rdma_get_reg_offset_src_addr_virtual(void)
+{
+	return 0;
+}
+
+uint32_t mdp_wrot_get_reg_offset_dst_addr_virtual(void)
+{
+	return 0;
+}
+
+uint32_t mdp_wdma_get_reg_offset_dst_addr_virtual(void)
+{
+	return 0;
+}
+
+/* MDP engine dump */
+void mdp_dump_rsz_common(void __iomem *base, const char *label)
+{
+	uint32_t value[8] = { 0 };
+	uint32_t request[8] = { 0 };
+	uint32_t state = 0;
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x004);
+	value[1] = MDP_REG_GET32(base + 0x00C);
+	value[2] = MDP_REG_GET32(base + 0x010);
+	value[3] = MDP_REG_GET32(base + 0x014);
+	value[4] = MDP_REG_GET32(base + 0x018);
+	MDP_REG_SET32(base + 0x040, 0x00000001);
+	value[5] = MDP_REG_GET32(base + 0x044);
+	MDP_REG_SET32(base + 0x040, 0x00000002);
+	value[6] = MDP_REG_GET32(base + 0x044);
+	MDP_REG_SET32(base + 0x040, 0x00000003);
+	value[7] = MDP_REG_GET32(base + 0x044);
+
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("RSZ_CONTROL: 0x%08x, RSZ_INPUT_IMAGE: 0x%08x\n",
+		 value[0], value[1]);
+	mdp_err("RSZ_OUTPUT_IMAGE: 0x%08x RSZ_VERTICAL_COEFF_STEP: 0x%08x\n",
+		 value[2], value[3]);
+	mdp_err("RSZ_HORIZONTAL_COEFF_STEP: 0x%08x, RSZ_DEBUG_1: 0x%08x\n",
+		 value[4], value[5]);
+	mdp_err(", RSZ_DEBUG_2: 0x%08x, RSZ_DEBUG_3: 0x%08x\n",
+		 value[6], value[7]);
+
+	/* parse state */
+	/* .valid=1/request=1: upstream module sends data */
+	/* .ready=1: downstream module receives data */
+	state = value[6] & 0xF;
+	request[0] = state & (0x1);	/* out valid */
+	request[1] = (state & (0x1 << 1)) >> 1;	/* out ready */
+	request[2] = (state & (0x1 << 2)) >> 2;	/* in valid */
+	request[3] = (state & (0x1 << 3)) >> 3;	/* in ready */
+	request[4] = (value[1] & 0x1FFF);	/* input_width */
+	request[5] = (value[1] >> 16) & 0x1FFF;	/* input_height */
+	request[6] = (value[2] & 0x1FFF);	/* output_width */
+	request[7] = (value[2] >> 16) & 0x1FFF;	/* output_height */
+
+	mdp_err("RSZ inRdy,inRsq,outRdy,outRsq: %d,%d,%d,%d (%s)\n",
+		request[3], request[2], request[1], request[0],
+		mdp_get_rsz_state(state));
+	mdp_err("RSZ input_width,input_height,output_width,output_height:");
+	mdp_err("%d,%d,%d,%d\n",
+		 request[4], request[5], request[6], request[7]);
+}
+
+void mdp_dump_tdshp_common(void __iomem *base, const char *label)
+{
+	uint32_t value[8] = { 0 };
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x114);
+	value[1] = MDP_REG_GET32(base + 0x11C);
+	value[2] = MDP_REG_GET32(base + 0x104);
+	value[3] = MDP_REG_GET32(base + 0x108);
+	value[4] = MDP_REG_GET32(base + 0x10C);
+	value[5] = MDP_REG_GET32(base + 0x120);
+	value[6] = MDP_REG_GET32(base + 0x128);
+	value[7] = MDP_REG_GET32(base + 0x110);
+
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("TDSHP INPUT_CNT: 0x%08x, OUTPUT_CNT: 0x%08x\n",
+		value[0], value[1]);
+	mdp_err("TDSHP INTEN: 0x%08x, INTSTA: 0x%08x, 0x10C: 0x%08x\n",
+		value[2], value[3], value[4]);
+	mdp_err("TDSHP CFG: 0x%08x, IN_SIZE: 0x%08x, OUT_SIZE: 0x%08x\n",
+		value[7], value[5], value[6]);
+}
+
+void mdp_virtual_function_setting(void)
+{
+	struct mdp_func_struct *pfunc = mdp_get_func();
+
+	pfunc->mdp_dump_rsz = mdp_dump_rsz_common;
+	pfunc->mdp_dump_tdshp = mdp_dump_tdshp_common;
+	pfunc->mdp_rdma_get_src_base_addr =
+		mdp_rdma_get_reg_offset_src_addr_virtual;
+	pfunc->mdp_wrot_get_reg_offset_dst_addr =
+		mdp_wrot_get_reg_offset_dst_addr_virtual;
+	pfunc->mdp_wdma_get_reg_offset_dst_addr =
+		mdp_wdma_get_reg_offset_dst_addr_virtual;
+}
+
+void mdp_dump_mmsys_config(void)
+{
+	int i = 0;
+	uint32_t value = 0;
+	static const struct RegDef configRegisters[] = {
+		{0xF80, "ISP_MOUT_EN"},
+		{0xF84, "MDP_RDMA0_MOUT_EN"},
+		{0xF8C, "MDP_PRZ0_MOUT_EN"},
+		{0xF90, "MDP_PRZ1_MOUT_EN"},
+		{0xF94, "MDP_COLOR_MOUT_EN"},
+		{0xF98, "IPU_MOUT_EN"},
+		{0xFE8, "MDP_AAL_MOUT_EN"},
+		/* {0x02C, "MDP_TDSHP_MOUT_EN"},*/
+		{0xF00, "DISP_OVL0_MOUT_EN"},
+		{0xF04, "DISP_OVL0_2L_MOUT_EN"},
+		{0xF08, "DISP_OVL1_2L_MOUT_EN"},
+		{0xF0C, "DISP_DITHER0_MOUT_EN"},
+		{0xF10, "DISP_RSZ_MOUT_EN"},
+		/* {0x040, "DISP_UFOE_MOUT_EN"}, */
+		/* {0x040, "MMSYS_MOUT_RST"}, */
+		{0xFA0, "DISP_TO_WROT_SOUT_SEL"},
+		{0xFA4, "MDP_COLOR_IN_SOUT_SEL"},
+		{0xFA8, "MDP_PATH0_SOUT_SEL"},
+		{0xFAC, "MDP_PATH1_SOUT_SEL"},
+		{0xFB0, "MDP_TDSHP_SOUT_SEL"},
+		{0xFC0, "MDP_PRZ0_SEL_IN"},
+		{0xFC4, "MDP_PRZ1_SEL_IN"},
+		{0xFC8, "MDP_TDSHP_SEL_IN"},
+		{0xFCC, "DISP_WDMA0_SEL_IN"},
+		{0xFDC, "MDP_COLOR_SEL_IN"},
+		{0xF20, "DISP_COLOR_OUT_SEL_IN"},
+		{0xFD0, "MDP_WROT0_SEL_IN"},
+		{0xFD4, "MDP_WDMA_SEL_IN"},
+		{0xFD8, "MDP_COLOR_OUT_SEL_IN"},
+		{0xFDC, "MDP_COLOR_SEL_IN "},
+		/* {0xFDC, "DISP_COLOR_SEL_IN"}, */
+		{0xFE0, "MDP_PATH0_SEL_IN"},
+		{0xFE4, "MDP_PATH1_SEL_IN"},
+		{0xFEC, "MDP_AAL_SEL_IN"},
+		{0xFF0, "MDP_CCORR_SEL_IN"},
+		{0xFF4, "MDP_CCORR_SOUT_SEL"},
+		/* {0x070, "DISP_WDMA1_SEL_IN"}, */
+		/* {0x074, "DISP_UFOE_SEL_IN"}, */
+		{0xF2C, "DSI0_SEL_IN"},
+		{0xF30, "DSI1_SEL_IN"},
+		{0xF50, "DISP_RDMA0_SOUT_SEL_IN"},
+		{0xF54, "DISP_RDMA1_SOUT_SEL_IN"},
+		{0x0F0, "MMSYS_MISC"},
+		/* ACK and REQ related */
+		{0x8B4, "DISP_DL_VALID_0"},
+		{0x8B8, "DISP_DL_VALID_1"},
+		{0x8C0, "DISP_DL_READY_0"},
+		{0x8C4, "DISP_DL_READY_1"},
+		{0x8CC, "MDP_DL_VALID_0"},
+		{0x8D0, "MDP_DL_VALID_1"},
+		{0x8D4, "MDP_DL_READY_0"},
+		{0x8D8, "MDP_DL_READY_1"},
+		{0x8E8, "MDP_MOUT_MASK"},
+		{0x948, "MDP_DL_VALID_2"},
+		{0x94C, "MDP_DL_READY_2"},
+		{0x950, "DISP_DL_VALID_2"},
+		{0x954, "DISP_DL_READY_2"},
+		{0x100, "MMSYS_CG_CON0"},
+		{0x110, "MMSYS_CG_CON1"},
+		/* Async DL related */
+		{0x960, "TOP_RELAY_FSM_RD"},
+		{0x934, "MDP_ASYNC_CFG_WD"},
+		{0x938, "MDP_ASYNC_CFG_RD"},
+		{0x958, "MDP_ASYNC_CFG_OUT_RD"},
+		{0x95C, "MDP_ASYNC_IPU_CFG_OUT_RD"},
+		{0x994, "ISP_RELAY_CFG_WD"},
+		{0x998, "ISP_RELAY_CNT_RD"},
+		{0x99C, "ISP_RELAY_CNT_LATCH_RD"},
+		{0x9A0, "IPU_RELAY_CFG_WD"},
+		{0x9A4, "IPU_RELAY_CNT_RD"},
+		{0x9A8, "IPU_RELAY_CNT_LATCH_RD"}
+
+
+	};
+
+	if (MMSYS_CONFIG_BASE == 0) {
+		mdp_err("%s:MMSYS_CONFIG_BASE=0!\n", __func__);
+		return;
+	}
+
+	for (i = 0; i < ARRAY_SIZE(configRegisters); i++) {
+		value = MDP_REG_GET32(MMSYS_CONFIG_BASE +
+			configRegisters[i].offset);
+		mdp_err("%s: 0x%08x\n", configRegisters[i].name, value);
+	}
+}
+
+const char *mdp_get_rdma_state(uint32_t state)
+{
+	switch (state) {
+	case 0x1:
+		return "idle";
+	case 0x2:
+		return "wait sof";
+	case 0x4:
+		return "reg update";
+	case 0x8:
+		return "clear0";
+	case 0x10:
+		return "clear1";
+	case 0x20:
+		return "int0";
+	case 0x40:
+		return "int1";
+	case 0x80:
+		return "data running";
+	case 0x100:
+		return "wait done";
+	case 0x200:
+		return "warm reset";
+	case 0x400:
+		return "wait reset";
+	default:
+		return "";
+	}
+}
+
+const char *mdp_get_rsz_state(const uint32_t state)
+{
+	switch (state) {
+	case 0x5:
+		return "downstream hang";	/* 0,1,0,1 */
+	case 0xa:
+		return "upstream hang";	/* 1,0,1,0 */
+	default:
+		return "";
+	}
+}
+
+const char *mdp_get_wdma_state(uint32_t state)
+{
+	switch (state) {
+	case 0x1:
+		return "idle";
+	case 0x2:
+		return "clear";
+	case 0x4:
+		return "prepare";
+	case 0x8:
+		return "prepare";
+	case 0x10:
+		return "data running";
+	case 0x20:
+		return "eof wait";
+	case 0x40:
+		return "soft reset wait";
+	case 0x80:
+		return "eof done";
+	case 0x100:
+		return "sof reset done";
+	case 0x200:
+		return "frame complete";
+	default:
+		return "";
+	}
+}
+
+void mdp_dump_rdma_common(void __iomem *base, const char *label)
+{
+	uint32_t value[17] = { 0 };
+	uint32_t state = 0;
+	uint32_t grep = 0;
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x030);
+	value[1] = MDP_REG_GET32(base +
+		   mdp_get_func()->mdp_rdma_get_src_base_addr());
+	value[2] = MDP_REG_GET32(base + 0x060);
+	value[3] = MDP_REG_GET32(base + 0x070);
+	value[4] = MDP_REG_GET32(base + 0x078);
+	value[5] = MDP_REG_GET32(base + 0x080);
+	value[6] = MDP_REG_GET32(base + 0x100);
+	value[7] = MDP_REG_GET32(base + 0x118);
+	value[8] = MDP_REG_GET32(base + 0x130);
+	value[9] = MDP_REG_GET32(base + 0x400);
+	value[10] = MDP_REG_GET32(base + 0x408);
+	value[11] = MDP_REG_GET32(base + 0x410);
+	value[12] = MDP_REG_GET32(base + 0x420);
+	value[13] = MDP_REG_GET32(base + 0x430);
+	value[14] = MDP_REG_GET32(base + 0x440);
+	value[15] = MDP_REG_GET32(base + 0x4D0);
+	value[16] = MDP_REG_GET32(base + 0x0);
+
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err
+	    ("RDMA_SRC_CON: 0x%08x, RDMA_SRC_BASE_0: 0x%08x\n",
+	     value[0], value[1]);
+	mdp_err
+	    ("RDMA_MF_BKGD_SIZE_IN_BYTE: 0x%08x RDMA_MF_SRC_SIZE: 0x%08x\n",
+	     value[2], value[3]);
+	mdp_err("RDMA_MF_CLIP_SIZE: 0x%08x, RDMA_MF_OFFSET_1: 0x%08x\n",
+		value[4], value[5]);
+	mdp_err("RDMA_SRC_END_0: 0x%08x, RDMA_SRC_OFFSET_0: 0x%08x\n",
+		 value[6], value[7]);
+	mdp_err("RDMA_SRC_OFFSET_W_0: 0x%08x, RDMA_MON_STA_0: 0x%08x\n",
+		 value[8], value[9]);
+	mdp_err("RDMA_MON_STA_1: 0x%08x, RDMA_MON_STA_2: 0x%08x\n",
+		 value[10], value[11]);
+	mdp_err("RDMA_MON_STA_4: 0x%08x, RDMA_MON_STA_6: 0x%08x\n",
+		 value[12], value[13]);
+	mdp_err("RDMA_MON_STA_8: 0x%08x, RDMA_MON_STA_26: 0x%08x\n",
+		 value[14], value[15]);
+	mdp_err("RDMA_EN: 0x%08x\n",
+		 value[16]);
+
+	/* parse state */
+	mdp_err("RDMA ack:%d req:%d\n", (value[9] & (1 << 11)) >> 11,
+		 (value[9] & (1 << 10)) >> 10);
+	state = (value[10] >> 8) & 0x7FF;
+	grep = (value[10] >> 20) & 0x1;
+	mdp_err("RDMA state: 0x%x (%s)\n", state, mdp_get_rdma_state(state));
+	mdp_err("RDMA horz_cnt: %d vert_cnt:%d\n",
+		value[15] & 0xFFF, (value[15] >> 16) & 0xFFF);
+
+	mdp_err("RDMA grep:%d => suggest to ask SMI help:%d\n", grep, grep);
+}
+
+void mdp_dump_rot_common(void __iomem *base, const char *label)
+{
+	uint32_t value[47] = { 0 };
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x000);
+	value[1] = MDP_REG_GET32(base + 0x008);
+	value[2] = MDP_REG_GET32(base + 0x00C);
+	value[3] = MDP_REG_GET32(base + 0x024);
+	value[4] = MDP_REG_GET32(base +
+		   mdp_get_func()->mdp_wrot_get_reg_offset_dst_addr());
+	value[5] = MDP_REG_GET32(base + 0x02C);
+	value[6] = MDP_REG_GET32(base + 0x004);
+	value[7] = MDP_REG_GET32(base + 0x030);
+	value[8] = MDP_REG_GET32(base + 0x078);
+	value[9] = MDP_REG_GET32(base + 0x070);
+	MDP_REG_SET32(base + 0x018, 0x00000100);
+	value[10] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000200);
+	value[11] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000300);
+	value[12] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000400);
+	value[13] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000500);
+	value[14] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000600);
+	value[15] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000700);
+	value[16] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000800);
+	value[17] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000900);
+	value[18] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000A00);
+	value[19] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000B00);
+	value[20] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000C00);
+	value[21] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000D00);
+	value[22] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000E00);
+	value[23] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00000F00);
+	value[24] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001000);
+	value[25] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001100);
+	value[26] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001200);
+	value[27] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001300);
+	value[28] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001400);
+	value[29] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001500);
+	value[30] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001600);
+	value[31] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001700);
+	value[32] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001800);
+	value[33] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001900);
+	value[34] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001A00);
+	value[35] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001B00);
+	value[36] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001C00);
+	value[37] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001D00);
+	value[38] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001E00);
+	value[39] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00001F00);
+	value[40] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00002000);
+	value[41] = MDP_REG_GET32(base + 0x0D0);
+	MDP_REG_SET32(base + 0x018, 0x00002100);
+	value[42] = MDP_REG_GET32(base + 0x0D0);
+	value[43] = MDP_REG_GET32(base + 0x01C);
+	value[44] = MDP_REG_GET32(base + 0x07C);
+	value[45] = MDP_REG_GET32(base + 0x010);
+	value[46] = MDP_REG_GET32(base + 0x014);
+
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("ROT_CTRL: 0x%08x, ROT_MAIN_BUF_SIZE: 0x%08x\n",
+		 value[0], value[1]);
+	mdp_err("ROT_SUB_BUF_SIZE: 0x%08x, ROT_TAR_SIZE: 0x%08x\n",
+		 value[2], value[3]);
+	mdp_err("ROT_BASE_ADDR: 0x%08x, ROT_OFST_ADDR: 0x%08x\n",
+		 value[4], value[5]);
+	mdp_err("ROT_DMA_PERF: 0x%08x, ROT_STRIDE: 0x%08x\n",
+		 value[6], value[7]);
+	mdp_err("ROT_IN_SIZE: 0x%08x, ROT_EOL: 0x%08x\n",
+		 value[8], value[9]);
+	mdp_err("ROT_DBUGG_1: 0x%08x, ROT_DEBUBG_2: 0x%08x\n",
+		 value[10], value[11]);
+	mdp_err("ROT_DBUGG_3: 0x%08x, ROT_DBUGG_4: 0x%08x\n",
+		 value[12], value[13]);
+	mdp_err("ROT_DEBUBG_5: 0x%08x, ROT_DBUGG_6: 0x%08x\n",
+		 value[14], value[15]);
+	mdp_err("ROT_DBUGG_7: 0x%08x, ROT_DEBUBG_8: 0x%08x\n",
+		 value[16], value[17]);
+	mdp_err("ROT_DBUGG_9: 0x%08x, ROT_DBUGG_A: 0x%08x\n",
+		 value[18], value[19]);
+	mdp_err("ROT_DEBUBG_B: 0x%08x, ROT_DBUGG_C: 0x%08x\n",
+		 value[20], value[21]);
+	mdp_err("ROT_DBUGG_D: 0x%08x, ROT_DEBUBG_E: 0x%08x\n",
+		 value[22], value[23]);
+	mdp_err("ROT_DBUGG_F: 0x%08x, ROT_DBUGG_10: 0x%08x\n",
+		 value[24], value[25]);
+	mdp_err("ROT_DEBUBG_11: 0x%08x, ROT_DEBUG_12: 0x%08x\n",
+		 value[26], value[27]);
+	mdp_err("ROT_DBUGG_13: 0x%08x, ROT_DBUGG_14: 0x%08x\n",
+		 value[28], value[29]);
+	mdp_err("ROT_DEBUG_15: 0x%08x, ROT_DBUGG_16: 0x%08x\n",
+		 value[30], value[31]);
+	mdp_err("ROT_DBUGG_17: 0x%08x, ROT_DEBUG_18: 0x%08x\n",
+		 value[32], value[33]);
+	mdp_err("ROT_DBUGG_19: 0x%08x, ROT_DBUGG_1A: 0x%08x\n",
+		 value[34], value[35]);
+	mdp_err("ROT_DEBUG_1B: 0x%08x, ROT_DBUGG_1C: 0x%08x\n",
+		 value[36], value[37]);
+	mdp_err("ROT_DBUGG_1D: 0x%08x, ROT_DEBUG_1E: 0x%08x\n",
+		 value[38], value[39]);
+	mdp_err("ROT_DBUGG_1F: 0x%08x, ROT_DBUGG_20: 0x%08x\n",
+		 value[40], value[41]);
+	mdp_err("ROT_DEBUG_21: 0x%08x\n",
+		 value[42]);
+	mdp_err("VIDO_INT: 0x%08x, VIDO_ROT_EN: 0x%08x\n",
+		value[43], value[44]);
+	mdp_err("VIDO_SOFT_RST: 0x%08x, VIDO_SOFT_RST_STAT: 0x%08x\n",
+		value[45], value[46]);
+}
+
+void mdp_dump_color_common(void __iomem *base, const char *label)
+{
+	uint32_t value[13] = { 0 };
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x400);
+	value[1] = MDP_REG_GET32(base + 0x404);
+	value[2] = MDP_REG_GET32(base + 0x408);
+	value[3] = MDP_REG_GET32(base + 0x40C);
+	value[4] = MDP_REG_GET32(base + 0x410);
+	value[5] = MDP_REG_GET32(base + 0x420);
+	value[6] = MDP_REG_GET32(base + 0xC00);
+	value[7] = MDP_REG_GET32(base + 0xC04);
+	value[8] = MDP_REG_GET32(base + 0xC08);
+	value[9] = MDP_REG_GET32(base + 0xC0C);
+	value[10] = MDP_REG_GET32(base + 0xC10);
+	value[11] = MDP_REG_GET32(base + 0xC50);
+	value[12] = MDP_REG_GET32(base + 0xC54);
+
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("COLOR CFG_MAIN: 0x%08x\n", value[0]);
+	mdp_err("COLOR PXL_CNT_MAIN: 0x%08x, LINE_CNT_MAIN: 0x%08x\n",
+		value[1], value[2]);
+	mdp_err("COLOR WIN_X_MAIN: 0x%08x, WIN_Y_MAIN: 0x%08x\n",
+		value[3], value[4]);
+	mdp_err("DBG_CFG_MAIN: 0x%08x, COLOR START: 0x%08x\n",
+		value[5], value[6]);
+	mdp_err("INTEN: 0x%08x, INTSTA: 0x%08x\n",
+		value[7], value[8]);
+	mdp_err("COLOR OUT_SEL: 0x%08x, FRAME_DONE_DEL: 0x%08x\n",
+		value[9], value[10]);
+	mdp_err
+	    ("COLOR INTERNAL_IP_WIDTH: 0x%08x, INTERNAL_IP_HEIGHT: 0x%08x\n",
+	     value[11], value[12]);
+}
+
+void mdp_dump_wdma_common(void __iomem *base, const char *label)
+{
+	uint32_t value[56] = { 0 };
+	uint32_t state = 0;
+	/* grep bit = 1, WDMA has sent request to SMI,
+	 *and not receive done yet
+	 */
+	uint32_t grep = 0;
+	uint32_t isFIFOFull = 0;	/* 1 for WDMA FIFO full */
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x014);
+	value[1] = MDP_REG_GET32(base + 0x018);
+	value[2] = MDP_REG_GET32(base + 0x028);
+	value[3] = MDP_REG_GET32(base +
+		   mdp_get_func()->mdp_wdma_get_reg_offset_dst_addr());
+	value[4] = MDP_REG_GET32(base + 0x078);
+	value[5] = MDP_REG_GET32(base + 0x080);
+	value[6] = MDP_REG_GET32(base + 0x0A0);
+	value[7] = MDP_REG_GET32(base + 0x0A8);
+
+	MDP_REG_SET32(base + 0x014, (value[0] & (0x0FFFFFFF)));
+	value[8] = MDP_REG_GET32(base + 0x014);
+	value[9] = MDP_REG_GET32(base + 0x0AC);
+	value[40] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x10000000 | (value[0] & (0x0FFFFFFF)));
+	value[10] = MDP_REG_GET32(base + 0x014);
+	value[11] = MDP_REG_GET32(base + 0x0AC);
+	value[41] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x20000000 | (value[0] & (0x0FFFFFFF)));
+	value[12] = MDP_REG_GET32(base + 0x014);
+	value[13] = MDP_REG_GET32(base + 0x0AC);
+	value[42] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x30000000 | (value[0] & (0x0FFFFFFF)));
+	value[14] = MDP_REG_GET32(base + 0x014);
+	value[15] = MDP_REG_GET32(base + 0x0AC);
+	value[43] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x40000000 | (value[0] & (0x0FFFFFFF)));
+	value[16] = MDP_REG_GET32(base + 0x014);
+	value[17] = MDP_REG_GET32(base + 0x0AC);
+	value[44] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x50000000 | (value[0] & (0x0FFFFFFF)));
+	value[18] = MDP_REG_GET32(base + 0x014);
+	value[19] = MDP_REG_GET32(base + 0x0AC);
+	value[45] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x60000000 | (value[0] & (0x0FFFFFFF)));
+	value[20] = MDP_REG_GET32(base + 0x014);
+	value[21] = MDP_REG_GET32(base + 0x0AC);
+	value[46] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x70000000 | (value[0] & (0x0FFFFFFF)));
+	value[22] = MDP_REG_GET32(base + 0x014);
+	value[23] = MDP_REG_GET32(base + 0x0AC);
+	value[47] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x80000000 | (value[0] & (0x0FFFFFFF)));
+	value[24] = MDP_REG_GET32(base + 0x014);
+	value[25] = MDP_REG_GET32(base + 0x0AC);
+	value[48] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0x90000000 | (value[0] & (0x0FFFFFFF)));
+	value[26] = MDP_REG_GET32(base + 0x014);
+	value[27] = MDP_REG_GET32(base + 0x0AC);
+	value[49] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0xA0000000 | (value[0] & (0x0FFFFFFF)));
+	value[28] = MDP_REG_GET32(base + 0x014);
+	value[29] = MDP_REG_GET32(base + 0x0AC);
+	value[50] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0xB0000000 | (value[0] & (0x0FFFFFFF)));
+	value[30] = MDP_REG_GET32(base + 0x014);
+	value[31] = MDP_REG_GET32(base + 0x0AC);
+	value[51] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0xC0000000 | (value[0] & (0x0FFFFFFF)));
+	value[32] = MDP_REG_GET32(base + 0x014);
+	value[33] = MDP_REG_GET32(base + 0x0AC);
+	value[52] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0xD0000000 | (value[0] & (0x0FFFFFFF)));
+	value[34] = MDP_REG_GET32(base + 0x014);
+	value[35] = MDP_REG_GET32(base + 0x0AC);
+	value[53] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0xE0000000 | (value[0] & (0x0FFFFFFF)));
+	value[36] = MDP_REG_GET32(base + 0x014);
+	value[37] = MDP_REG_GET32(base + 0x0AC);
+	value[54] = MDP_REG_GET32(base + 0x0B8);
+	MDP_REG_SET32(base + 0x014, 0xF0000000 | (value[0] & (0x0FFFFFFF)));
+	value[38] = MDP_REG_GET32(base + 0x014);
+	value[39] = MDP_REG_GET32(base + 0x0AC);
+	value[55] = MDP_REG_GET32(base + 0x0B8);
+
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("[MDP]WDMA_CFG: 0x%08x, WDMA_SRC_SIZE: 0x%08x\n",
+		 value[0], value[1]);
+	mdp_err("WDMA_DST_W_IN_BYTE = 0x%08x, [MDP]WDMA_DST_ADDR0: 0x%08x\n",
+		 value[2], value[3]);
+	mdp_err
+	    ("WDMA_DST_UV_PITCH: 0x%08x, WDMA_DST_ADDR_OFFSET0 = 0x%08x\n",
+	     value[4], value[5]);
+	mdp_err("[MDP]WDMA_STATUS: 0x%08x, WDMA_INPUT_CNT: 0x%08x\n",
+		value[6], value[7]);
+
+	/* Dump Addtional WDMA debug info */
+	mdp_err("WDMA_DEBUG_0 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[8], value[9], value[40]);
+	mdp_err("WDMA_DEBUG_1 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[10], value[11], value[41]);
+	mdp_err("WDMA_DEBUG_2 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[12], value[13], value[42]);
+	mdp_err("WDMA_DEBUG_3 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[14], value[15], value[43]);
+	mdp_err("WDMA_DEBUG_4 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[16], value[17], value[44]);
+	mdp_err("WDMA_DEBUG_5 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[18], value[19], value[45]);
+	mdp_err("WDMA_DEBUG_6 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[20], value[21], value[46]);
+	mdp_err("WDMA_DEBUG_7 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[22], value[23], value[47]);
+	mdp_err("WDMA_DEBUG_8 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[24], value[25], value[48]);
+	mdp_err("WDMA_DEBUG_9 +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[26], value[27], value[49]);
+	mdp_err("WDMA_DEBUG_A +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[28], value[29], value[50]);
+	mdp_err("WDMA_DEBUG_B +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[30], value[31], value[51]);
+	mdp_err("WDMA_DEBUG_C +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[32], value[33], value[52]);
+	mdp_err("WDMA_DEBUG_D +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[34], value[35], value[53]);
+	mdp_err("WDMA_DEBUG_E +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[36], value[37], value[54]);
+	mdp_err("WDMA_DEBUG_F +014: 0x%08x , +0ac: 0x%08x , +0b8: 0x%08x\n",
+		value[38], value[39], value[55]);
+
+	/* parse WDMA state */
+	state = value[6] & 0x3FF;
+	grep = (value[6] >> 13) & 0x1;
+	isFIFOFull = (value[6] >> 12) & 0x1;
+
+	mdp_err("WDMA state:0x%x (%s)\n", state, mdp_get_wdma_state(state));
+	mdp_err("WDMA in_req:%d in_ack:%d\n", (value[6] >> 15) & 0x1,
+		(value[6] >> 14) & 0x1);
+
+	/* note WDMA send request(i.e command) to SMI first,
+	 * then SMI takes request data from WDMA FIFO
+	 */
+	/* if SMI dose not process request and upstream HWs */
+	/* such as MDP_RSZ send data to WDMA, WDMA FIFO will full finally */
+	mdp_err("WDMA grep:%d, FIFO full:%d\n", grep, isFIFOFull);
+	mdp_err("WDMA suggest: Need SMI help:%d, Need check WDMA config:%d\n",
+		(grep), ((grep == 0) && (isFIFOFull == 1)));
+}
+
+void mdp_dump_rsz(void __iomem *base, const char *label)
+{
+	uint32_t value[11] = { 0 };
+	uint32_t request[4] = { 0 };
+	uint32_t state = 0;
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x004);
+	value[1] = MDP_REG_GET32(base + 0x008);
+	value[2] = MDP_REG_GET32(base + 0x010);
+	value[3] = MDP_REG_GET32(base + 0x014);
+	value[4] = MDP_REG_GET32(base + 0x018);
+	value[5] = MDP_REG_GET32(base + 0x01C);
+	MDP_REG_SET32(base + 0x044, 0x00000001);
+	value[6] = MDP_REG_GET32(base + 0x048);
+	MDP_REG_SET32(base + 0x044, 0x00000002);
+	value[7] = MDP_REG_GET32(base + 0x048);
+	MDP_REG_SET32(base + 0x044, 0x00000003);
+	value[8] = MDP_REG_GET32(base + 0x048);
+	value[9] = MDP_REG_GET32(base + 0x100);
+	value[10] = MDP_REG_GET32(base + 0x200);
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("RSZ_CONTROL_1: 0x%08x, RSZ_CONTROL_2: 0x%08x\n",
+		 value[0], value[1]);
+	mdp_err("RSZ_INPUT_IMAGE: 0x%08x, RSZ_OUTPUT_IMAGE: 0x%08x\n",
+		 value[2], value[3]);
+	mdp_err("RSZ_HORIZONTAL_COEFF_STEP: 0x%08x\n", value[4]);
+	mdp_err("RSZ_VERTICAL_COEFF_STEP: 0x%08x\n", value[5]);
+	mdp_err
+	    ("RSZ_DEBUG_1: 0x%08x, RSZ_DEBUG_2: 0x%08x, RSZ_DEBUG_3: 0x%08x\n",
+	     value[6], value[7], value[8]);
+	mdp_err("PAT1_GEN_SET: 0x%08x, PAT2_GEN_SET: 0x%08x\n",
+		value[9], value[10]);
+	/* parse state */
+	/* .valid=1/request=1: upstream module sends data */
+	/* .ready=1: downstream module receives data */
+	state = value[7] & 0xF;
+	request[0] = state & (0x1);	/* out valid */
+	request[1] = (state & (0x1 << 1)) >> 1;	/* out ready */
+	request[2] = (state & (0x1 << 2)) >> 2;	/* in valid */
+	request[3] = (state & (0x1 << 3)) >> 3;	/* in ready */
+	mdp_err("RSZ inRdy,inRsq,outRdy,outRsq: %d,%d,%d,%d (%s)\n",
+		request[3], request[2], request[1], request[0],
+		mdp_get_rsz_state(state));
+}
+void mdp_dump_tdshp(void __iomem *base, const char *label)
+{
+	uint32_t value[10] = { 0 };
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x114);
+	value[1] = MDP_REG_GET32(base + 0x11C);
+	value[2] = MDP_REG_GET32(base + 0x104);
+	value[3] = MDP_REG_GET32(base + 0x108);
+	value[4] = MDP_REG_GET32(base + 0x10C);
+	value[5] = MDP_REG_GET32(base + 0x110);
+	value[6] = MDP_REG_GET32(base + 0x120);
+	value[7] = MDP_REG_GET32(base + 0x124);
+	value[8] = MDP_REG_GET32(base + 0x128);
+	value[9] = MDP_REG_GET32(base + 0x12C);
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("TDSHP INPUT_CNT: 0x%08x, OUTPUT_CNT: 0x%08x\n",
+		value[0], value[1]);
+	mdp_err("TDSHP INTEN: 0x%08x, INTSTA: 0x%08x, STATUS: 0x%08x\n",
+		value[2], value[3], value[4]);
+	mdp_err("TDSHP CFG: 0x%08x, IN_SIZE: 0x%08x, OUT_SIZE: 0x%08x\n",
+		value[5], value[6], value[8]);
+	mdp_err("TDSHP OUTPUT_OFFSET: 0x%08x, BLANK_WIDTH: 0x%08x\n",
+		value[7], value[9]);
+}
+
+void mdp_dump_aal(void __iomem *base, const char *label)
+{
+	uint32_t value[9] = { 0 };
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x00C);    /* MDP_AAL_INTSTA       */
+	value[1] = MDP_REG_GET32(base + 0x010);    /* MDP_AAL_STATUS       */
+	value[2] = MDP_REG_GET32(base + 0x024);    /* MDP_AAL_INPUT_COUNT  */
+	value[3] = MDP_REG_GET32(base + 0x028);    /* MDP_AAL_OUTPUT_COUNT */
+	value[4] = MDP_REG_GET32(base + 0x030);    /* MDP_AAL_SIZE         */
+	value[5] = MDP_REG_GET32(base + 0x034);    /* MDP_AAL_OUTPUT_SIZE  */
+	value[6] = MDP_REG_GET32(base + 0x038);    /* MDP_AAL_OUTPUT_OFFSET*/
+	value[7] = MDP_REG_GET32(base + 0x4EC);    /* MDP_AAL_TILE_00      */
+	value[8] = MDP_REG_GET32(base + 0x4F0);    /* MDP_AAL_TILE_01      */
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("AAL_INTSTA: 0x%08x, AAL_STATUS: 0x%08x\n",
+		value[0], value[1]);
+	mdp_err("AAL_INPUT_COUNT: 0x%08x, AAL_OUTPUT_COUNT: 0x%08x\n",
+		value[2], value[3]);
+	mdp_err("AAL_SIZE: 0x%08x\n", value[4]);
+	mdp_err("AAL_OUTPUT_SIZE: 0x%08x, AAL_OUTPUT_OFFSET: 0x%08x\n",
+		value[5], value[6]);
+	mdp_err("AAL_TILE_00: 0x%08x, AAL_TILE_01: 0x%08x\n",
+		value[7], value[8]);
+}
+void mdp_dump_ccorr(void __iomem *base, const char *label)
+{
+	uint32_t value[5] = { 0 };
+
+	if (base == 0) {
+		mdp_err("=============== [MDP] %s Status ===============\n",
+			label);
+		mdp_err("%s:base=0!\n", __func__);
+		return;
+	}
+
+	value[0] = MDP_REG_GET32(base + 0x00C);/* MDP_CCORR_INTSTA         */
+	value[1] = MDP_REG_GET32(base + 0x010);/* MDP_CCORR_STATUS         */
+	value[2] = MDP_REG_GET32(base + 0x024);/* MDP_CCORR_INPUT_COUNT    */
+	value[3] = MDP_REG_GET32(base + 0x028);/* MDP_CCORR_OUTPUT_COUNT   */
+	value[4] = MDP_REG_GET32(base + 0x030);/* MDP_CCORR_SIZE       */
+	mdp_err("=============== [MDP] %s Status ===============\n",
+		label);
+	mdp_err("CCORR_INTSTA: 0x%08x, CCORR_STATUS: 0x%08x\n",
+		value[0], value[1]);
+	mdp_err("CCORR_INPUT_COUNT: 0x%08x, CCORR_OUTPUT_COUNT: 0x%08x\n",
+		value[2], value[3]);
+	mdp_err("CCORR_SIZE: 0x%08x\n",
+		value[4]);
+}
+
+uint32_t mdp_rdma_get_reg_offset_src_addr(void)
+{
+	return 0xF00;
+}
+
+uint32_t mdp_wrot_get_reg_offset_dst_addr(void)
+{
+	return 0xF00;
+}
+
+uint32_t mdp_wdma_get_reg_offset_dst_addr(void)
+{
+	return 0xF00;
+}
+
+void mdp_platform_function_setting(void)
+{
+	struct mdp_func_struct *pFunc = mdp_get_func();
+
+	pFunc->mdp_dump_mmsys_config = mdp_dump_mmsys_config;
+	pFunc->mdp_dump_rsz = mdp_dump_rsz;
+	pFunc->mdp_dump_tdshp = mdp_dump_tdshp;
+	pFunc->mdp_rdma_get_src_base_addr = mdp_rdma_get_reg_offset_src_addr;
+	pFunc->mdp_wrot_get_reg_offset_dst_addr =
+		mdp_wrot_get_reg_offset_dst_addr;
+	pFunc->mdp_wdma_get_reg_offset_dst_addr =
+		mdp_wdma_get_reg_offset_dst_addr;
+}
+
+int32_t mdp_dump_info(uint64_t comp_flag, int log_level)
+{
+	if (comp_flag & (1LL << MDP_COMP_RDMA0))
+		mdp_dump_rdma_common(MDP_RDMA0_BASE, "RDMA0");
+	if (comp_flag & (1LL << MDP_COMP_AAL0))
+		mdp_dump_aal(MDP_AAL_BASE, "AAL0");
+	if (comp_flag & (1LL << MDP_COMP_CCORR0))
+		mdp_dump_ccorr(MDP_CCORR_BASE, "CCORR0");
+	if (comp_flag & (1LL << MDP_COMP_RSZ0))
+		mdp_get_func()->mdp_dump_rsz(MDP_RSZ0_BASE, "RSZ0");
+	if (comp_flag & (1LL << MDP_COMP_RSZ1))
+		mdp_get_func()->mdp_dump_rsz(MDP_RSZ1_BASE, "RSZ1");
+	if (comp_flag & (1LL << MDP_COMP_TDSHP0))
+		mdp_get_func()->mdp_dump_tdshp(MDP_TDSHP_BASE, "TDSHP");
+	if (comp_flag & (1LL << MDP_COMP_COLOR0))
+		mdp_dump_color_common(MDP_COLOR_BASE, "COLOR0");
+	if (comp_flag & (1LL << MDP_COMP_WROT0))
+		mdp_dump_rot_common(MDP_WROT0_BASE, "WROT0");
+	if (comp_flag & (1LL << MDP_COMP_WDMA))
+		mdp_dump_wdma_common(MDP_WDMA_BASE, "WDMA");
+
+	return 0;
+}
+
+void mdp_debug_init(struct platform_device *pDevice)
+{
+	pr_err("%s:start\n", __func__);
+	g_mdp_debug.mdp_device = pDevice;
+
+	mdp_init_module_base_VA();
+	mdp_map_mmsys_VA();
+	mdp_virtual_function_setting();
+	mdp_platform_function_setting();
+
+	pr_err("%s:end\n", __func__);
+}
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.h
new file mode 100644
index 000000000000..537602f42209
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-debug.h
@@ -0,0 +1,40 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Daoyuan Huang <daoyuan.huang@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_DEBUG_H__
+#define __MTK_MDP3_DEBUG_H__
+
+#include <linux/soc/mediatek/mtk-cmdq.h>
+
+struct mdp_func_struct {
+	void (*mdp_dump_mmsys_config)(void);
+	void (*mdp_dump_rsz)(void __iomem *base, const char *label);
+	void (*mdp_dump_tdshp)(void __iomem *base, const char *label);
+	uint32_t (*mdp_rdma_get_src_base_addr)(void);
+	uint32_t (*mdp_wrot_get_reg_offset_dst_addr)(void);
+	uint32_t (*mdp_wdma_get_reg_offset_dst_addr)(void);
+};
+
+void mdp_debug_init(struct platform_device *pDevice);
+struct mdp_func_struct *mdp_get_func(void);
+const char *mdp_get_rsz_state(const uint32_t state);
+void mdp_dump_rdma_common(void __iomem *base, const char *label);
+void mdp_dump_rot_common(void __iomem *base, const char *label);
+void mdp_dump_color_common(void __iomem *base, const char *label);
+int32_t mdp_dump_info(uint64_t comp_flag, int log_level);
+
+
+#endif  /* __MTK_MDP3_DEBUG_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.c
new file mode 100644
index 000000000000..d5efd42c252c
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.c
@@ -0,0 +1,787 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/platform_device.h>
+#include <media/v4l2-ioctl.h>
+#include <media/v4l2-event.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk-mdp3-m2m.h"
+#ifdef MDP_UT
+int mdp_ut(struct mdp_dev *mdp);
+#endif
+
+static inline struct mdp_m2m_ctx *fh_to_ctx(struct v4l2_fh *fh)
+{
+	return container_of(fh, struct mdp_m2m_ctx, fh);
+}
+
+static inline struct mdp_m2m_ctx *ctrl_to_ctx(struct v4l2_ctrl *ctrl)
+{
+	return container_of(ctrl->handler, struct mdp_m2m_ctx, ctrl_handler);
+}
+
+static inline struct mdp_frame *ctx_get_frame(struct mdp_m2m_ctx *ctx,
+					      enum v4l2_buf_type type)
+{
+	if (V4L2_TYPE_IS_OUTPUT(type))
+		return &ctx->curr_param->output;
+	return &ctx->curr_param->captures[0];
+}
+
+static void mdp_m2m_ctx_set_state(struct mdp_m2m_ctx *ctx, u32 state)
+{
+	mutex_lock(&ctx->curr_param->lock);
+	ctx->curr_param->state |= state;
+	mutex_unlock(&ctx->curr_param->lock);
+}
+
+static void mdp_m2m_ctx_clear_state(struct mdp_m2m_ctx *ctx, u32 state)
+{
+	mutex_lock(&ctx->curr_param->lock);
+	ctx->curr_param->state &= ~state;
+	mutex_unlock(&ctx->curr_param->lock);
+}
+
+static bool mdp_m2m_ctx_is_state_set(struct mdp_m2m_ctx *ctx, u32 mask)
+{
+	bool ret;
+
+	mutex_lock(&ctx->curr_param->lock);
+	ret = (ctx->curr_param->state & mask) == mask;
+	mutex_unlock(&ctx->curr_param->lock);
+	return ret;
+}
+
+static void mdp_m2m_ctx_lock(struct vb2_queue *q)
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(q);
+
+	mutex_lock(&ctx->mdp_dev->m2m_lock);
+}
+
+static void mdp_m2m_ctx_unlock(struct vb2_queue *q)
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(q);
+
+	mutex_unlock(&ctx->mdp_dev->m2m_lock);
+}
+
+static void mdp_m2m_job_abort(void *priv)
+{
+}
+
+static void mdp_m2m_process_done(void *priv, int vb_state)
+{
+	struct mdp_m2m_ctx *ctx = priv;
+	struct vb2_buffer *src_vb, *dst_vb;
+	struct vb2_v4l2_buffer *src_vbuf, *dst_vbuf;
+
+	src_vb = v4l2_m2m_src_buf_remove(ctx->m2m_ctx);
+	src_vbuf = to_vb2_v4l2_buffer(src_vb);
+	dst_vb = v4l2_m2m_dst_buf_remove(ctx->m2m_ctx);
+	dst_vbuf = to_vb2_v4l2_buffer(dst_vb);
+
+	dst_vbuf->sequence = src_vbuf->sequence;
+	dst_vbuf->timecode = src_vbuf->timecode;
+	dst_vbuf->flags &= ~V4L2_BUF_FLAG_TSTAMP_SRC_MASK;
+	dst_vbuf->flags |= src_vbuf->flags & V4L2_BUF_FLAG_TSTAMP_SRC_MASK;
+
+	v4l2_m2m_buf_done(src_vbuf, vb_state);
+	v4l2_m2m_buf_done(dst_vbuf, vb_state);
+	v4l2_m2m_job_finish(ctx->mdp_dev->m2m_dev, ctx->m2m_ctx);
+}
+
+static void mdp_m2m_worker(struct work_struct *work)
+{
+	struct mdp_m2m_ctx *ctx = container_of(work, struct mdp_m2m_ctx, work);
+	struct mdp_frame *frame;
+	struct vb2_buffer *src_vb, *dst_vb;
+	struct img_ipi_frameparam param = {0};
+	struct mdp_cmdq_param task = {0};
+	enum vb2_buffer_state vb_state = VB2_BUF_STATE_ERROR;
+	int ret;
+
+	if (mdp_m2m_ctx_is_state_set(ctx, MDP_M2M_CTX_ERROR)) {
+		dev_err(&ctx->mdp_dev->pdev->dev,
+			"mdp_m2m_ctx is in error state\n");
+		goto worker_end;
+	}
+
+	param.frame_no = ctx->curr_param->frame_no;
+	param.type = ctx->curr_param->type;
+	param.num_inputs = 1;
+	param.num_outputs = 1;
+
+	frame = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE);
+	src_vb = v4l2_m2m_next_src_buf(ctx->m2m_ctx);
+	mdp_set_src_config(&param.inputs[0], frame, src_vb);
+
+	frame = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+	dst_vb = v4l2_m2m_next_dst_buf(ctx->m2m_ctx);
+	mdp_set_dst_config(&param.outputs[0], frame, dst_vb);
+
+	dst_vb->timestamp = src_vb->timestamp;
+	param.timestamp = src_vb->timestamp;
+
+	ret = mdp_vpu_process(&ctx->vpu, &param);
+	if (ret) {
+		dev_err(&ctx->mdp_dev->pdev->dev,
+			"VPU MDP process failed: %d\n", ret);
+		goto worker_end;
+	}
+
+	task.config = ctx->vpu.config;
+	task.param = &param;
+	task.composes[0] = &frame->compose;
+	task.wait = 1;
+	task.cmdq_cb = NULL;
+	task.cb_data = NULL;
+
+	ret = mdp_cmdq_send(ctx->mdp_dev, &task);
+	if (ret) {
+		dev_err(&ctx->mdp_dev->pdev->dev,
+			"CMDQ sendtask failed: %d\n", ret);
+		goto worker_end;
+	}
+
+	vb_state = VB2_BUF_STATE_DONE;
+
+worker_end:
+	mdp_m2m_process_done(ctx, vb_state);
+}
+
+static void mdp_m2m_device_run(void *priv)
+{
+	struct mdp_m2m_ctx *ctx = priv;
+
+	ctx->curr_param->frame_no = ctx->frame_count++;
+	queue_work(ctx->mdp_dev->job_wq, &ctx->work);
+}
+
+static int mdp_m2m_start_streaming(struct vb2_queue *q, unsigned int count)
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(q);
+	int ret;
+
+	ret = 0;//pm_runtime_get_sync(&ctx->mdp_dev->pdev->dev);
+	if (ret < 0)
+		mdp_dbg(1, "[%d] pm_runtime_get_sync failed:%d", ctx->id, ret);
+
+	return 0;
+}
+
+static struct vb2_buffer *mdp_m2m_buf_remove(struct mdp_m2m_ctx *ctx,
+					     unsigned int type)
+{
+	if (V4L2_TYPE_IS_OUTPUT(type))
+		return v4l2_m2m_src_buf_remove(ctx->m2m_ctx);
+	return v4l2_m2m_dst_buf_remove(ctx->m2m_ctx);
+}
+
+static void mdp_m2m_stop_streaming(struct vb2_queue *q)
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(q);
+	struct vb2_buffer *vb;
+
+	vb = mdp_m2m_buf_remove(ctx, q->type);
+	while (vb) {
+		v4l2_m2m_buf_done(to_vb2_v4l2_buffer(vb), VB2_BUF_STATE_ERROR);
+		vb = mdp_m2m_buf_remove(ctx, q->type);
+	}
+
+	//pm_runtime_put(&ctx->mdp_dev->pdev->dev);
+}
+
+static int mdp_m2m_queue_setup(struct vb2_queue *q,
+			       unsigned int *num_buffers,
+			       unsigned int *num_planes, unsigned int sizes[],
+			       struct device *alloc_devs[])
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(q);
+	struct v4l2_pix_format_mplane *pix_mp;
+	u32 i;
+
+	pix_mp = &ctx_get_frame(ctx, q->type)->format.fmt.pix_mp;
+	*num_planes = pix_mp->num_planes;
+	for (i = 0; i < pix_mp->num_planes; ++i)
+		sizes[i] = pix_mp->plane_fmt[i].sizeimage;
+	mdp_dbg(2, "[%d] type:%d, planes:%u, buffers:%u, size:%u,%u,%u",
+		ctx->id, q->type, *num_planes, *num_buffers,
+		sizes[0], sizes[1], sizes[2]);
+	return 0;
+}
+
+static int mdp_m2m_buf_prepare(struct vb2_buffer *vb)
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(vb->vb2_queue);
+	struct v4l2_pix_format_mplane *pix_mp;
+	u32 i;
+
+	if (!V4L2_TYPE_IS_OUTPUT(vb->type)) {
+		pix_mp = &ctx_get_frame(ctx, vb->type)->format.fmt.pix_mp;
+		for (i = 0; i < pix_mp->num_planes; ++i) {
+			vb2_set_plane_payload(vb, i,
+					      pix_mp->plane_fmt[i].sizeimage);
+		}
+	}
+	return 0;
+}
+
+static void mdp_m2m_buf_queue(struct vb2_buffer *vb)
+{
+	struct mdp_m2m_ctx *ctx = vb2_get_drv_priv(vb->vb2_queue);
+
+	v4l2_m2m_buf_queue(ctx->m2m_ctx, to_vb2_v4l2_buffer(vb));
+}
+
+static const struct vb2_ops mdp_m2m_qops = {
+	.queue_setup	= mdp_m2m_queue_setup,
+	.wait_prepare	= mdp_m2m_ctx_unlock,
+	.wait_finish	= mdp_m2m_ctx_lock,
+	.buf_prepare	= mdp_m2m_buf_prepare,
+	.start_streaming = mdp_m2m_start_streaming,
+	.stop_streaming	= mdp_m2m_stop_streaming,
+	.buf_queue	= mdp_m2m_buf_queue,
+};
+
+static int mdp_m2m_querycap(struct file *file, void *fh,
+			    struct v4l2_capability *cap)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+
+	strlcpy(cap->driver, MDP_MODULE_NAME, sizeof(cap->driver));
+	strlcpy(cap->card, ctx->mdp_dev->pdev->name, sizeof(cap->card));
+	strlcpy(cap->bus_info, "platform:mt8183", sizeof(cap->bus_info));
+	cap->capabilities = V4L2_CAP_VIDEO_M2M_MPLANE | V4L2_CAP_STREAMING |
+			V4L2_CAP_DEVICE_CAPS; /* | V4L2_CAP_META_OUTPUT */
+	cap->device_caps = V4L2_CAP_VIDEO_M2M_MPLANE | V4L2_CAP_STREAMING;
+	return 0;
+}
+
+static int mdp_m2m_enum_fmt_mplane(struct file *file, void *fh,
+				   struct v4l2_fmtdesc *f)
+{
+	return mdp_enum_fmt_mplane(f);
+}
+
+static int mdp_m2m_g_fmt_mplane(struct file *file, void *fh,
+				struct v4l2_format *f)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+	struct mdp_frame *frame;
+
+	frame = ctx_get_frame(ctx, f->type);
+	*f = frame->format;
+
+	mdp_dbg(2, "[%d] type:%d, frame:%ux%u", ctx->id, f->type,
+		f->fmt.pix_mp.width, f->fmt.pix_mp.height);
+	return 0;
+}
+
+static int mdp_m2m_s_fmt_mplane(struct file *file, void *fh,
+				struct v4l2_format *f)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+	struct mdp_frame *frame = ctx_get_frame(ctx, f->type);
+	struct mdp_frame *capture;
+	const struct mdp_format *fmt;
+	struct vb2_queue *vq;
+
+	mdp_dbg(2, "[%d] type:%d", ctx->id, f->type);
+
+	fmt = mdp_try_fmt_mplane(f, ctx->curr_param->limit, ctx->id);
+	if (!fmt) {
+		mdp_err("[%d] try_fmt failed, type:%d", ctx->id, f->type);
+		return -EINVAL;
+	}
+
+	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
+	if (vb2_is_streaming(vq)) {
+		dev_info(&ctx->mdp_dev->pdev->dev, "Queue %d busy\n", f->type);
+		return -EBUSY;
+	}
+
+	frame->format = *f;
+	frame->mdp_fmt = fmt;
+	frame->ycbcr_prof = mdp_map_ycbcr_prof_mplane(f, fmt->mdp_color);
+	frame->usage = V4L2_TYPE_IS_OUTPUT(f->type) ?
+		MDP_BUFFER_USAGE_HW_READ : MDP_BUFFER_USAGE_MDP;
+
+	capture = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+	if (V4L2_TYPE_IS_OUTPUT(f->type)) {
+		capture->crop.c.left = 0;
+		capture->crop.c.top = 0;
+		capture->crop.c.width = f->fmt.pix_mp.width;
+		capture->crop.c.height = f->fmt.pix_mp.height;
+
+		mdp_m2m_ctx_set_state(ctx, MDP_M2M_SRC_FMT);
+	} else {
+		capture->compose.left = 0;
+		capture->compose.top = 0;
+		capture->compose.width = f->fmt.pix_mp.width;
+		capture->compose.height = f->fmt.pix_mp.height;
+
+		mdp_m2m_ctx_set_state(ctx, MDP_M2M_DST_FMT);
+	}
+
+	mdp_dbg(2, "[%d] type:%d, frame:%ux%u", ctx->id, f->type,
+		f->fmt.pix_mp.width, f->fmt.pix_mp.height);
+	return 0;
+}
+
+static int mdp_m2m_try_fmt_mplane(struct file *file, void *fh,
+				  struct v4l2_format *f)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+
+	if (!mdp_try_fmt_mplane(f, ctx->curr_param->limit, ctx->id))
+		return -EINVAL;
+	return 0;
+}
+
+static int mdp_m2m_reqbufs(struct file *file, void *fh,
+			   struct v4l2_requestbuffers *reqbufs)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+
+	if (reqbufs->count == 0) {
+		if (V4L2_TYPE_IS_OUTPUT(reqbufs->type))
+			mdp_m2m_ctx_clear_state(ctx, MDP_M2M_SRC_FMT);
+		else
+			mdp_m2m_ctx_clear_state(ctx, MDP_M2M_DST_FMT);
+	}
+
+	return v4l2_m2m_reqbufs(file, ctx->m2m_ctx, reqbufs);
+}
+
+static int mdp_m2m_streamon(struct file *file, void *fh,
+			    enum v4l2_buf_type type)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+	int ret;
+
+	/* The source and target color formats need to be set */
+	if (V4L2_TYPE_IS_OUTPUT(type)) {
+		if (!mdp_m2m_ctx_is_state_set(ctx, MDP_M2M_SRC_FMT))
+			return -EINVAL;
+	} else {
+		if (!mdp_m2m_ctx_is_state_set(ctx, MDP_M2M_DST_FMT))
+			return -EINVAL;
+	}
+
+	if (!mdp_m2m_ctx_is_state_set(ctx, MDP_VPU_INIT)) {
+		ret = mdp_vpu_ctx_init(&ctx->vpu, &ctx->mdp_dev->vpu,
+				       MDP_DEV_M2M);
+		if (ret) {
+			dev_err(&ctx->mdp_dev->pdev->dev,
+				"VPU init failed %d\n", ret);
+			return -EINVAL;
+		}
+		mdp_m2m_ctx_set_state(ctx, MDP_VPU_INIT);
+	}
+
+	return v4l2_m2m_streamon(file, ctx->m2m_ctx, type);
+}
+
+static int mdp_m2m_g_selection(struct file *file, void *fh,
+			       struct v4l2_selection *s)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+	struct mdp_frame *frame;
+	bool valid;
+
+	if (V4L2_TYPE_IS_OUTPUT(s->type))
+		valid = mdp_target_is_crop(s->target);
+	else
+		valid = mdp_target_is_compose(s->target);
+
+	if (!valid) {
+		mdp_dbg(1, "[%d] invalid type:%u target:%u", ctx->id, s->type,
+			s->target);
+		return -EINVAL;
+	}
+
+	switch (s->target) {
+	case V4L2_SEL_TGT_CROP:
+		frame = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+		s->r = frame->crop.c;
+		return 0;
+	case V4L2_SEL_TGT_COMPOSE:
+		frame = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+		s->r = frame->compose;
+		return 0;
+	case V4L2_SEL_TGT_CROP_DEFAULT:
+	case V4L2_SEL_TGT_CROP_BOUNDS:
+	case V4L2_SEL_TGT_COMPOSE_DEFAULT:
+	case V4L2_SEL_TGT_COMPOSE_BOUNDS:
+		frame = ctx_get_frame(ctx, s->type);
+		s->r.left = 0;
+		s->r.top = 0;
+		s->r.width = frame->format.fmt.pix_mp.width;
+		s->r.height = frame->format.fmt.pix_mp.height;
+		return 0;
+	}
+	return -EINVAL;
+}
+
+static int mdp_m2m_s_selection(struct file *file, void *fh,
+			       struct v4l2_selection *s)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(fh);
+	struct mdp_frame *frame = ctx_get_frame(ctx, s->type);
+	struct mdp_frame *capture;
+	struct v4l2_rect r;
+	bool valid;
+	int ret;
+
+	if (V4L2_TYPE_IS_OUTPUT(s->type))
+		valid = (s->target == V4L2_SEL_TGT_CROP);
+	else
+		valid = (s->target == V4L2_SEL_TGT_COMPOSE);
+	if (!valid) {
+		mdp_dbg(1, "[%d] invalid type:%u target:%u", ctx->id, s->type,
+			s->target);
+		return -EINVAL;
+	}
+
+	ret = mdp_try_crop(&r, s, frame, ctx->id);
+	if (ret)
+		return ret;
+	capture = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+
+	/* Check to see if scaling ratio is within supported range */
+	if (mdp_m2m_ctx_is_state_set(ctx, MDP_M2M_DST_FMT | MDP_M2M_SRC_FMT)) {
+		if (mdp_target_is_crop(s->target)) {
+			ret = mdp_check_scaling_ratio(&r, &capture->compose,
+						      capture->rotation,
+						      ctx->curr_param->limit);
+		} else {
+			ret = mdp_check_scaling_ratio(&capture->crop.c, &r,
+						      capture->rotation,
+						      ctx->curr_param->limit);
+		}
+
+		if (ret) {
+			dev_info(&ctx->mdp_dev->pdev->dev,
+				 "Out of scaling range\n");
+			return ret;
+		}
+	}
+
+	if (mdp_target_is_crop(s->target))
+		capture->crop.c = r;
+	else
+		capture->compose = r;
+
+	s->r = r;
+	memset(s->reserved, 0, sizeof(s->reserved));
+	return 0;
+}
+
+static const struct v4l2_ioctl_ops mdp_m2m_ioctl_ops = {
+	.vidioc_querycap		= mdp_m2m_querycap,
+	.vidioc_enum_fmt_vid_cap_mplane	= mdp_m2m_enum_fmt_mplane,
+	.vidioc_enum_fmt_vid_out_mplane	= mdp_m2m_enum_fmt_mplane,
+	.vidioc_g_fmt_vid_cap_mplane	= mdp_m2m_g_fmt_mplane,
+	.vidioc_g_fmt_vid_out_mplane	= mdp_m2m_g_fmt_mplane,
+	.vidioc_s_fmt_vid_cap_mplane	= mdp_m2m_s_fmt_mplane,
+	.vidioc_s_fmt_vid_out_mplane	= mdp_m2m_s_fmt_mplane,
+	.vidioc_try_fmt_vid_cap_mplane	= mdp_m2m_try_fmt_mplane,
+	.vidioc_try_fmt_vid_out_mplane	= mdp_m2m_try_fmt_mplane,
+	.vidioc_reqbufs			= mdp_m2m_reqbufs,
+	.vidioc_querybuf		= v4l2_m2m_ioctl_querybuf,
+	.vidioc_qbuf			= v4l2_m2m_ioctl_qbuf,
+	.vidioc_expbuf			= v4l2_m2m_ioctl_expbuf,
+	.vidioc_dqbuf			= v4l2_m2m_ioctl_dqbuf,
+	.vidioc_create_bufs		= v4l2_m2m_ioctl_create_bufs,
+	.vidioc_streamon		= mdp_m2m_streamon,
+	.vidioc_streamoff		= v4l2_m2m_ioctl_streamoff,
+	.vidioc_g_selection		= mdp_m2m_g_selection,
+	.vidioc_s_selection		= mdp_m2m_s_selection,
+	.vidioc_subscribe_event		= v4l2_ctrl_subscribe_event,
+	.vidioc_unsubscribe_event	= v4l2_event_unsubscribe,
+};
+
+static int mdp_m2m_queue_init(void *priv,
+			      struct vb2_queue *src_vq,
+			      struct vb2_queue *dst_vq)
+{
+	struct mdp_m2m_ctx *ctx = priv;
+	int ret;
+
+	/* memset(src_vq, 0, sizeof(*src_vq)); */
+	src_vq->type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	src_vq->io_modes = VB2_MMAP | VB2_DMABUF;
+	src_vq->ops = &mdp_m2m_qops;
+	src_vq->mem_ops = &vb2_dma_contig_memops;
+	src_vq->drv_priv = ctx;
+	src_vq->buf_struct_size = sizeof(struct v4l2_m2m_buffer);
+	src_vq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_COPY;
+	src_vq->dev = &ctx->mdp_dev->pdev->dev;
+
+	ret = vb2_queue_init(src_vq);
+	if (ret)
+		return ret;
+
+	/* memset(dst_vq, 0, sizeof(*dst_vq)); */
+	dst_vq->type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	dst_vq->io_modes = VB2_MMAP | VB2_DMABUF;
+	dst_vq->ops = &mdp_m2m_qops;
+	dst_vq->mem_ops = &vb2_dma_contig_memops;
+	dst_vq->drv_priv = ctx;
+	dst_vq->buf_struct_size = sizeof(struct v4l2_m2m_buffer);
+	dst_vq->timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_COPY;
+	dst_vq->dev = &ctx->mdp_dev->pdev->dev;
+
+	return vb2_queue_init(dst_vq);
+}
+
+static int mdp_m2m_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	struct mdp_m2m_ctx *ctx = ctrl_to_ctx(ctrl);
+	struct mdp_frame *capture;
+
+	if (ctrl->flags & V4L2_CTRL_FLAG_INACTIVE)
+		return 0;
+
+	capture = ctx_get_frame(ctx, V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+	switch (ctrl->id) {
+	case V4L2_CID_HFLIP:
+		capture->hflip = ctrl->val;
+		break;
+	case V4L2_CID_VFLIP:
+		capture->vflip = ctrl->val;
+		break;
+	case V4L2_CID_ROTATE:
+		if (mdp_m2m_ctx_is_state_set(ctx,
+					     MDP_M2M_DST_FMT |
+					     MDP_M2M_SRC_FMT)) {
+			int ret = mdp_check_scaling_ratio(&capture->crop.c,
+				&capture->compose, ctrl->val,
+				ctx->curr_param->limit);
+
+			if (ret)
+				return ret;
+		}
+		capture->rotation = ctrl->val;
+		break;
+	}
+
+	return 0;
+}
+
+static const struct v4l2_ctrl_ops mdp_m2m_ctrl_ops = {
+	.s_ctrl	= mdp_m2m_s_ctrl,
+};
+
+static int mdp_m2m_ctrls_create(struct mdp_m2m_ctx *ctx)
+{
+	v4l2_ctrl_handler_init(&ctx->ctrl_handler, MDP_MAX_CTRLS);
+	ctx->ctrls.hflip = v4l2_ctrl_new_std(&ctx->ctrl_handler,
+					     &mdp_m2m_ctrl_ops, V4L2_CID_HFLIP,
+					     0, 1, 1, 0);
+	ctx->ctrls.vflip = v4l2_ctrl_new_std(&ctx->ctrl_handler,
+					     &mdp_m2m_ctrl_ops, V4L2_CID_VFLIP,
+					     0, 1, 1, 0);
+	ctx->ctrls.rotate = v4l2_ctrl_new_std(&ctx->ctrl_handler,
+					      &mdp_m2m_ctrl_ops,
+					      V4L2_CID_ROTATE, 0, 270, 90, 0);
+
+	if (ctx->ctrl_handler.error) {
+		int err = ctx->ctrl_handler.error;
+
+		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
+		dev_err(&ctx->mdp_dev->pdev->dev,
+			"Failed to create control handler\n");
+		return err;
+	}
+	return 0;
+}
+
+static int mdp_m2m_open(struct file *file)
+{
+	struct video_device *vdev = video_devdata(file);
+	struct mdp_dev *mdp = video_get_drvdata(vdev);
+	struct mdp_m2m_ctx *ctx;
+	int ret;
+
+	ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
+	if (!ctx)
+		return -ENOMEM;
+
+	if (mutex_lock_interruptible(&mdp->m2m_lock)) {
+		ret = -ERESTARTSYS;
+		goto err_lock;
+	}
+
+	ctx->id = mdp->id_count++;
+	ctx->mdp_dev = mdp;
+
+	v4l2_fh_init(&ctx->fh, vdev);
+	file->private_data = &ctx->fh;
+	ret = mdp_m2m_ctrls_create(ctx);
+	if (ret)
+		goto err_ctrls_create;
+
+	/* Use separate control handler per file handle */
+	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
+	v4l2_fh_add(&ctx->fh);
+
+	ctx->m2m_ctx = v4l2_m2m_ctx_init(mdp->m2m_dev, ctx, mdp_m2m_queue_init);
+	if (IS_ERR(ctx->m2m_ctx)) {
+		dev_err(&mdp->pdev->dev, "Failed to initialize m2m context\n");
+		ret = PTR_ERR(ctx->m2m_ctx);
+		goto err_m2m_ctx;
+	}
+	ctx->fh.m2m_ctx = ctx->m2m_ctx;
+
+	INIT_WORK(&ctx->work, mdp_m2m_worker);
+	ctx->frame_count = 1;
+
+	ctx->curr_param = mdp_frameparam_init();
+	if (IS_ERR(ctx->curr_param)) {
+		dev_err(&mdp->pdev->dev,
+			"Failed to initialize mdp parameter\n");
+		ret = PTR_ERR(ctx->curr_param);
+		goto err_param_init;
+	}
+	ctx->curr_param->type = MDP_STREAM_TYPE_BITBLT;
+
+	INIT_LIST_HEAD(&ctx->param_list);
+	list_add_tail(&ctx->curr_param->list, &ctx->param_list);
+
+	ret = mdp_vpu_get_locked(mdp);
+	if (ret < 0)
+		goto err_load_vpu;
+
+	mutex_unlock(&mdp->m2m_lock);
+
+	mdp_dbg(0, "%s [%d]", dev_name(&mdp->pdev->dev), ctx->id);
+
+	return 0;
+
+err_load_vpu:
+	mdp_frameparam_release(ctx->curr_param);
+err_param_init:
+	v4l2_m2m_ctx_release(ctx->m2m_ctx);
+err_m2m_ctx:
+	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
+	v4l2_fh_del(&ctx->fh);
+err_ctrls_create:
+	v4l2_fh_exit(&ctx->fh);
+	mutex_unlock(&mdp->m2m_lock);
+err_lock:
+	kfree(ctx);
+
+	return ret;
+}
+
+static int mdp_m2m_release(struct file *file)
+{
+	struct mdp_m2m_ctx *ctx = fh_to_ctx(file->private_data);
+	struct mdp_dev *mdp = video_drvdata(file);
+	struct mdp_frameparam *param, *n;
+
+	flush_workqueue(mdp->job_wq);
+	mutex_lock(&mdp->m2m_lock);
+	if (mdp_m2m_ctx_is_state_set(ctx, MDP_VPU_INIT))
+		mdp_vpu_ctx_deinit(&ctx->vpu);
+	mdp_vpu_put_locked(mdp);
+	list_for_each_entry_safe(param, n, &ctx->param_list, list) {
+		mdp_frameparam_release(param);
+	}
+
+	v4l2_m2m_ctx_release(ctx->m2m_ctx);
+	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
+	v4l2_fh_del(&ctx->fh);
+	v4l2_fh_exit(&ctx->fh);
+	mutex_unlock(&mdp->m2m_lock);
+
+	mdp_dbg(0, "%s [%d]", dev_name(&mdp->pdev->dev), ctx->id);
+	kfree(ctx);
+
+	return 0;
+}
+
+static const struct v4l2_file_operations mdp_m2m_fops = {
+	.owner		= THIS_MODULE,
+	.poll		= v4l2_m2m_fop_poll,
+	.unlocked_ioctl	= video_ioctl2,
+	.mmap		= v4l2_m2m_fop_mmap,
+	.open		= mdp_m2m_open,
+	.release	= mdp_m2m_release,
+};
+
+static const struct v4l2_m2m_ops mdp_m2m_ops = {
+	.device_run	= mdp_m2m_device_run,
+	.job_abort	= mdp_m2m_job_abort,
+};
+
+int mdp_m2m_device_register(struct mdp_dev *mdp)
+{
+	struct device *dev = &mdp->pdev->dev;
+	int ret = 0;
+
+	mdp->m2m_vdev = video_device_alloc();
+	if (!mdp->m2m_vdev) {
+		dev_err(dev, "Failed to allocate video device\n");
+		ret = -ENOMEM;
+		goto err_video_alloc;
+	}
+	//mdp->m2m_vdev->device_caps = V4L2_CAP_VIDEO_M2M_MPLANE |
+	//	V4L2_CAP_STREAMING;
+	mdp->m2m_vdev->fops = &mdp_m2m_fops;
+	mdp->m2m_vdev->ioctl_ops = &mdp_m2m_ioctl_ops;
+	mdp->m2m_vdev->release = video_device_release;
+	mdp->m2m_vdev->lock = &mdp->m2m_lock;
+	mdp->m2m_vdev->vfl_dir = VFL_DIR_M2M;
+	mdp->m2m_vdev->v4l2_dev = &mdp->v4l2_dev;
+	snprintf(mdp->m2m_vdev->name, sizeof(mdp->m2m_vdev->name), "%s:m2m",
+		 MDP_MODULE_NAME);
+	video_set_drvdata(mdp->m2m_vdev, mdp);
+
+	mdp->m2m_dev = v4l2_m2m_init(&mdp_m2m_ops);
+	if (IS_ERR(mdp->m2m_dev)) {
+		dev_err(dev, "Failed to initialize v4l2-m2m device\n");
+		ret = PTR_ERR(mdp->m2m_dev);
+		goto err_m2m_init;
+	}
+
+	ret = video_register_device(mdp->m2m_vdev, VFL_TYPE_GRABBER, 2);
+	if (ret) {
+		dev_err(dev, "Failed to register video device\n");
+		goto err_video_register;
+	}
+
+	v4l2_info(&mdp->v4l2_dev, "Driver registered as /dev/video%d",
+		  mdp->m2m_vdev->num);
+	return 0;
+
+err_video_register:
+	v4l2_m2m_release(mdp->m2m_dev);
+err_m2m_init:
+	video_device_release(mdp->m2m_vdev);
+err_video_alloc:
+
+	return ret;
+}
+
+void mdp_m2m_device_unregister(struct mdp_dev *mdp)
+{
+	video_unregister_device(mdp->m2m_vdev);
+	video_device_release(mdp->m2m_vdev);
+	v4l2_m2m_release(mdp->m2m_dev);
+}
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.h
new file mode 100644
index 000000000000..1f681b48c2ad
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-m2m.h
@@ -0,0 +1,52 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_M2M_H__
+#define __MTK_MDP3_M2M_H__
+
+#include <media/v4l2-ctrls.h>
+#include "mtk-mdp3-core.h"
+#include "mtk-mdp3-vpu.h"
+#include "mtk-mdp3-regs.h"
+
+#define MDP_MAX_CTRLS	10
+
+struct mdp_m2m_ctrls {
+	struct v4l2_ctrl	*hflip;
+	struct v4l2_ctrl	*vflip;
+	/* struct v4l2_ctrl	*sharpness; */
+	struct v4l2_ctrl	*rotate;
+};
+
+struct mdp_m2m_ctx {
+	u32				id;
+	struct mdp_dev			*mdp_dev;
+	struct v4l2_fh			fh;
+	struct v4l2_ctrl_handler	ctrl_handler;
+	struct mdp_m2m_ctrls		ctrls;
+	struct v4l2_m2m_ctx		*m2m_ctx;
+	struct mdp_vpu_ctx		vpu;
+	struct work_struct		work;
+	u32				frame_count;
+
+	struct mdp_frameparam		*curr_param;
+	struct list_head		param_list;
+};
+
+int mdp_m2m_device_register(struct mdp_dev *mdp);
+void mdp_m2m_device_unregister(struct mdp_dev *mdp);
+
+#endif  /* __MTK_MDP3_M2M_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.c
new file mode 100644
index 000000000000..9ac79286216c
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.c
@@ -0,0 +1,778 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <media/v4l2-common.h>
+#include <media/videobuf2-v4l2.h>
+#include <media/videobuf2-dma-contig.h>
+#include "mtk-mdp3-core.h"
+#include "mtk-mdp3-regs.h"
+
+static const struct mdp_format mdp_formats[] = {
+	{
+		.pixelformat	= V4L2_PIX_FMT_GREY,
+		.mdp_color	= MDP_COLOR_GREY,
+		.depth		= { 8 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_RGB565X,
+		.mdp_color	= MDP_COLOR_RGB565,
+		.depth		= { 16 },
+		.row_depth	= { 16 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_RGB565,
+		.mdp_color	= MDP_COLOR_BGR565,
+		.depth		= { 16 },
+		.row_depth	= { 16 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_RGB24,
+		.mdp_color	= MDP_COLOR_RGB888,
+		.depth		= { 24 },
+		.row_depth	= { 24 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_BGR24,
+		.mdp_color	= MDP_COLOR_BGR888,
+		.depth		= { 24 },
+		.row_depth	= { 24 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_ABGR32,
+		.mdp_color	= MDP_COLOR_BGRA8888,
+		.depth		= { 32 },
+		.row_depth	= { 32 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_ARGB32,
+		.mdp_color	= MDP_COLOR_ARGB8888,
+		.depth		= { 32 },
+		.row_depth	= { 32 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_UYVY,
+		.mdp_color	= MDP_COLOR_UYVY,
+		.depth		= { 16 },
+		.row_depth	= { 16 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_VYUY,
+		.mdp_color	= MDP_COLOR_VYUY,
+		.depth		= { 16 },
+		.row_depth	= { 16 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_YUYV,
+		.mdp_color	= MDP_COLOR_YUYV,
+		.depth		= { 16 },
+		.row_depth	= { 16 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_YVYU,
+		.mdp_color	= MDP_COLOR_YVYU,
+		.depth		= { 16 },
+		.row_depth	= { 16 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_YUV420,
+		.mdp_color	= MDP_COLOR_I420,
+		.depth		= { 12 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_YVU420,
+		.mdp_color	= MDP_COLOR_YV12,
+		.depth		= { 12 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV12,
+		.mdp_color	= MDP_COLOR_NV12,
+		.depth		= { 12 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV21,
+		.mdp_color	= MDP_COLOR_NV21,
+		.depth		= { 12 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV16,
+		.mdp_color	= MDP_COLOR_NV16,
+		.depth		= { 16 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV61,
+		.mdp_color	= MDP_COLOR_NV61,
+		.depth		= { 16 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV24,
+		.mdp_color	= MDP_COLOR_NV24,
+		.depth		= { 24 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV42,
+		.mdp_color	= MDP_COLOR_NV42,
+		.depth		= { 24 },
+		.row_depth	= { 8 },
+		.num_planes	= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_MT21C,
+		.mdp_color	= MDP_COLOR_420_BLK_UFO,
+		.depth		= { 8, 4 },
+		.row_depth	= { 8, 8 },
+		.num_planes	= 2,
+		.walign		= 4,
+		.halign		= 5,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV12MT,
+		.mdp_color	= MDP_COLOR_420_BLK,
+		.depth		= { 8, 4 },
+		.row_depth	= { 8, 8 },
+		.num_planes	= 2,
+		.walign		= 4,
+		.halign		= 5,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV12M,
+		.mdp_color	= MDP_COLOR_NV12,
+		.depth		= { 8, 4 },
+		.row_depth	= { 8, 8 },
+		.num_planes	= 2,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV21M,
+		.mdp_color	= MDP_COLOR_NV21,
+		.depth		= { 8, 4 },
+		.row_depth	= { 8, 8 },
+		.num_planes	= 2,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV16M,
+		.mdp_color	= MDP_COLOR_NV16,
+		.depth		= { 8, 8 },
+		.row_depth	= { 8, 8 },
+		.num_planes	= 2,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_NV61M,
+		.mdp_color	= MDP_COLOR_NV61,
+		.depth		= { 8, 8 },
+		.row_depth	= { 8, 8 },
+		.num_planes	= 2,
+		.walign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_YUV420M,
+		.mdp_color	= MDP_COLOR_I420,
+		.depth		= { 8, 2, 2 },
+		.row_depth	= { 8, 4, 4 },
+		.num_planes	= 3,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}, {
+		.pixelformat	= V4L2_PIX_FMT_YVU420M,
+		.mdp_color	= MDP_COLOR_YV12,
+		.depth		= { 8, 2, 2 },
+		.row_depth	= { 8, 4, 4 },
+		.num_planes	= 3,
+		.walign		= 1,
+		.halign		= 1,
+		.flags		= MDP_FMT_FLAG_OUTPUT | MDP_FMT_FLAG_CAPTURE,
+	}
+};
+
+static const struct mdp_limit mdp_def_limit = {
+	.out_limit = {
+		.wmin	= 16,
+		.hmin	= 16,
+		.wmax	= 19200,
+		.hmax	= 8176,
+	},
+	.cap_limit = {
+		.wmin	= 2,
+		.hmin	= 2,
+		.wmax	= 8176,
+		.hmax	= 8176,
+	},
+	.h_scale_up_max = 32,
+	.v_scale_up_max = 32,
+	.h_scale_down_max = 20,
+	.v_scale_down_max = 128,
+};
+
+static const struct mdp_format *mdp_find_fmt(u32 pixelformat, u32 type)
+{
+	u32 i, flag;
+
+	flag = V4L2_TYPE_IS_OUTPUT(type) ? MDP_FMT_FLAG_OUTPUT :
+					MDP_FMT_FLAG_CAPTURE;
+	for (i = 0; i < ARRAY_SIZE(mdp_formats); ++i) {
+		if (!(mdp_formats[i].flags & flag))
+			continue;
+		if (mdp_formats[i].pixelformat == pixelformat)
+			return &mdp_formats[i];
+	}
+	return NULL;
+}
+
+static const struct mdp_format *mdp_find_fmt_by_index(u32 index, u32 type)
+{
+	u32 i, flag, num = 0;
+
+	flag = V4L2_TYPE_IS_OUTPUT(type) ? MDP_FMT_FLAG_OUTPUT :
+					MDP_FMT_FLAG_CAPTURE;
+	for (i = 0; i < ARRAY_SIZE(mdp_formats); ++i) {
+		if (!(mdp_formats[i].flags & flag))
+			continue;
+		if (index == num)
+			return &mdp_formats[i];
+		num++;
+	}
+	return NULL;
+}
+
+/*
+ * Unlike the standard v4l2 video capture,
+ * MDP can specify the colorspace from the application.
+ */
+static void mdp_try_colsp_vid_cap_mplane(struct v4l2_pix_format_mplane *pix_mp,
+					 u32 mdp_color)
+{
+	if (MDP_COLOR_IS_RGB(mdp_color)) {
+		pix_mp->colorspace = V4L2_COLORSPACE_SRGB;
+		pix_mp->xfer_func = V4L2_XFER_FUNC_SRGB;
+		pix_mp->ycbcr_enc = V4L2_YCBCR_ENC_601;
+		pix_mp->quantization = V4L2_QUANTIZATION_FULL_RANGE;
+		return;
+	}
+
+	if (pix_mp->colorspace != V4L2_COLORSPACE_REC709 &&
+	    pix_mp->colorspace != V4L2_COLORSPACE_JPEG)
+		pix_mp->colorspace = V4L2_COLORSPACE_SRGB;
+	pix_mp->xfer_func = V4L2_MAP_XFER_FUNC_DEFAULT(pix_mp->colorspace);
+	pix_mp->ycbcr_enc = V4L2_MAP_YCBCR_ENC_DEFAULT(pix_mp->colorspace);
+	pix_mp->quantization = V4L2_MAP_QUANTIZATION_DEFAULT(false,
+							     pix_mp->colorspace,
+							     pix_mp->ycbcr_enc);
+}
+
+enum mdp_ycbcr_profile mdp_map_ycbcr_prof_mplane(struct v4l2_format *f,
+						 u32 mdp_color)
+{
+	struct v4l2_pix_format_mplane *pix_mp = &f->fmt.pix_mp;
+
+	if (MDP_COLOR_IS_RGB(mdp_color))
+		return MDP_YCBCR_PROFILE_FULL_BT601;
+
+	switch (pix_mp->colorspace) {
+	case V4L2_COLORSPACE_JPEG:
+		return MDP_YCBCR_PROFILE_JPEG;
+	case V4L2_COLORSPACE_REC709:
+	case V4L2_COLORSPACE_DCI_P3:
+		if (pix_mp->quantization == V4L2_QUANTIZATION_FULL_RANGE)
+			return MDP_YCBCR_PROFILE_FULL_BT709;
+		return MDP_YCBCR_PROFILE_BT709;
+	case V4L2_COLORSPACE_BT2020:
+		if (pix_mp->quantization == V4L2_QUANTIZATION_FULL_RANGE)
+			return MDP_YCBCR_PROFILE_FULL_BT2020;
+		return MDP_YCBCR_PROFILE_BT2020;
+	}
+	/* V4L2_COLORSPACE_SRGB or else */
+	if (pix_mp->quantization == V4L2_QUANTIZATION_FULL_RANGE)
+		return MDP_YCBCR_PROFILE_FULL_BT601;
+	return MDP_YCBCR_PROFILE_BT601;
+}
+
+static void mdp_bound_align_image(u32 *w, unsigned int wmin, unsigned int wmax,
+				  unsigned int walign,
+				u32 *h, unsigned int hmin, unsigned int hmax,
+				unsigned int halign, unsigned int salign)
+{
+	unsigned int org_w, org_h, wstep, hstep;
+
+	org_w = *w;
+	org_h = *h;
+	v4l_bound_align_image(w, wmin, wmax, walign, h, hmin, hmax, halign,
+			      salign);
+
+	wstep = 1 << walign;
+	hstep = 1 << halign;
+	if (*w < org_w && (*w + wstep) <= wmax)
+		*w += wstep;
+	if (*h < org_h && (*h + hstep) <= hmax)
+		*h += hstep;
+}
+
+static int mdp_clamp_align(s32 *x, int min, int max, unsigned int align)
+{
+	unsigned int mask;
+
+	if (min < 0 || max < 0)
+		return -ERANGE;
+
+	/* Bits that must be zero to be aligned */
+	mask = ~((1 << align) - 1);
+
+	min = 0 ? 0 : ((min + ~mask) & mask);
+	max = max & mask;
+	if ((unsigned int)min > (unsigned int)max)
+		return -ERANGE;
+
+	/* Clamp to aligned min and max */
+	*x = clamp(*x, min, max);
+
+	/* Round to nearest aligned value */
+	if (align)
+		*x = (*x + (1 << (align - 1))) & mask;
+	return 0;
+}
+
+int mdp_enum_fmt_mplane(struct v4l2_fmtdesc *f)
+{
+	const struct mdp_format *fmt;
+
+	if (!V4L2_TYPE_IS_MULTIPLANAR(f->type))
+		return -EINVAL;
+
+	fmt = mdp_find_fmt_by_index(f->index, f->type);
+	if (!fmt)
+		return -EINVAL;
+
+	/* f->description */
+	f->pixelformat = fmt->pixelformat;
+	return 0;
+}
+
+const struct mdp_format *mdp_try_fmt_mplane(struct v4l2_format *f,
+					    const struct mdp_limit *limit,
+					    u32 ctx_id)
+{
+	struct v4l2_pix_format_mplane *pix_mp = &f->fmt.pix_mp;
+	const struct mdp_format *fmt;
+	const struct mdp_pix_limit *pix_limit;
+	u32 wmin, wmax, hmin, hmax, org_w, org_h;
+	unsigned int i;
+
+	if (!V4L2_TYPE_IS_MULTIPLANAR(f->type))
+		return NULL;
+
+	fmt = mdp_find_fmt(pix_mp->pixelformat, f->type);
+	if (!fmt)
+		fmt = mdp_find_fmt_by_index(0, f->type);
+	if (!fmt) {
+		mdp_dbg(0, "[%d] pixelformat %c%c%c%c invalid", ctx_id,
+			(pix_mp->pixelformat & 0xff),
+			(pix_mp->pixelformat >>  8) & 0xff,
+			(pix_mp->pixelformat >> 16) & 0xff,
+			(pix_mp->pixelformat >> 24) & 0xff);
+		return NULL;
+	}
+
+	pix_mp->field = V4L2_FIELD_NONE;
+	pix_mp->flags = 0;
+	pix_mp->pixelformat = fmt->pixelformat;
+	if (!V4L2_TYPE_IS_OUTPUT(f->type))
+		mdp_try_colsp_vid_cap_mplane(pix_mp, fmt->mdp_color);
+	memset(pix_mp->reserved, 0, sizeof(pix_mp->reserved));
+
+	pix_limit = V4L2_TYPE_IS_OUTPUT(f->type) ? &limit->out_limit :
+		&limit->cap_limit;
+	wmin = pix_limit->wmin;
+	wmax = pix_limit->wmax;
+	hmin = pix_limit->hmin;
+	hmax = pix_limit->hmax;
+	org_w = pix_mp->width;
+	org_h = pix_mp->height;
+
+	mdp_bound_align_image(&pix_mp->width, wmin, wmax, fmt->walign,
+			      &pix_mp->height, hmin, hmax, fmt->halign,
+				fmt->salign);
+	if (org_w != pix_mp->width || org_h != pix_mp->height)
+		mdp_dbg(1, "[%d] size change: %ux%u to %ux%u", ctx_id,
+			org_w, org_h, pix_mp->width, pix_mp->height);
+
+	if (pix_mp->num_planes && pix_mp->num_planes != fmt->num_planes)
+		mdp_dbg(1, "[%d] num of planes change: %u to %u", ctx_id,
+			pix_mp->num_planes, fmt->num_planes);
+	pix_mp->num_planes = fmt->num_planes;
+
+	for (i = 0; i < pix_mp->num_planes; ++i) {
+		u32 min_bpl = (pix_mp->width * fmt->row_depth[i]) / 8;
+		u32 bpl = pix_mp->plane_fmt[i].bytesperline;
+		u32 si;
+
+		if (bpl < min_bpl)
+			bpl = min_bpl;
+		si = (bpl * pix_mp->height * fmt->depth[i]) / fmt->row_depth[i];
+
+		pix_mp->plane_fmt[i].bytesperline = bpl;
+		if (pix_mp->plane_fmt[i].sizeimage < si)
+			pix_mp->plane_fmt[i].sizeimage = si;
+		memset(pix_mp->plane_fmt[i].reserved, 0,
+		       sizeof(pix_mp->plane_fmt[i].reserved));
+		mdp_dbg(2, "[%d] p%u, bpl:%u (%u), sizeimage:%u (%u)", ctx_id,
+			i, bpl, min_bpl, pix_mp->plane_fmt[i].sizeimage, si);
+	}
+
+	return fmt;
+}
+
+static inline int mdp_clamp_start(s32 *x, int min, int max, unsigned int align,
+				  u32 flags)
+{
+	if (flags & V4L2_SEL_FLAG_GE)
+		max = *x;
+	if (flags & V4L2_SEL_FLAG_LE)
+		min = *x;
+	return mdp_clamp_align(x, min, max, align);
+}
+
+static inline int mdp_clamp_end(s32 *x, int min, int max, unsigned int align,
+				u32 flags)
+{
+	if (flags & V4L2_SEL_FLAG_GE)
+		min = *x;
+	if (flags & V4L2_SEL_FLAG_LE)
+		max = *x;
+	return mdp_clamp_align(x, min, max, align);
+}
+
+int mdp_try_crop(struct v4l2_rect *r, const struct v4l2_selection *s,
+		 struct mdp_frame *frame, u32 ctx_id)
+{
+	s32 left, top, right, bottom;
+	u32 framew, frameh, walign, halign;
+	int ret;
+
+	mdp_dbg(2, "[%d] target:%d, set:(%d,%d) %ux%u", ctx_id, s->target,
+		s->r.left, s->r.top, s->r.width, s->r.height);
+
+	left = s->r.left;
+	top = s->r.top;
+	right = s->r.left + s->r.width;
+	bottom = s->r.top + s->r.height;
+	framew = frame->format.fmt.pix_mp.width;
+	frameh = frame->format.fmt.pix_mp.height;
+
+	if (mdp_target_is_crop(s->target)) {
+		walign = 1;
+		halign = 1;
+	} else {
+		walign = frame->mdp_fmt->walign;
+		halign = frame->mdp_fmt->halign;
+	}
+
+	mdp_dbg(2, "[%d] align:%u,%u, bound:%ux%u", ctx_id,
+		walign, halign, framew, frameh);
+
+	ret = mdp_clamp_start(&left, 0, right, walign, s->flags);
+	if (ret)
+		return ret;
+	ret = mdp_clamp_start(&top, 0, bottom, halign, s->flags);
+	if (ret)
+		return ret;
+	ret = mdp_clamp_end(&right, left, framew, walign, s->flags);
+	if (ret)
+		return ret;
+	ret = mdp_clamp_end(&bottom, top, frameh, halign, s->flags);
+	if (ret)
+		return ret;
+
+	r->left = left;
+	r->top = top;
+	r->width = right - left;
+	r->height = bottom - top;
+
+	mdp_dbg(2, "[%d] crop:(%d,%d) %ux%u", ctx_id,
+		r->left, r->top, r->width, r->height);
+	return 0;
+}
+
+int mdp_check_scaling_ratio(const struct v4l2_rect *crop,
+			    const struct v4l2_rect *compose, s32 rotation,
+	const struct mdp_limit *limit)
+{
+	u32 crop_w, crop_h, comp_w, comp_h;
+
+	crop_w = crop->width;
+	crop_h = crop->height;
+	if (90 == rotation || 270 == rotation) {
+		comp_w = compose->height;
+		comp_h = compose->width;
+	} else {
+		comp_w = compose->width;
+		comp_h = compose->height;
+	}
+
+	if ((crop_w / comp_w) > limit->h_scale_down_max ||
+	    (crop_h / comp_h) > limit->v_scale_down_max ||
+	    (comp_w / crop_w) > limit->h_scale_up_max ||
+	    (comp_h / crop_h) > limit->v_scale_up_max)
+		return -ERANGE;
+	return 0;
+}
+
+/* Stride that is accepted by MDP HW */
+static u32 mdp_fmt_get_stride(const struct mdp_format *fmt,
+			      u32 bytesperline, unsigned int plane)
+{
+	enum mdp_color c = fmt->mdp_color;
+	u32 stride;
+
+	stride = (bytesperline * MDP_COLOR_BITS_PER_PIXEL(c))
+		/ fmt->row_depth[0];
+	if (plane == 0)
+		return stride;
+	if (plane < MDP_COLOR_GET_PLANE_COUNT(c)) {
+		if (MDP_COLOR_IS_BLOCK_MODE(c))
+			stride = stride / 2;
+		return stride;
+	}
+	return 0;
+}
+
+/* Stride that is accepted by MDP HW of format with contiguous planes */
+static u32 mdp_fmt_get_stride_contig(const struct mdp_format *fmt,
+				     u32 pix_stride, unsigned int plane)
+{
+	enum mdp_color c = fmt->mdp_color;
+	u32 stride = pix_stride;
+
+	if (plane == 0)
+		return stride;
+	if (plane < MDP_COLOR_GET_PLANE_COUNT(c)) {
+		stride = stride >> MDP_COLOR_GET_H_SUBSAMPLE(c);
+		if (MDP_COLOR_IS_UV_COPLANE(c) && !MDP_COLOR_IS_BLOCK_MODE(c))
+			stride = stride * 2;
+		return stride;
+	}
+	return 0;
+}
+
+/* Plane size that is accepted by MDP HW */
+static u32 mdp_fmt_get_plane_size(const struct mdp_format *fmt,
+				  u32 stride, u32 height, unsigned int plane)
+{
+	enum mdp_color c = fmt->mdp_color;
+	u32 bytesperline;
+
+	bytesperline = (stride * fmt->row_depth[0])
+		/ MDP_COLOR_BITS_PER_PIXEL(c);
+	if (plane == 0)
+		return bytesperline * height;
+	if (plane < MDP_COLOR_GET_PLANE_COUNT(c)) {
+		height = height >> MDP_COLOR_GET_V_SUBSAMPLE(c);
+		if (MDP_COLOR_IS_BLOCK_MODE(c))
+			bytesperline = bytesperline * 2;
+		return bytesperline * height;
+	}
+	return 0;
+}
+
+static void mdp_prepare_buffer(struct img_image_buffer *b,
+			       struct mdp_frame *frame, struct vb2_buffer *vb)
+{
+	struct v4l2_pix_format_mplane *pix_mp = &frame->format.fmt.pix_mp;
+	unsigned int i;
+
+	b->format.colorformat = frame->mdp_fmt->mdp_color;
+	b->format.ycbcr_prof = frame->ycbcr_prof;
+	for (i = 0; i < pix_mp->num_planes; ++i) {
+		u32 stride = mdp_fmt_get_stride(frame->mdp_fmt,
+			pix_mp->plane_fmt[i].bytesperline, i);
+
+		b->format.plane_fmt[i].stride = stride;
+		b->format.plane_fmt[i].size =
+			mdp_fmt_get_plane_size(frame->mdp_fmt, stride,
+					       pix_mp->height, i);
+		b->iova[i] = vb2_dma_contig_plane_dma_addr(vb, i);
+	}
+	for (; i < MDP_COLOR_GET_PLANE_COUNT(b->format.colorformat); ++i) {
+		u32 stride = mdp_fmt_get_stride_contig(frame->mdp_fmt,
+			b->format.plane_fmt[0].stride, i);
+
+		b->format.plane_fmt[i].stride = stride;
+		b->format.plane_fmt[i].size =
+			mdp_fmt_get_plane_size(frame->mdp_fmt, stride,
+					       pix_mp->height, i);
+		b->iova[i] = b->iova[i - 1] + b->format.plane_fmt[i - 1].size;
+	}
+	b->usage = frame->usage;
+}
+
+void mdp_set_src_config(struct img_input *in,
+			struct mdp_frame *frame, struct vb2_buffer *vb)
+{
+	in->buffer.format.width = frame->format.fmt.pix_mp.width;
+	in->buffer.format.height = frame->format.fmt.pix_mp.height;
+	mdp_prepare_buffer(&in->buffer, frame, vb);
+
+	/* in->flags |= ; */	/* HDR, DRE, dither */
+}
+
+static u32 mdp_to_fixed(u32 *r, struct v4l2_fract *f)
+{
+	u32 q;
+
+	if (f->denominator == 0) {
+		*r = 0;
+		return 0;
+	}
+
+	q = f->numerator / f->denominator;
+	*r = (((u64)f->numerator - q * f->denominator) << IMG_SUBPIXEL_SHIFT)
+		/ f->denominator;
+	return q;
+}
+
+static void mdp_set_src_crop(struct img_crop *c, struct mdp_crop *crop)
+{
+	c->left = crop->c.left
+		+ mdp_to_fixed(&c->left_subpix, &crop->left_subpix);
+	c->top = crop->c.top
+		+ mdp_to_fixed(&c->top_subpix, &crop->top_subpix);
+	c->width = crop->c.width
+		+ mdp_to_fixed(&c->width_subpix, &crop->width_subpix);
+	c->height = crop->c.height
+		+ mdp_to_fixed(&c->height_subpix, &crop->height_subpix);
+}
+
+static void mdp_set_orientation(struct img_output *out,
+				s32 rotation, bool hflip, bool vflip)
+{
+	u8 flip = 0;
+
+	if (hflip)
+		flip ^= 1;
+	if (vflip) {
+		/*
+		 * A vertical flip is equivalent to
+		 * a 180-degree rotation with a horizontal flip
+		 */
+		rotation += 180;
+		flip ^= 1;
+	}
+
+	out->rotation = rotation % 360;
+	if (flip != 0)
+		out->flags |= IMG_CTRL_FLAG_HFLIP;
+	else
+		out->flags &= ~IMG_CTRL_FLAG_HFLIP;
+}
+
+void mdp_set_dst_config(struct img_output *out,
+			struct mdp_frame *frame, struct vb2_buffer *vb)
+{
+	out->buffer.format.width = frame->compose.width;
+	out->buffer.format.height = frame->compose.height;
+	mdp_prepare_buffer(&out->buffer, frame, vb);
+	mdp_set_src_crop(&out->crop, &frame->crop);
+	mdp_set_orientation(out, frame->rotation, frame->hflip, frame->vflip);
+
+	/* out->flags |= ; */	/* sharpness, dither */
+}
+
+struct mdp_frameparam *mdp_frameparam_init(void)
+{
+	struct mdp_frameparam *param;
+	struct mdp_frame *frame;
+
+	param = kzalloc(sizeof(*param), GFP_KERNEL);
+	if (!param)
+		return ERR_PTR(-ENOMEM);
+
+	INIT_LIST_HEAD(&param->list);
+	mutex_init(&param->lock);
+	param->state = 0;
+	param->limit = &mdp_def_limit;
+	param->type = MDP_STREAM_TYPE_UNKNOWN;
+	param->frame_no = 0;
+
+	frame = &param->output;
+	frame->format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+	frame->mdp_fmt = mdp_try_fmt_mplane(&frame->format, param->limit, 0);
+	frame->ycbcr_prof =
+		mdp_map_ycbcr_prof_mplane(&frame->format,
+					  frame->mdp_fmt->mdp_color);
+	frame->usage = MDP_BUFFER_USAGE_HW_READ;
+
+	param->num_captures = 1;
+	frame = &param->captures[0];
+	frame->format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+	frame->mdp_fmt = mdp_try_fmt_mplane(&frame->format, param->limit, 0);
+	frame->ycbcr_prof =
+		mdp_map_ycbcr_prof_mplane(&frame->format,
+					  frame->mdp_fmt->mdp_color);
+	frame->usage = MDP_BUFFER_USAGE_MDP;
+	frame->crop.c.width = param->output.format.fmt.pix_mp.width;
+	frame->crop.c.height = param->output.format.fmt.pix_mp.height;
+	frame->compose.width = frame->format.fmt.pix_mp.width;
+	frame->compose.height = frame->format.fmt.pix_mp.height;
+
+	return param;
+}
+
+void mdp_frameparam_release(struct mdp_frameparam *param)
+{
+	kfree(param);
+}
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.h
new file mode 100644
index 000000000000..daf2a4d2a935
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-regs.h
@@ -0,0 +1,388 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_REGS_H__
+#define __MTK_MDP3_REGS_H__
+
+#include <linux/io.h>
+#include <linux/videodev2.h>
+#include <media/videobuf2-core.h>
+#include "mtk-img-ipi.h"
+
+/*
+ * MDP native color code
+ * Plane count: 1, 2, 3
+ * H-subsample: 0, 1, 2
+ * V-subsample: 0, 1
+ * Color group: 0-RGB, 1-YUV, 2-raw
+ */
+#define MDP_COLOR(PACKED, LOOSE, VIDEO, PLANE, HF, VF, BITS, GROUP, SWAP, ID)\
+	(((PACKED) << 27) | ((LOOSE) << 26) | ((VIDEO) << 23) |\
+	 ((PLANE) << 21) | ((HF) << 19) | ((VF) << 18) | ((BITS) << 8) |\
+	 ((GROUP) << 6) | ((SWAP) << 5) | ((ID) << 0))
+
+#define MDP_COLOR_IS_10BIT_PACKED(c)    ((0x08000000 & (c)) >> 27)
+#define MDP_COLOR_IS_10BIT_LOOSE(c)    (((0x0c000000 & (c)) >> 26) == 1)
+#define MDP_COLOR_IS_10BIT_TILE(c)     (((0x0c000000 & (c)) >> 26) == 3)
+#define MDP_COLOR_IS_UFP(c)             ((0x02000000 & (c)) >> 25)
+#define MDP_COLOR_IS_INTERLACED(c)      ((0x01000000 & (c)) >> 24)
+#define MDP_COLOR_IS_BLOCK_MODE(c)      ((0x00800000 & (c)) >> 23)
+#define MDP_COLOR_GET_PLANE_COUNT(c)    ((0x00600000 & (c)) >> 21)
+#define MDP_COLOR_GET_H_SUBSAMPLE(c)    ((0x00180000 & (c)) >> 19)
+#define MDP_COLOR_GET_V_SUBSAMPLE(c)    ((0x00040000 & (c)) >> 18)
+#define MDP_COLOR_BITS_PER_PIXEL(c)     ((0x0003ff00 & (c)) >>  8)
+#define MDP_COLOR_GET_GROUP(c)          ((0x000000c0 & (c)) >>  6)
+#define MDP_COLOR_IS_SWAPPED(c)         ((0x00000020 & (c)) >>  5)
+#define MDP_COLOR_GET_UNIQUE_ID(c)      ((0x0000001f & (c)) >>  0)
+#define MDP_COLOR_GET_HW_FORMAT(c)      ((0x0000001f & (c)) >>  0)
+
+#define MDP_COLOR_IS_RGB(c)		(MDP_COLOR_GET_GROUP(c) == 0)
+#define MDP_COLOR_IS_YUV(c)		(MDP_COLOR_GET_GROUP(c) == 1)
+#define MDP_COLOR_IS_UV_COPLANE(c)	((MDP_COLOR_GET_PLANE_COUNT(c) == 2) &&\
+					 MDP_COLOR_IS_YUV(c))
+
+#define MDP_REG_GET32(addr)	(readl((void *)addr) & 0xffffffff)
+#define MDP_REG_GET16(addr)	(readl((void *)addr) & 0x0000ffff)
+
+#define MDP_REG_SET32(addr, val)	writel(val, addr)
+
+enum mdp_color {
+	MDP_COLOR_UNKNOWN	= 0,
+
+	//MDP_COLOR_FULLG8,
+	MDP_COLOR_FULLG8_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0,  8, 2,  0, 21),
+	MDP_COLOR_FULLG8_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1,  8, 2,  0, 21),
+	MDP_COLOR_FULLG8_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0,  8, 2,  0, 21),
+	MDP_COLOR_FULLG8_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1,  8, 2,  0, 21),
+	MDP_COLOR_FULLG8	= MDP_COLOR_FULLG8_BGGR,
+
+	//MDP_COLOR_FULLG10,
+	MDP_COLOR_FULLG10_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0, 10, 2,  0, 21),
+	MDP_COLOR_FULLG10_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1, 10, 2,  0, 21),
+	MDP_COLOR_FULLG10_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0, 10, 2,  0, 21),
+	MDP_COLOR_FULLG10_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1, 10, 2,  0, 21),
+	MDP_COLOR_FULLG10	= MDP_COLOR_FULLG10_BGGR,
+
+	//MDP_COLOR_FULLG12,
+	MDP_COLOR_FULLG12_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0, 12, 2,  0, 21),
+	MDP_COLOR_FULLG12_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1, 12, 2,  0, 21),
+	MDP_COLOR_FULLG12_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0, 12, 2,  0, 21),
+	MDP_COLOR_FULLG12_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1, 12, 2,  0, 21),
+	MDP_COLOR_FULLG12	= MDP_COLOR_FULLG12_BGGR,
+
+	//MDP_COLOR_FULLG14,
+	MDP_COLOR_FULLG14_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0, 14, 2,  0, 21),
+	MDP_COLOR_FULLG14_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1, 14, 2,  0, 21),
+	MDP_COLOR_FULLG14_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0, 14, 2,  0, 21),
+	MDP_COLOR_FULLG14_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1, 14, 2,  0, 21),
+	MDP_COLOR_FULLG14	= MDP_COLOR_FULLG14_BGGR,
+
+	MDP_COLOR_UFO10		= MDP_COLOR(0, 0, 0, 1, 0, 0, 10, 2,  0, 24),
+
+	//MDP_COLOR_BAYER8,
+	MDP_COLOR_BAYER8_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0,  8, 2,  0, 20),
+	MDP_COLOR_BAYER8_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1,  8, 2,  0, 20),
+	MDP_COLOR_BAYER8_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0,  8, 2,  0, 20),
+	MDP_COLOR_BAYER8_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1,  8, 2,  0, 20),
+	MDP_COLOR_BAYER8	= MDP_COLOR_BAYER8_BGGR,
+
+	//MDP_COLOR_BAYER10,
+	MDP_COLOR_BAYER10_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0, 10, 2,  0, 20),
+	MDP_COLOR_BAYER10_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1, 10, 2,  0, 20),
+	MDP_COLOR_BAYER10_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0, 10, 2,  0, 20),
+	MDP_COLOR_BAYER10_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1, 10, 2,  0, 20),
+	MDP_COLOR_BAYER10	= MDP_COLOR_BAYER10_BGGR,
+
+	//MDP_COLOR_BAYER12,
+	MDP_COLOR_BAYER12_RGGB	= MDP_COLOR(0, 0, 0, 1, 0, 0, 12, 2,  0, 20),
+	MDP_COLOR_BAYER12_GRBG	= MDP_COLOR(0, 0, 0, 1, 0, 1, 12, 2,  0, 20),
+	MDP_COLOR_BAYER12_GBRG	= MDP_COLOR(0, 0, 0, 1, 1, 0, 12, 2,  0, 20),
+	MDP_COLOR_BAYER12_BGGR	= MDP_COLOR(0, 0, 0, 1, 1, 1, 12, 2,  0, 20),
+	MDP_COLOR_BAYER12	= MDP_COLOR_BAYER12_BGGR,
+
+	MDP_COLOR_RGB48		= MDP_COLOR(0, 0, 0, 1, 0, 0, 48, 0,  0, 23),
+	/* For bayer+mono raw-16 */
+	MDP_COLOR_RGB565_RAW	= MDP_COLOR(0, 0, 0, 1, 0, 0, 16, 2,  0, 0),
+
+	MDP_COLOR_BAYER8_UNPAK	= MDP_COLOR(0, 0, 0, 1, 0, 0,  8, 2,  0, 22),
+	MDP_COLOR_BAYER10_UNPAK	= MDP_COLOR(0, 0, 0, 1, 0, 0, 10, 2,  0, 22),
+	MDP_COLOR_BAYER12_UNPAK	= MDP_COLOR(0, 0, 0, 1, 0, 0, 12, 2,  0, 22),
+	MDP_COLOR_BAYER14_UNPAK	= MDP_COLOR(0, 0, 0, 1, 0, 0, 14, 2,  0, 22),
+
+	/* Unified formats */
+	MDP_COLOR_GREY		= MDP_COLOR(0, 0, 0, 1, 0, 0,  8, 1,  0, 7),
+
+	MDP_COLOR_RGB565	= MDP_COLOR(0, 0, 0, 1, 0, 0, 16, 0,  0, 0),
+	MDP_COLOR_BGR565	= MDP_COLOR(0, 0, 0, 1, 0, 0, 16, 0,  1, 0),
+	MDP_COLOR_RGB888	= MDP_COLOR(0, 0, 0, 1, 0, 0, 24, 0,  1, 1),
+	MDP_COLOR_BGR888	= MDP_COLOR(0, 0, 0, 1, 0, 0, 24, 0,  0, 1),
+	MDP_COLOR_RGBA8888	= MDP_COLOR(0, 0, 0, 1, 0, 0, 32, 0,  1, 2),
+	MDP_COLOR_BGRA8888	= MDP_COLOR(0, 0, 0, 1, 0, 0, 32, 0,  0, 2),
+	MDP_COLOR_ARGB8888	= MDP_COLOR(0, 0, 0, 1, 0, 0, 32, 0,  1, 3),
+	MDP_COLOR_ABGR8888	= MDP_COLOR(0, 0, 0, 1, 0, 0, 32, 0,  0, 3),
+
+	MDP_COLOR_UYVY		= MDP_COLOR(0, 0, 0, 1, 1, 0, 16, 1,  0, 4),
+	MDP_COLOR_VYUY		= MDP_COLOR(0, 0, 0, 1, 1, 0, 16, 1,  1, 4),
+	MDP_COLOR_YUYV		= MDP_COLOR(0, 0, 0, 1, 1, 0, 16, 1,  0, 5),
+	MDP_COLOR_YVYU		= MDP_COLOR(0, 0, 0, 1, 1, 0, 16, 1,  1, 5),
+
+	MDP_COLOR_I420		= MDP_COLOR(0, 0, 0, 3, 1, 1,  8, 1,  0, 8),
+	MDP_COLOR_YV12		= MDP_COLOR(0, 0, 0, 3, 1, 1,  8, 1,  1, 8),
+	MDP_COLOR_I422		= MDP_COLOR(0, 0, 0, 3, 1, 0,  8, 1,  0, 9),
+	MDP_COLOR_YV16		= MDP_COLOR(0, 0, 0, 3, 1, 0,  8, 1,  1, 9),
+	MDP_COLOR_I444		= MDP_COLOR(0, 0, 0, 3, 0, 0,  8, 1,  0, 10),
+	MDP_COLOR_YV24		= MDP_COLOR(0, 0, 0, 3, 0, 0,  8, 1,  1, 10),
+
+	MDP_COLOR_NV12		= MDP_COLOR(0, 0, 0, 2, 1, 1,  8, 1,  0, 12),
+	MDP_COLOR_NV21		= MDP_COLOR(0, 0, 0, 2, 1, 1,  8, 1,  1, 12),
+	MDP_COLOR_NV16		= MDP_COLOR(0, 0, 0, 2, 1, 0,  8, 1,  0, 13),
+	MDP_COLOR_NV61		= MDP_COLOR(0, 0, 0, 2, 1, 0,  8, 1,  1, 13),
+	MDP_COLOR_NV24		= MDP_COLOR(0, 0, 0, 2, 0, 0,  8, 1,  0, 14),
+	MDP_COLOR_NV42		= MDP_COLOR(0, 0, 0, 2, 0, 0,  8, 1,  1, 14),
+
+	/* Mediatek proprietary formats */
+	/* UFO encoded block mode */
+	MDP_COLOR_420_BLK_UFO	= MDP_COLOR(0, 0, 5, 2, 1, 1, 256, 1, 0, 12),
+	/* Block mode */
+	MDP_COLOR_420_BLK	= MDP_COLOR(0, 0, 1, 2, 1, 1, 256, 1, 0, 12),
+	/* Block mode + field mode */
+	MDP_COLOR_420_BLKI	= MDP_COLOR(0, 0, 3, 2, 1, 1, 256, 1, 0, 12),
+	/* Block mode */
+	MDP_COLOR_422_BLK	= MDP_COLOR(0, 0, 1, 1, 1, 0, 512, 1, 0, 4),
+
+	MDP_COLOR_IYU2		= MDP_COLOR(0, 0, 0, 1, 0, 0, 24,  1, 0, 25),
+	MDP_COLOR_YUV444	= MDP_COLOR(0, 0, 0, 1, 0, 0, 24,  1, 0, 30),
+
+	/* Packed 10-bit formats */
+	MDP_COLOR_RGBA1010102	= MDP_COLOR(1, 0, 0, 1, 0, 0, 32,  0, 1, 2),
+	MDP_COLOR_BGRA1010102	= MDP_COLOR(1, 0, 0, 1, 0, 0, 32,  0, 0, 2),
+	/* Packed 10-bit UYVY */
+	MDP_COLOR_UYVY_10P	= MDP_COLOR(1, 0, 0, 1, 1, 0, 20,  1, 0, 4),
+	/* Packed 10-bit NV21 */
+	MDP_COLOR_NV21_10P	= MDP_COLOR(1, 0, 0, 2, 1, 1, 10,  1, 1, 12),
+	/* 10-bit block mode */
+	MDP_COLOR_420_BLK_10_H	= MDP_COLOR(1, 0, 1, 2, 1, 1, 320, 1, 0, 12),
+	/* 10-bit HEVC tile mode */
+	MDP_COLOR_420_BLK_10_V	= MDP_COLOR(1, 1, 1, 2, 1, 1, 320, 1, 0, 12),
+	/* UFO encoded 10-bit block mode */
+	MDP_COLOR_420_BLK_U10_H	= MDP_COLOR(1, 0, 5, 2, 1, 1, 320, 1, 0, 12),
+	/* UFO encoded 10-bit HEVC tile mode */
+	MDP_COLOR_420_BLK_U10_V	= MDP_COLOR(1, 1, 5, 2, 1, 1, 320, 1, 0, 12),
+
+	/* Loose 10-bit formats */
+	MDP_COLOR_UYVY_10L	= MDP_COLOR(0, 1, 0, 1, 1, 0, 20,  1, 0, 4),
+	MDP_COLOR_VYUY_10L	= MDP_COLOR(0, 1, 0, 1, 1, 0, 20,  1, 1, 4),
+	MDP_COLOR_YUYV_10L	= MDP_COLOR(0, 1, 0, 1, 1, 0, 20,  1, 0, 5),
+	MDP_COLOR_YVYU_10L	= MDP_COLOR(0, 1, 0, 1, 1, 0, 20,  1, 1, 5),
+	MDP_COLOR_NV12_10L	= MDP_COLOR(0, 1, 0, 2, 1, 1, 10,  1, 0, 12),
+	MDP_COLOR_NV21_10L	= MDP_COLOR(0, 1, 0, 2, 1, 1, 10,  1, 1, 12),
+	MDP_COLOR_NV16_10L	= MDP_COLOR(0, 1, 0, 2, 1, 0, 10,  1, 0, 13),
+	MDP_COLOR_NV61_10L	= MDP_COLOR(0, 1, 0, 2, 1, 0, 10,  1, 1, 13),
+	MDP_COLOR_YV12_10L	= MDP_COLOR(0, 1, 0, 3, 1, 1, 10,  1, 1, 8),
+	MDP_COLOR_I420_10L	= MDP_COLOR(0, 1, 0, 3, 1, 1, 10,  1, 0, 8),
+};
+
+/* Minimum Y stride that is accepted by MDP HW */
+static inline u32 mdp_color_get_min_y_stride(enum mdp_color c, u32 width)
+{
+	return ((MDP_COLOR_BITS_PER_PIXEL(c) * width) + 4) >> 3;
+}
+
+/* Minimum UV stride that is accepted by MDP HW */
+static inline u32 mdp_color_get_min_uv_stride(enum mdp_color c, u32 width)
+{
+	u32 min_stride;
+
+	if (MDP_COLOR_GET_PLANE_COUNT(c) == 1)
+		return 0;
+	min_stride = mdp_color_get_min_y_stride(c, width)
+		>> MDP_COLOR_GET_H_SUBSAMPLE(c);
+	if (MDP_COLOR_IS_UV_COPLANE(c) && !MDP_COLOR_IS_BLOCK_MODE(c))
+		min_stride = min_stride * 2;
+	return min_stride;
+}
+
+/* Minimum Y plane size that is necessary in buffer */
+static inline u32 mdp_color_get_min_y_size(enum mdp_color c,
+					   u32 width, u32 height)
+{
+	if (MDP_COLOR_IS_BLOCK_MODE(c))
+		return ((MDP_COLOR_BITS_PER_PIXEL(c) * width) >> 8) * height;
+	return mdp_color_get_min_y_stride(c, width) * height;
+}
+
+/* Minimum UV plane size that is necessary in buffer */
+static inline u32 mdp_color_get_min_uv_size(enum mdp_color c,
+					    u32 width, u32 height)
+{
+	height = height >> MDP_COLOR_GET_V_SUBSAMPLE(c);
+	if (MDP_COLOR_IS_BLOCK_MODE(c) && (MDP_COLOR_GET_PLANE_COUNT(c) > 1))
+		return ((MDP_COLOR_BITS_PER_PIXEL(c) * width) >> 8) * height;
+	return mdp_color_get_min_uv_stride(c, width) * height;
+}
+
+/* Combine colorspace, xfer_func, ycbcr_encoding, and quantization */
+enum mdp_ycbcr_profile {
+	/* V4L2_YCBCR_ENC_601 and V4L2_QUANTIZATION_LIM_RANGE */
+	MDP_YCBCR_PROFILE_BT601,
+	/* V4L2_YCBCR_ENC_709 and V4L2_QUANTIZATION_LIM_RANGE */
+	MDP_YCBCR_PROFILE_BT709,
+	/* V4L2_YCBCR_ENC_601 and V4L2_QUANTIZATION_FULL_RANGE */
+	MDP_YCBCR_PROFILE_JPEG,
+	MDP_YCBCR_PROFILE_FULL_BT601 = MDP_YCBCR_PROFILE_JPEG,
+
+	/* Colorspaces not support for capture */
+	/* V4L2_YCBCR_ENC_BT2020 and V4L2_QUANTIZATION_LIM_RANGE */
+	MDP_YCBCR_PROFILE_BT2020,
+	/* V4L2_YCBCR_ENC_709 and V4L2_QUANTIZATION_FULL_RANGE */
+	MDP_YCBCR_PROFILE_FULL_BT709,
+	/* V4L2_YCBCR_ENC_BT2020 and V4L2_QUANTIZATION_FULL_RANGE */
+	MDP_YCBCR_PROFILE_FULL_BT2020,
+};
+
+#define MDP_FMT_FLAG_OUTPUT	BIT(0)
+#define MDP_FMT_FLAG_CAPTURE	BIT(1)
+
+struct mdp_format {
+	u32	pixelformat;
+	u32	mdp_color;
+	u8	depth[VIDEO_MAX_PLANES];
+	u8	row_depth[VIDEO_MAX_PLANES];
+	u8	num_planes;
+	u8	walign;
+	u8	halign;
+	u8	salign;
+	u32	flags;
+};
+
+struct mdp_pix_limit {
+	u32	wmin;
+	u32	hmin;
+	u32	wmax;
+	u32	hmax;
+};
+
+struct mdp_limit {
+	struct mdp_pix_limit	out_limit;
+	struct mdp_pix_limit	cap_limit;
+	u32			h_scale_up_max;
+	u32			v_scale_up_max;
+	u32			h_scale_down_max;
+	u32			v_scale_down_max;
+};
+
+enum mdp_stream_type {
+	MDP_STREAM_TYPE_UNKNOWN,
+
+	MDP_STREAM_TYPE_BITBLT,
+	MDP_STREAM_TYPE_GPU_BITBLT,
+	MDP_STREAM_TYPE_DUAL_BITBLT,
+	MDP_STREAM_TYPE_2ND_BITBLT,
+
+	/* MDP_STREAM_TYPE_FRAG, */
+	/* MDP_STREAM_TYPE_FRAG_JPEGDEC, */
+
+	MDP_STREAM_TYPE_ISP_IC,
+	MDP_STREAM_TYPE_ISP_VR,
+	MDP_STREAM_TYPE_ISP_ZSD,
+	MDP_STREAM_TYPE_ISP_IP,
+	MDP_STREAM_TYPE_ISP_VSS,
+	MDP_STREAM_TYPE_ISP_ZSD_SLOW,
+	/* MDP_STREAM_TYPE_ISP_ZSD_ONE, */
+
+	MDP_STREAM_TYPE_WPE,
+	MDP_STREAM_TYPE_WPE2,
+};
+
+struct mdp_crop {
+	struct v4l2_rect	c;
+	struct v4l2_fract	left_subpix;
+	struct v4l2_fract	top_subpix;
+	struct v4l2_fract	width_subpix;
+	struct v4l2_fract	height_subpix;
+};
+
+struct mdp_frame {
+	struct v4l2_format	format;
+	const struct mdp_format	*mdp_fmt;
+	u32			ycbcr_prof;	/* enum mdp_ycbcr_profile */
+	u32			usage;		/* enum mdp_buffer_usage */
+	struct mdp_crop		crop;
+	struct v4l2_rect	compose;
+	s32			rotation;
+	u32			hflip:1;
+	u32			vflip:1;
+	u32			hdr:1;
+	u32			dre:1;
+	u32			sharpness:1;
+	u32			dither:1;
+};
+
+static inline bool mdp_target_is_crop(u32 target)
+{
+	return (target == V4L2_SEL_TGT_CROP) ||
+		(target == V4L2_SEL_TGT_CROP_DEFAULT) ||
+		(target == V4L2_SEL_TGT_CROP_BOUNDS);
+}
+
+static inline bool mdp_target_is_compose(u32 target)
+{
+	return (target == V4L2_SEL_TGT_COMPOSE) ||
+		(target == V4L2_SEL_TGT_COMPOSE_DEFAULT) ||
+		(target == V4L2_SEL_TGT_COMPOSE_BOUNDS);
+}
+
+#define MDP_MAX_CAPTURES	IMG_MAX_HW_OUTPUTS
+
+#define MDP_VPU_INIT		BIT(0)
+#define MDP_M2M_SRC_FMT		BIT(1)
+#define MDP_M2M_DST_FMT		BIT(2)
+#define MDP_M2M_CTX_ERROR	BIT(5)
+
+struct mdp_frameparam {
+	struct list_head	list;
+	/* synchronization protect for m2m context state */
+	struct mutex		lock;
+	u32			state;
+	const struct mdp_limit	*limit;
+	u32			type;	/* enum mdp_stream_type */
+	u32			frame_no;
+	struct mdp_frame	output;
+	struct mdp_frame	captures[MDP_MAX_CAPTURES];
+	u32			num_captures;
+	/* __u8			pq_data[]; */
+};
+
+int mdp_enum_fmt_mplane(struct v4l2_fmtdesc *f);
+const struct mdp_format *mdp_try_fmt_mplane(struct v4l2_format *f,
+					    const struct mdp_limit *limit,
+					    u32 ctx_id);
+enum mdp_ycbcr_profile mdp_map_ycbcr_prof_mplane(struct v4l2_format *f,
+						 u32 mdp_color);
+int mdp_try_crop(struct v4l2_rect *r, const struct v4l2_selection *s,
+		 struct mdp_frame *frame, u32 ctx_id);
+int mdp_check_scaling_ratio(const struct v4l2_rect *crop,
+			    const struct v4l2_rect *compose, s32 rotation,
+	const struct mdp_limit *limit);
+void mdp_set_src_config(struct img_input *in,
+			struct mdp_frame *frame, struct vb2_buffer *vb);
+void mdp_set_dst_config(struct img_output *out,
+			struct mdp_frame *frame, struct vb2_buffer *vb);
+
+struct mdp_frameparam *mdp_frameparam_init(void);
+void mdp_frameparam_release(struct mdp_frameparam *param);
+
+#endif  /* __MTK_MDP3_REGS_H__ */
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-ut.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-ut.c
new file mode 100644
index 000000000000..e259aeca54fb
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-ut.c
@@ -0,0 +1,663 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/of_platform.h>
+#include <linux/of_address.h>
+#include "mtk-mdp3-core.h"
+#include "mtk-mdp3-m2m.h"
+#include "mtk-mdp3-vpu.h"
+#include "mtk-mdp3-regs.h"
+#include "mtk-mdp3-comp.h"
+#include "mtk-mdp3-cmdq.h"
+#include "mdp-platform.h"
+
+#include "mmsys_config.h"
+#include "mdp_reg_rdma.h"
+#include "mdp_reg_rsz.h"
+#include "mdp_reg_wrot.h"
+#include "mdp_reg_wdma.h"
+#include "isp_reg.h"
+
+static void dump_config(struct img_config *config)
+{
+	struct img_compparam *comp;
+	struct img_mmsys_ctrl *ctrl;
+	int i, j;
+
+	mdp_dbg(1, "comps:%d subfrms:%d",
+		config->num_components, config->num_subfrms);
+	for (i = 0; i < config->num_components; i++) {
+		comp = &config->components[i];
+		mdp_dbg(1, "comp-%d type:%d input:%d outputs:%d",
+			i, comp->type, comp->input, comp->num_outputs);
+		for (j = 0; j < comp->num_outputs; j++)
+			mdp_dbg(1, "%6c output%d:%d", ' ', j,
+				comp->outputs[j]);
+		mdp_dbg(1, "%6c disable:%d bypass:%d in:%dx%d out:%dx%d", ' ',
+			comp->frame.output_disable, comp->frame.bypass,
+			comp->frame.in_width, comp->frame.in_height,
+			comp->frame.out_width, comp->frame.out_height);
+		mdp_dbg(1, "crop:(%d %d %d %d) total:%d->%d",
+			comp->frame.crop.left, comp->frame.crop.top,
+			comp->frame.crop.width, comp->frame.crop.height,
+			comp->frame.in_total_width,
+			comp->frame.out_total_width);
+		switch (comp->type) {
+		case MDP_RDMA0:
+			mdp_dbg(1, "%6c rdma src:%#08x ctrl:%#08x", ' ',
+				comp->rdma.src_ctrl, comp->rdma.control);
+			mdp_dbg(1, "iova[%#x %#x %#x] mf:%d sf:%d trans:%#08x",
+				comp->rdma.iova[0], comp->rdma.iova[1],
+				comp->rdma.iova[2], comp->rdma.mf_bkgd,
+				comp->rdma.sf_bkgd, comp->rdma.transform);
+			break;
+		case MDP_SCL0:
+		case MDP_SCL1:
+			mdp_dbg(1, "%6c rsz %#08x %#08x", ' ',
+				comp->rsz.coeff_step_x, comp->rsz.coeff_step_y);
+			break;
+		case MDP_WROT0:
+			mdp_dbg(1, "%6c wrot iova[%#x %#x %#x]", ' ',
+				comp->wrot.iova[0], comp->wrot.iova[1],
+				comp->wrot.iova[2]);
+			mdp_dbg(1, "stride[%d %d %d]",
+				comp->wrot.stride[0], comp->wrot.stride[1],
+				comp->wrot.stride[2]);
+			mdp_dbg(1, "ctrl:%#08x mat:%#08x",
+				comp->wrot.control, comp->wrot.mat_ctrl);
+			break;
+		}
+	}
+	for (j = 0; j < config->num_subfrms; j++) {
+		ctrl = &config->ctrls[j];
+		mdp_dbg(1, "%3c sub-%d ctrls:%d", ' ', j, ctrl->num_sets);
+		for (i = 0; i < ctrl->num_sets; i++)
+			mdp_dbg(1, "%9c ctrl %#08x %#x", ' ',
+				ctrl->sets[i].reg, ctrl->sets[i].value);
+		for (i = 0; i < config->num_components; i++) {
+			comp = &config->components[i];
+			mdp_dbg(1, "%9c comp %d disable:%d in:[%d %d %d %d]",
+				' ',
+				comp->type, comp->subfrms[j].tile_disable,
+				comp->subfrms[j].in.left,
+				comp->subfrms[j].in.top,
+				comp->subfrms[j].in.right,
+				comp->subfrms[j].in.bottom);
+			mdp_dbg(1, "out:[%d %d %d %d]",
+				comp->subfrms[j].out.left,
+				comp->subfrms[j].out.top,
+				comp->subfrms[j].out.right,
+				comp->subfrms[j].out.bottom);
+			switch (comp->type) {
+			case MDP_RDMA0:
+				mdp_dbg(1, "%14c rdma ofst[%#x %#x %#x]", ' ',
+					comp->rdma.subfrms[j].offset[0],
+					comp->rdma.subfrms[j].offset[1],
+					comp->rdma.subfrms[j].offset[2]);
+				mdp_dbg(1, "src:%#08x clip:%#08x ofst:%#08x",
+					comp->rdma.subfrms[j].src,
+					comp->rdma.subfrms[j].clip,
+					comp->rdma.subfrms[j].clip_ofst);
+				break;
+			case MDP_SCL0:
+			case MDP_SCL1:
+				mdp_dbg(1, "%14c rsz src:%#08x clip:%#08x", ' ',
+					comp->rsz.subfrms[j].src,
+					comp->rsz.subfrms[j].clip);
+				break;
+			case MDP_WROT0:
+				mdp_dbg(1, "%14c wrot ofst[%#x %#x %#x]", ' ',
+					comp->wrot.subfrms[j].offset[0],
+					comp->wrot.subfrms[j].offset[1],
+					comp->wrot.subfrms[j].offset[2]);
+				mdp_dbg(1, "src:%#08x clip:%#08x ofst:%#08x",
+					comp->wrot.subfrms[j].src,
+					comp->wrot.subfrms[j].clip,
+					comp->wrot.subfrms[j].clip_ofst);
+				break;
+			}
+		}
+	}
+}
+
+#define FRAMEHEIGHT	48
+#define IOVABASE	0x50000000
+#define PLANESIZE	0x00100000
+#define PLANEOFFSET	0x00001000
+#define SRCBASE	(IOVABASE + 0x0)
+#define SRCOFFSET	0x00010000
+#define DSTBASE	(IOVABASE + 0x01000000)
+#define DSTOFFSET	0X00020000
+
+#define CROP { \
+	.width = FRAMEWIDTH, \
+	.height = FRAMEHEIGHT, \
+}
+#define REGION { \
+	.right = FRAMEWIDTH - 1, \
+	.bottom = FRAMEHEIGHT - 1, \
+}
+#define FRAME_STRUCT { \
+	.output_disable = false, \
+	.bypass = false, \
+	.in_width = FRAMEWIDTH, \
+	.in_height = FRAMEHEIGHT, \
+	.out_width = FRAMEWIDTH, \
+	.out_height = FRAMEHEIGHT, \
+	.crop = CROP, \
+	.in_total_width = FRAMEWIDTH, \
+	.out_total_width = FRAMEWIDTH, \
+}
+#define SUBFRM_STRUCT { \
+	.tile_disable = false, \
+	.in = REGION, \
+	.out = REGION, \
+}
+#define COMP_STRUCT { \
+	.input = 0, \
+	.outputs[0] = 0, \
+	.num_outputs = 1, \
+	.frame = FRAME_STRUCT, \
+	.subfrms = { SUBFRM_STRUCT }, \
+	.num_subfrms = 1, \
+}
+#define PIX_FORMAT(colr) { \
+	.width = FRAMEWIDTH, \
+	.height = FRAMEHEIGHT, \
+	.colorformat = (colr), \
+	.plane_fmt = { { \
+		.size = FRAMEWIDTH * FRAMEHEIGHT * 4, \
+		.stride = FRAMEWIDTH * 4, \
+	}, }, \
+}
+#define SRCIOVA { SRCBASE, SRCBASE + PLANESIZE, SRCBASE + PLANESIZE * 2 }
+#define SRCIOVAEND { \
+	SRCBASE + PLANESIZE - 1, \
+	SRCBASE + PLANESIZE * 2 - 1, \
+	SRCBASE + PLANESIZE * 3 - 1 }
+#define SRCSUBOFFSET { \
+	SRCOFFSET, \
+	SRCOFFSET + PLANEOFFSET, \
+	SRCOFFSET + PLANEOFFSET * 2 }
+#define DSTIOVA { DSTBASE, DSTBASE + PLANESIZE, DSTBASE + PLANESIZE * 2 }
+#define DSTSUBOFFSET { \
+	DSTOFFSET, \
+	DSTOFFSET + PLANEOFFSET, \
+	DSTOFFSET + PLANEOFFSET * 2 }
+#define RDMADATA { \
+	.src_ctrl = (MDP_COLOR_GET_HW_FORMAT(SRCCOLR) <<  0) + \
+		(3 <<  9) + \
+		(0 << 11) + \
+		(0 << 12) + \
+		(MDP_COLOR_IS_SWAPPED(SRCCOLR) << 14) + \
+		(MDP_COLOR_IS_BLOCK_MODE(SRCCOLR) << 15) + \
+		(1 << 19) + \
+		(MDP_COLOR_IS_10BIT_PACKED(SRCCOLR) << 22) + \
+		(MDP_COLOR_IS_10BIT_TILE(SRCCOLR) << 23) + \
+		(0 << 24) + \
+		(0 << 25), /* alpha rotation */ \
+	.control = ((!MDP_COLOR_IS_BLOCK_MODE(SRCCOLR)) << 12) + \
+		(0 <<  8) + \
+		(1 <<  4), \
+	.iova = SRCIOVA, \
+	.iova_end = SRCIOVAEND, \
+	.mf_bkgd = FRAMEWIDTH * 4, \
+	.sf_bkgd = 0, \
+	.transform = (0 << 24) + \
+		(0 << 20) + \
+		(0 << 16), \
+	.subfrms = { { \
+		.offset = SRCSUBOFFSET, \
+		.src = (FRAMEHEIGHT << 16) + (FRAMEWIDTH <<  0), \
+		.clip = (FRAMEHEIGHT << 16) + (FRAMEWIDTH <<  0), \
+		.clip_ofst = 0, \
+	}, }, \
+}
+#define WROTDATA { \
+	.iova = DSTIOVA, \
+	.control = (0 << 30) + \
+		(0 << 28) + \
+		(1 << 24) + \
+		(0 << 20) + \
+		(0 << 16) + /* alpha rotation */ \
+		(1 << 14) + \
+		(1 << 12) + \
+		(MDP_COLOR_IS_SWAPPED(DSTCOLR) <<  8) + \
+		(MDP_COLOR_GET_HW_FORMAT(DSTCOLR) <<  0), \
+	.stride = { FRAMEWIDTH * 4, 0, 0 }, \
+	.mat_ctrl = (0 << 4) + \
+		(0 << 1) + \
+		(0 << 0), \
+	.fifo_test = 128, \
+	.filter = (0 << 4) + \
+		(0 << 0), \
+	.subfrms = { { \
+		.offset = DSTSUBOFFSET, \
+		.src = (FRAMEHEIGHT << 16) + (FRAMEWIDTH <<  0), \
+		.clip = (FRAMEHEIGHT << 16) + (FRAMEWIDTH <<  0), \
+		.clip_ofst = 0, \
+		.main_buf = 0x401000, \
+	}, }, \
+}
+#define MDPINPUT { \
+	.buffer = { \
+		.format = PIX_FORMAT(SRCCOLR), \
+		.iova = SRCIOVA, \
+		.usage = MDP_BUFFER_USAGE_HW_READ, \
+	}, \
+	.flags = 0, \
+}
+#define MDPOUTPUT { \
+	.buffer = { \
+		.format = PIX_FORMAT(DSTCOLR), \
+		.iova = DSTIOVA, \
+		.usage = MDP_BUFFER_USAGE_MDP, \
+	}, \
+	.crop = CROP, \
+	.flags = IMG_CTRL_FLAG_HFLIP, \
+}
+#define _PARAM_COMMON \
+	.type = MDP_STREAM_TYPE_BITBLT, \
+	.num_inputs = 1, \
+	.num_outputs = 1, \
+	.inputs = { MDPINPUT }, \
+	.outputs = { MDPOUTPUT }
+#define PARAM_CMDQ { \
+	_PARAM_COMMON, \
+}
+#define PARAM_VPU { \
+	_PARAM_COMMON, \
+	.config_data = { \
+		.va = (unsigned long)vpu->config, \
+		.pa = vpu->inst_addr, \
+	}, \
+}
+#define TASK(cfg) { \
+	.config = (cfg), \
+	.param = &param, \
+	.composes = { &compose, }, \
+	.wait = 1, \
+}
+
+static int mdp_cmdq_alpharot_ut(struct mdp_dev *mdp)
+{
+#undef  SRCCOLR
+#undef  DSTCOLR
+#undef  FRAMEWIDTH
+#define SRCCOLR	MDP_COLOR_RGBA8888
+#define DSTCOLR	MDP_COLOR_ABGR8888
+#define FRAMEWIDTH	64
+	static const struct mdp_rdma_data initrdma = RDMADATA;
+	static const struct mdp_wrot_data initwrot = WROTDATA;
+	static const struct img_config initcfg = {
+		.components = { COMP_STRUCT, COMP_STRUCT, COMP_STRUCT },
+		.num_components = 3,
+		.ctrls = { {
+			.sets = { {
+				.reg = MDP_RDMA0_MOUT_EN,
+				.value = 4,
+			}, {
+				.reg = MDP_PATH0_SEL_IN,
+				.value = 3,
+			}, {
+				.reg = MDP_WROT0_SEL_IN,
+				.value = 0,
+			}, {
+				.reg = MDP_PATH0_SOUT_SEL,
+				.value = 0,
+			}, },
+			.num_sets = 4,
+		}, },
+		.num_subfrms = 1,
+	};
+
+	struct img_config *config = kzalloc(sizeof(*config), GFP_KERNEL);
+	struct img_ipi_frameparam param = PARAM_CMDQ;
+	struct v4l2_rect compose;
+	struct mdp_cmdq_param task = TASK(config);
+	int ret;
+
+	mdp_dbg(1, "");
+	*config = initcfg;
+	config->components[0].type = MDP_RDMA0;
+	config->components[0].id = 0;
+	config->components[0].rdma = initrdma;
+	config->components[0].rdma.src_ctrl |= (1 << 25); /* alpha rotation */
+	config->components[1].type = MDP_PATH0_SOUT;
+	config->components[1].id = 0;
+	config->components[2].type = MDP_WROT0;
+	config->components[2].id = 0;
+	config->components[2].wrot = initwrot;
+	config->components[2].wrot.control &= ~((1 << 16) | (1 << 8));
+	config->components[2].wrot.control |= (1 << 16) + /* alpha rotation */
+		/* workaround for alpha rotation */
+		((MDP_COLOR_IS_SWAPPED(DSTCOLR) ? 0 : 1) <<  8);
+
+	compose.left = param.outputs[0].crop.left;
+	compose.top = param.outputs[0].crop.top;
+	compose.width = param.outputs[0].crop.width;
+	compose.height = param.outputs[0].crop.height;
+
+	ret = mdp_cmdq_send(mdp, &task);
+	if (ret)
+		dev_err(&mdp->pdev->dev, "%s failed: %d\n", __func__, ret);
+	/* print cmdq result */
+	kfree(config);
+	return ret;
+}
+
+static int mdp_vpu_alpharot_ut(struct mdp_dev *mdp, struct mdp_vpu_ctx *vpu)
+{
+#undef  SRCCOLR
+#undef  DSTCOLR
+#undef  FRAMEWIDTH
+#define SRCCOLR	MDP_COLOR_RGBA8888
+#define DSTCOLR	MDP_COLOR_ABGR8888
+#define FRAMEWIDTH	64
+	struct img_ipi_frameparam param = PARAM_VPU;
+	struct v4l2_rect compose;
+	struct mdp_cmdq_param task = TASK(vpu->config);
+	int ret;
+
+	mdp_dbg(1, "");
+	ret = mdp_vpu_process(vpu, &param);
+	if (ret) {
+		dev_err(&mdp->pdev->dev, "%s processing failed: %d\n",
+			__func__, ret);
+		return ret;
+	}
+	dump_config(vpu->config);
+
+	compose.left = param.outputs[0].crop.left;
+	compose.top = param.outputs[0].crop.top;
+	compose.width = param.outputs[0].crop.width;
+	compose.height = param.outputs[0].crop.height;
+
+	ret = mdp_cmdq_send(mdp, &task);
+	if (ret)
+		dev_err(&mdp->pdev->dev, "%s failed: %d\n", __func__, ret);
+	/* print cmdq result */
+	return ret;
+}
+
+static int mdp_cmdq_resizer_ut(struct mdp_dev *mdp)
+{
+#undef  SRCCOLR
+#undef  DSTCOLR
+#undef  FRAMEWIDTH
+#define SRCCOLR	MDP_COLOR_RGBA8888
+#define DSTCOLR	MDP_COLOR_ABGR8888
+#define FRAMEWIDTH	64
+	static const struct mdp_rdma_data initrdma = RDMADATA;
+	static const struct mdp_wrot_data initwrot = WROTDATA;
+	static const struct img_config initcfg = {
+		.components = {
+			COMP_STRUCT, COMP_STRUCT, COMP_STRUCT,
+			COMP_STRUCT, COMP_STRUCT
+		},
+		.num_components = 5,
+		.ctrls = { {
+			.sets = { {
+				.reg = MDP_RDMA0_MOUT_EN,
+				.value = 1,
+			}, {
+				.reg = MDP_PRZ0_MOUT_EN,
+				.value = 1,
+			}, {
+				.reg = MDP_CCORR_SEL_IN,
+				.value = 1,
+			}, {
+				.reg = MDP_PRZ0_SEL_IN,
+				.value = 1,
+			}, {
+				.reg = MDP_PATH0_SEL_IN,
+				.value = 0,
+			}, {
+				.reg = MDP_WROT0_SEL_IN,
+				.value = 0,
+			}, {
+				.reg = MDP_CCORR_SOUT_SEL,
+				.value = 1,
+			}, {
+				.reg = MDP_PATH0_SOUT_SEL,
+				.value = 0,
+			}, },
+			.num_sets = 8,
+		}, },
+		.num_subfrms = 1,
+	};
+
+	struct img_config *config = kzalloc(sizeof(*config), GFP_KERNEL);
+	struct img_ipi_frameparam param = PARAM_CMDQ;
+	struct v4l2_rect compose;
+	struct mdp_cmdq_param task = TASK(config);
+	int ret;
+
+	mdp_dbg(1, "");
+	*config = initcfg;
+	config->components[0].type = MDP_RDMA0;
+	config->components[0].id = 0;
+	config->components[0].rdma = initrdma;
+	config->components[1].type = MDP_CCORR0;
+	config->components[1].id = 0;
+	config->components[2].type = MDP_SCL0;
+	config->components[2].id = 0;
+	config->components[2].frame.bypass = true;
+	config->components[3].type = MDP_PATH0_SOUT;
+	config->components[3].id = 0;
+	config->components[4].type = MDP_WROT0;
+	config->components[4].id = 0;
+	config->components[4].wrot = initwrot;
+
+	compose.left = param.outputs[0].crop.left;
+	compose.top = param.outputs[0].crop.top;
+	compose.width = param.outputs[0].crop.width;
+	compose.height = param.outputs[0].crop.height;
+
+	ret = mdp_cmdq_send(mdp, &task);
+	if (ret)
+		dev_err(&mdp->pdev->dev, "%s failed: %d\n", __func__, ret);
+	/* print cmdq result */
+	kfree(config);
+	return ret;
+}
+
+static int mdp_vpu_resizer_ut(struct mdp_dev *mdp, struct mdp_vpu_ctx *vpu)
+{
+#undef  SRCCOLR
+#undef  DSTCOLR
+#undef  FRAMEWIDTH
+#define SRCCOLR	MDP_COLOR_RGB888
+#define DSTCOLR	MDP_COLOR_ABGR8888
+#define FRAMEWIDTH	64
+	struct img_ipi_frameparam param = PARAM_VPU;
+	struct v4l2_rect compose;
+	struct mdp_cmdq_param task = TASK(vpu->config);
+	int ret;
+
+	mdp_dbg(1, "");
+	ret = mdp_vpu_process(vpu, &param);
+	if (ret) {
+		dev_err(&mdp->pdev->dev, "%s processing failed: %d\n",
+			__func__, ret);
+		return ret;
+	}
+	dump_config(vpu->config);
+
+	compose.left = param.outputs[0].crop.left;
+	compose.top = param.outputs[0].crop.top;
+	compose.width = param.outputs[0].crop.width;
+	compose.height = param.outputs[0].crop.height;
+
+	ret = mdp_cmdq_send(mdp, &task);
+	if (ret)
+		dev_err(&mdp->pdev->dev, "%s failed: %d\n", __func__, ret);
+	/* print cmdq result */
+	return ret;
+}
+
+static int mdp_vpu_tile_ut(struct mdp_dev *mdp, struct mdp_vpu_ctx *vpu)
+{
+#undef  SRCCOLR
+#undef  DSTCOLR
+#undef  FRAMEWIDTH
+#define SRCCOLR	MDP_COLOR_RGB888
+#define DSTCOLR	MDP_COLOR_ABGR8888
+#define FRAMEWIDTH	1920
+	struct img_ipi_frameparam param = PARAM_VPU;
+	struct v4l2_rect compose;
+	struct mdp_cmdq_param task = TASK(vpu->config);
+	int ret;
+
+	mdp_dbg(1, "");
+	ret = mdp_vpu_process(vpu, &param);
+	if (ret) {
+		dev_err(&mdp->pdev->dev, "%s processing failed: %d\n",
+			__func__, ret);
+		return ret;
+	}
+	dump_config(vpu->config);
+
+	compose.left = param.outputs[0].crop.left;
+	compose.top = param.outputs[0].crop.top;
+	compose.width = param.outputs[0].crop.width;
+	compose.height = param.outputs[0].crop.height;
+
+	ret = mdp_cmdq_send(mdp, &task);
+	if (ret)
+		dev_err(&mdp->pdev->dev, "%s failed: %d\n", __func__, ret);
+	/* print cmdq result */
+	return ret;
+}
+
+/* define SMI register settings */
+#define REG_SMI_LARBx_NONSEC_CON(base, port)	((base) + 0x380 + ((port) << 2))
+
+static int mdp_cmdq_ut(struct mdp_dev *mdp)
+{
+	int ret;
+
+	mdp_dbg(1, "");
+	ret = mdp_cmdq_alpharot_ut(mdp);
+	if (ret)
+		return ret;
+	mdp_dbg(1, "pass");
+	ret = mdp_cmdq_resizer_ut(mdp);
+	if (ret)
+		return ret;
+	mdp_dbg(1, "pass");
+	return ret;
+}
+
+static int mdp_vpu_ut(struct mdp_dev *mdp)
+{
+	struct mdp_vpu_ctx vpu;
+	int ret;
+
+	mdp_dbg(1, "");
+	ret = mdp_vpu_ctx_init(&vpu, &mdp->vpu, MDP_DEV_M2M);
+	if (ret) {
+		dev_err(&mdp->pdev->dev, "VPU init failed %d\n", ret);
+		return -EINVAL;
+	}
+
+	ret = mdp_vpu_alpharot_ut(mdp, &vpu);
+	if (ret)
+		goto teardown;
+	mdp_dbg(1, "pass");
+	ret = mdp_vpu_resizer_ut(mdp, &vpu);
+	if (ret)
+		goto teardown;
+	mdp_dbg(1, "pass");
+	ret = mdp_vpu_tile_ut(mdp, &vpu);
+	if (ret)
+		goto teardown;
+	mdp_dbg(1, "pass");
+
+teardown:
+	mdp_vpu_ctx_deinit(&vpu);
+	return ret;
+}
+
+int mdp_ut(struct mdp_dev *mdp)
+{
+	struct device_node *node;
+	void __iomem *va;
+	int ret;
+
+	/* Set SMI LARB to disable MMU (VA) */
+	node = of_parse_phandle(mdp->pdev->dev.of_node, "mediatek,larb", 0);
+	if (!node) {
+		dev_err(&mdp->pdev->dev, "Cannot get SMI larb node\n");
+		return -EINVAL;
+	}
+
+	va = of_iomap(node, 0);
+	of_node_put(node);
+	/* larb0 port6 rdma0 */
+	writel(0, REG_SMI_LARBx_NONSEC_CON(va, 6));
+	/* larb0 port7 wrot0 */
+	writel(0, REG_SMI_LARBx_NONSEC_CON(va, 7));
+	/* larb1 port8 wdma */
+	writel(0, REG_SMI_LARBx_NONSEC_CON(va, 8));
+
+	ret = mdp_cmdq_ut(mdp);
+	if (ret)
+		goto teardown;
+	ret = mdp_vpu_ut(mdp);
+	if (ret)
+		goto teardown;
+	//ret = mdp_m2m_ut(mdp);
+
+teardown:
+	/* larb0 port6 rdma0 */
+	writel(1, REG_SMI_LARBx_NONSEC_CON(va, 6));
+	/* larb0 port7 wrot0 */
+	writel(1, REG_SMI_LARBx_NONSEC_CON(va, 7));
+	/* larb1 port8 wdma */
+	writel(1, REG_SMI_LARBx_NONSEC_CON(va, 8));
+	return ret;
+}
+
+ssize_t mdp_ut_run(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev =
+		container_of(dev, struct platform_device, dev);
+	struct mdp_dev *mdp = platform_get_drvdata(pdev);
+	int ret = 0;
+
+	if (mutex_lock_interruptible(&mdp->m2m_lock)) {
+		ret = -ERESTARTSYS;
+		goto err_lock;
+	}
+
+	ret = mdp_vpu_get_locked(mdp);
+	if (ret < 0)
+		goto err_load_vpu;
+
+	ret = mdp_ut(mdp);
+	if (ret)
+		dev_err(dev, "mdp_ut ret=%d\n", ret);
+
+	mdp_vpu_put_locked(mdp);
+
+err_load_vpu:
+	mutex_unlock(&mdp->m2m_lock);
+
+err_lock:
+
+	return sizeof(buf);
+}
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.c b/drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.c
new file mode 100644
index 000000000000..e6189991331d
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.c
@@ -0,0 +1,277 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/remoteproc.h>
+#include <linux/platform_data/mtk_scp.h>
+#include "mtk-mdp3-vpu.h"
+#include "mtk-mdp3-core.h"
+
+#define MDP_VPU_MESSAGE_TIMEOUT 500U
+
+static inline struct mdp_dev *vpu_to_mdp(struct mdp_vpu_dev *vpu)
+{
+	return container_of(vpu, struct mdp_dev, vpu);
+}
+
+static void mdp_vpu_ipi_handle_init_ack(void *data, unsigned int len,
+					void *priv)
+{
+	struct mdp_ipi_init_msg *msg = (struct mdp_ipi_init_msg *)data;
+	struct mdp_vpu_dev *vpu =
+		(struct mdp_vpu_dev *)(unsigned long)msg->drv_data;
+
+	if (!vpu->work_size)
+		vpu->work_size = msg->work_size;
+	else
+		vpu->status = msg->status;
+	complete(&vpu->ipi_acked);
+}
+
+static void mdp_vpu_ipi_handle_deinit_ack(void *data, unsigned int len,
+					  void *priv)
+{
+	struct mdp_ipi_deinit_msg *msg = (struct mdp_ipi_deinit_msg *)data;
+	struct mdp_vpu_dev *vpu =
+		(struct mdp_vpu_dev *)(unsigned long)msg->drv_data;
+
+	vpu->status = msg->status;
+	complete(&vpu->ipi_acked);
+}
+
+static void mdp_vpu_ipi_handle_frame_ack(void *data, unsigned int len,
+					 void *priv)
+{
+	struct img_ipi_frameparam *param = (struct img_ipi_frameparam *)data;
+	struct mdp_vpu_ctx *ctx =
+		(struct mdp_vpu_ctx *)(unsigned long)param->drv_data;
+
+	ctx->failure = param->state;
+	if (ctx->failure) {
+		struct mdp_dev *mdp = vpu_to_mdp(ctx->vpu_dev);
+
+		dev_info(&mdp->pdev->dev, "VPU MDP failure:%d\n", ctx->failure);
+	}
+	complete(&ctx->vpu_dev->ipi_acked);
+}
+
+int mdp_vpu_register(struct platform_device *pdev)
+{
+	int err;
+
+	err = scp_ipi_register(pdev, SCP_IPI_MDP_INIT,
+		mdp_vpu_ipi_handle_init_ack, NULL);
+	if (err) {
+		dev_err(&pdev->dev, "scp_ipi_register failed %d\n", err);
+		goto err_ipi_init;
+	}
+	err = scp_ipi_register(pdev, SCP_IPI_MDP_DEINIT,
+		mdp_vpu_ipi_handle_deinit_ack, NULL);
+	if (err) {
+		dev_err(&pdev->dev, "scp_ipi_register failed %d\n", err);
+		goto err_ipi_deinit;
+	}
+	err = scp_ipi_register(pdev, SCP_IPI_MDP_FRAME,
+		mdp_vpu_ipi_handle_frame_ack, NULL);
+	if (err) {
+		dev_err(&pdev->dev, "scp_ipi_register failed %d\n", err);
+		goto err_ipi_frame;
+	}
+	return 0;
+
+err_ipi_frame:
+	/* vpu_ipi_unregister(IPI_MDP_DEINIT); */
+err_ipi_deinit:
+	/* vpu_ipi_unregister(IPI_MDP_INIT); */
+err_ipi_init:
+
+	return err;
+}
+
+void mdp_vpu_unregister(struct platform_device *pdev)
+{
+	/* vpu_ipi_unregister(IPI_MDP_INIT); */
+	/* vpu_ipi_unregister(IPI_MDP_DEINIT); */
+	/* vpu_ipi_unregister(IPI_MDP_FRAME); */
+}
+
+static int mdp_vpu_sendmsg(struct mdp_vpu_dev *vpu, enum scp_ipi_id id,
+	void *buf, unsigned int len)
+{
+	int ret;
+
+	if (!vpu->pdev) {
+		struct mdp_dev *mdp = vpu_to_mdp(vpu);
+
+		dev_dbg(&mdp->pdev->dev, "vpu pdev is NULL");
+		return -EINVAL;
+	}
+	ret = scp_ipi_send(vpu->pdev, id, buf, len, 2000);
+
+	if (ret) {
+		dev_err(&vpu->pdev->dev, "scp_ipi_send failed %d\n", ret);
+		return -EPERM;
+	}
+	ret =
+	wait_for_completion_timeout(&vpu->ipi_acked,
+				    msecs_to_jiffies(MDP_VPU_MESSAGE_TIMEOUT));
+	if (!ret)
+		ret = -ETIME;
+	else if (vpu->status)
+		ret = -EINVAL;
+	else
+		ret = 0;
+	return ret;
+}
+
+int mdp_vpu_dev_init(struct mdp_vpu_dev *vpu, struct platform_device *pdev,
+		     struct mutex *lock)
+{
+	struct mdp_ipi_init_msg msg = {
+		.drv_data = (unsigned long)vpu,
+	};
+	phys_addr_t mem_size, pool;
+	const size_t pool_size = sizeof(struct mdp_config_pool);
+	struct mdp_dev *mdp = vpu_to_mdp(vpu);
+	int err;
+
+	init_completion(&vpu->ipi_acked);
+	vpu->pdev = pdev;
+	vpu->lock = lock;
+	vpu->work_size = 0;
+	err = mdp_vpu_sendmsg(vpu, SCP_IPI_MDP_INIT, &msg, sizeof(msg));
+	if (err)
+		goto err_work_size;
+	/* vpu work_size was set in mdp_vpu_ipi_handle_init_ack */
+
+	vpu->work = scp_get_reserve_mem_virt(SCP_MDP_MEM_ID);
+	vpu->work_addr = scp_get_reserve_mem_phys(SCP_MDP_MEM_ID);
+	mem_size = scp_get_reserve_mem_size(SCP_MDP_MEM_ID);
+	pool = ALIGN(vpu->work + vpu->work_size, 8);
+	if (pool + pool_size - vpu->work > mem_size) {
+		dev_err(&mdp->pdev->dev,
+			"VPU memory insufficient: %lx + %lx > %llx",
+			vpu->work_size, pool_size, mem_size);
+		err = -ENOMEM;
+		goto err_mem_size;
+	}
+
+	dev_info(&mdp->pdev->dev,
+		 "VPU work:%llx pa:%llx sz:%lx pool:%llx sz:%lx (mem sz:%llx)",
+		vpu->work, vpu->work_addr, vpu->work_size,
+		pool, pool_size, mem_size);
+	vpu->pool = (struct mdp_config_pool *)pool;
+	msg.work_addr = vpu->work_addr;
+	msg.work_size = vpu->work_size;
+	err = mdp_vpu_sendmsg(vpu, SCP_IPI_MDP_INIT, &msg, sizeof(msg));
+	if (err)
+		goto err_work_size;
+	memset(vpu->pool, 0, sizeof(*vpu->pool));
+	return 0;
+
+err_work_size:
+	switch (vpu->status) {
+	case -MDP_IPI_EBUSY:
+		err = -EBUSY;
+		break;
+	case -MDP_IPI_ENOMEM:
+		err = -ENOSPC;	/* -ENOMEM */
+		break;
+	}
+err_mem_size:
+	return err;
+}
+
+int mdp_vpu_dev_deinit(struct mdp_vpu_dev *vpu)
+{
+	struct mdp_ipi_deinit_msg msg = {
+		.drv_data = (unsigned long)vpu,
+		.work_addr = vpu->work_addr,
+	};
+
+	return mdp_vpu_sendmsg(vpu, SCP_IPI_MDP_DEINIT, &msg, sizeof(msg));
+}
+
+static struct img_config *mdp_config_get(struct mdp_vpu_dev *vpu,
+					 enum mdp_config_id id, uint32_t *addr)
+{
+	struct img_config *config;
+
+	if (id < 0 || id >= MDP_CONFIG_POOL_SIZE)
+		return ERR_PTR(-EINVAL);
+	if (vpu->lock)
+		mutex_lock(vpu->lock);
+	vpu->pool->cfg_count[id]++;
+	config = &vpu->pool->configs[id];
+	*addr = vpu->work_addr + ((unsigned long)config - vpu->work);
+	if (vpu->lock)
+		mutex_unlock(vpu->lock);
+	return config;
+}
+
+static int mdp_config_put(struct mdp_vpu_dev *vpu,
+			  enum mdp_config_id id,
+			  const struct img_config *config)
+{
+	int err = 0;
+
+	if (id < 0 || id >= MDP_CONFIG_POOL_SIZE)
+		return -EINVAL;
+	if (vpu->lock)
+		mutex_lock(vpu->lock);
+	if (!vpu->pool->cfg_count[id] || config != &vpu->pool->configs[id])
+		err = -EINVAL;
+	else
+		vpu->pool->cfg_count[id]--;
+	if (vpu->lock)
+		mutex_unlock(vpu->lock);
+	return err;
+}
+
+int mdp_vpu_ctx_init(struct mdp_vpu_ctx *ctx, struct mdp_vpu_dev *vpu,
+		     enum mdp_config_id id)
+{
+	ctx->config = mdp_config_get(vpu, id, &ctx->inst_addr);
+	if (IS_ERR(ctx->config)) {
+		int err = PTR_ERR(ctx->config);
+
+		ctx->config = NULL;
+		return err;
+	}
+	ctx->config_id = id;
+	ctx->vpu_dev = vpu;
+	return 0;
+}
+
+int mdp_vpu_ctx_deinit(struct mdp_vpu_ctx *ctx)
+{
+	int err = mdp_config_put(ctx->vpu_dev, ctx->config_id, ctx->config);
+
+	ctx->config_id = 0;
+	ctx->config = NULL;
+	ctx->inst_addr = 0;
+	return err;
+}
+
+int mdp_vpu_process(struct mdp_vpu_ctx *ctx, struct img_ipi_frameparam *param)
+{
+	memset((void *)ctx->vpu_dev->work, 0, ctx->vpu_dev->work_size);
+	memset(ctx->config, 0, sizeof(*ctx->config));
+	param->config_data.va = (unsigned long)ctx->config;
+	param->config_data.pa = ctx->inst_addr;
+	param->drv_data = (unsigned long)ctx;
+	return mdp_vpu_sendmsg(ctx->vpu_dev, SCP_IPI_MDP_FRAME,
+		param, sizeof(*param));
+}
+
diff --git a/drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.h b/drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.h
new file mode 100644
index 000000000000..f6551d774902
--- /dev/null
+++ b/drivers/media/platform/mtk-mdp3/mtk-mdp3-vpu.h
@@ -0,0 +1,89 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ * Author: Ping-Hsun Wu <ping-hsun.wu@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MTK_MDP3_VPU_H__
+#define __MTK_MDP3_VPU_H__
+
+#include <linux/platform_device.h>
+#include "mtk-img-ipi.h"
+
+enum mdp_ipi_result {
+	MDP_IPI_SUCCESS	= 0,
+	MDP_IPI_ENOMEM	= 12,
+	MDP_IPI_EBUSY	= 16,
+	MDP_IPI_EINVAL	= 22,
+	MDP_IPI_EMINST	= 24,
+	MDP_IPI_ERANGE	= 34,
+	MDP_IPI_NR_ERRNO,
+
+	MDP_IPI_EOTHER	= MDP_IPI_NR_ERRNO,
+	MDP_IPI_PATH_CANT_MERGE,
+	MDP_IPI_OP_FAIL,
+};
+
+struct mdp_ipi_init_msg {
+	u32	status;
+	u64	drv_data;
+	u32	work_addr;	/* [in] working buffer address */
+	u32	work_size;	/* [in] working buffer size */
+} __attribute__ ((__packed__));
+
+struct mdp_ipi_deinit_msg {
+	u32	status;
+	u64	drv_data;
+	u32	work_addr;
+} __attribute__ ((__packed__));
+
+enum mdp_config_id {
+	MDP_DEV_M2M = 0,
+	MDP_CONFIG_POOL_SIZE	/* ALWAYS keep at the end */
+};
+
+struct mdp_config_pool {
+	u64		cfg_count[MDP_CONFIG_POOL_SIZE];
+	struct img_config	configs[MDP_CONFIG_POOL_SIZE];
+};
+
+struct mdp_vpu_dev {
+	struct mutex		*lock;
+	struct platform_device	*pdev;
+	struct completion	ipi_acked;
+	phys_addr_t		work;
+	phys_addr_t		work_addr;
+	size_t			work_size;
+	struct mdp_config_pool	*pool;
+	u32		status;
+};
+
+struct mdp_vpu_ctx {
+	struct mdp_vpu_dev	*vpu_dev;
+	u32		config_id;
+	struct img_config	*config;
+	u32		inst_addr;
+	s32			failure;
+};
+
+int mdp_vpu_register(struct platform_device *pdev);
+void mdp_vpu_unregister(struct platform_device *pdev);
+int mdp_vpu_dev_init(struct mdp_vpu_dev *vpu, struct platform_device *pdev,
+		     struct mutex *lock);
+int mdp_vpu_dev_deinit(struct mdp_vpu_dev *vpu);
+int mdp_vpu_ctx_init(struct mdp_vpu_ctx *ctx, struct mdp_vpu_dev *vpu,
+		     enum mdp_config_id id);
+int mdp_vpu_ctx_deinit(struct mdp_vpu_ctx *ctx);
+int mdp_vpu_process(struct mdp_vpu_ctx *vpu, struct img_ipi_frameparam *param);
+
+#endif  /* __MTK_MDP3_VPU_H__ */
+
diff --git a/drivers/media/platform/mtk-vpu/mtk_vpu.c b/drivers/media/platform/mtk-vpu/mtk_vpu.c
index 01cab05e7b81..3c87c315e948 100644
--- a/drivers/media/platform/mtk-vpu/mtk_vpu.c
+++ b/drivers/media/platform/mtk-vpu/mtk_vpu.c
@@ -595,8 +595,26 @@ static struct vpu_reserve_mblock vpu_reserve_mblock[] = {
 		.num = ISP_MEM_ID,
 		.start_phys = 0x0,
 		.start_virt = 0x0,
-		.size = 0x1400000,  /*20MB*/
+		.size = 0x200000,   /*2MB*/
 	},
+	{
+		.num = DIP_MEM_ID,
+		.start_phys = 0x0,
+		.start_virt = 0x0,
+		.size = 0x900000,   /*9MB*/
+	},
+	{
+		.num = MDP_MEM_ID,
+		.start_phys = 0x0,
+		.start_virt = 0x0,
+		.size = 0x600000,   /*6MB*/
+	},
+        {
+                .num = FD_MEM_ID,
+                .start_phys = 0x0,
+                .start_virt = 0x0,
+                .size = 0x100000,   /*1MB*/
+        },
 };
 
 int vpu_reserve_mem_of_init(struct reserved_mem *rmem)
diff --git a/drivers/media/platform/mtk-vpu/mtk_vpu.h b/drivers/media/platform/mtk-vpu/mtk_vpu.h
index ca09de70ceda..9c4cd0f53292 100644
--- a/drivers/media/platform/mtk-vpu/mtk_vpu.h
+++ b/drivers/media/platform/mtk-vpu/mtk_vpu.h
@@ -66,6 +66,13 @@ enum ipi_id {
 	IPI_VENC_H264,
 	IPI_VENC_VP8,
 	IPI_MDP,
+	IPI_MDP_INIT = IPI_MDP,
+	IPI_MDP_DEINIT,
+	IPI_MDP_FRAME,
+	IPI_DIP,
+	IPI_ISP_CMD,
+	IPI_ISP_FRAME,
+	IPI_FD_CMD,
 	IPI_MAX,
 };
 
@@ -201,6 +208,9 @@ void *vpu_mapping_dm_addr(struct platform_device *pdev,
 /* vpu reserve memory ID definition*/
 enum vpu_reserve_mem_id_t {
 	ISP_MEM_ID,
+	MDP_MEM_ID,
+	DIP_MEM_ID,
+	FD_MEM_ID,
 	NUMS_MEM_ID,
 };
 
diff --git a/drivers/media/v4l2-core/v4l2-compat-ioctl32.c b/drivers/media/v4l2-core/v4l2-compat-ioctl32.c
index f4325329fbd6..fe4577a46869 100644
--- a/drivers/media/v4l2-core/v4l2-compat-ioctl32.c
+++ b/drivers/media/v4l2-core/v4l2-compat-ioctl32.c
@@ -323,6 +323,7 @@ static int __get_v4l2_format32(struct v4l2_format __user *p64,
 		return copy_in_user(&p64->fmt.sdr, &p32->fmt.sdr,
 				    sizeof(p64->fmt.sdr)) ? -EFAULT : 0;
 	case V4L2_BUF_TYPE_META_CAPTURE:
+	case V4L2_BUF_TYPE_META_OUTPUT:
 		return copy_in_user(&p64->fmt.meta, &p32->fmt.meta,
 				    sizeof(p64->fmt.meta)) ? -EFAULT : 0;
 	default:
@@ -392,6 +393,7 @@ static int __put_v4l2_format32(struct v4l2_format __user *p64,
 		return copy_in_user(&p32->fmt.sdr, &p64->fmt.sdr,
 				    sizeof(p64->fmt.sdr)) ? -EFAULT : 0;
 	case V4L2_BUF_TYPE_META_CAPTURE:
+	case V4L2_BUF_TYPE_META_OUTPUT:
 		return copy_in_user(&p32->fmt.meta, &p64->fmt.meta,
 				    sizeof(p64->fmt.meta)) ? -EFAULT : 0;
 	default:
diff --git a/drivers/media/v4l2-core/v4l2-dev.c b/drivers/media/v4l2-core/v4l2-dev.c
index feb749aaaa42..fcd355e06518 100644
--- a/drivers/media/v4l2-core/v4l2-dev.c
+++ b/drivers/media/v4l2-core/v4l2-dev.c
@@ -597,7 +597,8 @@ static void determine_valid_ioctls(struct video_device *vdev)
 			       ops->vidioc_enum_fmt_vid_overlay ||
 			       ops->vidioc_enum_fmt_meta_cap)) ||
 		    (is_tx && (ops->vidioc_enum_fmt_vid_out ||
-			       ops->vidioc_enum_fmt_vid_out_mplane)))
+			       ops->vidioc_enum_fmt_vid_out_mplane ||
+			       ops->vidioc_enum_fmt_meta_out)))
 			set_bit(_IOC_NR(VIDIOC_ENUM_FMT), valid_ioctls);
 		if ((is_rx && (ops->vidioc_g_fmt_vid_cap ||
 			       ops->vidioc_g_fmt_vid_cap_mplane ||
@@ -605,7 +606,8 @@ static void determine_valid_ioctls(struct video_device *vdev)
 			       ops->vidioc_g_fmt_meta_cap)) ||
 		    (is_tx && (ops->vidioc_g_fmt_vid_out ||
 			       ops->vidioc_g_fmt_vid_out_mplane ||
-			       ops->vidioc_g_fmt_vid_out_overlay)))
+			       ops->vidioc_g_fmt_vid_out_overlay ||
+			       ops->vidioc_g_fmt_meta_out)))
 			 set_bit(_IOC_NR(VIDIOC_G_FMT), valid_ioctls);
 		if ((is_rx && (ops->vidioc_s_fmt_vid_cap ||
 			       ops->vidioc_s_fmt_vid_cap_mplane ||
@@ -613,7 +615,8 @@ static void determine_valid_ioctls(struct video_device *vdev)
 			       ops->vidioc_s_fmt_meta_cap)) ||
 		    (is_tx && (ops->vidioc_s_fmt_vid_out ||
 			       ops->vidioc_s_fmt_vid_out_mplane ||
-			       ops->vidioc_s_fmt_vid_out_overlay)))
+			       ops->vidioc_s_fmt_vid_out_overlay ||
+			       ops->vidioc_s_fmt_meta_out)))
 			 set_bit(_IOC_NR(VIDIOC_S_FMT), valid_ioctls);
 		if ((is_rx && (ops->vidioc_try_fmt_vid_cap ||
 			       ops->vidioc_try_fmt_vid_cap_mplane ||
@@ -621,7 +624,8 @@ static void determine_valid_ioctls(struct video_device *vdev)
 			       ops->vidioc_try_fmt_meta_cap)) ||
 		    (is_tx && (ops->vidioc_try_fmt_vid_out ||
 			       ops->vidioc_try_fmt_vid_out_mplane ||
-			       ops->vidioc_try_fmt_vid_out_overlay)))
+			       ops->vidioc_try_fmt_vid_out_overlay ||
+			       ops->vidioc_try_fmt_meta_out)))
 			 set_bit(_IOC_NR(VIDIOC_TRY_FMT), valid_ioctls);
 		SET_VALID_IOCTL(ops, VIDIOC_OVERLAY, vidioc_overlay);
 		SET_VALID_IOCTL(ops, VIDIOC_G_FBUF, vidioc_g_fbuf);
diff --git a/drivers/media/v4l2-core/v4l2-ioctl.c b/drivers/media/v4l2-core/v4l2-ioctl.c
index beb0d0722385..a65cdb039702 100644
--- a/drivers/media/v4l2-core/v4l2-ioctl.c
+++ b/drivers/media/v4l2-core/v4l2-ioctl.c
@@ -194,6 +194,7 @@ const char *v4l2_type_names[] = {
 	[V4L2_BUF_TYPE_SDR_CAPTURE]        = "sdr-cap",
 	[V4L2_BUF_TYPE_SDR_OUTPUT]         = "sdr-out",
 	[V4L2_BUF_TYPE_META_CAPTURE]       = "meta-cap",
+	[V4L2_BUF_TYPE_META_OUTPUT]        = "meta-out",
 };
 EXPORT_SYMBOL(v4l2_type_names);
 
@@ -368,6 +369,7 @@ static void v4l_print_format(const void *arg, bool write_only)
 			(sdr->pixelformat >> 24) & 0xff);
 		break;
 	case V4L2_BUF_TYPE_META_CAPTURE:
+	case V4L2_BUF_TYPE_META_OUTPUT:
 		meta = &p->fmt.meta;
 		pr_cont(", dataformat=%c%c%c%c, buffersize=%u\n",
 			(meta->dataformat >>  0) & 0xff,
@@ -1001,6 +1003,10 @@ static int check_fmt(struct file *file, enum v4l2_buf_type type)
 		if (is_vid && is_rx && ops->vidioc_g_fmt_meta_cap)
 			return 0;
 		break;
+	case V4L2_BUF_TYPE_META_OUTPUT:
+		if (is_vid && is_tx && ops->vidioc_g_fmt_meta_out)
+			return 0;
+		break;
 	default:
 		break;
 	}
@@ -1409,6 +1415,11 @@ static int v4l_enum_fmt(const struct v4l2_ioctl_ops *ops,
 			break;
 		ret = ops->vidioc_enum_fmt_meta_cap(file, fh, arg);
 		break;
+	case V4L2_BUF_TYPE_META_OUTPUT:
+		if (unlikely(!ops->vidioc_enum_fmt_meta_out))
+			break;
+		ret = ops->vidioc_enum_fmt_meta_out(file, fh, arg);
+		break;
 	}
 	if (ret == 0)
 		v4l_fill_fmtdesc(p);
@@ -1487,6 +1498,8 @@ static int v4l_g_fmt(const struct v4l2_ioctl_ops *ops,
 		return ops->vidioc_g_fmt_sdr_out(file, fh, arg);
 	case V4L2_BUF_TYPE_META_CAPTURE:
 		return ops->vidioc_g_fmt_meta_cap(file, fh, arg);
+	case V4L2_BUF_TYPE_META_OUTPUT:
+		return ops->vidioc_g_fmt_meta_out(file, fh, arg);
 	}
 	return -EINVAL;
 }
@@ -1595,6 +1608,11 @@ static int v4l_s_fmt(const struct v4l2_ioctl_ops *ops,
 			break;
 		CLEAR_AFTER_FIELD(p, fmt.meta);
 		return ops->vidioc_s_fmt_meta_cap(file, fh, arg);
+	case V4L2_BUF_TYPE_META_OUTPUT:
+		if (unlikely(!ops->vidioc_s_fmt_meta_out))
+			break;
+		CLEAR_AFTER_FIELD(p, fmt.meta);
+		return ops->vidioc_s_fmt_meta_out(file, fh, arg);
 	}
 	return -EINVAL;
 }
@@ -1682,6 +1700,11 @@ static int v4l_try_fmt(const struct v4l2_ioctl_ops *ops,
 			break;
 		CLEAR_AFTER_FIELD(p, fmt.meta);
 		return ops->vidioc_try_fmt_meta_cap(file, fh, arg);
+	case V4L2_BUF_TYPE_META_OUTPUT:
+		if (unlikely(!ops->vidioc_try_fmt_meta_out))
+			break;
+		CLEAR_AFTER_FIELD(p, fmt.meta);
+		return ops->vidioc_try_fmt_meta_out(file, fh, arg);
 	}
 	return -EINVAL;
 }
diff --git a/drivers/memory/mtk-emi.c b/drivers/memory/mtk-emi.c
new file mode 100644
index 000000000000..cb6a988c4d70
--- /dev/null
+++ b/drivers/memory/mtk-emi.c
@@ -0,0 +1,405 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2015-2016 MediaTek Inc.
+ * Author: Xi Chen <xixi.chen@mediatek.com>
+ */
+
+#include <linux/cdev.h>
+#include <linux/clk.h>
+#include <linux/component.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/fs.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/time.h>
+#include <linux/timer.h>
+#include <soc/mediatek/emi.h>
+
+/* 67ms emi bw  */
+#define EMI_BW_ARRAY_SIZE	67
+
+#define MT8173_SMI_LARB_NR	6
+#define MT8167_SMI_LARB_NR	3
+#define MTK_SMI_LARB_NR_MAX	8
+#define MT8173_MMU_EN		0xf00
+#define MT8167_MMU_EN		0xfc0
+#define MT8167_LARB0_OFF	0
+#define MT8167_LARB1_OFF	8
+#define MT8167_LARB2_OFF	21
+
+/*****************************************************************************
+ *  Type Definitions
+ *****************************************************************************/
+enum DDRTYPE {
+	TYPE_LPDDR3 = 1,
+	TYPE_LPDDR4,
+	TYPE_LPDDR4X
+};
+
+enum {
+	EMI_BASE_IDX_EMI = 0,
+	EMI_BASE_IDX_EMI_CH0,
+	EMI_BASE_IDX_EMI_CH1,
+
+	NR_EMI_BASE_IDX,
+};
+
+struct emi_base_addr {
+	unsigned int phy_addr;
+	unsigned int remap_addr;
+};
+
+struct mtk_emi {
+	void __iomem *cen_emi_base;
+	void __iomem *chn_emi_base[MAX_CH];
+	void __iomem *emi_mpu_base;
+
+	struct emi_info_t emi_info;
+
+	struct timer_list emi_bw_timer;
+	struct timeval old_tv;
+
+	unsigned long long emi_bw_array[EMI_BW_ARRAY_SIZE];
+	int emi_bw_cur_idx;
+	int emi_bw_max_idx;
+};
+
+/* because timer can't pass argument, so add the global
+ * static struct device * for timer callback usage
+ */
+static struct device *emi_dev;
+
+static unsigned long long emi_get_max_bw_in_last_array(struct device *dev,
+	unsigned long long arr[], unsigned int size)
+{
+	unsigned int i = 0;
+	unsigned long long max = arr[0];
+
+	while (i < size) {
+		if (arr[i] > max)
+			max = arr[i];
+		++i;
+	}
+	return max;
+}
+
+unsigned long long mtk_emi_get_max_bw(void)
+{
+	struct mtk_emi *emi;
+
+	if (!emi_dev)
+		return 0;
+
+	emi = dev_get_drvdata(emi_dev);
+	return emi_get_max_bw_in_last_array(emi_dev,
+		emi->emi_bw_array, ARRAY_SIZE(emi->emi_bw_array));
+}
+EXPORT_SYMBOL(mtk_emi_get_max_bw);
+
+static void emi_update_bw_array(struct device *dev, unsigned int val)
+{
+	struct mtk_emi *emi = dev_get_drvdata(emi_dev);
+
+	if (emi->emi_bw_cur_idx == emi->emi_bw_max_idx) {
+		/* remove the first array element */
+		memmove(emi->emi_bw_array, emi->emi_bw_array + 1,
+			sizeof(unsigned long long) * (emi->emi_bw_max_idx - 1));
+		emi->emi_bw_array[emi->emi_bw_max_idx - 1] = val;
+	} else
+		emi->emi_bw_array[emi->emi_bw_cur_idx++] = val;
+}
+
+static void emi_dump_bw_array(struct device *dev)
+{
+	int i = 0;
+	int unit = 10;
+	struct mtk_emi *emi = dev_get_drvdata(emi_dev);
+
+	while (i < emi->emi_bw_max_idx) {
+		if (i != 0 && i % unit == 0)
+			pr_info("\n");
+		pr_info("0x%x ", emi->emi_bw_array[i]);
+
+		++i;
+	}
+
+	pr_info("\n");
+}
+
+static void emi_counter_reset(struct device *dev)
+{
+	struct mtk_emi *emi = dev_get_drvdata(dev);
+
+	writel(EMI_BMEN_DEFAULT_VALUE, EMI_BMEN);
+	writel(EMI_MSEL_DEFAULT_VALUE, EMI_MSEL);
+	writel(EMI_MSEL2_DEFAULT_VALUE, EMI_MSEL2);
+	writel(EMI_BMEN2_DEFAULT_VALUE, EMI_BMEN2);
+	writel(EMI_BMRW0_DEFAULT_VALUE, EMI_BMRW0);
+}
+
+static void emi_counter_pause(struct device *dev)
+{
+	struct mtk_emi *emi = dev_get_drvdata(dev);
+	const unsigned int value = readl(EMI_BMEN);
+
+	/* BW monitor */
+	writel(value | BUS_MON_PAUSE, EMI_BMEN);
+}
+
+static void emi_counter_continue(struct device *dev)
+{
+	struct mtk_emi *emi = dev_get_drvdata(dev);
+	const unsigned int value = readl(EMI_BMEN);
+
+	/* BW monitor */
+	writel(value & (~BUS_MON_PAUSE), EMI_BMEN);
+}
+
+static void emi_counter_enable(struct device *dev, const unsigned int enable)
+{
+	unsigned int value, value_set;
+	struct mtk_emi *emi = dev_get_drvdata(dev);
+
+	value = readl(EMI_BMEN);
+	if (enable == 0) {	/* disable monitor circuit */
+		/*  bit3 =1	bit0 = 0-> clear */
+		value_set = (value) | (BUS_MON_IDLE);
+		writel(value_set, EMI_BMEN);
+
+		value_set = ((value) | (BUS_MON_IDLE)) & ~(BUS_MON_EN);
+		writel(value_set, EMI_BMEN);
+
+		value_set = ((value) & ~(BUS_MON_IDLE)) & ~(BUS_MON_EN);
+		writel(value_set, EMI_BMEN);
+	} else {		/* enable monitor circuit */
+		/*  bit3 =0	&   bit0=1 */
+		value_set = (value & ~(BUS_MON_IDLE));
+		writel(value_set, EMI_BMEN);
+
+		value_set = (value & ~(BUS_MON_IDLE)) | (BUS_MON_EN);
+		writel(value_set, EMI_BMEN);
+	}
+}
+
+static void mtk_emi_mon_start(struct device *dev)
+{
+	emi_counter_enable(dev, 0);
+	emi_counter_reset(dev);
+	emi_counter_enable(dev, 1);
+}
+
+static void mtk_emi_mon_restart(struct device *dev)
+{
+	emi_counter_continue(dev);
+	emi_counter_enable(dev, 0);
+	emi_counter_reset(dev);
+	emi_counter_enable(dev, 1);
+}
+
+static void mtk_emi_mon_stop(struct device *dev)
+{
+	emi_counter_pause(dev);
+}
+
+static ssize_t emi_show_max_bw(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	unsigned long long var, bw_cpu;
+	unsigned int bw_gpu;
+	struct mtk_emi *emi = dev_get_drvdata(dev);
+
+	if (!dev) {
+		pr_warn("dev is null!!\n");
+		return 0;
+	}
+
+	var = mtk_emi_get_max_bw();
+	bw_gpu = readl(EMI_BWVL_4TH) & 0x7f;
+	bw_cpu = readl(EMI_WSCT3);
+
+	return scnprintf(buf, PAGE_SIZE,
+		"gpu_max_bw:%llu(0x%x) EMI_BWVL_4TH:0x%x, cpu:%llu(0x%x)\n",
+		var, var, bw_gpu, bw_cpu, bw_cpu);
+}
+DEVICE_ATTR(bw,  0440, emi_show_max_bw, NULL);
+
+static ssize_t emi_dump_bw(struct device *dev, struct device_attribute *attr,
+			   char *buf)
+{
+	unsigned long long var;
+
+	if (!dev) {
+		pr_warn("dev is null!!\n");
+		return 0;
+	}
+
+	emi_dump_bw_array(dev);
+	var = mtk_emi_get_max_bw();
+
+	return scnprintf(buf, PAGE_SIZE,
+		"\temi_max_bw:%llu(0x%x)\n", var, var);
+}
+DEVICE_ATTR(dump_bw,  0440, emi_dump_bw, NULL);
+
+static int emi_bw_ms = 1;
+module_param_named(bw_ms, emi_bw_ms, int, 0664);
+
+static void emi_bw_timer_callback(struct timer_list *tm)
+{
+	struct timeval tv;
+	unsigned long long val, cur_max;
+	struct mtk_emi *emi = dev_get_drvdata(emi_dev);
+
+	do_gettimeofday(&tv);
+
+	/* pasue emi monitor for get WACT value*/
+	mtk_emi_mon_stop(emi_dev);
+
+	val = readl(EMI_WSCT4);	/* GPU BW */
+	val *= 8;
+
+	cur_max = mtk_emi_get_max_bw();
+	emi_update_bw_array(emi_dev, val);
+
+	/* set mew timer expires and restart emi monitor */
+	emi->old_tv = tv;
+	emi->emi_bw_timer.expires = jiffies + msecs_to_jiffies(emi_bw_ms);
+
+	add_timer(&(emi->emi_bw_timer));
+	mtk_emi_mon_restart(emi_dev);
+}
+
+static int emi_probe(struct platform_device *pdev)
+{
+	struct mtk_emi *emi;
+	struct resource *res;
+	struct device *dev = &pdev->dev;
+	int i, ret;
+
+	emi = devm_kzalloc(dev, sizeof(*emi), GFP_KERNEL);
+	if (!emi)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	emi->cen_emi_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(emi->cen_emi_base)) {
+		pr_err("[EMI] unable to map cen_emi_base\n");
+		devm_kfree(dev, emi);
+		return -EINVAL;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
+	emi->emi_mpu_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(emi->emi_mpu_base)) {
+		pr_err("[EMI] unable to map emi_mpu_base\n");
+		devm_kfree(dev, emi);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < MAX_CH; i++) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, 2 + i);
+		emi->chn_emi_base[i] = devm_ioremap_resource(dev, res);
+		if (IS_ERR(emi->chn_emi_base[i])) {
+			pr_err("[EMI] unable to map ch%d_emi_base\n", i);
+			devm_kfree(dev, emi);
+			return -EINVAL;
+		}
+	}
+
+	platform_set_drvdata(pdev, emi);
+
+	emi_dev = dev;
+	/* start emi bw monitor */
+	mtk_emi_mon_start(dev);
+
+	emi->emi_bw_max_idx = ARRAY_SIZE(emi->emi_bw_array);
+	/* setup timer */
+	timer_setup(&(emi->emi_bw_timer), NULL, 0);
+	do_gettimeofday(&(emi->old_tv));
+
+	emi->emi_bw_timer.function = emi_bw_timer_callback;
+	emi->emi_bw_timer.expires = jiffies + msecs_to_jiffies(1);
+	add_timer(&(emi->emi_bw_timer));
+
+	/* debug node */
+	ret = device_create_file(dev, &dev_attr_bw);
+	if (ret) {
+		dev_err(dev, "create bw file failed!\n");
+		goto err_create_attr_bw;
+	}
+	ret = device_create_file(dev, &dev_attr_dump_bw);
+	if (ret) {
+		dev_err(dev, "create dump_bw file failed!\n");
+		goto err_create_attr_dump_bw;
+	}
+
+	return 0;
+
+err_create_attr_dump_bw:
+	del_timer(&(emi->emi_bw_timer));
+	device_remove_file(dev, &dev_attr_bw);
+err_create_attr_bw:
+	devm_kfree(dev, emi);
+	return -ENOMEM;
+}
+
+static int emi_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct mtk_emi *emi = dev_get_drvdata(dev);
+
+	del_timer(&(emi->emi_bw_timer));
+	device_remove_file(dev, &dev_attr_dump_bw);
+	device_remove_file(dev, &dev_attr_bw);
+
+	devm_kfree(dev, emi);
+	return 0;
+}
+
+#ifdef CONFIG_OF
+static const struct of_device_id emi_of_ids[] = {
+	{.compatible = "mediatek,mt8183-emi",},
+	{}
+};
+#endif
+
+static struct platform_driver emi_bw_driver = {
+	.probe = emi_probe,
+	.remove = emi_remove,
+	.driver = {
+		.name = "emi_bw",
+		.owner = THIS_MODULE,
+		.pm = NULL,
+#ifdef CONFIG_OF
+		.of_match_table = emi_of_ids,
+#endif
+	},
+};
+
+static int __init emi_bw_init(void)
+{
+	int ret;
+
+	/* register EMI ctrl interface */
+	ret = platform_driver_register(&emi_bw_driver);
+	if (ret) {
+		pr_err("[EMI/BWL] fail to register emi_bw_driver\n");
+		return -ENODEV;
+	}
+
+	return 0;
+}
+
+static void __exit emi_bw_exit(void)
+{
+	platform_driver_unregister(&emi_bw_driver);
+}
+
+postcore_initcall(emi_bw_init);
+module_exit(emi_bw_exit);
+
diff --git a/drivers/mmc/host/mtk-sdio-proc.c b/drivers/mmc/host/mtk-sdio-proc.c
new file mode 100644
index 000000000000..6f4c3cd96d42
--- /dev/null
+++ b/drivers/mmc/host/mtk-sdio-proc.c
@@ -0,0 +1,342 @@
+/*
+ * Copyright (c) 2014-2015 MediaTek Inc.
+ * Author: Chaotian.Jing <chaotian.jing@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include "mtk-sdio-proc.h"
+
+static struct mmc_host *host;
+
+/**
+ * sdio_proc_show dispaly the common cccr and cis.
+ */
+static int sdio_proc_show(struct seq_file *m, void *v)
+{
+	struct mmc_card *card;
+	struct sdio_cccr cccr;
+
+	WARN_ON(!host);
+	card = host->card;
+	cccr = card->cccr;
+
+	seq_puts(m, "\n=========================================\n");
+	seq_puts(m, "common cccr:\n");
+	seq_printf(m, "sdio_vsn:%x, sd_vsn:%x, multi_block%x.\n"
+			"low_speed:%x, wide_bus:%x, hight_power:%x.\n"
+			"high_speed:%x, disable_cd:%x.\n",
+			cccr.sdio_vsn, cccr.sd_vsn, cccr.multi_block,
+			cccr.low_speed, cccr.wide_bus, cccr.high_power,
+			cccr.high_speed, cccr.disable_cd);
+
+	seq_puts(m, "common cis:\n");
+	seq_printf(m, "vendor: %x, device:%x, blksize:%x, max_dtr:%x\n",
+			card->cis.vendor, card->cis.device,
+			card->cis.blksize, card->cis.max_dtr);
+
+	seq_puts(m, "read cmd format:\n");
+	seq_puts(m, "echo 0 0xReg 0xfunction> /proc/sdio\n");
+	seq_puts(m, "write cmd format:\n");
+	seq_puts(m, "echo 1 0xReg 0xfunction 0xValue> /proc/sdio\n");
+	seq_puts(m, "setspeed cmd format:\n");
+	seq_puts(m, "echo 2 0xclkfrequency > /proc/sdio\n");
+	seq_puts(m, "tune cmd format:\n");
+	seq_puts(m, "echo 3 0xloop_cycles > /proc/sdio\n");
+	seq_puts(m, "multi read cmd format:\n");
+	seq_puts(m, "echo 4 0x13 0x0 > /proc/sdio\n");
+	seq_puts(m, "multi write cmd format:\n");
+	seq_puts(m, "echo 5 0x13 0x0 0xvalue > /proc/sdio\n");
+	seq_puts(m, "Notice:value is the read result!\n");
+	seq_puts(m, "=========================================\n");
+
+	return 0;
+}
+
+static int sdio_tuning(void)
+{
+	int err = 0;
+
+	err = mmc_send_tuning(host, MMC_SEND_TUNING_BLOCK, NULL);
+	if (err)
+		pr_err("tuning result is %d.\n", err);
+	return err;
+}
+
+/**
+ * sdio_proc_write - read/write sdio function register.
+ */
+static ssize_t sdio_proc_write(struct file *file, const char *buf,
+		size_t count, loff_t *f_pos)
+{
+	struct mmc_card *card;
+	struct sdio_func *func;
+	struct mmc_ios *ios;
+	char *cmd_buf;
+	unsigned int cmd, addr, fn, value, hqa_result;
+	unsigned char result;
+	int i = 0, ret;
+	unsigned long long count_r = 0, count_w = 0, total = 0;
+
+	WARN_ON(!host);
+	card = host->card;
+	ios = &host->ios;
+
+	cmd_buf = kzalloc((count + 1), GFP_KERNEL);
+	if (!cmd_buf)
+		return -ENOMEM;
+
+	func = kzalloc(sizeof(struct sdio_func), GFP_KERNEL);
+	if (!func)
+		return -ENOMEM;
+
+	ret = copy_from_user(cmd_buf, buf, count);
+	if (ret < 0) {
+		kfree(cmd_buf);
+		kfree(func);
+		return -EFAULT;
+	}
+
+	*(cmd_buf + count) = '\0';
+	ret = sscanf(cmd_buf, "%x %x %x %x",
+			&cmd, &addr, &fn, &value);
+	if (ret == 0) {
+		pr_err("please enter cmd.\n");
+		return ret;
+	}
+
+	if ((cmd == tune) || (cmd == speed))
+		fn = 0;
+
+	/* Judge whether request fn is over the max functions. */
+	if (fn > card->sdio_funcs) {
+		pr_err("the fn is over the max sdio funcs.\n");
+		return -EFAULT;
+	}
+
+	if (fn) {
+		/**
+		 * The test read/write api don't need more func
+		 * information. So we just use the card & func->num
+		 * to the new struct func.
+		 */
+		if (card->sdio_func[fn - 1]) {
+			func->card = card;
+			func->num = card->sdio_func[fn - 1]->num;
+			func->tuples = card->sdio_func[fn - 1]->tuples;
+			func->tmpbuf = card->sdio_func[fn - 1]->tmpbuf;
+			func->max_blksize = card->sdio_func[fn - 1]->max_blksize;
+			if ((cmd == hqa_read) || (cmd == hqa_write) || (cmd == burn))
+				func->cur_blksize = 8;
+			else
+				func->cur_blksize = 1;
+			func = card->sdio_func[fn - 1];
+		} else
+			pr_err("func %d is null,.\n", fn);
+	} else {
+		/**
+		  * function 0 should not need struct func.
+		  * but the api need the parameter, so we create
+		  * the a new func for function 0.
+		  */
+		func->card = card;
+		func->tuples = card->tuples;
+		func->num = 0;
+		func->max_blksize = 16;
+		if ((cmd == hqa_read) || (cmd == hqa_write) || (cmd == burn))
+			func->cur_blksize = 16;
+		else
+			func->cur_blksize = 1;
+
+		func->tmpbuf = kmalloc(func->cur_blksize, GFP_KERNEL);
+		if (!func->tmpbuf) {
+			kfree(func);
+			return -ENOMEM;
+		}
+		memset(func->tmpbuf, 0, func->cur_blksize);
+	}
+
+	sdio_claim_host(func);
+	pr_err("===========================================\n");
+
+	switch (cmd) {
+	case read:
+		pr_err("read addr:%x, fn:%d.\n", addr, fn);
+		ret = 0;
+		if (fn == 0)
+			result = sdio_f0_readb(func, addr, &ret);
+		else
+			result = sdio_readb(func, addr, &ret);
+
+		if (ret)
+			pr_err("Read f%d reg(%x) fail(%d).\n",
+					func->num, addr, ret);
+		else
+			pr_err("f%d reg(%x) is 0x%02x.\n",
+					func->num, addr, result);
+		break;
+	case write:
+		pr_err("write addr:%x, value:%x, fn %d.\n",
+				addr, (u8)value, fn);
+		ret = 0;
+		if (fn == 0)
+			/* (0xF0 - 0xFF) are permiited for func0 */
+			sdio_f0_writeb(func, (u8)value, addr, &ret);
+		else
+			sdio_writeb(func, (u8)value, addr, &ret);
+
+		if (ret)
+			pr_err("write f%d reg(%x) fail(%d).\n",
+					func->num, addr, ret);
+		else
+			pr_err("write f%d reg(%x) success(%d).\n",
+					func->num, addr, ret);
+
+		break;
+	case speed:
+		pr_err("set frequence:%x.\n", addr);
+
+		if (addr > 200000000)
+			addr = 200000000;
+		ios->clock = addr;
+		pr_err("%s: clock %uHz busmode %u powermode %u cs %u Vdd %u width %u timing %u\n",
+				mmc_hostname(host), ios->clock, ios->bus_mode,
+				ios->power_mode, ios->chip_select, ios->vdd,
+				ios->bus_width, ios->timing);
+
+		host->ops->set_ios(host, ios);
+		break;
+	case tune:
+		value = 0;
+		pr_err("read loop / 0x200:%x.\n", addr);
+
+		do {
+			result = sdio_tuning();
+			if (result)
+				value = value + 1;
+
+			i = i + 1;
+		} while (i < addr);
+
+		pr_err("send tuning cmd is result (%d).\n", value);
+		break;
+	case hqa_read:
+		pr_err("hqa_r addr:%x, fn %d\n", addr, fn);
+		i = 0;
+		hqa_result = 0;
+		do {
+			ret = 0;
+			hqa_result = sdio_readl(func, addr, &ret);
+			if (ret)
+				pr_err("Read f%d reg(%x) fail(%d).\n",
+						func->num, addr, ret);
+
+			i = i + 1;
+		} while (i < 0x10000);
+		pr_err("Read %d cycles success:f%d reg(%x) is 0x%02x.\n",
+				i, func->num, addr, hqa_result);
+		break;
+	case hqa_write:
+		pr_err("hqa_w addr:%x, value:%x, fn %d\n",
+				addr, value, fn);
+		i = 0;
+		hqa_result = 0;
+		do {
+			ret = 0;
+			sdio_writel(func, value, addr, &ret);
+			if (ret)
+				pr_err("write f%d reg(%x) fail(%d).\n",
+						func->num, addr, ret);
+
+			i = i + 1;
+		} while (i < 0x10000);
+		pr_err("write f%d reg(%x) success(%d).\n",
+				func->num, addr, ret);
+		break;
+	case burn:
+		do {
+			ret = 0;
+			addr = 0x13;
+			value = sdio_readl(func, addr, &ret);
+			if (ret)
+				pr_err("Read f%d reg(%x) fail(%d).\n",
+						func->num, addr, ret);
+			else {
+				pr_err("********read success********\n");
+				count_r = count_r + 1;
+			}
+			msleep(20);
+
+			ret = 0;
+			addr = 0x13;
+			func->cur_blksize = 4;
+			sdio_writel(func, value, addr, &ret);
+			if (ret)
+				pr_err("write f%d reg(%x) fail(%d).\n",
+						func->num, addr, ret);
+			else {
+				pr_err("********write success*******\n");
+				count_w = count_w + 1;
+			}
+			total = total + 1;
+			msleep(20);
+			pr_err("success read:%llx, write:%llx, total:%llx.\n",
+					count_r, count_w, total);
+		} while (1);
+		break;
+	default:
+		pr_err("cmd is not valid.\n");
+		break;
+	}
+
+	pr_err("\n===========================================\n");
+	sdio_release_host(func);
+
+	kfree(cmd_buf);
+	kfree(func);
+
+	return count;
+}
+
+/**
+ * open function show some stable information.
+ */
+static int sdio_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, sdio_proc_show, inode->i_private);
+}
+
+/**
+  * sdio pre is our own function.
+  * seq or single pre is the kernel function.
+  */
+static const struct file_operations sdio_proc_fops = {
+	.owner = THIS_MODULE,
+	.open = sdio_proc_open,
+	.release = single_release,
+	.write = sdio_proc_write,
+	.read = seq_read,
+	.llseek = seq_lseek,
+};
+
+int sdio_proc_init(struct mmc_host *host_init)
+{
+	struct proc_dir_entry *prEntry;
+
+	host = host_init;
+
+	prEntry = proc_create("sdio", 0660, NULL, &sdio_proc_fops);
+	if (prEntry)
+		pr_err("[%s]/proc/sdio_proc is created.\n", __func__);
+	else
+		pr_err("[%s]Create /proc/sdio_proc failed.\n", __func__);
+
+	return 0;
+}
diff --git a/drivers/mmc/host/mtk-sdio-proc.h b/drivers/mmc/host/mtk-sdio-proc.h
new file mode 100644
index 000000000000..33659ba69be3
--- /dev/null
+++ b/drivers/mmc/host/mtk-sdio-proc.h
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2014-2015 MediaTek Inc.
+ * Author: Chaotian.Jing <chaotian.jing@mediatek.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/kthread.h>
+#include <linux/delay.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/proc_fs.h>
+#include <linux/string.h>
+#include <linux/uaccess.h>
+#include <linux/mmc/host.h>
+#include <linux/vmalloc.h>
+#include <linux/fs.h>
+#include <linux/seq_file.h>
+#include <linux/slab.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/sdio_func.h>
+
+int sdio_proc_init(struct mmc_host *host);
+
+enum {
+	read = 0,
+	write,
+	speed,
+	tune,
+	hqa_read,
+	hqa_write,
+	burn
+};
diff --git a/drivers/remoteproc/mtk_common.h b/drivers/remoteproc/mtk_common.h
new file mode 100644
index 000000000000..19a907810271
--- /dev/null
+++ b/drivers/remoteproc/mtk_common.h
@@ -0,0 +1,77 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ */
+
+#ifndef __RPROC_MTK_COMMON_H
+#define __RPROC_MTK_COMMON_H
+
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/remoteproc.h>
+
+#define MT8183_SW_RSTN			0x0
+#define MT8183_SW_RSTN_BIT		BIT(0)
+#define MT8183_SCP_TO_HOST		0x1C
+#define MT8183_SCP_IPC_INT_BIT		BIT(0)
+#define MT8183_SCP_WDT_INT_BIT		BIT(8)
+#define MT8183_HOST_TO_SCP		0x28
+#define MT8183_HOST_IPC_INT_BIT		BIT(0)
+#define MT8183_SCP_SRAM_PDN		0x402C
+
+#define SCP_FW_VER_LEN		32
+
+struct scp_run {
+	u32 signaled;
+	s8 fw_ver[SCP_FW_VER_LEN];
+	u32 dec_capability;
+	u32 enc_capability;
+	wait_queue_head_t wq;
+};
+
+struct scp_ipi_desc {
+	scp_ipi_handler_t handler;
+	void *priv;
+};
+
+struct mtk_scp {
+	struct device *dev;
+	struct rproc *rproc;
+	struct clk *clk;
+	void __iomem *reg_base;
+	void __iomem *sram_base;
+	size_t sram_size;
+
+	struct share_obj *recv_buf;
+	struct share_obj *send_buf;
+	struct scp_run run;
+	struct mutex lock; /* for protecting mtk_scp data structure */
+	struct scp_ipi_desc ipi_desc[SCP_IPI_MAX];
+	bool ipi_id_ack[SCP_IPI_MAX];
+	wait_queue_head_t ack_wq;
+
+	void __iomem *cpu_addr;
+	phys_addr_t phys_addr;
+	size_t dram_size;
+
+	struct rproc_subdev *rpmsg_subdev;
+};
+
+/**
+ * struct share_obj - SRAM buffer shared with
+ *		      AP and SCP
+ *
+ * @id:		IPI id
+ * @len:	share buffer length
+ * @share_buf:	share buffer data
+ */
+struct share_obj {
+	s32 id;
+	u32 len;
+	u8 share_buf[288];
+};
+
+void scp_memcpy_aligned(void *dst, const void *src, unsigned int len);
+
+#endif
diff --git a/drivers/remoteproc/mtk_scp.c b/drivers/remoteproc/mtk_scp.c
new file mode 100644
index 000000000000..167991b29161
--- /dev/null
+++ b/drivers/remoteproc/mtk_scp.c
@@ -0,0 +1,699 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+
+#include <asm/barrier.h>
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of_address.h>
+#include <linux/of_platform.h>
+#include <linux/platform_data/mtk_scp.h>
+#include <linux/platform_device.h>
+#include <linux/remoteproc.h>
+#include <linux/rpmsg/mtk_rpmsg.h>
+
+#include "mtk_common.h"
+#include "remoteproc_internal.h"
+
+#define MAX_CODE_SIZE 0x500000
+#define SCP_FW_BASE 0x800
+
+struct platform_device *scp_get_pdev(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *scp_node;
+	struct platform_device *scp_pdev;
+
+	scp_node = of_parse_phandle(dev->of_node, "mediatek,scp", 0);
+	if (!scp_node) {
+		dev_err(dev, "can't get SCP node\n");
+		return NULL;
+	}
+
+	scp_pdev = of_find_device_by_node(scp_node);
+	if (WARN_ON(!scp_pdev)) {
+		dev_err(dev, "SCP pdev failed\n");
+		of_node_put(scp_node);
+		return NULL;
+	}
+
+	return scp_pdev;
+}
+EXPORT_SYMBOL_GPL(scp_get_pdev);
+
+static void scp_wdt_handler(struct mtk_scp *scp)
+{
+	rproc_report_crash(scp->rproc, RPROC_WATCHDOG);
+}
+
+static void scp_init_ipi_handler(void *data, unsigned int len, void *priv)
+{
+	struct mtk_scp *scp = (struct mtk_scp *)priv;
+	struct scp_run *run = (struct scp_run *)data;
+
+	scp->run.signaled = run->signaled;
+	strncpy(scp->run.fw_ver, run->fw_ver, SCP_FW_VER_LEN);
+	scp->run.dec_capability = run->dec_capability;
+	scp->run.enc_capability = run->enc_capability;
+	wake_up_interruptible(&scp->run.wq);
+}
+
+static void scp_ipi_handler(struct mtk_scp *scp)
+{
+	struct share_obj *rcv_obj = scp->recv_buf;
+	struct scp_ipi_desc *ipi_desc = scp->ipi_desc;
+	u8 tmp_data[288];
+
+	if (rcv_obj->id >= SCP_IPI_MAX || !ipi_desc[rcv_obj->id].handler) {
+		dev_err(scp->dev, "No such ipi id = %d\n", rcv_obj->id);
+		return;
+	}
+
+	memcpy_fromio(tmp_data, &rcv_obj->share_buf, rcv_obj->len);
+	ipi_desc[rcv_obj->id].handler(tmp_data,
+				      rcv_obj->len,
+				      ipi_desc[rcv_obj->id].priv);
+	scp->ipi_id_ack[rcv_obj->id] = true;
+	wake_up(&scp->ack_wq);
+}
+
+static int scp_ipi_init(struct mtk_scp *scp)
+{
+	size_t send_offset = SCP_FW_BASE - sizeof(struct share_obj);
+	size_t recv_offset = send_offset - sizeof(struct share_obj);
+
+	/* Disable SCP to host interrupt */
+	writel(MT8183_SCP_IPC_INT_BIT, scp->reg_base + MT8183_SCP_TO_HOST);
+
+	/* shared buffer initialization */
+	scp->recv_buf = (__force struct share_obj *)(scp->sram_base +
+						recv_offset);
+	scp->send_buf = (__force struct share_obj *)(scp->sram_base +
+						send_offset);
+	memset_io(scp->recv_buf, 0, sizeof(scp->recv_buf));
+	memset_io(scp->send_buf, 0, sizeof(scp->send_buf));
+
+	return 0;
+}
+
+static void scp_reset_assert(const struct mtk_scp *scp)
+{
+	u32 val;
+
+	val = readl(scp->reg_base + MT8183_SW_RSTN);
+	val &= ~MT8183_SW_RSTN_BIT;
+	writel(val, scp->reg_base + MT8183_SW_RSTN);
+}
+
+static void scp_reset_deassert(const struct mtk_scp *scp)
+{
+	u32 val;
+
+	val = readl(scp->reg_base + MT8183_SW_RSTN);
+	val |= MT8183_SW_RSTN_BIT;
+	writel(val, scp->reg_base + MT8183_SW_RSTN);
+}
+
+static irqreturn_t scp_irq_handler(int irq, void *priv)
+{
+	struct mtk_scp *scp = priv;
+	u32 scp_to_host;
+	int ret;
+
+	ret = clk_prepare_enable(scp->clk);
+	if(ret) {
+		dev_err(scp->dev, "failed to enable clocks\n");
+		return IRQ_NONE;
+	}
+
+	scp_to_host = readl(scp->reg_base + MT8183_SCP_TO_HOST);
+	if (scp_to_host & MT8183_SCP_IPC_INT_BIT) {
+		scp_ipi_handler(scp);
+	} else {
+		dev_err(scp->dev, "SCP watchdog timeout! 0x%x", scp_to_host);
+		scp_wdt_handler(scp);
+	}
+
+	/*
+	 * Ensure that all writes to SRAM are committed before another
+	 * interrupt.
+	 */
+	mb();
+	/* SCP won't send another interrupt until we set SCP_TO_HOST to 0. */
+	writel(MT8183_SCP_IPC_INT_BIT | MT8183_SCP_WDT_INT_BIT,
+	       scp->reg_base + MT8183_SCP_TO_HOST);
+	clk_disable_unprepare(scp->clk);
+
+	return IRQ_HANDLED;
+}
+
+static void verb_memcpy(void *dest, __const void *src, __kernel_size_t n) {
+	pr_info("Copy %llx <- %llx 0x%x\n", (long)dest, (long)src, (int)n);
+	memcpy_toio(dest, src, n);
+}
+
+static int scp_load(struct rproc *rproc, const struct firmware *fw)
+{
+	const struct mtk_scp *scp = rproc->priv;
+	struct device *dev = scp->dev;
+	int ret;
+
+	uint32_t image_offset = 0;
+	uint32_t ap_loader_size;
+	uint32_t ap_firmware_size;
+	uint32_t ap_cached_size;
+
+	const uint32_t ap_loader_start = 0x0;
+	const uint32_t ap_loader_config = 0x400;
+	const uint32_t ap_firmware_start = 0x800;
+	const uint32_t ap_cached_start = 0x80000;
+	const uint32_t ap_cached_backup_start = 0x180000;
+
+	uint32_t magic[9];
+
+	u32 val;
+
+	ret = clk_prepare_enable(scp->clk);
+	if (ret) {
+		dev_err(dev, "failed to enable clocks\n");
+		return ret;
+	}
+
+	/* Hold SCP in reset while loading FW. */
+	scp_reset_assert(scp);
+
+	// Step 0
+	writel(0x0, scp->reg_base + MT8183_SCP_SRAM_PDN);
+
+	// CLK_CTRL_L1_SRAM_PD
+	writel(0x0, scp->reg_base + 0x4080);
+	// CLK_CTRL_TCM_TAIL_SRAM_PD
+	writel(0x0, scp->reg_base + 0x4094);
+
+	// HACK: Step 1 tinysys-loader
+	ap_loader_size = *(uint32_t *)(fw->data+image_offset+0x4);
+	image_offset += 0x200;
+	verb_memcpy(scp->cpu_addr+ap_loader_start, fw->data+image_offset,
+		ap_loader_size);
+	image_offset += round_up(ap_loader_size, 16);
+
+	// HACK: Step 2 tinysys-scp
+	ap_firmware_size = *(uint32_t *)(fw->data+image_offset+0x4);
+	image_offset += 0x200;
+	verb_memcpy(scp->cpu_addr+ap_firmware_start, fw->data+image_offset,
+		ap_firmware_size);
+	image_offset += round_up(ap_firmware_size, 16);
+
+	// HACK: Step 3 tinysys-scp-dram
+	ap_cached_size = *(uint32_t *)(fw->data+image_offset+0x4);
+	image_offset += 0x200;
+	verb_memcpy(scp->cpu_addr+ap_cached_start, fw->data+image_offset,
+		ap_cached_size);
+	// HACK: Step 3.1
+	verb_memcpy(scp->cpu_addr+ap_cached_backup_start, fw->data+image_offset,
+		ap_cached_size);
+
+	/* Blank the SRAM for easier debugging */
+	memset_io(scp->sram_base, 0, scp->sram_size);
+	// HACK: Step 6
+	verb_memcpy(scp->sram_base, fw->data+0x200, ap_loader_size);
+	// HACK: Step 7
+
+	pr_info("phys_addr is %llx!\n", (long)scp->phys_addr);
+
+	// ap_loader_start/size
+	magic[0] = scp->phys_addr+ap_loader_start;
+	magic[1] = ap_loader_size;
+	// ap_firmware_start/size
+	magic[2] = scp->phys_addr+ap_firmware_start;
+	magic[3] = ap_firmware_size;
+	// ap_cached_start/size/backup_start
+	magic[4] = scp->phys_addr+ap_cached_start;
+	magic[5] = ap_cached_size;
+	magic[6] = scp->phys_addr+ap_cached_backup_start;
+	// struct_size
+	magic[7] = sizeof(magic);
+	// log_thru
+	magic[8] = 0;
+	verb_memcpy(scp->sram_base+ap_loader_config, magic, sizeof(magic));
+
+	// HACK: step 8
+	// SCP_JTAG_REG |= SCP_JTAG_EN
+	val = readl(scp->reg_base + 0x00A0);
+	writel(val | 0x3C, scp->reg_base + 0x00A0);
+
+	pr_info("Loaded!\n");
+	return ret;
+}
+
+static int scp_start(struct rproc *rproc)
+{
+	struct mtk_scp *scp = (struct mtk_scp *)rproc->priv;
+	struct device *dev = scp->dev;
+	struct scp_run *run;
+	int ret;
+
+	ret = clk_prepare_enable(scp->clk);
+	if (ret) {
+		dev_err(dev, "failed to enable clocks\n");
+		return ret;
+	}
+
+	run = &scp->run;
+	run->signaled = false;
+
+	scp_reset_deassert(scp);
+
+	ret = wait_event_interruptible_timeout(
+					run->wq,
+					run->signaled,
+					msecs_to_jiffies(2000));
+
+	if (ret == 0) {
+		dev_err(dev, "wait SCP initialization timeout!\n");
+		ret = -ETIME;
+		goto stop;
+	}
+	if (ret == -ERESTARTSYS) {
+		dev_err(dev, "wait SCP interrupted by a signal!\n");
+		goto stop;
+	}
+	clk_disable_unprepare(scp->clk);
+	dev_info(dev, "SCP is ready. FW version %s\n", run->fw_ver);
+
+	return 0;
+
+stop:
+	scp_reset_assert(scp);
+	clk_disable_unprepare(scp->clk);
+	return ret;
+}
+
+static void *scp_da_to_va(struct rproc *rproc, u64 da, int len)
+{
+	struct mtk_scp *scp = (struct mtk_scp *)rproc->priv;
+	int offset;
+
+	if (da < scp->sram_size) {
+		offset = da;
+		if (offset >= 0 && ((offset + len) < scp->sram_size))
+			return (__force void *)(scp->sram_base + offset);
+	} else if (da >= scp->sram_size &&
+		   da < (scp->sram_size + MAX_CODE_SIZE)) {
+		offset = da;
+		if (offset >= 0 && (offset + len) < MAX_CODE_SIZE)
+			return scp->cpu_addr + offset;
+	} else {
+		offset = da - scp->phys_addr;
+		if (offset >= 0 &&
+		    (offset + len) < (scp->dram_size - MAX_CODE_SIZE))
+			return scp->cpu_addr + offset;
+	}
+
+	return NULL;
+}
+
+static int scp_stop(struct rproc *rproc)
+{
+	struct mtk_scp *scp = (struct mtk_scp *)rproc->priv;
+	int ret;
+	u32 val;
+
+	ret = clk_prepare_enable(scp->clk);
+	if (ret) {
+		dev_err(scp->dev, "failed to enable clocks\n");
+		return ret;
+	}
+
+	dev_info(scp->dev, "scp stop\n");
+
+	val = readl(scp->reg_base + MT8183_SW_RSTN);
+	val &= ~MT8183_SW_RSTN_BIT;
+	writel(val, scp->reg_base + MT8183_SW_RSTN);
+
+	scp_reset_assert(scp);
+	clk_disable_unprepare(scp->clk);
+
+	return 0;
+}
+
+static const struct rproc_ops scp_ops = {
+	.start		= scp_start,
+	.stop		= scp_stop,
+	.load		= scp_load,
+	.da_to_va	= scp_da_to_va,
+};
+
+unsigned int scp_get_vdec_hw_capa(struct platform_device *pdev)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+
+	return scp->run.dec_capability;
+}
+EXPORT_SYMBOL_GPL(scp_get_vdec_hw_capa);
+
+unsigned int scp_get_venc_hw_capa(struct platform_device *pdev)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+
+	return scp->run.enc_capability;
+}
+EXPORT_SYMBOL_GPL(scp_get_venc_hw_capa);
+
+void *scp_mapping_dm_addr(struct platform_device *pdev, u32 mem_addr)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+	void *ptr;
+
+	ptr = scp_da_to_va(scp->rproc, mem_addr, 0);
+	if (!ptr)
+		return ERR_PTR(-EINVAL);
+
+	return ptr;
+}
+EXPORT_SYMBOL_GPL(scp_mapping_dm_addr);
+
+#if SCP_RESERVED_MEM
+phys_addr_t scp_mem_base_phys;
+phys_addr_t scp_mem_base_virt;
+phys_addr_t scp_mem_size;
+
+static struct scp_reserve_mblock scp_reserve_mblock[] = {
+	{
+		.num = SCP_ISP_MEM_ID,
+		.start_phys = 0x0,
+		.start_virt = 0x0,
+		.size = 0x1400000,  /*20MB*/
+	},
+	{
+		.num = SCP_DIP_MEM_ID,
+		.start_phys = 0x0,
+		.start_virt = 0x0,
+		.size = 0x900000,   /*9MB*/
+	},
+	{
+		.num = SCP_MDP_MEM_ID,
+		.start_phys = 0x0,
+		.start_virt = 0x0,
+		.size = 0x600000,   /*6MB*/
+	},
+        {
+                .num = SCP_FD_MEM_ID,
+                .start_phys = 0x0,
+                .start_virt = 0x0,
+                .size = 0x100000,   /*1MB*/
+        },
+};
+
+static int scp_reserve_mem_init(struct mtk_scp *scp)
+{
+	enum scp_reserve_mem_id_t id;
+	phys_addr_t accumlate_memory_size = 0;
+
+	scp_mem_base_phys = (phys_addr_t) (scp->phys_addr + MAX_CODE_SIZE);
+	scp_mem_size = (phys_addr_t) (scp->dram_size - MAX_CODE_SIZE);
+
+	dev_info(scp->dev,
+		 "phys:0x%llx - 0x%llx (0x%llx)\n",
+		 scp_mem_base_phys,
+		 scp_mem_base_phys + scp_mem_size,
+		 scp_mem_size);
+	accumlate_memory_size = 0;
+	for (id = 0; id < SCP_NUMS_MEM_ID; id++) {
+		scp_reserve_mblock[id].start_phys =
+			scp_mem_base_phys + accumlate_memory_size;
+		accumlate_memory_size += scp_reserve_mblock[id].size;
+		dev_info(scp->dev,
+			 "[reserve_mem:%d]: phys:0x%llx - 0x%llx (0x%llx)\n",
+			 id, scp_reserve_mblock[id].start_phys,
+			 scp_reserve_mblock[id].start_phys +
+				 scp_reserve_mblock[id].size,
+			 scp_reserve_mblock[id].size);
+	}
+	return 0;
+}
+
+static int scp_reserve_memory_ioremap(struct mtk_scp *scp)
+{
+	enum scp_reserve_mem_id_t id;
+	phys_addr_t accumlate_memory_size = 0;
+
+	scp_mem_base_virt = (phys_addr_t)(size_t)ioremap_wc(scp_mem_base_phys,
+							    scp_mem_size);
+
+	dev_info(scp->dev,
+		 "virt:0x%llx - 0x%llx (0x%llx)\n",
+		(phys_addr_t)scp_mem_base_virt,
+		(phys_addr_t)scp_mem_base_virt + (phys_addr_t)scp_mem_size,
+		scp_mem_size);
+	for (id = 0; id < SCP_NUMS_MEM_ID; id++) {
+		scp_reserve_mblock[id].start_virt =
+			scp_mem_base_virt + accumlate_memory_size;
+		accumlate_memory_size += scp_reserve_mblock[id].size;
+	}
+	/* the reserved memory should be larger then expected memory
+	 * or scp_reserve_mblock does not match dts
+	 */
+	WARN_ON(accumlate_memory_size > scp_mem_size);
+#ifdef DEBUG
+	for (id = 0; id < NUMS_MEM_ID; id++) {
+		dev_info(scp->dev,
+			 "[mem_reserve-%d] phys:0x%llx,virt:0x%llx,size:0x%llx\n",
+			 id,
+			 scp_get_reserve_mem_phys(id),
+			 scp_get_reserve_mem_virt(id),
+			 scp_get_reserve_mem_size(id));
+	}
+#endif
+	return 0;
+}
+phys_addr_t scp_get_reserve_mem_phys(enum scp_reserve_mem_id_t id)
+{
+	if (id >= SCP_NUMS_MEM_ID) {
+		pr_err("[SCP] no reserve memory for %d", id);
+		return 0;
+	} else
+		return scp_reserve_mblock[id].start_phys;
+}
+EXPORT_SYMBOL_GPL(scp_get_reserve_mem_phys);
+
+phys_addr_t scp_get_reserve_mem_virt(enum scp_reserve_mem_id_t id)
+{
+	if (id >= SCP_NUMS_MEM_ID) {
+		pr_err("[SCP] no reserve memory for %d", id);
+		return 0;
+	} else
+		return scp_reserve_mblock[id].start_virt;
+}
+EXPORT_SYMBOL_GPL(scp_get_reserve_mem_virt);
+
+phys_addr_t scp_get_reserve_mem_size(enum scp_reserve_mem_id_t id)
+{
+	if (id >= SCP_NUMS_MEM_ID) {
+		pr_err("[SCP] no reserve memory for %d", id);
+		return 0;
+	} else
+		return scp_reserve_mblock[id].size;
+}
+EXPORT_SYMBOL_GPL(scp_get_reserve_mem_size);
+#endif
+
+static int scp_map_memory_region(struct mtk_scp *scp)
+{
+	struct device_node *node;
+	struct resource r;
+	int ret;
+
+	node = of_parse_phandle(scp->dev->of_node, "memory-region", 0);
+	if (!node) {
+		dev_err(scp->dev, "no memory-region specified\n");
+		return -EINVAL;
+	}
+
+	ret = of_address_to_resource(node, 0, &r);
+	if (ret)
+		return ret;
+
+	scp->phys_addr = r.start;
+	scp->dram_size = resource_size(&r);
+	scp->cpu_addr =
+		devm_ioremap_wc(scp->dev, scp->phys_addr, scp->dram_size);
+
+	if (!scp->cpu_addr) {
+		dev_err(scp->dev, "unable to map memory region: %pa+%zx\n",
+			&r.start, scp->dram_size);
+		return -EBUSY;
+	}
+
+#if SCP_RESERVED_MEM
+	scp_reserve_mem_init(scp);
+	scp_reserve_memory_ioremap(scp);
+#endif
+	return 0;
+}
+
+static struct mtk_rpmsg_info mtk_scp_rpmsg_info = {
+	.send_ipi = scp_ipi_send,
+	.register_ipi = scp_ipi_register,
+	.unregister_ipi = scp_ipi_unregister,
+	.ns_ipi_id = SCP_IPI_NS_SERVICE,
+};
+
+static void scp_add_rpmsg_subdev(struct mtk_scp *scp)
+{
+	scp->rpmsg_subdev =
+		mtk_rpmsg_create_rproc_subdev(to_platform_device(scp->dev),
+					      &mtk_scp_rpmsg_info);
+	if (scp->rpmsg_subdev)
+		rproc_add_subdev(scp->rproc, scp->rpmsg_subdev);
+}
+
+static void scp_remove_rpmsg_subdev(struct mtk_scp *scp)
+{
+	if (scp->rpmsg_subdev) {
+		rproc_remove_subdev(scp->rproc, scp->rpmsg_subdev);
+		mtk_rpmsg_destroy_rproc_subdev(scp->rpmsg_subdev);
+		scp->rpmsg_subdev = NULL;
+	}
+}
+
+static int scp_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct mtk_scp *scp;
+	struct rproc *rproc;
+	struct resource *res;
+	char *fw_name = "scp.img";
+	int ret;
+
+	rproc = rproc_alloc(dev,
+			    np->name,
+			    &scp_ops,
+			    fw_name,
+			    sizeof(*scp));
+	if (!rproc) {
+		dev_err(dev, "unable to allocate remoteproc\n");
+		return -ENOMEM;
+	}
+
+	scp = (struct mtk_scp *)rproc->priv;
+	scp->rproc = rproc;
+	scp->dev = dev;
+	platform_set_drvdata(pdev, scp);
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "sram");
+	scp->sram_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR((__force void *)scp->sram_base)) {
+		dev_err(dev, "Failed to parse and map sram memory\n");
+		ret = PTR_ERR((__force void *)scp->sram_base);
+		goto free_rproc;
+	}
+	scp->sram_size = resource_size(res);
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "cfg");
+	scp->reg_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR((__force void *)scp->reg_base)) {
+		dev_err(dev, "Failed to parse and map cfg memory\n");
+		ret = PTR_ERR((__force void *)scp->reg_base);
+		goto free_rproc;
+	}
+
+	ret = scp_map_memory_region(scp);
+	if (ret)
+		goto free_rproc;
+
+	scp->clk = devm_clk_get(dev, "main");
+	if (IS_ERR(scp->clk)) {
+		dev_err(dev, "Failed to get clock\n");
+		ret = PTR_ERR(scp->clk);
+		goto free_rproc;
+	}
+
+	ret = clk_prepare_enable(scp->clk);
+	if (ret) {
+		dev_err(dev, "failed to enable clocks\n");
+		goto free_rproc;
+	}
+
+	ret = scp_ipi_init(scp);
+	clk_disable_unprepare(scp->clk);
+	if (ret) {
+		dev_err(dev, "Failed to init ipi\n");
+		goto free_rproc;
+	}
+
+	/* register SCP initialization IPI */
+	ret = scp_ipi_register(pdev,
+			       SCP_IPI_INIT,
+			       scp_init_ipi_handler,
+			       scp);
+	if (ret) {
+		dev_err(dev, "Failed to register IPI_SCP_INIT\n");
+		goto free_rproc;
+	}
+
+	mutex_init(&scp->lock);
+
+	init_waitqueue_head(&scp->run.wq);
+	init_waitqueue_head(&scp->ack_wq);
+
+	scp_add_rpmsg_subdev(scp);
+
+	ret = devm_request_threaded_irq(dev, platform_get_irq(pdev, 0), NULL,
+					scp_irq_handler, IRQF_ONESHOT,
+					pdev->name, scp);
+
+	if (ret) {
+		dev_err(dev, "failed to request irq\n");
+		goto remove_subdev;
+	}
+
+	ret = rproc_add(rproc);
+	if (ret)
+		goto remove_subdev;
+
+	return 0;
+
+remove_subdev:
+	scp_remove_rpmsg_subdev(scp);
+	mutex_destroy(&scp->lock);
+free_rproc:
+	rproc_free(rproc);
+
+	return ret;
+}
+
+static int scp_remove(struct platform_device *pdev)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+
+	scp_remove_rpmsg_subdev(scp);
+	rproc_del(scp->rproc);
+	rproc_free(scp->rproc);
+
+	return 0;
+}
+
+static const struct of_device_id mtk_scp_of_match[] = {
+	{ .compatible = "mediatek,mt8183-scp"},
+	{},
+};
+MODULE_DEVICE_TABLE(of, mtk_scp_of_match);
+
+static struct platform_driver mtk_scp_driver = {
+	.probe = scp_probe,
+	.remove = scp_remove,
+	.driver = {
+		.name = "mtk-scp",
+		.of_match_table = of_match_ptr(mtk_scp_of_match),
+	},
+};
+
+module_platform_driver(mtk_scp_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("MediaTek SCP control driver");
diff --git a/drivers/remoteproc/mtk_scp_ipi.c b/drivers/remoteproc/mtk_scp_ipi.c
new file mode 100644
index 000000000000..10b0cbda7aee
--- /dev/null
+++ b/drivers/remoteproc/mtk_scp_ipi.c
@@ -0,0 +1,163 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright (c) 2018 MediaTek Inc.
+
+#include <asm/barrier.h>
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/platform_data/mtk_scp.h>
+#include <linux/platform_device.h>
+
+#include "mtk_common.h"
+
+int scp_ipi_register(struct platform_device *pdev,
+		     enum scp_ipi_id id,
+		     scp_ipi_handler_t handler,
+		     void *priv)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+	struct scp_ipi_desc *ipi_desc;
+
+	if (!scp) {
+		dev_err(&pdev->dev, "scp device is not ready\n");
+		return -EPROBE_DEFER;
+	}
+
+	if (WARN_ON(id < 0) || WARN_ON(id >= SCP_IPI_MAX) ||
+	    WARN_ON(handler == NULL))
+		return -EINVAL;
+
+	ipi_desc = scp->ipi_desc;
+	ipi_desc[id].handler = handler;
+	ipi_desc[id].priv = priv;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(scp_ipi_register);
+
+void scp_ipi_unregister(struct platform_device *pdev, enum scp_ipi_id id)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+	struct scp_ipi_desc *ipi_desc;
+
+	if (!scp)
+		return;
+
+	if (WARN_ON(id < 0) || WARN_ON(id >= SCP_IPI_MAX))
+		return;
+
+	ipi_desc = scp->ipi_desc;
+	ipi_desc[id].handler = NULL;
+	ipi_desc[id].priv = NULL;
+}
+EXPORT_SYMBOL_GPL(scp_ipi_unregister);
+
+/*
+ * Copy src to dst, where dst is in SCP SRAM region.
+ * Since AP access of SCP SRAM don't support byte write, this always write a
+ * full word at a time, and may cause some extra bytes to be written at the
+ * beginning & ending of dst.
+ */
+void scp_memcpy_aligned(void *dst, const void *src, unsigned int len)
+{
+	void *ptr;
+	u32 val;
+	unsigned int i = 0;
+
+	if (!IS_ALIGNED((unsigned long)dst, 4)) {
+		ptr = (void *)ALIGN_DOWN((unsigned long)dst, 4);
+		i = 4 - (dst - ptr);
+		val = readl_relaxed(ptr);
+		memcpy((u8 *)&val + (4 - i), src, i);
+		writel_relaxed(val, ptr);
+	}
+
+	while (i + 4 <= len) {
+		val = *((u32 *)(src + i));
+		writel_relaxed(val, dst + i);
+		i += 4;
+	}
+	if (i < len) {
+		val = readl_relaxed(dst + i);
+		memcpy(&val, src + i, len - i);
+		writel_relaxed(val, dst + i);
+	}
+}
+EXPORT_SYMBOL_GPL(scp_memcpy_aligned);
+
+int scp_ipi_send(struct platform_device *pdev,
+		 enum scp_ipi_id id,
+		 void *buf,
+		 unsigned int len,
+		 unsigned int wait)
+{
+	struct mtk_scp *scp = platform_get_drvdata(pdev);
+	struct share_obj *send_obj = scp->send_buf;
+	unsigned long timeout;
+	int ret;
+
+	if (WARN_ON(id <= SCP_IPI_INIT) || WARN_ON(id >= SCP_IPI_MAX) ||
+	    WARN_ON(id == SCP_IPI_NS_SERVICE) ||
+	    WARN_ON(len > sizeof(send_obj->share_buf)) || WARN_ON(!buf))
+		return -EINVAL;
+
+	mutex_lock(&scp->lock);
+
+	ret = clk_prepare_enable(scp->clk);
+	if (ret) {
+		dev_err(scp->dev, "failed to enable clock\n");
+		return ret;
+	}
+
+	 /* Wait until SCP receives the last command */
+	timeout = jiffies + msecs_to_jiffies(2000);
+	do {
+		if (time_after(jiffies, timeout)) {
+			dev_err(scp->dev, "%s: IPI timeout!\n", __func__);
+			ret = -EIO;
+			mutex_unlock(&scp->lock);
+			goto clock_disable;
+		}
+	} while (readl(scp->reg_base + MT8183_HOST_TO_SCP));
+
+	scp_memcpy_aligned(send_obj->share_buf, buf, len);
+
+	send_obj->len = len;
+	send_obj->id = id;
+
+	scp->ipi_id_ack[id] = false;
+	/*
+	 * Ensure that all writes to SRAM are committed before sending the
+	 * interrupt to SCP.
+	 */
+	mb();
+	/* send the command to SCP */
+	writel(MT8183_HOST_IPC_INT_BIT, scp->reg_base + MT8183_HOST_TO_SCP);
+
+	mutex_unlock(&scp->lock);
+
+	if (wait) {
+		/* wait for SCP's ACK */
+		timeout = msecs_to_jiffies(wait);
+		ret = wait_event_timeout(scp->ack_wq,
+					 scp->ipi_id_ack[id],
+					 timeout);
+		scp->ipi_id_ack[id] = false;
+		if (WARN(!ret,
+			 "scp ipi %d ack time out !", id))
+			ret = -EIO;
+		else
+			ret = 0;
+	}
+
+clock_disable:
+	clk_disable_unprepare(scp->clk);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(scp_ipi_send);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("MediaTek scp IPI interface");
diff --git a/drivers/rpmsg/mtk_rpmsg.c b/drivers/rpmsg/mtk_rpmsg.c
new file mode 100644
index 000000000000..e5e988941ea6
--- /dev/null
+++ b/drivers/rpmsg/mtk_rpmsg.c
@@ -0,0 +1,396 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Copyright 2018 Google LLC.
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <linux/remoteproc.h>
+#include <linux/rpmsg/mtk_rpmsg.h>
+#include <linux/workqueue.h>
+
+#include "rpmsg_internal.h"
+
+struct mtk_rpmsg_rproc_subdev {
+	struct platform_device *pdev;
+	struct mtk_rpmsg_info *info;
+	struct rpmsg_endpoint *ns_ept;
+	struct rproc_subdev subdev;
+
+	struct work_struct register_work;
+	struct list_head channels;
+	struct mutex channels_lock;
+};
+
+#define to_mtk_subdev(d) container_of(d, struct mtk_rpmsg_rproc_subdev, subdev)
+
+struct mtk_rpmsg_channel_info {
+	struct rpmsg_channel_info info;
+	bool registered;
+	struct list_head list;
+};
+
+/**
+ * struct rpmsg_ns_msg - dynamic name service announcement message
+ * @name: name of remote service that is published
+ * @addr: address of remote service that is published
+ *
+ * This message is sent across to publish a new service. When we receive these
+ * messages, an appropriate rpmsg channel (i.e device) is created. In turn, the
+ * ->probe() handler of the appropriate rpmsg driver will be invoked
+ *  (if/as-soon-as one is registered).
+ */
+struct rpmsg_ns_msg {
+	char name[RPMSG_NAME_SIZE];
+	u32 addr;
+} __packed;
+
+struct mtk_rpmsg_device {
+	struct rpmsg_device rpdev;
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev;
+};
+
+struct mtk_rpmsg_endpoint {
+	struct rpmsg_endpoint ept;
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev;
+};
+
+#define to_mtk_rpmsg_device(r) container_of(r, struct mtk_rpmsg_device, rpdev)
+#define to_mtk_rpmsg_endpoint(r) container_of(r, struct mtk_rpmsg_endpoint, ept)
+
+static const struct rpmsg_endpoint_ops mtk_rpmsg_endpoint_ops;
+
+static void __ept_release(struct kref *kref)
+{
+	struct rpmsg_endpoint *ept = container_of(kref, struct rpmsg_endpoint,
+						  refcount);
+	kfree(to_mtk_rpmsg_endpoint(ept));
+}
+
+static void mtk_rpmsg_ipi_handler(void *data, unsigned int len, void *priv)
+{
+	struct mtk_rpmsg_endpoint *mept = priv;
+	struct rpmsg_endpoint *ept = &mept->ept;
+	int ret;
+
+	ret = (*ept->cb)(ept->rpdev, data, len, ept->priv, ept->addr);
+	if (ret)
+		dev_warn(&ept->rpdev->dev, "rpmsg handler return error = %d",
+			 ret);
+}
+
+static struct rpmsg_endpoint *
+__rpmsg_create_ept(struct mtk_rpmsg_rproc_subdev *mtk_subdev,
+		   struct rpmsg_device *rpdev, rpmsg_rx_cb_t cb, void *priv,
+		   u32 id)
+{
+	struct mtk_rpmsg_endpoint *mept;
+	struct rpmsg_endpoint *ept;
+	struct platform_device *pdev = mtk_subdev->pdev;
+	int ret;
+
+	mept = kzalloc(sizeof(*mept), GFP_KERNEL);
+	if (!mept)
+		return NULL;
+	mept->mtk_subdev = mtk_subdev;
+
+	ept = &mept->ept;
+	kref_init(&ept->refcount);
+
+	ept->rpdev = rpdev;
+	ept->cb = cb;
+	ept->priv = priv;
+	ept->ops = &mtk_rpmsg_endpoint_ops;
+	ept->addr = id;
+
+	ret = mtk_subdev->info->register_ipi(pdev, id, mtk_rpmsg_ipi_handler,
+					     mept);
+	if (ret) {
+		dev_err(&pdev->dev, "IPI register failed, id = %d", id);
+		kref_put(&ept->refcount, __ept_release);
+		return NULL;
+	}
+
+	return ept;
+}
+
+static struct rpmsg_endpoint *
+mtk_rpmsg_create_ept(struct rpmsg_device *rpdev, rpmsg_rx_cb_t cb, void *priv,
+		     struct rpmsg_channel_info chinfo)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev =
+		to_mtk_rpmsg_device(rpdev)->mtk_subdev;
+
+	return __rpmsg_create_ept(mtk_subdev, rpdev, cb, priv, chinfo.src);
+}
+
+static void mtk_rpmsg_destroy_ept(struct rpmsg_endpoint *ept)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev =
+		to_mtk_rpmsg_endpoint(ept)->mtk_subdev;
+
+	mtk_subdev->info->unregister_ipi(mtk_subdev->pdev, ept->addr);
+	kref_put(&ept->refcount, __ept_release);
+}
+
+static int mtk_rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev =
+		to_mtk_rpmsg_endpoint(ept)->mtk_subdev;
+
+	return mtk_subdev->info->send_ipi(mtk_subdev->pdev, ept->addr, data,
+					  len, 0);
+}
+
+static int mtk_rpmsg_trysend(struct rpmsg_endpoint *ept, void *data, int len)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev =
+		to_mtk_rpmsg_endpoint(ept)->mtk_subdev;
+
+	/*
+	 * TODO: This currently is same as mtk_rpmsg_send, and wait until SCP
+	 * received the last command.
+	 */
+	return mtk_subdev->info->send_ipi(mtk_subdev->pdev, ept->addr, data,
+					  len, 0);
+}
+
+static const struct rpmsg_endpoint_ops mtk_rpmsg_endpoint_ops = {
+	.destroy_ept = mtk_rpmsg_destroy_ept,
+	.send = mtk_rpmsg_send,
+	.trysend = mtk_rpmsg_trysend,
+};
+
+static void mtk_rpmsg_release_device(struct device *dev)
+{
+	struct rpmsg_device *rpdev = to_rpmsg_device(dev);
+	struct mtk_rpmsg_device *mdev = to_mtk_rpmsg_device(rpdev);
+
+	kfree(mdev);
+}
+
+static const struct rpmsg_device_ops mtk_rpmsg_device_ops = {
+	.create_ept = mtk_rpmsg_create_ept,
+};
+
+static struct device_node *
+mtk_rpmsg_match_device_subnode(struct device_node *node, const char *channel)
+{
+	struct device_node *child;
+	const char *name;
+	int ret;
+
+	for_each_available_child_of_node(node, child) {
+		ret = of_property_read_string(child, "mtk,rpmsg-name", &name);
+		if (ret)
+			continue;
+
+		if (strcmp(name, channel) == 0)
+			return child;
+	}
+
+	return NULL;
+}
+
+static int mtk_rpmsg_register_device(struct mtk_rpmsg_rproc_subdev *mtk_subdev,
+				     struct rpmsg_channel_info *info)
+{
+	struct rpmsg_device *rpdev;
+	struct mtk_rpmsg_device *mdev;
+	struct platform_device *pdev = mtk_subdev->pdev;
+	int ret;
+
+	mdev = kzalloc(sizeof(*mdev), GFP_KERNEL);
+	if (!mdev)
+		return -ENOMEM;
+
+	mdev->mtk_subdev = mtk_subdev;
+
+	rpdev = &mdev->rpdev;
+	rpdev->ops = &mtk_rpmsg_device_ops;
+	rpdev->src = info->src;
+	rpdev->dst = info->dst;
+	strncpy(rpdev->id.name, info->name, RPMSG_NAME_SIZE);
+
+	rpdev->dev.of_node =
+		mtk_rpmsg_match_device_subnode(pdev->dev.of_node, info->name);
+	rpdev->dev.parent = &pdev->dev;
+	rpdev->dev.release = mtk_rpmsg_release_device;
+
+	ret = rpmsg_register_device(rpdev);
+	if (ret) {
+		kfree(mdev);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void mtk_register_device_work_function(struct work_struct *register_work)
+{
+	struct mtk_rpmsg_rproc_subdev *subdev = container_of(
+		register_work, struct mtk_rpmsg_rproc_subdev, register_work);
+	struct platform_device *pdev = subdev->pdev;
+	struct mtk_rpmsg_channel_info *info;
+	int ret;
+
+	mutex_lock(&subdev->channels_lock);
+	list_for_each_entry(info, &subdev->channels, list) {
+		if (info->registered)
+			continue;
+
+		ret = mtk_rpmsg_register_device(subdev, &info->info);
+		if (ret) {
+			dev_err(&pdev->dev, "Can't create rpmsg_device\n");
+			continue;
+		}
+
+		info->registered = true;
+	}
+	mutex_unlock(&subdev->channels_lock);
+}
+
+static int mtk_rpmsg_create_device(struct mtk_rpmsg_rproc_subdev *mtk_subdev,
+				   char *name, u32 addr)
+{
+	struct mtk_rpmsg_channel_info *info;
+
+	info = kzalloc(sizeof(*info), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	strncpy(info->info.name, name, RPMSG_NAME_SIZE);
+	info->info.src = addr;
+	info->info.dst = RPMSG_ADDR_ANY;
+	mutex_lock(&mtk_subdev->channels_lock);
+	list_add(&info->list, &mtk_subdev->channels);
+	mutex_unlock(&mtk_subdev->channels_lock);
+
+	schedule_work(&mtk_subdev->register_work);
+	return 0;
+}
+
+static int mtk_rpmsg_ns_cb(struct rpmsg_device *rpdev, void *data, int len,
+			   void *priv, u32 src)
+{
+	struct rpmsg_ns_msg *msg = data;
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev = priv;
+	struct device *dev = &mtk_subdev->pdev->dev;
+
+	int ret;
+
+	if (len != sizeof(*msg)) {
+		dev_err(dev, "malformed ns msg (%d)\n", len);
+		return -EINVAL;
+	}
+
+	/*
+	 * the name service ept does _not_ belong to a real rpmsg channel,
+	 * and is handled by the rpmsg bus itself.
+	 * for sanity reasons, make sure a valid rpdev has _not_ sneaked
+	 * in somehow.
+	 */
+	if (rpdev) {
+		dev_err(dev, "anomaly: ns ept has an rpdev handle\n");
+		return -EINVAL;
+	}
+
+	/* don't trust the remote processor for null terminating the name */
+	msg->name[RPMSG_NAME_SIZE - 1] = '\0';
+
+	dev_info(dev, "creating channel %s addr 0x%x\n", msg->name, msg->addr);
+
+	ret = mtk_rpmsg_create_device(mtk_subdev, msg->name, msg->addr);
+	if (ret) {
+		dev_err(dev, "create rpmsg device failed\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+int mtk_rpmsg_prepare(struct rproc_subdev *subdev)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev = to_mtk_subdev(subdev);
+
+	/* a dedicated endpoint handles the name service msgs */
+	if (mtk_subdev->info->ns_ipi_id >= 0) {
+		mtk_subdev->ns_ept =
+			__rpmsg_create_ept(mtk_subdev, NULL, mtk_rpmsg_ns_cb,
+					   mtk_subdev,
+					   mtk_subdev->info->ns_ipi_id);
+		if (!mtk_subdev->ns_ept) {
+			dev_err(&mtk_subdev->pdev->dev,
+				"failed to create name service endpoint\n");
+			return -ENOMEM;
+		}
+	}
+
+	return 0;
+}
+
+void mtk_rpmsg_stop(struct rproc_subdev *subdev, bool crashed)
+{
+	struct mtk_rpmsg_channel_info *info, *next;
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev = to_mtk_subdev(subdev);
+	struct device *dev = &mtk_subdev->pdev->dev;
+
+	if (mtk_subdev->ns_ept)
+		mtk_rpmsg_destroy_ept(mtk_subdev->ns_ept);
+	cancel_work_sync(&mtk_subdev->register_work);
+
+	mutex_lock(&mtk_subdev->channels_lock);
+	list_for_each_entry(info, &mtk_subdev->channels, list) {
+		if (!info->registered)
+			continue;
+		if (rpmsg_unregister_device(dev, &info->info)) {
+			dev_warn(
+				dev,
+				"rpmsg_unregister_device failed for %s.%d.%d\n",
+				info->info.name, info->info.src,
+				info->info.dst);
+		}
+	}
+
+	list_for_each_entry_safe(info, next,
+				 &mtk_subdev->channels, list) {
+		list_del(&info->list);
+		kfree(info);
+	}
+	mutex_unlock(&mtk_subdev->channels_lock);
+}
+
+struct rproc_subdev *
+mtk_rpmsg_create_rproc_subdev(struct platform_device *pdev,
+			      struct mtk_rpmsg_info *info)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev;
+
+	mtk_subdev = kzalloc(sizeof(*mtk_subdev), GFP_KERNEL);
+	if (!mtk_subdev)
+		return NULL;
+
+	mtk_subdev->pdev = pdev;
+	mtk_subdev->subdev.prepare = mtk_rpmsg_prepare;
+	mtk_subdev->subdev.stop = mtk_rpmsg_stop;
+	mtk_subdev->info = info;
+	INIT_LIST_HEAD(&mtk_subdev->channels);
+	INIT_WORK(&mtk_subdev->register_work,
+		  mtk_register_device_work_function);
+	mutex_init(&mtk_subdev->channels_lock);
+
+	return &mtk_subdev->subdev;
+}
+EXPORT_SYMBOL_GPL(mtk_rpmsg_create_rproc_subdev);
+
+void mtk_rpmsg_destroy_rproc_subdev(struct rproc_subdev *subdev)
+{
+	struct mtk_rpmsg_rproc_subdev *mtk_subdev = to_mtk_subdev(subdev);
+
+	kfree(mtk_subdev);
+}
+EXPORT_SYMBOL_GPL(mtk_rpmsg_destroy_rproc_subdev);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("MediaTek scp rpmsg driver");
diff --git a/include/dt-bindings/gce/mt8183-gce.h b/include/dt-bindings/gce/mt8183-gce.h
new file mode 100644
index 000000000000..aeb95154fac2
--- /dev/null
+++ b/include/dt-bindings/gce/mt8183-gce.h
@@ -0,0 +1,177 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 MediaTek Inc.
+ * Author: Bibby Hsieh <bibby.hsieh@mediatek.com>
+ *
+ */
+
+#ifndef _DT_BINDINGS_GCE_MT8183_H
+#define _DT_BINDINGS_GCE_MT8183_H
+
+#define CMDQ_NO_TIMEOUT		0xffffffff
+
+#define CMDQ_THR_MAX_COUNT	24
+
+/* GCE HW thread priority */
+#define CMDQ_THR_PRIO_LOWEST	0
+#define CMDQ_THR_PRIO_HIGHEST	1
+
+/* GCE SUBSYS */
+#define SUBSYS_1300XXXX		0
+#define SUBSYS_1400XXXX		1
+#define SUBSYS_1401XXXX		2
+#define SUBSYS_1402XXXX		3
+#define SUBSYS_1502XXXX		4
+#define SUBSYS_1880XXXX		5
+#define SUBSYS_1881XXXX		6
+#define SUBSYS_1882XXXX		7
+#define SUBSYS_1883XXXX		8
+#define SUBSYS_1884XXXX		9
+#define SUBSYS_1000XXXX		10
+#define SUBSYS_1001XXXX		11
+#define SUBSYS_1002XXXX		12
+#define SUBSYS_1003XXXX		13
+#define SUBSYS_1004XXXX		14
+#define SUBSYS_1005XXXX		15
+#define SUBSYS_1020XXXX		16
+#define SUBSYS_1028XXXX		17
+#define SUBSYS_1700XXXX		18
+#define SUBSYS_1701XXXX		19
+#define SUBSYS_1702XXXX		20
+#define SUBSYS_1703XXXX		21
+#define SUBSYS_1800XXXX		22
+#define SUBSYS_1801XXXX		23
+#define SUBSYS_1802XXXX		24
+#define SUBSYS_1804XXXX		25
+#define SUBSYS_1805XXXX		26
+#define SUBSYS_1808XXXX		27
+#define SUBSYS_180aXXXX		28
+#define SUBSYS_180bXXXX		29
+
+#define CMDQ_EVENT_DISP_RDMA0_SOF					0
+#define CMDQ_EVENT_DISP_RDMA1_SOF					1
+#define CMDQ_EVENT_MDP_RDMA0_SOF					2
+#define CMDQ_EVENT_MDP_RSZ0_SOF						4
+#define CMDQ_EVENT_MDP_RSZ1_SOF						5
+#define CMDQ_EVENT_MDP_TDSHP_SOF					6
+#define CMDQ_EVENT_MDP_WROT0_SOF					7
+#define CMDQ_EVENT_MDP_WDMA0_SOF					8
+#define CMDQ_EVENT_DISP_OVL0_SOF					9
+#define CMDQ_EVENT_DISP_OVL0_2L_SOF					10
+#define CMDQ_EVENT_DISP_OVL1_2L_SOF					11
+#define CMDQ_EVENT_DISP_WDMA0_SOF					12
+#define CMDQ_EVENT_DISP_COLOR0_SOF					13
+#define CMDQ_EVENT_DISP_CCORR0_SOF					14
+#define CMDQ_EVENT_DISP_AAL0_SOF					15
+#define CMDQ_EVENT_DISP_GAMMA0_SOF					16
+#define CMDQ_EVENT_DISP_DITHER0_SOF					17
+#define CMDQ_EVENT_DISP_PWM0_SOF					18
+#define CMDQ_EVENT_DISP_DSI0_SOF					19
+#define CMDQ_EVENT_DISP_DPI0_SOF					20
+#define CMDQ_EVENT_DISP_RSZ_SOF						22
+#define CMDQ_EVENT_MDP_AAL_SOF						23
+#define CMDQ_EVENT_MDP_CCORR_SOF					24
+#define CMDQ_EVENT_DISP_DBI_SOF						25
+#define CMDQ_EVENT_DISP_RDMA0_EOF					26
+#define CMDQ_EVENT_DISP_RDMA1_EOF					27
+#define CMDQ_EVENT_MDP_RDMA0_EOF					28
+#define CMDQ_EVENT_MDP_RSZ0_EOF						30
+#define CMDQ_EVENT_MDP_RSZ1_EOF						31
+#define CMDQ_EVENT_MDP_TDSHP_EOF					32
+#define CMDQ_EVENT_MDP_WROT0_EOF					33
+#define CMDQ_EVENT_MDP_WDMA0_EOF					34
+#define CMDQ_EVENT_DISP_OVL0_EOF					35
+#define CMDQ_EVENT_DISP_OVL0_2L_EOF					36
+#define CMDQ_EVENT_DISP_OVL1_2L_EOF					37
+#define CMDQ_EVENT_DISP_WDMA0_EOF					38
+#define CMDQ_EVENT_DISP_COLOR0_EOF					39
+#define CMDQ_EVENT_DISP_CCORR0_EOF					40
+#define CMDQ_EVENT_DISP_AAL0_EOF					41
+#define CMDQ_EVENT_DISP_GAMMA0_EOF					42
+#define CMDQ_EVENT_DISP_DITHER0_EOF					43
+#define CMDQ_EVENT_DSI0_EOF						44
+#define CMDQ_EVENT_DPI0_EOF						45
+#define CMDQ_EVENT_DISP_RSZ_EOF						47
+#define CMDQ_EVENT_MDP_AAL_EOF						48
+#define CMDQ_EVENT_MDP_CCORR_EOF					49
+#define CMDQ_EVENT_DBI_EOF						50
+#define CMDQ_EVENT_MUTEX_STREAM_DONE0					130
+#define CMDQ_EVENT_MUTEX_STREAM_DONE1					131
+#define CMDQ_EVENT_MUTEX_STREAM_DONE2					132
+#define CMDQ_EVENT_MUTEX_STREAM_DONE3					133
+#define CMDQ_EVENT_MUTEX_STREAM_DONE4					134
+#define CMDQ_EVENT_MUTEX_STREAM_DONE5					135
+#define CMDQ_EVENT_MUTEX_STREAM_DONE6					136
+#define CMDQ_EVENT_MUTEX_STREAM_DONE7					137
+#define CMDQ_EVENT_MUTEX_STREAM_DONE8					138
+#define CMDQ_EVENT_MUTEX_STREAM_DONE9					139
+#define CMDQ_EVENT_MUTEX_STREAM_DONE10					140
+#define CMDQ_EVENT_MUTEX_STREAM_DONE11					141
+#define CMDQ_EVENT_DISP_RDMA0_BUF_UNDERRUN_EVEN				142
+#define CMDQ_EVENT_DISP_RDMA1_BUF_UNDERRUN_EVEN				143
+#define CMDQ_EVENT_DSI0_TE_EVENT					144
+#define CMDQ_EVENT_DSI0_IRQ_EVENT					145
+#define CMDQ_EVENT_DSI0_DONE_EVENT					146
+#define CMDQ_EVENT_DISP_WDMA0_SW_RST_DONE				150
+#define CMDQ_EVENT_MDP_WDMA_SW_RST_DONE					151
+#define CMDQ_EVENT_MDP_WROT0_SW_RST_DONE				152
+#define CMDQ_EVENT_MDP_RDMA0_SW_RST_DONE				154
+#define CMDQ_EVENT_DISP_OVL0_FRAME_RST_DONE_PULE			155
+#define CMDQ_EVENT_DISP_OVL0_2L_FRAME_RST_DONE_ULSE			156
+#define CMDQ_EVENT_DISP_OVL1_2L_FRAME_RST_DONE_ULSE			157
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_0					257
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_1					258
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_2					259
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_3					260
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_4					261
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_5					262
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_6					263
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_7					264
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_8					265
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_9					266
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_10					267
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_11					268
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_12					269
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_13					270
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_14					271
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_15					272
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_16					273
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_17					274
+#define CMDQ_EVENT_ISP_FRAME_DONE_P2_18					275
+#define CMDQ_EVENT_AMD_FRAME_DONE					276
+#define CMDQ_EVENT_DVE_DONE						277
+#define CMDQ_EVENT_WMFE_DONE						278
+#define CMDQ_EVENT_RSC_DONE						279
+#define CMDQ_EVENT_MFB_DONE						280
+#define CMDQ_EVENT_WPE_A_DONE						281
+#define CMDQ_EVENT_SPE_B_DONE						282
+#define CMDQ_EVENT_OCC_DONE						283
+#define CMDQ_EVENT_VENC_CMDQ_FRAME_DONE					289
+#define CMDQ_EVENT_JPG_ENC_CMDQ_DONE					290
+#define CMDQ_EVENT_JPG_DEC_CMDQ_DONE					291
+#define CMDQ_EVENT_VENC_CMDQ_MB_DONE					292
+#define CMDQ_EVENT_VENC_CMDQ_128BYTE_DONE				293
+#define CMDQ_EVENT_ISP_FRAME_DONE_A					321
+#define CMDQ_EVENT_ISP_FRAME_DONE_B					322
+#define CMDQ_EVENT_CAMSV0_PASS1_DONE					323
+#define CMDQ_EVENT_CAMSV1_PASS1_DONE					324
+#define CMDQ_EVENT_CAMSV2_PASS1_DONE					325
+#define CMDQ_EVENT_TSF_DONE						326
+#define CMDQ_EVENT_SENINF_CAM0_FIFO_FULL				327
+#define CMDQ_EVENT_SENINF_CAM1_FIFO_FULL				328
+#define CMDQ_EVENT_SENINF_CAM2_FIFO_FULL				329
+#define CMDQ_EVENT_SENINF_CAM3_FIFO_FULL				330
+#define CMDQ_EVENT_SENINF_CAM4_FIFO_FULL				331
+#define CMDQ_EVENT_SENINF_CAM5_FIFO_FULL				332
+#define CMDQ_EVENT_SENINF_CAM6_FIFO_FULL				333
+#define CMDQ_EVENT_SENINF_CAM7_FIFO_FULL				334
+#define CMDQ_EVENT_IPU_CORE0_DONE0					353
+#define CMDQ_EVENT_IPU_CORE0_DONE1					354
+#define CMDQ_EVENT_IPU_CORE0_DONE2					355
+#define CMDQ_EVENT_IPU_CORE0_DONE3					356
+#define CMDQ_EVENT_IPU_CORE1_DONE0					385
+#define CMDQ_EVENT_IPU_CORE1_DONE1					386
+#define CMDQ_EVENT_IPU_CORE1_DONE2					387
+#define CMDQ_EVENT_IPU_CORE1_DONE3					388
+
+#endif
diff --git a/include/dt-bindings/reset-controller/mt8183-resets.h b/include/dt-bindings/reset-controller/mt8183-resets.h
new file mode 100644
index 000000000000..f0d92af29f3f
--- /dev/null
+++ b/include/dt-bindings/reset-controller/mt8183-resets.h
@@ -0,0 +1,89 @@
+/*
+ * Copyright (c) 2017 MediaTek Inc.
+ * Author: Yong Liang, MediaTek
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _DT_BINDINGS_RESET_CONTROLLER_MT8183
+#define _DT_BINDINGS_RESET_CONTROLLER_MT8183
+
+/* INFRACFG AO resets */
+#define MT8183_INFRACFG_AO_THERM_SW_RST				0
+#define MT8183_INFRACFG_AO_USB_TOP_SW_RST			1
+#define MT8183_INFRACFG_AO_MM_IOMMU_SW_RST			3
+#define MT8183_INFRACFG_AO_MSDC3_SW_RST				4
+#define MT8183_INFRACFG_AO_MSDC2_SW_RST				5
+#define MT8183_INFRACFG_AO_MSDC1_SW_RST				6
+#define MT8183_INFRACFG_AO_MSDC0_SW_RST				7
+#define MT8183_INFRACFG_AO_APDMA_SW_RST				9
+#define MT8183_INFRACFG_AO_MIMP_D_SW_RST			10
+#define MT8183_INFRACFG_AO_BTIF_SW_RST				12
+#define MT8183_INFRACFG_AO_DISP_PWM_SW_RST			14
+#define MT8183_INFRACFG_AO_AUXADC_SW_RST			15
+
+#define MT8183_INFRACFG_AO_IRTX_SW_RST				32
+#define MT8183_INFRACFG_AO_SPI0_SW_RST				33
+#define MT8183_INFRACFG_AO_I2C0_SW_RST				34
+#define MT8183_INFRACFG_AO_I2C1_SW_RST				35
+#define MT8183_INFRACFG_AO_I2C2_SW_RST				36
+#define MT8183_INFRACFG_AO_I2C3_SW_RST				37
+#define MT8183_INFRACFG_AO_UART0_SW_RST				38
+#define MT8183_INFRACFG_AO_UART1_SW_RST				39
+#define MT8183_INFRACFG_AO_UART2_SW_RST				40
+#define MT8183_INFRACFG_AO_PWM_SW_RST				41
+#define MT8183_INFRACFG_AO_SPI1_SW_RST				42
+#define MT8183_INFRACFG_AO_I2C4_SW_RST				43
+#define MT8183_INFRACFG_AO_DVFSP_SW_RST				44
+#define MT8183_INFRACFG_AO_SPI2_SW_RST				45
+#define MT8183_INFRACFG_AO_SPI3_SW_RST				46
+#define MT8183_INFRACFG_AO_UFSHCI_SW_RST			47
+
+#define MT8183_INFRACFG_AO_PMIC_WRAP_SW_RST			64
+#define MT8183_INFRACFG_AO_SPM_SW_RST				65
+#define MT8183_INFRACFG_AO_USBSIF_SW_RST			66
+#define MT8183_INFRACFG_AO_KP_SW_RST				68
+#define MT8183_INFRACFG_AO_APXGPT_SW_RST			69
+#define MT8183_INFRACFG_AO_CLDMA_AO_SW_RST			70
+#define MT8183_INFRACFG_AO_UNIPRO_UFS_SW_RST			71
+#define MT8183_INFRACFG_AO_DX_CC_SW_RST				72
+#define MT8183_INFRACFG_AO_UFSPHY_SW_RST			73
+
+#define MT8183_INFRACFG_AO_DX_CC_SEC_SW_RST			96
+#define MT8183_INFRACFG_AO_GCE_SW_RST				97
+#define MT8183_INFRACFG_AO_CLDMA_SW_RST				98
+#define MT8183_INFRACFG_AO_TRNG_SW_RST				99
+#define MT8183_INFRACFG_AO_AP_MD_CCIF_1_SW_RST			103
+#define MT8183_INFRACFG_AO_AP_MD_CCIF_SW_RST			104
+#define MT8183_INFRACFG_AO_I2C1_IMM_SW_RST			105
+#define MT8183_INFRACFG_AO_I2C1_ARB_SW_RST			106
+#define MT8183_INFRACFG_AO_I2C2_IMM_SW_RST			107
+#define MT8183_INFRACFG_AO_I2C2_ARB_SW_RST			108
+#define MT8183_INFRACFG_AO_I2C5_SW_RST				109
+#define MT8183_INFRACFG_AO_I2C5_IMM_SW_RST			110
+#define MT8183_INFRACFG_AO_I2C5_ARB_SW_RST			111
+#define MT8183_INFRACFG_AO_SPI4_SW_RST				112
+#define MT8183_INFRACFG_AO_SPI5_SW_RST				113
+#define MT8183_INFRACFG_AO_INFRA2MFGAXI_CBIP_CLAS_SW_RST	114
+#define MT8183_INFRACFG_AO_MFGAXI2INFRA_M0_CBIP_GLAS_OUT_SW_RST	115
+#define MT8183_INFRACFG_AO_MFGAXI2INFRA_M1_CBIP_GLAS_OUT_SW_RST	116
+#define MT8183_INFRACFG_AO_UFS_AES_SW_RST			117
+#define MT8183_INFRACFG_AO_CCU_I2C_IRQ_SW_RST			118
+#define MT8183_INFRACFG_AO_CCU_I2C_DMA_SW_RST			119
+#define MT8183_INFRACFG_AO_I2C6_SW_RST				120
+#define MT8183_INFRACFG_AO_CCU_GALS_SW_RST			121
+#define MT8183_INFRACFG_AO_IPU_GALS_SW_RST			122
+#define MT8183_INFRACFG_AO_CONN2AP_GALS_SW_RST			123
+#define MT8183_INFRACFG_AO_AP_MD_CCIF2_SW_RST			124
+#define MT8183_INFRACFG_AO_AP_MD_CCIF3_SW_RST			125
+#define MT8183_INFRACFG_AO_I2C7_SW_RST				126
+#define MT8183_INFRACFG_AO_I2C8_SW_RST				127
+
+#endif  /* _DT_BINDINGS_RESET_CONTROLLER_MT8183 */
diff --git a/include/linux/platform_data/mtk_scp.h b/include/linux/platform_data/mtk_scp.h
new file mode 100644
index 000000000000..90f91431c5f4
--- /dev/null
+++ b/include/linux/platform_data/mtk_scp.h
@@ -0,0 +1,166 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018 MediaTek Inc.
+ */
+
+#ifndef _MTK_SCP_H
+#define _MTK_SCP_H
+
+#include <linux/platform_device.h>
+
+typedef void (*scp_ipi_handler_t) (void *data,
+				   unsigned int len,
+				   void *priv);
+
+/**
+ * enum ipi_id - the id of inter-processor interrupt
+ *
+ * @SCP_IPI_INIT:	 The interrupt from scp is to notfiy kernel
+ *			 SCP initialization completed.
+ *			 IPI_SCP_INIT is sent from SCP when firmware is
+ *			 loaded. AP doesn't need to send IPI_SCP_INIT
+ *			 command to SCP.
+ *			 For other IPI below, AP should send the request
+ *			 to SCP to trigger the interrupt.
+ * @SCP_IPI_MAX:	 The maximum IPI number
+ */
+
+enum scp_ipi_id {
+	SCP_IPI_INIT = 0,
+	SCP_IPI_VDEC_H264,
+	SCP_IPI_VDEC_VP8,
+	SCP_IPI_VDEC_VP9,
+	SCP_IPI_VENC_H264,
+	SCP_IPI_VENC_VP8,
+	SCP_IPI_MDP_INIT,
+	SCP_IPI_MDP_DEINIT,
+	SCP_IPI_MDP_FRAME,
+	SCP_IPI_DIP,
+	SCP_IPI_ISP_CMD,
+	SCP_IPI_ISP_FRAME,
+	SCP_IPI_FD_CMD,
+	SCP_IPI_CROS_HOST_CMD,
+	SCP_IPI_NS_SERVICE = 0xFF,
+	SCP_IPI_MAX = 0x100,
+};
+
+
+/**
+ * scp_ipi_register - register an ipi function
+ *
+ * @pdev:	SCP platform device
+ * @id:		IPI ID
+ * @handler:	IPI handler
+ * @priv:	private data for IPI handler
+ *
+ * Register an ipi function to receive ipi interrupt from SCP.
+ *
+ * Return: Return 0 if ipi registers successfully, otherwise it is failed.
+ */
+int scp_ipi_register(struct platform_device *pdev,
+		     enum scp_ipi_id id,
+		     scp_ipi_handler_t handler,
+		     void *priv);
+
+/**
+ * scp_ipi_unregister - unregister an ipi function
+ *
+ * @pdev:	SCP platform device
+ * @id:		IPI ID
+ *
+ * Unregister an ipi function to receive ipi interrupt from SCP.
+ */
+void scp_ipi_unregister(struct platform_device *pdev, enum scp_ipi_id id);
+
+/**
+ * scp_ipi_send - send data from AP to scp.
+ *
+ * @pdev:	SCP platform device
+ * @id:		IPI ID
+ * @buf:	the data buffer
+ * @len:	the data buffer length
+ * @wait:	1: need ack
+ *
+ * This function is thread-safe. When this function returns,
+ * SCP has received the data and starts the processing.
+ * When the processing completes, IPI handler registered
+ * by scp_ipi_register will be called in interrupt context.
+ *
+ * Return: Return 0 if sending data successfully, otherwise it is failed.
+ **/
+int scp_ipi_send(struct platform_device *pdev,
+		 enum scp_ipi_id id,
+		 void *buf,
+		 unsigned int len,
+		 unsigned int wait);
+
+/**
+ * scp_get_pdev - get SCP's platform device
+ *
+ * @pdev:	the platform device of the module requesting SCP platform
+ *		device for using SCP API.
+ *
+ * Return: Return NULL if it is failed.
+ * otherwise it is SCP's platform device
+ **/
+struct platform_device *scp_get_pdev(struct platform_device *pdev);
+
+/**
+ * scp_get_vdec_hw_capa - get video decoder hardware capability
+ *
+ * @pdev:	SCP platform device
+ *
+ * Return: video decoder hardware capability
+ **/
+unsigned int scp_get_vdec_hw_capa(struct platform_device *pdev);
+
+/**
+ * scp_get_venc_hw_capa - get video encoder hardware capability
+ *
+ * @pdev:	SCP platform device
+ *
+ * Return: video encoder hardware capability
+ **/
+unsigned int scp_get_venc_hw_capa(struct platform_device *pdev);
+
+/**
+ * scp_mapping_dm_addr - Mapping SRAM/DRAM to kernel virtual address
+ *
+ * @pdev:	SCP platform device
+ * @mem_addr:	SCP views memory address
+ *
+ * Mapping the SCP's SRAM address /
+ * DMEM (Data Extended Memory) memory address /
+ * Working buffer memory address to
+ * kernel virtual address.
+ *
+ * Return: Return ERR_PTR(-EINVAL) if mapping failed,
+ * otherwise the mapped kernel virtual address
+ **/
+void *scp_mapping_dm_addr(struct platform_device *pdev,
+			  u32 mem_addr);
+
+#define SCP_RESERVED_MEM	(1)
+#if SCP_RESERVED_MEM
+/* scp reserve memory ID definition*/
+enum scp_reserve_mem_id_t {
+	SCP_ISP_MEM_ID,
+	SCP_MDP_MEM_ID,
+	SCP_DIP_MEM_ID,
+	SCP_FD_MEM_ID,
+	SCP_NUMS_MEM_ID,
+};
+
+struct scp_reserve_mblock {
+	enum scp_reserve_mem_id_t num;
+	u64 start_phys;
+	u64 start_virt;
+	u64 size;
+};
+
+extern phys_addr_t scp_get_reserve_mem_phys(enum scp_reserve_mem_id_t id);
+extern phys_addr_t scp_get_reserve_mem_virt(enum scp_reserve_mem_id_t id);
+extern phys_addr_t scp_get_reserve_mem_size(enum scp_reserve_mem_id_t id);
+#endif
+
+#endif /* _MTK_SCP_H */
diff --git a/include/linux/rpmsg/mtk_rpmsg.h b/include/linux/rpmsg/mtk_rpmsg.h
new file mode 100644
index 000000000000..90f848696161
--- /dev/null
+++ b/include/linux/rpmsg/mtk_rpmsg.h
@@ -0,0 +1,30 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright 2018 Google LLC.
+ */
+
+#ifndef __LINUX_RPMSG_MTK_RPMSG_H
+#define __LINUX_RPMSG_MTK_RPMSG_H
+
+#include <linux/device.h>
+#include <linux/remoteproc.h>
+
+typedef void (*ipi_handler_t)(void *data, unsigned int len, void *priv);
+
+/* TODO: Document */
+struct mtk_rpmsg_info {
+	int (*register_ipi)(struct platform_device *pdev, u32 id,
+			    ipi_handler_t handler, void *priv);
+	void (*unregister_ipi)(struct platform_device *pdev, u32 id);
+	int (*send_ipi)(struct platform_device *pdev, u32 id,
+			void *buf, unsigned int len, unsigned int wait);
+	int ns_ipi_id;
+};
+
+struct rproc_subdev *
+mtk_rpmsg_create_rproc_subdev(struct platform_device *pdev,
+			      struct mtk_rpmsg_info *info);
+
+void mtk_rpmsg_destroy_rproc_subdev(struct rproc_subdev *subdev);
+
+#endif
diff --git a/include/media/v4l2-ioctl.h b/include/media/v4l2-ioctl.h
index 5848d92c30da..8f6c497e3b7b 100644
--- a/include/media/v4l2-ioctl.h
+++ b/include/media/v4l2-ioctl.h
@@ -318,6 +318,8 @@ struct v4l2_ioctl_ops {
 				       struct v4l2_fmtdesc *f);
 	int (*vidioc_enum_fmt_meta_cap)(struct file *file, void *fh,
 					struct v4l2_fmtdesc *f);
+	int (*vidioc_enum_fmt_meta_out)(struct file *file, void *fh,
+					struct v4l2_fmtdesc *f);
 
 	/* VIDIOC_G_FMT handlers */
 	int (*vidioc_g_fmt_vid_cap)(struct file *file, void *fh,
@@ -346,6 +348,8 @@ struct v4l2_ioctl_ops {
 				    struct v4l2_format *f);
 	int (*vidioc_g_fmt_meta_cap)(struct file *file, void *fh,
 				     struct v4l2_format *f);
+	int (*vidioc_g_fmt_meta_out)(struct file *file, void *fh,
+				     struct v4l2_format *f);
 
 	/* VIDIOC_S_FMT handlers */
 	int (*vidioc_s_fmt_vid_cap)(struct file *file, void *fh,
@@ -374,6 +378,8 @@ struct v4l2_ioctl_ops {
 				    struct v4l2_format *f);
 	int (*vidioc_s_fmt_meta_cap)(struct file *file, void *fh,
 				     struct v4l2_format *f);
+	int (*vidioc_s_fmt_meta_out)(struct file *file, void *fh,
+				     struct v4l2_format *f);
 
 	/* VIDIOC_TRY_FMT handlers */
 	int (*vidioc_try_fmt_vid_cap)(struct file *file, void *fh,
@@ -402,6 +408,8 @@ struct v4l2_ioctl_ops {
 				      struct v4l2_format *f);
 	int (*vidioc_try_fmt_meta_cap)(struct file *file, void *fh,
 				       struct v4l2_format *f);
+	int (*vidioc_try_fmt_meta_out)(struct file *file, void *fh,
+				       struct v4l2_format *f);
 
 	/* Buffer handlers */
 	int (*vidioc_reqbufs)(struct file *file, void *fh,
diff --git a/include/soc/mediatek/emi.h b/include/soc/mediatek/emi.h
new file mode 100644
index 000000000000..83bdaeb6840b
--- /dev/null
+++ b/include/soc/mediatek/emi.h
@@ -0,0 +1,116 @@
+/* SPDX-License-Identifier: GPL-2.0  */
+/*
+ * Copyright (c) 2015-2016 MediaTek Inc.
+ * Author: Xi Chen <xixi.chen@mediatek.com>
+ */
+
+#ifndef _MTK_EMI_H_
+#define _MTK_EMI_H_
+
+#define MAX_CH		2
+#define MAX_RK		2
+
+struct emi_info_t {
+	unsigned int dram_type;
+	unsigned int ch_num;
+	unsigned int rk_num;
+	unsigned int rank_size[MAX_RK];
+};
+
+/*****************************************************************************
+ *  Macro Definiations
+ *****************************************************************************/
+#define EMI_REG_BASE                (0x10219000)
+#define EMI_REG_BASE_MAPPED         (emi->cen_emi_base)
+
+#define EMI_MDCT                    (EMI_REG_BASE_MAPPED + 0x078)
+#define EMI_MDCT_2ND                (EMI_REG_BASE_MAPPED + 0x07C)
+
+#define EMI_ARBA                    (EMI_REG_BASE_MAPPED + 0x100)
+#define EMI_ARBB                    (EMI_REG_BASE_MAPPED + 0x108)
+#define EMI_ARBC                    (EMI_REG_BASE_MAPPED + 0x110)
+#define EMI_ARBD                    (EMI_REG_BASE_MAPPED + 0x118)
+#define EMI_ARBE                    (EMI_REG_BASE_MAPPED + 0x120)
+#define EMI_ARBF                    (EMI_REG_BASE_MAPPED + 0x128)
+#define EMI_ARBG                    (EMI_REG_BASE_MAPPED + 0x130)
+#define EMI_ARBH                    (EMI_REG_BASE_MAPPED + 0x138)
+
+#define EMI_BMEN                    (EMI_REG_BASE_MAPPED + 0x400)
+#define EMI_BCNT                    (EMI_REG_BASE_MAPPED + 0x408)
+#define EMI_TACT                    (EMI_REG_BASE_MAPPED + 0x410)
+#define EMI_TSCT                    (EMI_REG_BASE_MAPPED + 0x418)
+#define EMI_WACT                    (EMI_REG_BASE_MAPPED + 0x420)
+#define EMI_WSCT                    (EMI_REG_BASE_MAPPED + 0x428)
+#define EMI_BACT                    (EMI_REG_BASE_MAPPED + 0x430)
+#define EMI_BSCT                    (EMI_REG_BASE_MAPPED + 0x438)
+#define EMI_MSEL                    (EMI_REG_BASE_MAPPED + 0x440)
+#define EMI_TSCT2                   (EMI_REG_BASE_MAPPED + 0x448)
+#define EMI_TSCT3                   (EMI_REG_BASE_MAPPED + 0x450)
+#define EMI_WSCT2                   (EMI_REG_BASE_MAPPED + 0x458)
+#define EMI_WSCT3                   (EMI_REG_BASE_MAPPED + 0x460)
+#define EMI_WSCT4                   (EMI_REG_BASE_MAPPED + 0x464)
+#define EMI_MSEL2                   (EMI_REG_BASE_MAPPED + 0x468)
+
+#define EMI_BMEN2                   (EMI_REG_BASE_MAPPED + 0x4E8)
+
+#define EMI_BMRW0                   (EMI_REG_BASE_MAPPED + 0x4F8)
+
+#define EMI_TTYPE1                  (EMI_REG_BASE_MAPPED + 0x500)
+#define EMI_TTYPE17                 (EMI_REG_BASE_MAPPED + 0x580)
+
+#define EMI_BWVL                    (EMI_REG_BASE_MAPPED + 0x7D0)
+#define EMI_BWVL_2ND                (EMI_REG_BASE_MAPPED + 0x7D4)
+#define EMI_BWVL_3RD                (EMI_REG_BASE_MAPPED + 0x7D8)
+#define EMI_BWVL_4TH                (EMI_REG_BASE_MAPPED + 0x7DC)
+#define EMI_BWVL_5TH                (EMI_REG_BASE_MAPPED + 0x7E0)
+
+#define EMI_CH0_REG_BASE            (0x1022D000)
+#define EMI_CH0_REG_BASE_MAPPED     (emi->chn_emi_base[0])
+#define EMI_CH0_DRS_ST2             (EMI_CH0_REG_BASE_MAPPED + 0x17C)
+#define EMI_CH0_DRS_ST3             (EMI_CH0_REG_BASE_MAPPED + 0x180)
+#define EMI_CH0_DRS_ST4             (EMI_CH0_REG_BASE_MAPPED + 0x184)
+
+#define EMI_CH1_REG_BASE            (0x10235000)
+#define EMI_CH1_REG_BASE_MAPPED     (emi->chn_emi_base[1])
+#define EMI_CH1_DRS_ST2             (EMI_CH1_REG_BASE_MAPPED + 0x17C)
+#define EMI_CH1_DRS_ST3             (EMI_CH1_REG_BASE_MAPPED + 0x180)
+#define EMI_CH1_DRS_ST4             (EMI_CH1_REG_BASE_MAPPED + 0x184)
+
+/*
+ * DEFAULT_VALUE
+ */
+#define EMI_BMEN_DEFAULT_VALUE    (0x00FF0000)
+#define EMI_BMEN2_DEFAULT_VALUE   (0x02000000)
+#define EMI_BMRW0_DEFAULT_VALUE   (0xFFFFFFFF)
+#define EMI_MSEL_DEFAULT_VALUE    (0x00030024)
+#define EMI_MSEL2_DEFAULT_VALUE   (0x000000C0)
+#define BC_OVERRUN                (0x00000100)
+
+/* EMI_BMEN */
+#define BUS_MON_EN          BIT(0)
+#define BUS_MON_PAUSE       BIT(1)
+#define BUS_MON_IDLE        BIT(3)
+
+#define MAX_DRAM_CH_NUM     (2)
+#define DRAM_RANK_NUM       (2)
+#define DRAM_PDIR_NUM       (8)
+#define EMI_TTYPE_NUM       (21)
+#define EMI_TSCT_NUM        (3)
+#define EMI_MDCT_NUM        (2)
+#define EMI_DRS_ST_NUM      (3)
+#define EMI_BW_LIMIT_NUM    (8)
+
+#define DRAMC_CG_SHIFT      (9)
+
+#define EMI_IDX_SIZE        (1024)
+
+#define EMI_BWVL_UNIT       (271)
+
+#define MBW_BUF_LEN         (0x800000)
+#define DATA_CNT_PER_BLK    (35)
+#define BLK_CNT_PER_BUF     (0x800)
+
+/* public apis */
+unsigned long long emi_get_max_bw(void);
+
+#endif
diff --git a/include/uapi/linux/v4l2-controls.h b/include/uapi/linux/v4l2-controls.h
index e4ee10ee917d..c561ac7fdbe3 100644
--- a/include/uapi/linux/v4l2-controls.h
+++ b/include/uapi/linux/v4l2-controls.h
@@ -190,6 +190,10 @@ enum v4l2_colorfx {
  * We reserve 16 controls for this driver. */
 #define V4L2_CID_USER_IMX_BASE			(V4L2_CID_USER_BASE + 0x10b0)
 
+/* The base for the mediatek ISP Pass 1 driver controls */
+/* We reserve 16 controls for this driver. */
+#define V4L2_CID_USER_MTK_CAM_BASE		(V4L2_CID_USER_BASE + 0x10c0)
+
 /* MPEG-class control IDs */
 /* The MPEG controls are applicable to all codec controls
  * and the 'MPEG' part of the define is historical */
diff --git a/include/uapi/linux/videodev2.h b/include/uapi/linux/videodev2.h
index fb0b74b698d0..a58a503ce5c3 100644
--- a/include/uapi/linux/videodev2.h
+++ b/include/uapi/linux/videodev2.h
@@ -145,6 +145,7 @@ enum v4l2_buf_type {
 	V4L2_BUF_TYPE_SDR_CAPTURE          = 11,
 	V4L2_BUF_TYPE_SDR_OUTPUT           = 12,
 	V4L2_BUF_TYPE_META_CAPTURE         = 13,
+	V4L2_BUF_TYPE_META_OUTPUT	   = 14,
 	/* Deprecated, do not use */
 	V4L2_BUF_TYPE_PRIVATE              = 0x80,
 };
@@ -469,7 +470,7 @@ struct v4l2_capability {
 #define V4L2_CAP_READWRITE              0x01000000  /* read/write systemcalls */
 #define V4L2_CAP_ASYNCIO                0x02000000  /* async I/O */
 #define V4L2_CAP_STREAMING              0x04000000  /* streaming I/O ioctls */
-
+#define V4L2_CAP_META_OUTPUT		0x08000000  /* Is a metadata output device */
 #define V4L2_CAP_TOUCH                  0x10000000  /* Is a touch device */
 
 #define V4L2_CAP_DEVICE_CAPS            0x80000000  /* sets device capabilities field */
@@ -694,6 +695,20 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_IPU3_SGRBG10	v4l2_fourcc('i', 'p', '3', 'G') /* IPU3 packed 10-bit GRBG bayer */
 #define V4L2_PIX_FMT_IPU3_SRGGB10	v4l2_fourcc('i', 'p', '3', 'r') /* IPU3 packed 10-bit RGGB bayer */
 
+/* Vendor specific - Mediatek ISP compressed formats */
+#define V4L2_PIX_FMT_MTISP_U8	v4l2_fourcc('M', 'T', 'U', '8') /* Unpacked bayer format, 16-bit */
+#define V4L2_PIX_FMT_MTISP_U10  v4l2_fourcc('M', 'T', 'U', 'A') /* Unpacked bayer format, 16-bit */
+#define V4L2_PIX_FMT_MTISP_U12  v4l2_fourcc('M', 'T', 'U', 'C') /* Unpacked bayer format, 16-bit */
+#define V4L2_PIX_FMT_MTISP_U14  v4l2_fourcc('M', 'T', 'U', 'E') /* Unpacked bayer format, 16-bit */
+#define V4L2_PIX_FMT_MTISP_B8	v4l2_fourcc('M', 'T', 'B', '8') /* Packed   bayer format,  8-bit */
+#define V4L2_PIX_FMT_MTISP_B10  v4l2_fourcc('M', 'T', 'B', 'A') /* Packed   bayer format, 10-bit */
+#define V4L2_PIX_FMT_MTISP_B12  v4l2_fourcc('M', 'T', 'B', 'C') /* Packed   bayer format, 12-bit */
+#define V4L2_PIX_FMT_MTISP_B14  v4l2_fourcc('M', 'T', 'B', 'E') /* Packed   bayer format, 14-bit */
+#define V4L2_PIX_FMT_MTISP_F8	v4l2_fourcc('M', 'T', 'F', '8') /* Full-G   bayer format,  8-bit */
+#define V4L2_PIX_FMT_MTISP_F10  v4l2_fourcc('M', 'T', 'F', 'A') /* Full-G   bayer format, 10-bit */
+#define V4L2_PIX_FMT_MTISP_F12  v4l2_fourcc('M', 'T', 'F', 'C') /* Full-G   bayer format, 12-bit */
+#define V4L2_PIX_FMT_MTISP_F14  v4l2_fourcc('M', 'T', 'F', 'E') /* Full-G   bayer format, 14-bit */
+
 /* SDR formats - used only for Software Defined Radio devices */
 #define V4L2_SDR_FMT_CU8          v4l2_fourcc('C', 'U', '0', '8') /* IQ u8 */
 #define V4L2_SDR_FMT_CU16LE       v4l2_fourcc('C', 'U', '1', '6') /* IQ u16le */
@@ -715,6 +730,13 @@ struct v4l2_pix_format {
 #define V4L2_META_FMT_VSP1_HGT    v4l2_fourcc('V', 'S', 'P', 'T') /* R-Car VSP1 2-D Histogram */
 #define V4L2_META_FMT_UVC         v4l2_fourcc('U', 'V', 'C', 'H') /* UVC Payload Header metadata */
 
+/* Vendor specific - Mediatek ISP parameters for firmware */
+#define V4L2_META_FMT_MTISP_PARAMS v4l2_fourcc('M', 'T', 'f', 'p') /* ISP tuning parameters */
+#define V4L2_META_FMT_MTISP_3A	   v4l2_fourcc('M', 'T', 'f', 'a') /* AE/AWB histogram */
+#define V4L2_META_FMT_MTISP_AF	   v4l2_fourcc('M', 'T', 'f', 'f') /* AF histogram */
+#define V4L2_META_FMT_MTISP_LCS	   v4l2_fourcc('M', 'T', 'f', 'c') /* Local contrast enhanced statistics */
+#define V4L2_META_FMT_MTISP_LMV	   v4l2_fourcc('M', 'T', 'f', 'm') /* Local motion vector histogram */
+
 /* priv field value to indicates that subsequent fields are valid. */
 #define V4L2_PIX_FMT_PRIV_MAGIC		0xfeedcafe
 
-- 
2.21.0.1020.gf2820cf01a-goog

